{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.rc_context at 0x201bf30b908>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random as rnd\n",
    "import warnings,datetime,os,calendar,csv,time\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Dense,LSTM,Conv2D,Dropout,BatchNormalization,Input,Concatenate,Add,Activation,MaxPooling2D,AveragePooling2D\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "from sklearn.cluster import KMeans,MeanShift\n",
    "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge,Lasso,LinearRegression,SGDClassifier,SGDRegressor\n",
    "from sklearn.mixture import BayesianGaussianMixture,GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor,RadiusNeighborsClassifier,RadiusNeighborsRegressor,NearestNeighbors\n",
    "from sklearn.manifold import Isomap,TSNE\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,train_test_split\n",
    "from sklearn.svm import LinearSVC,LinearSVR\n",
    "from sklearn.neural_network import BernoulliRBM,MLPClassifier,MLPRegressor\n",
    "from sklearn.decomposition import FactorAnalysis,KernelPCA,PCA,MiniBatchSparsePCA,FastICA\n",
    "from sklearn.preprocessing import CategoricalEncoder,KBinsDiscretizer,LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "\n",
    "import gym\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "\n",
    "import pickle,h5py,json\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import iexfinance as iex\n",
    "from iexfinance.stocks import get_historical_data\n",
    "from scipy.signal import resample,correlate\n",
    "from scipy import fftpack\n",
    "from lmfit import Model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()\n",
    "plt.xkcd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def make_dateaxis(start_date,end_date):\n",
    "    datelist = []\n",
    "    d = start_date\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    while d <= end_date:\n",
    "        if (d.weekday()==5 or d.weekday()==6):\n",
    "            d += delta\n",
    "            continue\n",
    "        datelist.append(d)\n",
    "        d += delta\n",
    "    datelist = np.stack(datelist,axis=0)\n",
    "    return datelist\n",
    "\n",
    "def unpack_index(DF,datelist,idx,fname,verbose=False):\n",
    "    index_flist = []\n",
    "    first_datapoint_found = False\n",
    "    for d in list(datelist):\n",
    "        try:\n",
    "            index_f = DF[idx][fname].loc[d.strftime('%Y-%m-%d')]\n",
    "        except:\n",
    "            index_f = 0\n",
    "        if index_f==0 and first_datapoint_found:\n",
    "            index_f = np.nan\n",
    "        if index_f!=0 and not first_datapoint_found:\n",
    "            first_datapoint_found = True\n",
    "        if verbose: print('Date %s: Open Value %.3f'%(d.strftime('%Y-%m-%d'),index_f))\n",
    "        index_flist.append(index_f)\n",
    "    index_flist = np.stack(index_flist,axis=0)\n",
    "    nans,x = nan_helper(index_flist)\n",
    "    index_flist[nans]= np.interp(x(nans),x(~nans),index_flist[~nans])\n",
    "    return index_flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime(2015,1,1)\n",
    "end_date = datetime.datetime(2017,1,1)\n",
    "\n",
    "with open('Documents\\stock_symb.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "content = [line.strip() for line in lines]\n",
    "tickers = [content[i] for i in list(np.random.permutation(np.arange(len(content))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/50\n",
      "Processing 1/50\n",
      "Processing 2/50\n",
      "Processing 3/50\n",
      "Processing 4/50\n",
      "Processing 5/50\n",
      "Processing 6/50\n",
      "Processing 7/50\n",
      "Processing 8/50\n",
      "Processing 9/50\n",
      "Processing 10/50\n",
      "Processing 11/50\n",
      "Processing 12/50\n",
      "Processing 13/50\n",
      "Processing 14/50\n",
      "Processing 15/50\n",
      "Processing 16/50\n",
      "Processing 17/50\n",
      "Processing 18/50\n",
      "Processing 19/50\n",
      "Processing 20/50\n",
      "Processing 21/50\n",
      "Processing 22/50\n",
      "Processing 23/50\n",
      "Processing 24/50\n",
      "Processing 25/50\n",
      "Processing 26/50\n",
      "Processing 27/50\n",
      "Processing 28/50\n",
      "Processing 29/50\n",
      "Processing 30/50\n",
      "Processing 31/50\n",
      "Processing 32/50\n",
      "Processing 33/50\n",
      "Processing 34/50\n",
      "Processing 35/50\n",
      "Processing 36/50\n",
      "Processing 37/50\n",
      "Processing 38/50\n",
      "Processing 39/50\n",
      "Processing 40/50\n",
      "Processing 41/50\n",
      "Processing 42/50\n",
      "Processing 43/50\n",
      "Processing 44/50\n",
      "Processing 45/50\n",
      "Processing 46/50\n",
      "Processing 47/50\n",
      "Processing 48/50\n",
      "Processing 49/50\n"
     ]
    }
   ],
   "source": [
    "ticker_set = tickers[:50]\n",
    "datesequ = get_historical_data(ticker_set[0],start=start_date,end=end_date,output_format='pandas').index\n",
    "\n",
    "DATA = []\n",
    "DF = []\n",
    "\n",
    "ctr = 0\n",
    "for ticker in ticker_set:\n",
    "\n",
    "    print('Processing %d/%d'%(ctr,len(ticker_set)))\n",
    "    ctr += 1\n",
    "    try:\n",
    "        df = get_historical_data(ticker,start=start_date,end=end_date,output_format='pandas')\n",
    "    except:\n",
    "        continue\n",
    "    if df.shape[0]!=len(datesequ): continue\n",
    "    \n",
    "    open_price = df['open'].values.reshape(1,-1)\n",
    "    high_price = df['high'].values.reshape(1,-1)\n",
    "    low_price = df['low'].values.reshape(1,-1)\n",
    "    close_price = df['close'].values.reshape(1,-1)\n",
    "    volume = df['volume'].values.reshape(1,-1)\n",
    "    \n",
    "    if open_price.shape[1]==0: continue\n",
    "    if high_price.shape[1]==0: continue\n",
    "    if low_price.shape[1]==0: continue\n",
    "    if close_price.shape[1]==0: continue\n",
    "    if volume.shape[1]==0: continue\n",
    "    if any([math.isnan(float(k)) for k in list(open_price[0])]): continue\n",
    "    if any([math.isnan(float(k)) for k in list(high_price[0])]): continue\n",
    "    if any([math.isnan(float(k)) for k in list(low_price[0])]): continue\n",
    "    if any([math.isnan(float(k)) for k in list(close_price[0])]): continue\n",
    "    if any([math.isnan(float(k)) for k in list(volume[0])]): continue\n",
    "    \n",
    "    DF.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateaxis = make_dateaxis(start_date=start_date,end_date=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKET_OPEN = []\n",
    "MARKET_CLOSE = []\n",
    "MARKET_HIGH = []\n",
    "MARKET_LOW = []\n",
    "VOLUME = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "    MARKET_OPEN.append(unpack_index(DF,datelist=dateaxis,idx=22,fname='open'))\n",
    "    MARKET_CLOSE.append(unpack_index(DF,datelist=dateaxis,idx=22,fname='close'))\n",
    "    MARKET_HIGH.append(unpack_index(DF,datelist=dateaxis,idx=22,fname='high'))\n",
    "    MARKET_LOW.append(unpack_index(DF,datelist=dateaxis,idx=22,fname='low'))\n",
    "    VOLUME.append(unpack_index(DF,datelist=dateaxis,idx=22,fname='volume'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOPEN = np.stack(MARKET_OPEN,axis=0) \n",
    "MCLOSE = np.stack(MARKET_CLOSE,axis=0)\n",
    "MHIGH = np.stack(MARKET_HIGH,axis=0)\n",
    "MLOW = np.stack(MARKET_LOW,axis=0)\n",
    "VOL = np.stack(VOLUME,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_owned_volume_pctg = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUDGET = 28000\n",
    "PORTOFOLIO = np.zeros(shape=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dd in range(dateaxis.shape[0]):\n",
    "    \n",
    "    for idx in range(5):\n",
    "        \n",
    "        upvol = round(max_owned_volume_pctg*VOL[idx,dd])-PORTOFOLIO[idx]\n",
    "        upmoney = np.floor(BUDGET/MOPEN[idx,dd])\n",
    "        \n",
    "        max_purch = min(upvol,upmoney)\n",
    "        max_sell = PORTOFOLIO[idx]\n",
    "        \n",
    "        purch = int(rnd.rand()*max_purch)\n",
    "        sell = int(rnd.rand()*max_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7124319779745806"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
