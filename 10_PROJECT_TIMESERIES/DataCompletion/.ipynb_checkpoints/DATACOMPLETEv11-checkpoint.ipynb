{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.rc_context at 0x1732473d8d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random as rnd\n",
    "import warnings,datetime,os,calendar,csv,time\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Dense,LSTM,Conv2D,Dropout,BatchNormalization,Input,Concatenate,Add,Activation,MaxPooling2D,AveragePooling2D,Flatten\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "from sklearn.cluster import KMeans,MeanShift\n",
    "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge,Lasso,LinearRegression,SGDClassifier,SGDRegressor\n",
    "from sklearn.mixture import BayesianGaussianMixture,GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor,RadiusNeighborsClassifier,RadiusNeighborsRegressor,NearestNeighbors\n",
    "from sklearn.manifold import Isomap,TSNE\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,train_test_split\n",
    "from sklearn.svm import LinearSVC,LinearSVR\n",
    "from sklearn.neural_network import BernoulliRBM,MLPClassifier,MLPRegressor\n",
    "from sklearn.decomposition import FactorAnalysis,KernelPCA,PCA,MiniBatchSparsePCA,FastICA\n",
    "from sklearn.preprocessing import CategoricalEncoder,KBinsDiscretizer,LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "\n",
    "import pickle,h5py,json\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import iexfinance as iex\n",
    "from iexfinance.stocks import get_historical_data\n",
    "from scipy.signal import resample,correlate\n",
    "from scipy import fftpack\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()\n",
    "plt.xkcd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime(2015,1,1)\n",
    "end_date = datetime.datetime(2017,1,1)\n",
    "\n",
    "with open('Documents\\stock_symb.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "content = [line.strip() for line in lines]\n",
    "tickers = [content[i] for i in list(np.random.permutation(np.arange(len(content))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/50\n",
      "Processing 10/50\n",
      "Processing 20/50\n",
      "Processing 30/50\n",
      "Processing 40/50\n"
     ]
    }
   ],
   "source": [
    "ticker_set = tickers[:50]\n",
    "print_progress = 10\n",
    "\n",
    "DATA = []\n",
    "\n",
    "ctr = 0\n",
    "for ticker in ticker_set:\n",
    "\n",
    "    if ctr%print_progress==0: print('Processing %d/%d'%(ctr,len(ticker_set)))\n",
    "    ctr += 1\n",
    "    try:\n",
    "        df = get_historical_data(ticker,start=start_date,end=end_date,output_format='pandas')\n",
    "    except:\n",
    "        continue\n",
    "    data = df['open'].values\n",
    "    DATA.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First project: Fill in NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = [len(data) for data in DATA]\n",
    "most_common_length = max(set(datalen),key=datalen.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = [data for data in DATA if np.sum(np.isnan(data))==0 and len(data)==most_common_length]\n",
    "xuse = [data for data in DATA if np.sum(np.isnan(data))!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 50\n",
    "\n",
    "S = []\n",
    "for x in xtrain:\n",
    "    for k in range(len(x)-lookback):\n",
    "        S.append(x[k:k+lookback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_nans = 0.2\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for s in S:\n",
    "    num_nans = round(perc_nans*len(s))\n",
    "    nan_indices = rnd.permutation(np.arange(0,len(s)))[:num_nans]\n",
    "    ss = s.copy()\n",
    "    ss[nan_indices]=-1\n",
    "    X.append(ss)\n",
    "    Y.append(s)\n",
    "X = np.stack(X,axis=0)\n",
    "Y = np.stack(Y,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,Y,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.5246, 47.534 , 48.2714, 48.5645, -1.    , 49.364 , 48.1669,\n",
       "       46.866 , 47.5399, -1.    , 49.535 , -1.    , 49.402 , 48.2334,\n",
       "       49.3925, 49.573 , 50.3045, 50.732 , 50.7415, 51.1311, 51.2165,\n",
       "       51.0361, 51.3211, 51.2736, 51.3251, 51.3211, 51.2054, 51.3306,\n",
       "       -1.    , 51.7514, 51.8417, -1.    , -1.    , -1.    , 51.8341,\n",
       "       52.1571, 52.7081, 53.0121, 53.4872, 53.5561, 53.6637, 54.1522,\n",
       "       54.1712, 53.6772, -1.    , 53.7817, -1.    , 53.6962, 53.5917,\n",
       "       -1.    ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.5246, 47.534 , 48.2714, 48.5645, 48.8225, 49.364 , 48.1669,\n",
       "       46.866 , 47.5399, 48.6325, 49.535 , 50.1335, 49.402 , 48.2334,\n",
       "       49.3925, 49.573 , 50.3045, 50.732 , 50.7415, 51.1311, 51.2165,\n",
       "       51.0361, 51.3211, 51.2736, 51.3251, 51.3211, 51.2054, 51.3306,\n",
       "       51.6821, 51.7514, 51.8417, 52.0431, 52.0431, 51.4826, 51.8341,\n",
       "       52.1571, 52.7081, 53.0121, 53.4872, 53.5561, 53.6637, 54.1522,\n",
       "       54.1712, 53.6772, 53.9812, 53.7817, 53.7342, 53.6962, 53.5917,\n",
       "       53.3447])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_in = Input(shape=(Xtrain.shape[1],1,))\n",
    "encoder = LSTM(units=15,activation=tf.keras.activations.relu,return_state=True)\n",
    "[enc_out,states_h,states_c] = encoder(enc_in)\n",
    "states = [states_h,states_c]\n",
    "\n",
    "dec_in = Input(shape=(Xtrain.shape[1],1,))\n",
    "decoder = LSTM(units=15,activation=tf.keras.activations.relu,return_state=True,return_sequences=True)\n",
    "dec_out,_,_ = decoder(dec_in,initial_state=states)\n",
    "dec_dense = Dense(units=Ytrain.shape[1],activation=tf.nn.softmax)\n",
    "decdense_out = dec_dense(dec_out)\n",
    "\n",
    "model = Model([enc_in,dec_in],decdense_out)\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
