{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.rc_context at 0x15e8fbd8400>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random as rnd\n",
    "import warnings,datetime,os,calendar,csv,time\n",
    "import pickle,h5py,json\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Dense,LSTM,Conv2D,Dropout,BatchNormalization,Input,Concatenate,Add,Activation,MaxPooling2D,AveragePooling2D\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "from sklearn.cluster import KMeans,MeanShift\n",
    "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge,Lasso,LinearRegression,SGDClassifier,SGDRegressor\n",
    "from sklearn.mixture import BayesianGaussianMixture,GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor,RadiusNeighborsClassifier,RadiusNeighborsRegressor,NearestNeighbors\n",
    "from sklearn.manifold import Isomap,TSNE\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,train_test_split\n",
    "from sklearn.svm import LinearSVC,LinearSVR\n",
    "from sklearn.neural_network import BernoulliRBM,MLPClassifier,MLPRegressor\n",
    "from sklearn.decomposition import FactorAnalysis,KernelPCA,PCA,MiniBatchSparsePCA,FastICA\n",
    "from sklearn.preprocessing import CategoricalEncoder,KBinsDiscretizer,LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler\n",
    "\n",
    "from scipy import fftpack\n",
    "from scipy.signal import resample,correlate\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "\n",
    "import gym\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import networkx as nx\n",
    "from lmfit import Model\n",
    "\n",
    "import iexfinance as iex\n",
    "from iexfinance.stocks import get_historical_data\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()\n",
    "plt.xkcd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_set(num_samples,BINMAX=8,NOISE_STD=0.1):\n",
    "    \n",
    "    MAXLEN = len(bin(BINMAX)[2:])-1\n",
    "\n",
    "    p_list = [bin(k)[2:].rjust(MAXLEN,'0') for k in range(BINMAX)]\n",
    "    symbols = np.array([[int(k) for k in l] for l in p_list])\n",
    "    \n",
    "    y = rnd.choice(BINMAX,p=np.ones(symbols.shape[0])/symbols.shape[0],size=[num_samples])\n",
    "    X = np.array([symbols[k] for k in y])\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel():\n",
    "    \n",
    "    def __init__(self,channel_in_size,channel_out_size,MU_R=-1,SIGMA_R=0.1,MU_H=8,SIGMA_H=0.5,SWAP_PROB_SIGMA=0.1):\n",
    "        \n",
    "        self.channel_in_size = channel_in_size\n",
    "        self.channel_out_size = channel_out_size\n",
    "        \n",
    "        self.MU_R = MU_R\n",
    "        self.SIGMA_R = SIGMA_R\n",
    "        \n",
    "        self.MU_H = MU_H\n",
    "        self.SIGMA_H = SIGMA_H\n",
    "        self.SWAP_PROB_SIGMA = SWAP_PROB_SIGMA\n",
    "        \n",
    "        self.H = self.SIGMA_H*rnd.randn(self.channel_out_size,self.channel_in_size) + self.MU_H\n",
    "        \n",
    "        p_swap_c = rnd.rand(self.channel_out_size,self.channel_out_size)\n",
    "        self.p_swap = self.SWAP_PROB_SIGMA*(np.triu(p_swap_c,1)+np.triu(p_swap_c,1).transpose())\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def transfer(self,channel_in):\n",
    "        \n",
    "        x_in = np.array([int(k) for l in bin(channel_in)[2:].rjust(self.channel_in_size,'0') for k in l])\n",
    "        \n",
    "        y_unnoisy = np.dot(self.H,x_in.reshape(-1,1))\n",
    "        y_noisy = y_unnoisy + (self.SIGMA_R*rnd.randn(self.channel_out_size) + self.MU_R).reshape(-1,1)\n",
    "        \n",
    "        for k0 in range(self.p_swap.shape[0]):\n",
    "            for k1 in range(self.p_swap.shape[1]):\n",
    "                if rnd.rand()<self.p_swap[k0,k1]: \n",
    "                    m0 = y_noisy[k0]\n",
    "                    m1 = y_noisy[k1]\n",
    "                    y_noisy[k0] = m1\n",
    "                    y_noisy[k1] = m0\n",
    "        \n",
    "        return x_in,y_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "mychannel = Channel(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1]), array([[7.28136505],\n",
       "        [7.42846644]]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mychannel.transfer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-203-a996662d8cfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMAXIN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -- 3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.619898  ],\n",
       "       [7.46546017],\n",
       "       [7.73989789],\n",
       "       [7.46546017],\n",
       "       [6.46397254]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_,y_ = generate_set(3000)\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_ohe = ohe.fit_transform(y_.reshape(-1,1)).todense()\n",
    "\n",
    "X0,X1,y0,y1 = train_test_split(X_,y_ohe,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'func'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-1958c89607ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mout0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['mse'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'func'"
     ]
    }
   ],
   "source": [
    "in0 = Input(shape=(2,))\n",
    "x0 = Dense(units=5,activation='relu')(in0) \n",
    "x1 = Dense(units=5,activation='relu')(x0) \n",
    "out0 = Dense(units=4,activation='softmax')(x1)\n",
    "\n",
    "model = Model(inputs=in0,outputs=out0)\n",
    "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_8:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input(shape=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
