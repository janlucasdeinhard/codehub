{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random as rnd\n",
    "import warnings,os,datetime,time\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,BatchNormalization,Dropout,LSTM,Concatenate,Activation,Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import spacy\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '..//..//..//TF_data//BLOGENTRIES//blogs//'\n",
    "\n",
    "files = os.listdir(basedir)[:250]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for c_file in files:\n",
    "    \n",
    "    try:\n",
    "        with open(basedir+c_file) as fp: soup = BeautifulSoup(fp, 'xml')\n",
    "    except:\n",
    "        continue\n",
    "    cells = soup.findAll(['date','post'])\n",
    "\n",
    "    data = []\n",
    "    for k in range(0,len(cells),2):\n",
    "        data.append([\n",
    "            str(cells[k]).replace('<date>','').replace('</date>','').replace(',','-'),\n",
    "            str(cells[k+1]).replace('<post>','').replace('</post>','').replace('\\n','').replace('\\t','').lstrip().rstrip()\n",
    "        ])\n",
    "    cf = pd.DataFrame(data).rename(columns={0:'Date Post',1:'Text Post'})\n",
    "    c_ID,c_Gender,c_Age,c_Topic,c_AstroSign = c_file.split('.')[:-1]\n",
    "\n",
    "    cf['ID Poster'] = c_ID\n",
    "    cf['Gender Poster'] = c_Gender\n",
    "    cf['Age Poster'] = c_Age\n",
    "    cf['Topic Channel'] = c_Topic\n",
    "    cf['Astro Sign Poster'] = c_AstroSign\n",
    "    \n",
    "    df = pd.concat([df,cf]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[['Text Post','ID Poster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0[df0['ID Poster'].isin(df0['ID Poster'].value_counts().sort_values(ascending=False).index[:4])]\n",
    "df0['Text Sentence'] = df0['Text Post'].apply(lambda x: [xxx for xx in sent_tokenize(x) for xxx in xx.split(',')])\n",
    "df0 = df0.drop(columns=['Text Post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.explode(column='Text Sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0[df0['Text Sentence'].apply(lambda x: type(x)==str)].reset_index(drop=True)\n",
    "df0['Text Sentence'] = df0['Text Sentence'].apply(lambda x: x.lower())\n",
    "df0['Length Sentence'] = df0['Text Sentence'].apply(lambda x: len(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0[df0['Length Sentence']>=20]\n",
    "df0 = df0.sample(frac=1).reset_index(drop=True)\n",
    "df0 = df0.drop(columns=['Length Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Poster</th>\n",
       "      <th>Text Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1093457</td>\n",
       "      <td>you are not allowed to have an opinion of bbc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1078410</td>\n",
       "      <td>--benjamin franklin     got this one for the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1093691</td>\n",
       "      <td>2 people to work 3 tills which we refuse to do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1093691</td>\n",
       "      <td>( you can tell she was glad to see us) i'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1093691</td>\n",
       "      <td>the most surprising thing was that she then pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>1093691</td>\n",
       "      <td>my business studies results are as follows... ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>106651</td>\n",
       "      <td>but i knew it was around me and hidden in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>1093691</td>\n",
       "      <td>so really i'm stressing about things that aren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>106651</td>\n",
       "      <td>i was annoyed i had to be 23 again but i was g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>1078410</td>\n",
       "      <td>1913--the system of privately-owned federal r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6357 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID Poster                                      Text Sentence\n",
       "0      1093457   you are not allowed to have an opinion of bbc...\n",
       "1      1078410  --benjamin franklin     got this one for the p...\n",
       "2      1093691  2 people to work 3 tills which we refuse to do...\n",
       "3      1093691  ( you can tell she was glad to see us) i'm rea...\n",
       "4      1093691  the most surprising thing was that she then pa...\n",
       "...        ...                                                ...\n",
       "6352   1093691  my business studies results are as follows... ...\n",
       "6353    106651   but i knew it was around me and hidden in the...\n",
       "6354   1093691  so really i'm stressing about things that aren...\n",
       "6355    106651  i was annoyed i had to be 23 again but i was g...\n",
       "6356   1078410   1913--the system of privately-owned federal r...\n",
       "\n",
       "[6357 rows x 2 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for k in df0.index:\n",
    "    c_doc = nlp(df0.loc[k,'Text Sentence'])\n",
    "\n",
    "    T = ''\n",
    "    D = ''\n",
    "    for c_sent in c_doc.sents:\n",
    "        for c_tok in c_sent:\n",
    "            if c_tok.dep_ in ['nsubj','ROOT','dobj']:\n",
    "                T += c_tok.text+'_'\n",
    "                D += c_tok.dep_+'_'\n",
    "\n",
    "    if D.find('nsubj_ROOT_dobj_')>=0:\n",
    "        R = T[D.find('nsubj_ROOT_dobj_'):].split('_')[:3]\n",
    "        \n",
    "    if R not in results and '' not in R:\n",
    "        results.append(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
