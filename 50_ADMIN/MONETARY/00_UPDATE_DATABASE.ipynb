{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import datetime,os\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import pyodbc\n",
    "import re\n",
    "from itertools import product\n",
    "\n",
    "# Identify matches in df and STR\n",
    "def find_matches(df,STR,THRESHOLD=0.01):\n",
    "    # Iterate over all possible pairs\n",
    "    l_duplicated = []\n",
    "    for k in product(df.index.tolist(),STR.index.tolist()):\n",
    "        # Single out corresponding data rows\n",
    "        x0 = df.iloc[k[0]].tolist()\n",
    "        x1 = STR.iloc[k[1]].tolist()\n",
    "        # Accumulate divergence\n",
    "        c_div = 0\n",
    "        for kk in range(len(x0)):\n",
    "            # Distinguish time stamps, strings and floats\n",
    "            if type(x0[kk]) is pd._libs.tslibs.timestamps.Timestamp:\n",
    "                c_div += np.abs((x0[kk]-x1[kk]).days)\n",
    "            elif type(x0[kk]) is str:\n",
    "                c_div += float((100-fuzz.ratio(x0[kk],x1[kk]))/100)\n",
    "            elif type(x0[kk]) is np.float64:\n",
    "                c_div += np.abs(float(x0[kk])-float(x1[kk]))\n",
    "            else:\n",
    "                raise Exception('Column name does not match expected format.')\n",
    "        # Compare to threshold\n",
    "        if c_div<THRESHOLD: l_duplicated.append(k)\n",
    "    # Build into a pandas data frame\n",
    "    matches = pd.DataFrame(l_duplicated).rename(columns={0:'DF index',1:'STR index'})\n",
    "    return matches\n",
    "\n",
    "# Read in new data\n",
    "def read_newdata(dirpath):\n",
    "    # Read new data\n",
    "    bf = pd.DataFrame()\n",
    "    for file in os.listdir(dirpath):\n",
    "        tf = pd.read_excel(dirpath+file)\n",
    "        if tf['Betrag'].dtype=='int64': tf['Betrag'] = tf['Betrag'].apply(lambda x: float(str(x)[:-2]+'.'+str(x)[-2:]))\n",
    "        bf = pd.concat([bf,tf],sort=False)\n",
    "    # Transform new data\n",
    "    bf['Buchungstag'] = pd.to_datetime(bf['Buchungstag'],format='%d.%m.%y')\n",
    "    bf['Valutadatum'] = pd.to_datetime(bf['Valutadatum'],format='%d.%m.%y')\n",
    "    # Clean string columns\n",
    "    for colname in ['Buchungstext','Verwendungszweck','Beguenstigter/Zahlungspflichtiger']:\n",
    "        bf[colname] = bf[colname].map(lambda x: re.sub(r'\\W+', ' ', str(x)))\n",
    "    # Key data and remove duplicates\n",
    "    bf['KEYID'] = bf[['Auftragskonto','Buchungstag','Buchungstext','Verwendungszweck','Kontonummer/IBAN','BIC (SWIFT-Code)','Betrag']].apply(lambda x: str(hash(''.join(str(x.values).replace('\\'','').replace('\\n','').replace('\\t','').replace(' ','')))),axis=1)\n",
    "    bf = bf[~bf['KEYID'].duplicated()].reset_index(drop=True)\n",
    "    \n",
    "    # Transform base data\n",
    "    df = bf[['Buchungstag','Valutadatum','Buchungstext','Verwendungszweck','Beguenstigter/Zahlungspflichtiger','Kontonummer/IBAN','Betrag','KEYID']].rename(columns={\n",
    "        'Valutadatum':'Date_ordered', \n",
    "        'Buchungstag':'Date_booked', \n",
    "        'Buchungstext':'Text_transaction', \n",
    "        'Verwendungszweck':'Use',\n",
    "        'Beguenstigter/Zahlungspflichtiger':'Contact', \n",
    "        'Kontonummer/IBAN':'AccNum', \n",
    "        'Betrag':'Value_transaction'\n",
    "    }).reset_index(drop=True)\n",
    "    # Transform added information\n",
    "    af = bf[['Auftragskonto','Glaeubiger ID','Mandatsreferenz','Kundenreferenz (End-to-End)','Sammlerreferenz','Lastschrift Ursprungsbetrag','Auslagenersatz Ruecklastschrift','BIC (SWIFT-Code)','Waehrung','Info','KEYID']].rename(columns={\n",
    "        'Auftragskonto':'OrderAccount', \n",
    "        'Glaeubiger ID':'LenderID', \n",
    "        'Mandatsreferenz':'MandateReference',\n",
    "        'Kundenreferenz (End-to-End)':'CustomerReference', \n",
    "        'Sammlerreferenz':'CollectorReference',\n",
    "        'Lastschrift Ursprungsbetrag':'Amount0', \n",
    "        'Auslagenersatz Ruecklastschrift':'Amount1',\n",
    "        'BIC (SWIFT-Code)':'BIC', \n",
    "        'Waehrung':'Currency', \n",
    "        'Info':'Information'\n",
    "    }).reset_index(drop=True)\n",
    "    return bf,df,af\n",
    "\n",
    "# Read in STR table\n",
    "def read_STR(dbpath):\n",
    "    # Connect to Access DB\n",
    "    conn = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ='+dbpath+';')\n",
    "    # Read Single Transactions table\n",
    "    STR = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT * FROM STR\n",
    "    '''\n",
    "    ,conn).reset_index(drop=True)\n",
    "    # Close connection\n",
    "    conn.close()\n",
    "    # Transform STR\n",
    "    STR['Date_booked'] = pd.to_datetime(STR['Date_booked'])\n",
    "    STR['Date_ordered'] = pd.to_datetime(STR['Date_ordered'])\n",
    "    STR['Value_transaction'] = STR['Value_transaction'].astype('float')\n",
    "    return STR\n",
    "\n",
    "# Read in TRI table\n",
    "def read_TRI(dbpath):\n",
    "    # Connect to Access DB\n",
    "    conn = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ='+dbpath+';')\n",
    "    # Read Transaction Information table\n",
    "    TRI = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT * FROM TRINFORMATION\n",
    "    '''\n",
    "    ,conn).reset_index(drop=True)\n",
    "    # Close connection\n",
    "    conn.close()\n",
    "    return TRI\n",
    "\n",
    "# Main function\n",
    "def __main__():    \n",
    "    # Path definitions\n",
    "    newdatapath = '..\\\\..\\\\..\\\\TF_data\\\\ADMIN\\\\01\\\\'\n",
    "    dbpath = '..\\\\..\\\\..\\\\..\\\\banking.accdb'\n",
    "    # Read new input\n",
    "    bf,df,af = read_newdata(newdatapath)\n",
    "    # Read existing databases\n",
    "    STR = read_STR(dbpath)\n",
    "    TRI = read_TRI(dbpath)\n",
    "    # Find duplicates\n",
    "    matches = find_matches(df,STR)\n",
    "    # Isolate new data entries\n",
    "    if matches.shape[0]==0:\n",
    "        new_data = df.copy()\n",
    "        new_added_information = af.copy()\n",
    "    else:\n",
    "        new_data = df.drop(index=matches['DF index'].tolist()).reset_index(drop=True)\n",
    "        new_added_information = af.drop(index=matches['DF index'].tolist()).reset_index(drop=True)\n",
    "    # Fill nulls with something that makes sense in a DB\n",
    "    new_data = new_data.fillna('nan')\n",
    "    new_added_information = new_added_information.fillna('nan')\n",
    "    # Establish DB connection\n",
    "    engine = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ='+dbpath+';')\n",
    "    # Write to STR\n",
    "    for t in new_data.iterrows():\n",
    "        cursor = engine.cursor()\n",
    "        sql_query = '''\n",
    "        INSERT INTO STR VALUES(\n",
    "        '''\n",
    "        sql_query = sql_query + str(t[1].tolist()).replace('[','').replace(']','').replace('Timestamp(','').replace(')','')\n",
    "        sql_query = sql_query.replace('\\n','') + ');'\n",
    "        cursor.execute(sql_query)\n",
    "        engine.commit()\n",
    "    # Close connection\n",
    "    engine.close()\n",
    "    # Establish DB connection\n",
    "    engine = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ='+dbpath+';')\n",
    "    # Write to TRINFORMATION\n",
    "    for t in new_added_information.iterrows():\n",
    "        cursor = engine.cursor()\n",
    "        sql_query = '''\n",
    "        INSERT INTO TRINFORMATION VALUES(\n",
    "        '''\n",
    "        sql_query = sql_query + str(t[1].tolist()).replace('[','').replace(']','').replace('Timestamp(','').replace(')','')\n",
    "        sql_query = sql_query.replace('\\n','') + ');'\n",
    "        cursor.execute(sql_query)\n",
    "        engine.commit()\n",
    "    # Close connection\n",
    "    engine.close()\n",
    "    # Return\n",
    "    return new_data,new_added_information\n",
    "\n",
    "# Call main\n",
    "new_entries_STR,new_entries_TRINFORMATION = __main__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
