{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.rc_context at 0x1e151a50be0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random as rnd\n",
    "import warnings,datetime,os,calendar,csv,time\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Dense,LSTM,Conv2D,Dropout,BatchNormalization,Input,Concatenate,Add,Activation,MaxPooling2D,AveragePooling2D\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "from sklearn.cluster import KMeans,MeanShift\n",
    "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge,Lasso,LinearRegression,SGDClassifier,SGDRegressor\n",
    "from sklearn.mixture import BayesianGaussianMixture,GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor,RadiusNeighborsClassifier,RadiusNeighborsRegressor,NearestNeighbors\n",
    "from sklearn.manifold import Isomap,TSNE\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,train_test_split\n",
    "from sklearn.svm import LinearSVC,LinearSVR\n",
    "from sklearn.neural_network import BernoulliRBM,MLPClassifier,MLPRegressor\n",
    "from sklearn.decomposition import FactorAnalysis,KernelPCA,PCA,MiniBatchSparsePCA,FastICA\n",
    "from sklearn.preprocessing import CategoricalEncoder,KBinsDiscretizer,LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "\n",
    "import gym\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "\n",
    "import pickle,h5py,json\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import iexfinance as iex\n",
    "from iexfinance.stocks import get_historical_data\n",
    "from scipy.signal import resample,correlate\n",
    "from scipy import fftpack\n",
    "from lmfit import Model as lmmodel\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()\n",
    "plt.xkcd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def make_dateaxis(start_date,end_date):\n",
    "    datelist = []\n",
    "    d = start_date\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    while d <= end_date:\n",
    "        if (d.weekday()==5 or d.weekday()==6):\n",
    "            d += delta\n",
    "            continue\n",
    "        datelist.append(d)\n",
    "        d += delta\n",
    "    datelist = np.stack(datelist,axis=0)\n",
    "    return datelist\n",
    "\n",
    "def unpack_index(DF,datelist,idx,fname,verbose=False):\n",
    "    index_flist = []\n",
    "    first_datapoint_found = False\n",
    "    for d in list(datelist):\n",
    "        try:\n",
    "            index_f = DF[idx][fname].loc[d.strftime('%Y-%m-%d')]\n",
    "        except:\n",
    "            index_f = 0\n",
    "        if index_f==0 and first_datapoint_found:\n",
    "            index_f = np.nan\n",
    "        if index_f!=0 and not first_datapoint_found:\n",
    "            first_datapoint_found = True\n",
    "        if verbose: print('Date %s: Open Value %.3f'%(d.strftime('%Y-%m-%d'),index_f))\n",
    "        index_flist.append(index_f)\n",
    "    index_flist = np.stack(index_flist,axis=0)\n",
    "    nans,x = nan_helper(index_flist)\n",
    "    index_flist[nans]= np.interp(x(nans),x(~nans),index_flist[~nans])\n",
    "    return index_flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime(2015,1,1)\n",
    "end_date = datetime.datetime(2017,1,1)\n",
    "\n",
    "with open('Documents\\stock_symb.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "content = [line.strip() for line in lines]\n",
    "tickers = [content[i] for i in list(np.random.permutation(np.arange(len(content))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/50\n",
      "Processing 10/50\n",
      "Processing 20/50\n",
      "Processing 30/50\n",
      "Processing 40/50\n"
     ]
    }
   ],
   "source": [
    "ticker_set = tickers[:50]\n",
    "\n",
    "DATA = []\n",
    "\n",
    "ctr = 0\n",
    "for ticker in ticker_set:\n",
    "\n",
    "    if ctr%10==0: print('Processing %d/%d'%(ctr,len(ticker_set)))\n",
    "    ctr += 1\n",
    "    try:\n",
    "        df = get_historical_data(ticker,start=start_date,end=end_date,output_format='pandas')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    data = df['open'].values\n",
    "    DATA.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 491, #nans = 33\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for data in DATA:\n",
    "    if len(data)!=504 or np.isnan(np.array(data)).sum()!=0:\n",
    "        del DATA[ctr]\n",
    "    ctr += 1\n",
    "for data in DATA:\n",
    "    print('Length = %d, #nans = %d'%(len(data),np.isnan(np.array(data)).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDATA = []\n",
    "for data in DATA:\n",
    "    DDATA.append(np.diff(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 100\n",
    "\n",
    "IN = []\n",
    "NEXT = []\n",
    "\n",
    "for data in DDATA:\n",
    "    \n",
    "    for k in range(lookback,data.shape[0]):\n",
    "        \n",
    "        IN.append(data[k-lookback:k])\n",
    "        NEXT.append(data[k])\n",
    "        \n",
    "D = np.stack(IN,axis=0)\n",
    "L = np.stack(NEXT,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = train_test_split(D,L,test_size=0.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "in0 = Input(shape=(lookback,1,))\n",
    "lstm0 = LSTM(units=15,activation='relu',return_sequences=False,return_state=False)\n",
    "dense0 = Dense(units=1,activation='sigmoid')\n",
    "\n",
    "x = lstm0(in0)\n",
    "out0 = dense0(x)\n",
    "\n",
    "model = Model(in0,out0)\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7214 samples, validate on 1804 samples\n",
      "Epoch 1/5\n",
      "7214/7214 [==============================] - 106s 15ms/step - loss: nan - acc: 1.3862e-04 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "7214/7214 [==============================] - 126s 17ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "7214/7214 [==============================] - 92s 13ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "7214/7214 [==============================] - 102s 14ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "7214/7214 [==============================] - 94s 13ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e15ec49128>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain.reshape(-1,lookback,1),ytrain,batch_size=5,epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
