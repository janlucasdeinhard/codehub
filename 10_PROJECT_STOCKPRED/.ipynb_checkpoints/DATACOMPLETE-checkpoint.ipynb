{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.rc_context at 0x1f6c911a9e8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random as rnd\n",
    "import warnings,datetime,os,calendar,csv,time\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Dense,LSTM,Conv2D,Dropout,BatchNormalization,Input,Concatenate,Add,Activation,MaxPooling2D,AveragePooling2D\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "from sklearn.cluster import KMeans,MeanShift\n",
    "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge,Lasso,LinearRegression,SGDClassifier,SGDRegressor\n",
    "from sklearn.mixture import BayesianGaussianMixture,GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor,RadiusNeighborsClassifier,RadiusNeighborsRegressor,NearestNeighbors\n",
    "from sklearn.manifold import Isomap,TSNE\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,train_test_split\n",
    "from sklearn.svm import LinearSVC,LinearSVR\n",
    "from sklearn.neural_network import BernoulliRBM,MLPClassifier,MLPRegressor\n",
    "from sklearn.decomposition import FactorAnalysis,KernelPCA,PCA,MiniBatchSparsePCA,FastICA\n",
    "from sklearn.preprocessing import CategoricalEncoder,KBinsDiscretizer,LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "\n",
    "import gym\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "\n",
    "import pickle,h5py,json\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import iexfinance as iex\n",
    "from iexfinance.stocks import get_historical_data\n",
    "from scipy.signal import resample,correlate\n",
    "from scipy import fftpack\n",
    "from lmfit import Model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()\n",
    "plt.xkcd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def make_dateaxis(start_date,end_date):\n",
    "    datelist = []\n",
    "    d = start_date\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    while d <= end_date:\n",
    "        if (d.weekday()==5 or d.weekday()==6):\n",
    "            d += delta\n",
    "            continue\n",
    "        datelist.append(d)\n",
    "        d += delta\n",
    "    datelist = np.stack(datelist,axis=0)\n",
    "    return datelist\n",
    "\n",
    "def unpack_index(DF,datelist,idx,fname,verbose=False):\n",
    "    index_flist = []\n",
    "    first_datapoint_found = False\n",
    "    for d in list(datelist):\n",
    "        try:\n",
    "            index_f = DF[idx][fname].loc[d.strftime('%Y-%m-%d')]\n",
    "        except:\n",
    "            index_f = 0\n",
    "        if index_f==0 and first_datapoint_found:\n",
    "            index_f = np.nan\n",
    "        if index_f!=0 and not first_datapoint_found:\n",
    "            first_datapoint_found = True\n",
    "        if verbose: print('Date %s: Open Value %.3f'%(d.strftime('%Y-%m-%d'),index_f))\n",
    "        index_flist.append(index_f)\n",
    "    index_flist = np.stack(index_flist,axis=0)\n",
    "    nans,x = nan_helper(index_flist)\n",
    "    index_flist[nans]= np.interp(x(nans),x(~nans),index_flist[~nans])\n",
    "    return index_flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime(2015,1,1)\n",
    "end_date = datetime.datetime(2017,1,1)\n",
    "\n",
    "with open('Documents\\stock_symb.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "content = [line.strip() for line in lines]\n",
    "tickers = [content[i] for i in list(np.random.permutation(np.arange(len(content))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/50\n",
      "Processing 10/50\n",
      "Processing 20/50\n",
      "Processing 30/50\n",
      "Processing 40/50\n"
     ]
    }
   ],
   "source": [
    "ticker_set = tickers[:50]\n",
    "\n",
    "DATA = []\n",
    "\n",
    "ctr = 0\n",
    "for ticker in ticker_set:\n",
    "\n",
    "    if ctr%10==0: print('Processing %d/%d'%(ctr,len(ticker_set)))\n",
    "    ctr += 1\n",
    "    try:\n",
    "        df = get_historical_data(ticker,start=start_date,end=end_date,output_format='pandas')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    data = df['open'].values\n",
    "    DATA.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 0, #nans = 0\n",
      "Length = 164, #nans = 106\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 494, #nans = 161\n",
      "Length = 0, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 457, #nans = 46\n",
      "Length = 504, #nans = 0\n",
      "Length = 495, #nans = 7\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 0, #nans = 0\n",
      "Length = 287, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 0, #nans = 0\n",
      "Length = 0, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 293, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 389, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n",
      "Length = 504, #nans = 0\n"
     ]
    }
   ],
   "source": [
    "for data in DATA:\n",
    "    print('Length = %d, #nans = %d'%(len(data),np.isnan(np.array(data)).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
