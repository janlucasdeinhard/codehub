{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "import os,datetime,warnings,time\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Dense,LSTM,Conv2D,Conv2DTranspose,Dropout,GRU,Activation,Add,Concatenate,BatchNormalization,Bidirectional,Embedding,Flatten\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..\\\\..\\\\TF_data\\\\TURING\\\\train.txt','r') as f:\n",
    "    raw = f.read()\n",
    "raw = raw.lower()\n",
    "raw = raw.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CHATBOT:\n",
    "    \n",
    "    def __init__(self,sentences):\n",
    "        self.sentences = sentences\n",
    "        #self.words = words\n",
    "        \n",
    "        self.lemmer = nltk.stem.WordNetLemmatizer()\n",
    "        self.remove_punct_dict = dict((ord(punct),None) for punct in string.punctuation)\n",
    "    \n",
    "    def created_message(self):\n",
    "        opening_statement = 'Chatbot has been set up and is running, please start a conversation!\\n'\n",
    "        print(opening_statement)\n",
    "        return\n",
    "    \n",
    "    def Preprocess(self,text):\n",
    "        return text.replace('\\n',' ').lower().translate(self.remove_punct_dict)\n",
    "\n",
    "    def LemNormalize(self,text):\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        result = [self.lemmer.lemmatize(token) for token in tokens]\n",
    "        return result\n",
    "    \n",
    "    def respond(self,user_input):\n",
    "        self.sentences.append(user_input)\n",
    "        \n",
    "        response = ''\n",
    "        \n",
    "        TfidfVec = TfidfVectorizer(preprocessor=self.Preprocess,tokenizer=self.LemNormalize,stop_words='english')\n",
    "        tfidf = TfidfVec.fit_transform(self.sentences)\n",
    "        \n",
    "        sims = cosine_similarity(tfidf[-1],tfidf)\n",
    "        idx = sims.argsort()[0][-2]\n",
    "        flat = sims.flatten()\n",
    "        flat.sort()\n",
    "        req_tfidf = flat[-2]\n",
    "        if req_tfidf==0:\n",
    "            response += 'I am sorry, I do not understand!'\n",
    "        else:\n",
    "            response += self.sentences[idx]\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot has been set up and is running, please start a conversation!\n",
      "\n",
      "Is this the real life?\n",
      "life!\n",
      "\n",
      "Are you a boy?\n",
      "leave this for boys and fools; but as for thee, do thou the substance of my matter see.\n",
      "\n",
      "What do you mean?\n",
      "then said christian, what means this?\n",
      "\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "robo = CHATBOT(sentences)\n",
    "robo.created_message()\n",
    "time.sleep(2)\n",
    "\n",
    "terminate_flag = False\n",
    "while not terminate_flag:\n",
    "    user_input = input()\n",
    "    if user_input=='exit':\n",
    "        terminate_flag = True\n",
    "        continue\n",
    "    robo_response = robo.respond(user_input)\n",
    "    print('%s\\n'%robo_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
