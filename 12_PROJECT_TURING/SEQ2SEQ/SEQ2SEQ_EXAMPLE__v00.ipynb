{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random as rnd\n",
    "import os,warnings,sys,itertools,datetime,time,timeit\n",
    "\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.functional as F\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import _pickle as pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../../../TF_Data/Dropbox/TF_data/SEQ2SEQ/de-en/'\n",
    "#root_path = '../../../../../../../TF_data/SEQ2SEQ/de-en/''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_path+'europarl-v7.de-en.en','r',encoding='utf-8') as file:\n",
    "    data_en = file.read()\n",
    "with open(root_path+'europarl-v7.de-en.de','r',encoding='utf-8') as file:\n",
    "    data_de = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0:'SOS',1:'EOS'}\n",
    "        self.word2count = {}\n",
    "        self.nwords = 2\n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.nwords\n",
    "            self.index2word[self.nwords] = word\n",
    "            self.word2count[word] = 1\n",
    "            self.nwords += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    def addSentence(self,sent):\n",
    "        for word in sent:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "    s = re.sub(r'([.!?])',r' \\1',s)\n",
    "    s = re.sub(r'[^a-zA-Z.!?]+', r' ',s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-71de56f5da26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/pairs.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0minput_lang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/input_lang.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0moutput_lang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/output_lang.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/pairs.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "LOAD_PREPARED_LANGUAGE_MODEL = True\n",
    "\n",
    "if not LOAD_PREPARED_LANGUAGE_MODEL:\n",
    "    df = pd.DataFrame(data_en.split('\\n'),data_de.split('\\n')).reset_index(drop=False).rename(columns={\n",
    "        'index':'DE',\n",
    "        0:'EN'\n",
    "    })\n",
    "    \n",
    "    input_lang = Lang('de')\n",
    "    output_lang = Lang('en')\n",
    "    \n",
    "    for r,cs in df.iterrows():\n",
    "        input_lang.addSentence(normalizeString(cs.DE))\n",
    "        output_lang.addSentence(normalizeString(cs.EN))\n",
    "    \n",
    "    pickle.dump(input_lang,open('./data/input_lang.pkl','wb'))\n",
    "    pickle.dump(output_lang,open('./data/output_lang.pkl','wb'))\n",
    "    df.to_pickle('./data/pairs.pkl')\n",
    "else:\n",
    "    input_lang = pickle.load(open('./data/input_lang.pkl','rb'))\n",
    "    output_lang = pickle.load(open('./data/output_lang.pkl','rb'))\n",
    "    df = pickle.load(open('./data/pairs.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(input_lang,op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
