{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 7\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))  \n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "\n",
    "W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\n",
    "\n",
    "inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
    "\n",
    "current_state = init_state\n",
    "states_series = []\n",
    "for current_input in inputs_series:\n",
    "    current_input = tf.reshape(current_input, [batch_size, 1])\n",
    "    input_and_state_concatenated = tf.concat([current_input, current_state],1)  \n",
    "\n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)  \n",
    "    states_series.append(next_state)\n",
    "    current_state = next_state\n",
    "\n",
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] \n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19a24e86eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New epoch 0\n",
      "Step  0 , loss =  0.750792\n",
      "Step  100 , loss =  0.668942\n",
      "Step  200 , loss =  0.692769\n",
      "Step  300 , loss =  0.702386\n",
      "Step  400 , loss =  0.68508\n",
      "Step  500 , loss =  0.70122\n",
      "Step  600 , loss =  0.6919\n",
      "New epoch 1\n",
      "Step  0 , loss =  0.668319\n",
      "Step  100 , loss =  0.687189\n",
      "Step  200 , loss =  0.692837\n",
      "Step  300 , loss =  0.697508\n",
      "Step  400 , loss =  0.699982\n",
      "Step  500 , loss =  0.693207\n",
      "Step  600 , loss =  0.674553\n",
      "New epoch 2\n",
      "Step  0 , loss =  0.684156\n",
      "Step  100 , loss =  0.713381\n",
      "Step  200 , loss =  0.691478\n",
      "Step  300 , loss =  0.688937\n",
      "Step  400 , loss =  0.700142\n",
      "Step  500 , loss =  0.703858\n",
      "Step  600 , loss =  0.683998\n",
      "New epoch 3\n",
      "Step  0 , loss =  0.699638\n",
      "Step  100 , loss =  0.690764\n",
      "Step  200 , loss =  0.698018\n",
      "Step  300 , loss =  0.692581\n",
      "Step  400 , loss =  0.697624\n",
      "Step  500 , loss =  0.693175\n",
      "Step  600 , loss =  0.693644\n",
      "New epoch 4\n",
      "Step  0 , loss =  0.694773\n",
      "Step  100 , loss =  0.689794\n",
      "Step  200 , loss =  0.707792\n",
      "Step  300 , loss =  0.685612\n",
      "Step  400 , loss =  0.692601\n",
      "Step  500 , loss =  0.551769\n",
      "Step  600 , loss =  0.138702\n",
      "New epoch 5\n",
      "Step  0 , loss =  0.245901\n",
      "Step  100 , loss =  0.065987\n",
      "Step  200 , loss =  0.0187406\n",
      "Step  300 , loss =  0.0194382\n",
      "Step  400 , loss =  0.0137573\n",
      "Step  500 , loss =  0.0135439\n",
      "Step  600 , loss =  0.0154209\n",
      "New epoch 6\n",
      "Step  0 , loss =  0.15081\n",
      "Step  100 , loss =  0.00643002\n",
      "Step  200 , loss =  0.00629\n",
      "Step  300 , loss =  0.00449985\n",
      "Step  400 , loss =  0.00595973\n",
      "Step  500 , loss =  0.00452142\n",
      "Step  600 , loss =  0.00345518\n",
      "New epoch 7\n",
      "Step  0 , loss =  0.157653\n",
      "Step  100 , loss =  0.00265591\n",
      "Step  200 , loss =  0.00255474\n",
      "Step  300 , loss =  0.00267698\n",
      "Step  400 , loss =  0.00294588\n",
      "Step  500 , loss =  0.00169415\n",
      "Step  600 , loss =  0.00236925\n",
      "New epoch 8\n",
      "Step  0 , loss =  0.248287\n",
      "Step  100 , loss =  0.00172886\n",
      "Step  200 , loss =  0.0018892\n",
      "Step  300 , loss =  0.00150354\n",
      "Step  400 , loss =  0.00153109\n",
      "Step  500 , loss =  0.00165018\n",
      "Step  600 , loss =  0.00167208\n",
      "New epoch 9\n",
      "Step  0 , loss =  0.247306\n",
      "Step  100 , loss =  0.00121871\n",
      "Step  200 , loss =  0.00119115\n",
      "Step  300 , loss =  0.00153959\n",
      "Step  400 , loss =  0.00132418\n",
      "Step  500 , loss =  0.00116805\n",
      "Step  600 , loss =  0.00123816\n",
      "New epoch 10\n",
      "Step  0 , loss =  0.208788\n",
      "Step  100 , loss =  0.00101831\n",
      "Step  200 , loss =  0.00123005\n",
      "Step  300 , loss =  0.00114715\n",
      "Step  400 , loss =  0.000696584\n",
      "Step  500 , loss =  0.00129301\n",
      "Step  600 , loss =  0.000965302\n",
      "New epoch 11\n",
      "Step  0 , loss =  0.190495\n",
      "Step  100 , loss =  0.000790743\n",
      "Step  200 , loss =  0.000686881\n",
      "Step  300 , loss =  0.000873219\n",
      "Step  400 , loss =  0.00073874\n",
      "Step  500 , loss =  0.00103917\n",
      "Step  600 , loss =  0.000609643\n",
      "New epoch 12\n",
      "Step  0 , loss =  0.157893\n",
      "Step  100 , loss =  0.000826179\n",
      "Step  200 , loss =  0.000555942\n",
      "Step  300 , loss =  0.000708616\n",
      "Step  400 , loss =  0.000664819\n",
      "Step  500 , loss =  0.00057772\n",
      "Step  600 , loss =  0.000698607\n",
      "New epoch 13\n",
      "Step  0 , loss =  0.197898\n",
      "Step  100 , loss =  0.000744434\n",
      "Step  200 , loss =  0.000597779\n",
      "Step  300 , loss =  0.000818845\n",
      "Step  400 , loss =  0.000591954\n",
      "Step  500 , loss =  0.000722321\n",
      "Step  600 , loss =  0.000598364\n",
      "New epoch 14\n",
      "Step  0 , loss =  0.238405\n",
      "Step  100 , loss =  0.000716724\n",
      "Step  200 , loss =  0.000572097\n",
      "Step  300 , loss =  0.000582554\n",
      "Step  400 , loss =  0.000474417\n",
      "Step  500 , loss =  0.000590739\n",
      "Step  600 , loss =  0.000505295\n",
      "New epoch 15\n",
      "Step  0 , loss =  0.239461\n",
      "Step  100 , loss =  0.000640605\n",
      "Step  200 , loss =  0.000439263\n",
      "Step  300 , loss =  0.000509685\n",
      "Step  400 , loss =  0.000516936\n",
      "Step  500 , loss =  0.000615455\n",
      "Step  600 , loss =  0.000489624\n",
      "New epoch 16\n",
      "Step  0 , loss =  0.127638\n",
      "Step  100 , loss =  0.000456355\n",
      "Step  200 , loss =  0.000409805\n",
      "Step  300 , loss =  0.000415529\n",
      "Step  400 , loss =  0.000460523\n",
      "Step  500 , loss =  0.000460299\n",
      "Step  600 , loss =  0.000351758\n",
      "New epoch 17\n",
      "Step  0 , loss =  0.121299\n",
      "Step  100 , loss =  0.000404416\n",
      "Step  200 , loss =  0.00040194\n",
      "Step  300 , loss =  0.000349281\n",
      "Step  400 , loss =  0.000363944\n",
      "Step  500 , loss =  0.000283212\n",
      "Step  600 , loss =  0.000470504\n",
      "New epoch 18\n",
      "Step  0 , loss =  0.242749\n",
      "Step  100 , loss =  0.000421022\n",
      "Step  200 , loss =  0.000413903\n",
      "Step  300 , loss =  0.000428936\n",
      "Step  400 , loss =  0.000315248\n",
      "Step  500 , loss =  0.000406711\n",
      "Step  600 , loss =  0.000416731\n",
      "New epoch 19\n",
      "Step  0 , loss =  0.147871\n",
      "Step  100 , loss =  0.000312595\n",
      "Step  200 , loss =  0.000375249\n",
      "Step  300 , loss =  0.000319887\n",
      "Step  400 , loss =  0.000355771\n",
      "Step  500 , loss =  0.000389721\n",
      "Step  600 , loss =  0.000257076\n",
      "New epoch 20\n",
      "Step  0 , loss =  0.163506\n",
      "Step  100 , loss =  0.000331066\n",
      "Step  200 , loss =  0.000278633\n",
      "Step  300 , loss =  0.000293986\n",
      "Step  400 , loss =  0.000369648\n",
      "Step  500 , loss =  0.000321398\n",
      "Step  600 , loss =  0.000276699\n",
      "New epoch 21\n",
      "Step  0 , loss =  0.193092\n",
      "Step  100 , loss =  0.000330308\n",
      "Step  200 , loss =  0.000410354\n",
      "Step  300 , loss =  0.000313933\n",
      "Step  400 , loss =  0.00032772\n",
      "Step  500 , loss =  0.00040262\n",
      "Step  600 , loss =  0.000308206\n",
      "New epoch 22\n",
      "Step  0 , loss =  0.134296\n",
      "Step  100 , loss =  0.000294305\n",
      "Step  200 , loss =  0.000378878\n",
      "Step  300 , loss =  0.000236951\n",
      "Step  400 , loss =  0.000271044\n",
      "Step  500 , loss =  0.000268428\n",
      "Step  600 , loss =  0.000246955\n",
      "New epoch 23\n",
      "Step  0 , loss =  0.129762\n",
      "Step  100 , loss =  0.000313234\n",
      "Step  200 , loss =  0.000252925\n",
      "Step  300 , loss =  0.000233116\n",
      "Step  400 , loss =  0.000236505\n",
      "Step  500 , loss =  0.000247505\n",
      "Step  600 , loss =  0.000215034\n",
      "New epoch 24\n",
      "Step  0 , loss =  0.123697\n",
      "Step  100 , loss =  0.000223469\n",
      "Step  200 , loss =  0.000212197\n",
      "Step  300 , loss =  0.000211428\n",
      "Step  400 , loss =  0.000212051\n",
      "Step  500 , loss =  0.0002341\n",
      "Step  600 , loss =  0.000254722\n",
      "New epoch 25\n",
      "Step  0 , loss =  0.134846\n",
      "Step  100 , loss =  0.00022114\n",
      "Step  200 , loss =  0.000254199\n",
      "Step  300 , loss =  0.000263321\n",
      "Step  400 , loss =  0.000244602\n",
      "Step  500 , loss =  0.000313832\n",
      "Step  600 , loss =  0.000240469\n",
      "New epoch 26\n",
      "Step  0 , loss =  0.176233\n",
      "Step  100 , loss =  0.000232103\n",
      "Step  200 , loss =  0.000249617\n",
      "Step  300 , loss =  0.000198282\n",
      "Step  400 , loss =  0.000289137\n",
      "Step  500 , loss =  0.000223596\n",
      "Step  600 , loss =  0.000241761\n",
      "New epoch 27\n",
      "Step  0 , loss =  0.15044\n",
      "Step  100 , loss =  0.000215388\n",
      "Step  200 , loss =  0.000331552\n",
      "Step  300 , loss =  0.000240737\n",
      "Step  400 , loss =  0.000251045\n",
      "Step  500 , loss =  0.000239773\n",
      "Step  600 , loss =  0.000191842\n",
      "New epoch 28\n",
      "Step  0 , loss =  0.145943\n",
      "Step  100 , loss =  0.000228655\n",
      "Step  200 , loss =  0.000289014\n",
      "Step  300 , loss =  0.00020369\n",
      "Step  400 , loss =  0.000181352\n",
      "Step  500 , loss =  0.000269949\n",
      "Step  600 , loss =  0.000213709\n",
      "New epoch 29\n",
      "Step  0 , loss =  0.0926385\n",
      "Step  100 , loss =  0.000190395\n",
      "Step  200 , loss =  0.000230893\n",
      "Step  300 , loss =  0.000177528\n",
      "Step  400 , loss =  0.00018257\n",
      "Step  500 , loss =  0.00024867\n",
      "Step  600 , loss =  0.000231664\n",
      "New epoch 30\n",
      "Step  0 , loss =  0.19435\n",
      "Step  100 , loss =  0.000269821\n",
      "Step  200 , loss =  0.000206386\n",
      "Step  300 , loss =  0.000237496\n",
      "Step  400 , loss =  0.000223998\n",
      "Step  500 , loss =  0.000203333\n",
      "Step  600 , loss =  0.000206746\n",
      "New epoch 31\n",
      "Step  0 , loss =  0.158938\n",
      "Step  100 , loss =  0.000169051\n",
      "Step  200 , loss =  0.000193299\n",
      "Step  300 , loss =  0.00023527\n",
      "Step  400 , loss =  0.000177667\n",
      "Step  500 , loss =  0.000159084\n",
      "Step  600 , loss =  0.000175967\n",
      "New epoch 32\n",
      "Step  0 , loss =  0.159893\n",
      "Step  100 , loss =  0.00019121\n",
      "Step  200 , loss =  0.000154543\n",
      "Step  300 , loss =  0.000164199\n",
      "Step  400 , loss =  0.000214444\n",
      "Step  500 , loss =  0.000161811\n",
      "Step  600 , loss =  0.000204987\n",
      "New epoch 33\n",
      "Step  0 , loss =  0.145342\n",
      "Step  100 , loss =  0.000151879\n",
      "Step  200 , loss =  0.000191703\n",
      "Step  300 , loss =  0.000154457\n",
      "Step  400 , loss =  0.000160461\n",
      "Step  500 , loss =  0.000158802\n",
      "Step  600 , loss =  0.000146259\n",
      "New epoch 34\n",
      "Step  0 , loss =  0.144867\n",
      "Step  100 , loss =  0.000182875\n",
      "Step  200 , loss =  0.000197847\n",
      "Step  300 , loss =  0.000219885\n",
      "Step  400 , loss =  0.000141499\n",
      "Step  500 , loss =  0.000170144\n",
      "Step  600 , loss =  0.000167549\n",
      "New epoch 35\n",
      "Step  0 , loss =  0.156612\n",
      "Step  100 , loss =  0.000163975\n",
      "Step  200 , loss =  0.000167133\n",
      "Step  300 , loss =  0.000155131\n",
      "Step  400 , loss =  0.000170945\n",
      "Step  500 , loss =  0.000182313\n",
      "Step  600 , loss =  0.000159191\n",
      "New epoch 36\n",
      "Step  0 , loss =  0.151979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  100 , loss =  0.000240787\n",
      "Step  200 , loss =  0.000196486\n",
      "Step  300 , loss =  0.000183412\n",
      "Step  400 , loss =  0.000211393\n",
      "Step  500 , loss =  0.000171212\n",
      "Step  600 , loss =  0.00016175\n",
      "New epoch 37\n",
      "Step  0 , loss =  0.1613\n",
      "Step  100 , loss =  0.000159007\n",
      "Step  200 , loss =  0.000167393\n",
      "Step  300 , loss =  0.000141423\n",
      "Step  400 , loss =  0.000125972\n",
      "Step  500 , loss =  0.00013995\n",
      "Step  600 , loss =  0.000138992\n",
      "New epoch 38\n",
      "Step  0 , loss =  0.17251\n",
      "Step  100 , loss =  0.000155783\n",
      "Step  200 , loss =  0.000158352\n",
      "Step  300 , loss =  0.000143938\n",
      "Step  400 , loss =  0.000143365\n",
      "Step  500 , loss =  0.000155048\n",
      "Step  600 , loss =  0.000158679\n",
      "New epoch 39\n",
      "Step  0 , loss =  0.122432\n",
      "Step  100 , loss =  0.000200895\n",
      "Step  200 , loss =  0.000144502\n",
      "Step  300 , loss =  0.000123484\n",
      "Step  400 , loss =  0.000128454\n",
      "Step  500 , loss =  0.000150605\n",
      "Step  600 , loss =  0.000129672\n",
      "New epoch 40\n",
      "Step  0 , loss =  0.189793\n",
      "Step  100 , loss =  0.00016195\n",
      "Step  200 , loss =  0.000164848\n",
      "Step  300 , loss =  0.000140583\n",
      "Step  400 , loss =  0.00013294\n",
      "Step  500 , loss =  0.000126368\n",
      "Step  600 , loss =  0.000122864\n",
      "New epoch 41\n",
      "Step  0 , loss =  0.178321\n",
      "Step  100 , loss =  0.000166103\n",
      "Step  200 , loss =  0.000179165\n",
      "Step  300 , loss =  0.000116799\n",
      "Step  400 , loss =  0.00012769\n",
      "Step  500 , loss =  0.00012884\n",
      "Step  600 , loss =  0.000122161\n",
      "New epoch 42\n",
      "Step  0 , loss =  0.154156\n",
      "Step  100 , loss =  0.000163756\n",
      "Step  200 , loss =  0.000153535\n",
      "Step  300 , loss =  0.000127482\n",
      "Step  400 , loss =  0.000149609\n",
      "Step  500 , loss =  0.000125079\n",
      "Step  600 , loss =  0.000109158\n",
      "New epoch 43\n",
      "Step  0 , loss =  0.179493\n",
      "Step  100 , loss =  0.000148816\n",
      "Step  200 , loss =  0.000125503\n",
      "Step  300 , loss =  0.000114416\n",
      "Step  400 , loss =  0.000123548\n",
      "Step  500 , loss =  0.000110291\n",
      "Step  600 , loss =  0.00011221\n",
      "New epoch 44\n",
      "Step  0 , loss =  0.0987589\n",
      "Step  100 , loss =  0.000126796\n",
      "Step  200 , loss =  0.00012193\n",
      "Step  300 , loss =  0.000107354\n",
      "Step  400 , loss =  0.00010767\n",
      "Step  500 , loss =  0.000104247\n",
      "Step  600 , loss =  0.000117011\n",
      "New epoch 45\n",
      "Step  0 , loss =  0.156715\n",
      "Step  100 , loss =  0.000120739\n",
      "Step  200 , loss =  0.000102835\n",
      "Step  300 , loss =  0.000102586\n",
      "Step  400 , loss =  0.000120506\n",
      "Step  500 , loss =  9.39514e-05\n",
      "Step  600 , loss =  9.95588e-05\n",
      "New epoch 46\n",
      "Step  0 , loss =  0.180831\n",
      "Step  100 , loss =  0.00021314\n",
      "Step  200 , loss =  0.000188928\n",
      "Step  300 , loss =  0.000173494\n",
      "Step  400 , loss =  0.000163691\n",
      "Step  500 , loss =  0.000136093\n",
      "Step  600 , loss =  0.000140425\n",
      "New epoch 47\n",
      "Step  0 , loss =  0.138121\n",
      "Step  100 , loss =  0.000140749\n",
      "Step  200 , loss =  0.000135971\n",
      "Step  300 , loss =  9.96095e-05\n",
      "Step  400 , loss =  0.000127989\n",
      "Step  500 , loss =  0.000124816\n",
      "Step  600 , loss =  0.0001293\n",
      "New epoch 48\n",
      "Step  0 , loss =  0.234975\n",
      "Step  100 , loss =  0.000118458\n",
      "Step  200 , loss =  0.000117218\n",
      "Step  300 , loss =  0.000121524\n",
      "Step  400 , loss =  0.000120389\n",
      "Step  500 , loss =  0.000104399\n",
      "Step  600 , loss =  0.00010945\n",
      "New epoch 49\n",
      "Step  0 , loss =  0.200454\n",
      "Step  100 , loss =  0.000166281\n",
      "Step  200 , loss =  0.000163548\n",
      "Step  300 , loss =  0.000149027\n",
      "Step  400 , loss =  0.000136876\n",
      "Step  500 , loss =  0.000123565\n",
      "Step  600 , loss =  0.000129871\n",
      "New epoch 50\n",
      "Step  0 , loss =  0.135662\n",
      "Step  100 , loss =  0.00012609\n",
      "Step  200 , loss =  0.000135944\n",
      "Step  300 , loss =  0.000119046\n",
      "Step  400 , loss =  0.000123493\n",
      "Step  500 , loss =  0.000121583\n",
      "Step  600 , loss =  0.000111966\n",
      "New epoch 51\n",
      "Step  0 , loss =  0.171394\n",
      "Step  100 , loss =  0.000122786\n",
      "Step  200 , loss =  0.000108\n",
      "Step  300 , loss =  0.00011545\n",
      "Step  400 , loss =  0.000105804\n",
      "Step  500 , loss =  0.000106247\n",
      "Step  600 , loss =  0.000116292\n",
      "New epoch 52\n",
      "Step  0 , loss =  0.115738\n",
      "Step  100 , loss =  9.17321e-05\n",
      "Step  200 , loss =  0.000106576\n",
      "Step  300 , loss =  0.000108746\n",
      "Step  400 , loss =  0.000103111\n",
      "Step  500 , loss =  8.04338e-05\n",
      "Step  600 , loss =  8.96049e-05\n",
      "New epoch 53\n",
      "Step  0 , loss =  0.225449\n",
      "Step  100 , loss =  0.000105731\n",
      "Step  200 , loss =  0.000100248\n",
      "Step  300 , loss =  0.000109303\n",
      "Step  400 , loss =  9.80896e-05\n",
      "Step  500 , loss =  0.00011497\n",
      "Step  600 , loss =  0.000117017\n",
      "New epoch 54\n",
      "Step  0 , loss =  0.131894\n",
      "Step  100 , loss =  0.00010399\n",
      "Step  200 , loss =  9.50339e-05\n",
      "Step  300 , loss =  0.000120746\n",
      "Step  400 , loss =  9.25079e-05\n",
      "Step  500 , loss =  9.4084e-05\n",
      "Step  600 , loss =  9.58086e-05\n",
      "New epoch 55\n",
      "Step  0 , loss =  0.117766\n",
      "Step  100 , loss =  8.94593e-05\n",
      "Step  200 , loss =  9.34707e-05\n",
      "Step  300 , loss =  9.54685e-05\n",
      "Step  400 , loss =  8.88045e-05\n",
      "Step  500 , loss =  9.46046e-05\n",
      "Step  600 , loss =  9.54531e-05\n",
      "New epoch 56\n",
      "Step  0 , loss =  0.155378\n",
      "Step  100 , loss =  8.24556e-05\n",
      "Step  200 , loss =  8.56685e-05\n",
      "Step  300 , loss =  8.70065e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-08b3afb91489>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Step '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\", loss = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpr_series\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8e6a8d22764f>\u001b[0m in \u001b[0;36mplot\u001b[1;34m(loss_list, predictions_series, batchX, batchY)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msingle_output_series\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"green\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m()\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \"\"\"\n\u001b[1;32m--> 691\u001b[1;33m     \u001b[0mget_current_fig_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2038\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2040\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_cursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0mRendererAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[1;32m-> 1144\u001b[1;33m                 renderer, self, dsu, self.suppressComposite)\n\u001b[0m\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2424\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2426\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2428\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[0mtpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_path_non_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[0maffine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path_effects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mget_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2394\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2396\u001b[1;33m             return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n\u001b[0m\u001b[0;32m   2397\u001b[0m                                 self._a.get_affine().get_matrix()))\n\u001b[0;32m   2398\u001b[0m     \u001b[0mget_affine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mget_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2396\u001b[0m             return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n\u001b[1;32m-> 2397\u001b[1;33m                                 self._a.get_affine().get_matrix()))\n\u001b[0m\u001b[0;32m   2398\u001b[0m     \u001b[0mget_affine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19a25663390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch_index in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "        c_state = np.zeros([batch_size,state_size])\n",
    "        \n",
    "        print('New epoch %d'%(epoch_index))\n",
    "        for batch_index in range(num_batches):\n",
    "            start_index = batch_index*truncated_backprop_length\n",
    "            stop_index = start_index + truncated_backprop_length\n",
    "            \n",
    "            batchX = x[:,start_index:stop_index]\n",
    "            batchY = y[:,start_index:stop_index]\n",
    "            \n",
    "            tl,ts,c_state,pr_series = sess.run([total_loss,train_step,current_state,predictions_series],feed_dict={\n",
    "                batchX_placeholder: batchX,\n",
    "                batchY_placeholder: batchY,\n",
    "                init_state: c_state\n",
    "            })\n",
    "            \n",
    "            loss_list.append(tl)\n",
    "            \n",
    "            if batch_index%100==0:\n",
    "                print('Step ',batch_index,\", loss = \",tl)\n",
    "                plot(loss_list,pr_series,batchX,batchY)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    path = 'RNN_model_dir\\\\RNN_001.ckpt'\n",
    "    save_path = saver.save(sess, path)\n",
    "                \n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    path = 'RNN_model_dir\\\\RNN_001.ckpt'\n",
    "    saver.restore(sess,path)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
