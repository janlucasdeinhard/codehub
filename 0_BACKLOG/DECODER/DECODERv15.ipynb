{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy.random as rnd\n",
    "import csv \n",
    "import time\n",
    "from scipy.signal import step\n",
    "import scipy.signal as signal\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "class DECODER(object):\n",
    "    \n",
    "    def decode_msg(self,MSG,TAXIS,TBIT,SLOTLEN,decoder_in_len=100,is_normalized=False,remove_offset=True,verbose=False):\n",
    "        MSG = np.reshape(MSG,[1,MSG.shape[0]])\n",
    "        if verbose:\n",
    "            plt.plot(TAXIS,MSG[0,:])\n",
    "            plt.title('RX data')\n",
    "            plt.show()\n",
    "        steps_per_slot = int(np.argmin(np.abs(TAXIS-TBIT*SLOTLEN)))\n",
    "        slot_num_est = int(np.floor(TAXIS.shape[0]/steps_per_slot))\n",
    "        slots_decoded = np.empty(shape=(slot_num_est,decoder_in_len))\n",
    "        if verbose:\n",
    "            print('Detected %d slots, recorded %d samples for each slot\\n'%(slot_num_est,steps_per_slot))\n",
    "        dec_msg_decoded = np.empty(shape=(1,slot_num_est))\n",
    "        for k in range(slot_num_est):\n",
    "            if verbose:\n",
    "                print('Working on slot %d/%d...'%(k+1,slot_num_est))\n",
    "            c_slot = MSG[0,k*steps_per_slot:(k+1)*steps_per_slot]\n",
    "            if not is_normalized:\n",
    "                if verbose:\n",
    "                    print('Slot normalization...\\n')\n",
    "                c_slot,_ = self.norm_data(np.reshape(c_slot,(1,steps_per_slot)),[0,1])\n",
    "            if remove_offset:\n",
    "                c_slot = c_slot - c_slot.min()\n",
    "            c_slot = signal.resample(c_slot,decoder_in_len,axis=1)\n",
    "            slots_decoded[k,:] = c_slot\n",
    "            if verbose:\n",
    "                plt.plot(slots_decoded[k,:])\n",
    "                plt.title('Slot no. '+str(k+1))\n",
    "                plt.show()\n",
    "            class_sugg,full_pred = self.decode(c_slot)\n",
    "            dec_msg_decoded[0,k] = class_sugg\n",
    "            if verbose:\n",
    "                print('Prediction for slot %d: %d\\n'%(k,class_sugg))\n",
    "        return dec_msg_decoded\n",
    "\n",
    "    def dec2bin(self,num,BITS):\n",
    "        if num >= 2**BITS:\n",
    "            return -1\n",
    "        res = num\n",
    "        B = np.zeros(shape=(1,BITS))\n",
    "        for k in range(BITS-1,-1,-1):\n",
    "            if 2**k <= res:\n",
    "                B[0,BITS-(k+1)] = 1\n",
    "                res = res - 2**k\n",
    "        return B\n",
    "\n",
    "    def dec2bin_array(self,decarray,SLOTLEN):\n",
    "        if len(decarray.shape)!=2:\n",
    "            decarray = np.reshape(decarray,(1,decarray.shape[0]))\n",
    "        binarray = np.empty(shape=(1,SLOTLEN*decarray.shape[1]))\n",
    "        for k in range(0,binarray.shape[1],SLOTLEN):\n",
    "            binarray[0,k:k+SLOTLEN] = self.dec2bin(decarray[0,int(k/SLOTLEN)],SLOTLEN)\n",
    "        return binarray\n",
    "\n",
    "    def byte2dec(self,inbyte):\n",
    "        outdec = 0\n",
    "        for k in range(inbyte.shape[0]):\n",
    "            outdec = outdec+inbyte[k]*(2**(7-k))\n",
    "        return outdec\n",
    "\n",
    "    def bin2bytes(self,binarray):\n",
    "        declist = []\n",
    "        strlist = []\n",
    "        inarray = binarray\n",
    "        if len(binarray.shape)!=2:\n",
    "            binarray = np.reshape(binarray,(1,binarray.shape[0]))\n",
    "        while inarray.shape[1]>=8:\n",
    "            onebyte = inarray[0,0:8]\n",
    "            inarray = inarray[0,8:]\n",
    "            inarray = np.reshape(inarray,(1,inarray.shape[0]))\n",
    "            T = int(self.byte2dec(onebyte))\n",
    "            declist.append(T)\n",
    "            strlist.append(chr(T))\n",
    "        residual_zeros = inarray.shape[1]\n",
    "        return strlist,declist,residual_zeros\n",
    "\n",
    "    def decode_binary(self,msg_path,Tbit,slotlen):\n",
    "        MSG = self.raw_datatable_load(msg_path)\n",
    "        t,d = MSG[0,:],MSG[1,:]\n",
    "        dd,cc = self.norm_data(np.reshape(d,(1,d.shape[0])),[0,1])\n",
    "        decoded = self.decode_msg(d,t,Tbit,slotlen)\n",
    "        bin_decoded = self.dec2bin_array(decoded,slotlen)\n",
    "        return bin_decoded\n",
    "\n",
    "    def decode_string(self,msg_path,Tbit,slotlen):\n",
    "        bin_decoded = self.decode_binary(msg_path,Tbit,slotlen)\n",
    "        mychars,mydecs,residual_zeros = self.bin2bytes(bin_decoded)\n",
    "        return mychars,mydecs,residual_zeros\n",
    "    \n",
    "    def fuzzify_dataset(self,DATA,randsampling_factor=0.7,verbose=False):\n",
    "        if randsampling_factor>1 or randsampling_factor<0:\n",
    "            raise Exception('Variable randsampling_factor specifies the percentage to which the full signal may be curtailed and should be between 0 and 1')\n",
    "        INTERDATA = np.empty(shape=DATA.shape)\n",
    "        NEWDATA = np.empty(shape=DATA.shape)\n",
    "        olength = DATA.shape[1]\n",
    "        minlength = int(olength*randsampling_factor)\n",
    "        for k in range(DATA.shape[0]):\n",
    "            databit = DATA[k,:]\n",
    "            if verbose:\n",
    "                print('Original data shape: ' + str(databit.shape))\n",
    "            newlength = int(minlength + (olength-minlength)*rnd.rand())\n",
    "            start_indx = rnd.randint(low=0,high=olength-newlength)\n",
    "            interdata = databit[start_indx:(start_indx+newlength)]\n",
    "            if verbose:\n",
    "                print('Original data cut to shape '+str(interdata.shape))\n",
    "            NEWDATA[k,:] = signal.resample(interdata,int(olength),axis=0)\n",
    "            if verbose:\n",
    "                print('Finally resampled to length of ' + str(NEWDATA[k,:].shape))\n",
    "        return NEWDATA\n",
    "    \n",
    "    def raw_datatable_load(self,filepath):\n",
    "        raw_data = open(filepath, 'rt')\n",
    "        reader_data = csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "        DATA = np.array(list(reader_data)).astype('float')\n",
    "        return DATA\n",
    "    \n",
    "    def lrelu(self, x, alpha=0.2):\n",
    "        return tf.maximum(x, tf.multiply(x,alpha))\n",
    "    \n",
    "    def norm_data(self, mydata, myrange, use_global_max=False, use_global_min=False):\n",
    "        try:\n",
    "            min_norm = myrange[0]\n",
    "            max_norm = myrange[1]\n",
    "            if use_global_min:\n",
    "                min_c = np.min(mydata)\n",
    "            if use_global_max:\n",
    "                max_c = np.max(mydata)\n",
    "        except:\n",
    "            print('Could not convert the specified range')\n",
    "        scaling_coefficients = np.zeros(mydata.shape[0])\n",
    "        newdata = np.zeros(mydata.shape)\n",
    "        for k in range(mydata.shape[0]):\n",
    "            dataline = mydata[k,:]\n",
    "            if np.count_nonzero(dataline)==0:\n",
    "                newdata[k,:]=dataline\n",
    "                continue\n",
    "            newdataline = np.zeros(dataline.shape)\n",
    "            if not use_global_min:\n",
    "                min_c = np.min(dataline)\n",
    "            if not use_global_max:\n",
    "                max_c = np.max(dataline)\n",
    "            coeff = (np.abs(max_norm-min_norm)/np.abs(max_c-min_c))\n",
    "            for kk in range(dataline.shape[0]):\n",
    "                newdataline[kk] = min_norm + coeff*dataline[kk]\n",
    "            scaling_coefficients[k]=coeff\n",
    "            newdata[k,:] = newdataline\n",
    "        return newdata, scaling_coefficients\n",
    "    \n",
    "    def load_data_and_labels(self, datapath, labelpath,noise=0,truncate_neg=True,mix_data=True):\n",
    "        raw_data = open(datapath, 'rt')\n",
    "        raw_labels = open(labelpath, 'rt')\n",
    "        reader_data = csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "        reader_labels = csv.reader(raw_labels, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "        DATA = np.array(list(reader_data)).astype('float')\n",
    "        LABELS = np.array(list(reader_labels)).astype('float')\n",
    "        DATA = DATA + noise*rnd.randn(DATA.shape[0],DATA.shape[1])\n",
    "        if truncate_neg:\n",
    "            DATA[DATA<0]=0\n",
    "        if mix_data:\n",
    "            permind = np.array(range(DATA.shape[0]))\n",
    "            permind = rnd.permutation(permind)\n",
    "            DATA = DATA[permind]\n",
    "            LABELS = LABELS[permind]\n",
    "        print(DATA.shape)\n",
    "        print(LABELS.shape)\n",
    "        if DATA.shape[0]!=LABELS.shape[0]:\n",
    "            raise Exception('DATA and LABELS not of equal shape')\n",
    "        if DATA.shape[1]!=self.datashape:\n",
    "            if self.verbose:\n",
    "                print('Data shape does not fit expected input shape, resampling...')\n",
    "            DATA = signal.resample(DATA,self.datashape,axis=1)\n",
    "        return DATA, LABELS\n",
    "    \n",
    "    def conv_net_test(self, inputs, keep_prob, reg=None, reuse=None):\n",
    "        filters_default = 20\n",
    "        act_fun = tf.nn.tanh\n",
    "        #act_fun = tf.nn.elu\n",
    "        with tf.variable_scope('conv_net', reuse=reuse) as scope:\n",
    "            # Reshape input\n",
    "            t = tf.reshape(inputs, [-1,1,self.datashape, 1])\n",
    "            # Conv layer 1\n",
    "            t = tf.layers.conv2d(inputs=t, filters=filters_default, kernel_size=(1,1), strides=(1,1), activation=act_fun, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,1), strides=(1,1))\n",
    "            t = tf.layers.dropout(t, keep_prob)\n",
    "            t = tf.layers.batch_normalization(t)\n",
    "            # Conv layer 2\n",
    "            t = tf.layers.conv2d(inputs=t, filters=filters_default, kernel_size=(1,1), strides=(1,1), activation=act_fun, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,1), strides=(1,1))\n",
    "            t = tf.layers.dropout(t, keep_prob)\n",
    "            t = tf.layers.batch_normalization(t)\n",
    "            # Conv layer 3\n",
    "            t = tf.layers.conv2d(inputs=t, filters=filters_default, kernel_size=(1,1), strides=(1,1), activation=act_fun, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,1), strides=(1,1))\n",
    "            t = tf.layers.dropout(t, keep_prob)\n",
    "            t = tf.layers.batch_normalization(t)\n",
    "            # Conv layer 4\n",
    "            t = tf.layers.conv2d(inputs=t, filters=filters_default, kernel_size=(1,1), strides=(1,1), activation=act_fun, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,1), strides=(1,1))\n",
    "            t = tf.layers.dropout(t, keep_prob)\n",
    "            t = tf.layers.batch_normalization(t)\n",
    "            # Conv layer 5\n",
    "            t = tf.layers.conv2d(inputs=t, filters=filters_default, kernel_size=(1,1), strides=(1,1), activation=act_fun, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,1), strides=(1,1))\n",
    "            t = tf.layers.dropout(t, keep_prob)\n",
    "            t = tf.layers.batch_normalization(t)\n",
    "            # Conv layer 6\n",
    "            t = tf.layers.conv2d(inputs=t, filters=filters_default, kernel_size=(1,1), strides=(1,1), activation=act_fun, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,1), strides=(1,1))\n",
    "            t = tf.layers.dropout(t, keep_prob)\n",
    "            t = tf.layers.batch_normalization(t)\n",
    "            # Dense layers\n",
    "            t = tf.reshape(t, (-1,int(t.shape[2])*int(t.shape[3])))\n",
    "            t = tf.layers.dense(inputs=t, units=40)\n",
    "            t = tf.layers.dense(inputs=t, units=self.num_classes)\n",
    "            return t\n",
    "    \n",
    "    def conv_net_wide(self, inputs, keep_prob, reg=None, reuse=None):\n",
    "        with tf.variable_scope('conv_net', reuse=reuse) as scope:\n",
    "            # Reshape input\n",
    "            t = tf.reshape(inputs, [-1,1,self.datashape, 1])\n",
    "            # Conv layer 1\n",
    "            t = tf.layers.conv2d(inputs=t, filters=1000, kernel_size=(1,10), strides=(1,2), activation=tf.nn.relu, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,5), strides=(1,2))\n",
    "            # Dropout and dense layers\n",
    "            t = tf.reshape(t, (-1,int(t.shape[2])*int(t.shape[3])))\n",
    "            t = tf.layers.dropout(t, keep_prob)\n",
    "            t = tf.layers.dense(inputs=t, units=self.num_classes)\n",
    "            return t\n",
    "        \n",
    "    def conv_net_deep(self, inputs, keep_prob, reg=None, reuse=None):\n",
    "        with tf.variable_scope('conv_net', reuse=reuse) as scope:\n",
    "            # Reshape input\n",
    "            t = tf.reshape(inputs, [-1,1,self.datashape, 1])\n",
    "            # Conv layer 1\n",
    "            t = tf.layers.conv2d(inputs=t, filters=100, kernel_size=(1,10), strides=(1,1), activation=tf.nn.relu, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,4), strides=(1,1))\n",
    "            # Conv layer 2\n",
    "            t = tf.layers.conv2d(inputs=t, filters=100, kernel_size=(1,10), strides=(1,1), activation=tf.nn.relu, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,4), strides=(1,1))\n",
    "            # Conv layer 3\n",
    "            t = tf.layers.conv2d(inputs=t, filters=100, kernel_size=(1,10), strides=(1,1), activation=tf.nn.relu, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,4), strides=(1,1))\n",
    "            # Dropout and dense layer\n",
    "            t = tf.reshape(t, (-1,int(t.shape[2])*int(t.shape[3])))\n",
    "            t = tf.layers.dropout(t, keep_prob)\n",
    "            t = tf.layers.dense(inputs=t, units=self.num_classes)\n",
    "            return t\n",
    "        \n",
    "    def conv_net_very_wide(self, inputs, keep_prob, reg=None, reuse=None):\n",
    "        with tf.variable_scope('conv_net', reuse=reuse) as scope:\n",
    "            # Reshape input\n",
    "            t = tf.reshape(inputs, [-1,1,self.datashape, 1])\n",
    "            # Conv layer 1\n",
    "            t = tf.layers.conv2d(inputs=t, filters=5000, kernel_size=(1,10), strides=(1,2), activation=tf.nn.relu, kernel_regularizer=reg)\n",
    "            t = tf.layers.max_pooling2d(inputs=t, pool_size=(1,2), strides=(1,2))\n",
    "            # Dropout and dense layer\n",
    "            t = tf.reshape(t, (-1,int(t.shape[2])*int(t.shape[3])))\n",
    "            t = tf.layers.dropout(t, keep_prob)\n",
    "            t = tf.layers.dense(inputs=t, units=self.num_classes)\n",
    "            return t\n",
    "        \n",
    "    def build_model(self, reg_scale=0.01):\n",
    "        tf.reset_default_graph()\n",
    "        in_vec = tf.placeholder(dtype=tf.float32, shape=[None, self.datashape], name='x_in')\n",
    "        true_label = tf.placeholder(dtype=tf.float32, shape=[None,self.num_classes], name='y_out')\n",
    "        keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "        reg = tf.contrib.layers.l2_regularizer(scale=reg_scale, scope='conv_net')\n",
    "        loss_reg = tf.losses.get_regularization_loss(scope='conv_net')\n",
    "        out_logits = self.CNNDict[self.conv_net_version](in_vec, keep_prob, reg=reg) \n",
    "        prediction = {\n",
    "            'classes': tf.argmax(input=out_logits, axis=1),\n",
    "            'probabilities': tf.nn.softmax(out_logits)\n",
    "        }\n",
    "        loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=true_label, logits=out_logits))\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(loss+loss_reg)\n",
    "        return optimizer, loss, prediction, out_logits, in_vec, true_label, keep_prob\n",
    "\n",
    "    def decode(self, inputs):\n",
    "        try:\n",
    "            inputs = np.reshape(inputs, (-1, self.datashape))\n",
    "        except:\n",
    "            return -1\n",
    "        pred = self.sess.run(self.prediction, feed_dict={\n",
    "            self.in_vec: np.reshape(inputs, (1, inputs.shape[1])),\n",
    "            self.keep_prob: 1.0\n",
    "        })\n",
    "        return pred['classes'], pred\n",
    "    \n",
    "    def init_session(self):\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        return sess\n",
    "    \n",
    "    def close(self):\n",
    "        self.sess.close()\n",
    "        return\n",
    "    \n",
    "    def train(self, datapath, labelpath, plot_step=500,noise=0,use_data_subset=-1,fuzzify=0):\n",
    "        if self.verbose:\n",
    "            print('Loading data...\\n')\n",
    "        TRAIN_DATA,TRAIN_LABELS = self.load_data_and_labels(datapath,labelpath,noise)\n",
    "        TRAIN_DATA,_ = self.norm_data(TRAIN_DATA,[0,1])\n",
    "        if fuzzify!=0:\n",
    "            TRAIN_DATA = self.fuzzify_dataset(TRAIN_DATA,randsampling_factor=fuzzify)\n",
    "        if use_data_subset>0 and use_data_subset<TRAIN_DATA.shape[0]:\n",
    "            TRAIN_DATA = TRAIN_DATA[0:use_data_subset]\n",
    "            TRAIN_LABELS = TRAIN_LABELS[0:use_data_subset]\n",
    "        if self.verbose:\n",
    "            print('Loaded %d data samples and corresponding labels\\n'%TRAIN_DATA.shape[0])\n",
    "        k_indices = np.arange(0, TRAIN_DATA.shape[0]-self.batch_size, self.batch_size)\n",
    "        maxindex = np.max(k_indices)\n",
    "        loss_store = np.zeros(shape=k_indices.shape)\n",
    "        ctr = 0\n",
    "        if self.verbose:\n",
    "            print('Launching training with %d steps\\n'%maxindex)\n",
    "        for k in k_indices:\n",
    "            if self.verbose:\n",
    "                print('Iteration %d out of %d'%(k,maxindex))\n",
    "            batch_t = TRAIN_DATA[k:k+self.batch_size,:]\n",
    "            batch_l = np.zeros(shape=(self.batch_size,self.num_classes))\n",
    "            for kk in range(self.batch_size):\n",
    "                batch_l[kk,int(TRAIN_LABELS[k+kk,:])]=1\n",
    "\n",
    "            opt, ls, pred = self.sess.run([self.optimizer, self.loss, self.prediction], feed_dict={\n",
    "                self.in_vec:np.reshape(batch_t,(self.batch_size,TRAIN_DATA.shape[1])), \n",
    "                self.true_label:np.reshape(batch_l,(self.batch_size,self.num_classes)), \n",
    "                self.keep_prob: self.train_keep_prob\n",
    "            })\n",
    "            loss_store[ctr] = ls\n",
    "            ctr+=1\n",
    "            if k%plot_step==0 and self.verbose:\n",
    "                print('Training step ', k, ' --> Real class: ', np.transpose(TRAIN_LABELS[k:k+self.batch_size,:]),', prediction: ', pred['classes'])\n",
    "                print('Training step %d --> loss=%f\\n'%(k,ls))\n",
    "        self.is_trained = True\n",
    "        return loss_store\n",
    "    \n",
    "    def test(self, datapath, labelpath,noise=0,use_data_subset=-1,fuzzify=0):\n",
    "        if self.verbose:\n",
    "            print('Loading data...\\n')\n",
    "        TEST_DATA,TEST_LABELS = self.load_data_and_labels(datapath,labelpath,noise)\n",
    "        TEST_DATA,_ = self.norm_data(TEST_DATA,[0,1])\n",
    "        if fuzzify!=0:\n",
    "            TEST_DATA = self.fuzzify_dataset(TEST_DATA,randsampling_factor=fuzzify)\n",
    "        if use_data_subset>0 and use_data_subset<TEST_DATA.shape[0]:\n",
    "            TEST_DATA = TEST_DATA[0:use_data_subset]\n",
    "            TEST_LABELS = TEST_LABELS[0:use_data_subset]\n",
    "        if self.verbose:\n",
    "            print('Loaded %d data samples and corresponding labels\\n'%TEST_DATA.shape[0])\n",
    "        total_test_len = TEST_DATA.shape[0]\n",
    "        misclfd = 0\n",
    "        loss_tracker = np.zeros((TEST_DATA.shape[0],1))\n",
    "        for k in range(TEST_DATA.shape[0]):\n",
    "            data = TEST_DATA[k,:]\n",
    "            real_label = TEST_LABELS[k,:]\n",
    "            pred_label, full_prediction = self.decode(data)\n",
    "            loss_tracker[k]=np.square(real_label-pred_label)\n",
    "            if loss_tracker[k]!=0:\n",
    "                misclfd+=1\n",
    "            if self.verbose:\n",
    "                print('k=%d: Avg loss so far = %f\\n     Misclassifications: %d\\n'%(k,np.mean(loss_tracker[0:k]),misclfd))\n",
    "        self.test_loss = loss_tracker\n",
    "        return np.mean(loss_tracker), misclfd, total_test_len\n",
    "    \n",
    "    def save(self, dirpath='model_dir\\\\decoder\\\\'):\n",
    "        saver = tf.train.Saver()\n",
    "        path = dirpath + 'DECODER_' + self.mID + '.ckpt'\n",
    "        save_path = saver.save(self.sess, path)\n",
    "        return save_path\n",
    "    \n",
    "    def load_model(self, path=None):\n",
    "        if path is None:\n",
    "            path = 'model_dir\\\\decoder\\\\DECODER_' + self.mID + '.ckpt'\n",
    "        saver = tf.train.Saver()\n",
    "        okay = -1\n",
    "        try:\n",
    "            saver.restore(self.sess,path)\n",
    "            okay = 0\n",
    "        except:\n",
    "            if self.verbose:\n",
    "                print('Could not find the model or failed to read file\\n')\n",
    "        return okay\n",
    "    \n",
    "    def __init__(self,mID,num_classes,datashape,batch_size=1,learning_rate=0.01,train_keep_prob=0.7,verbose=True,conv_net_version='test'):\n",
    "        self.mID = mID\n",
    "        self.verbose = verbose\n",
    "        self.is_trained = False\n",
    "        self.test_loss = None\n",
    "        self.conv_net_version = conv_net_version\n",
    "        self.CNNDict = {\n",
    "            'wide': self.conv_net_wide,\n",
    "            'deep': self.conv_net_deep,\n",
    "            'verywide': self.conv_net_very_wide,\n",
    "            'test': self.conv_net_test\n",
    "        }\n",
    "        assert self.conv_net_version in self.CNNDict.keys()\n",
    "        self.num_classes = num_classes\n",
    "        self.datashape = datashape\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.train_keep_prob = train_keep_prob\n",
    "        self.optimizer, self.loss, self.prediction, self.out_logits, self.in_vec, self.true_label, self.keep_prob = self.build_model()\n",
    "        self.sess = self.init_session()\n",
    "        if self.verbose:\n",
    "            print('DECODER has been set up and is ready for use!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = 'data\\\\DECODERDATA\\\\27DATA_train.csv'\n",
    "training_label_path = 'data\\\\DECODERDATA\\\\27LABELS_train.csv'\n",
    "test_data_path = 'data\\\\DECODERDATA\\\\27DATA_test.csv'\n",
    "test_label_path = 'data\\\\DECODERDATA\\\\27LABELS_test.csv'\n",
    "manualtrial_data_path = 'data\\\\DECODERDATA\\\\27DATA_manualtrial.csv'\n",
    "manualtrial_label_path = 'data\\\\DECODERDATA\\\\27LABELS_manualtrial.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting previous decoder...\n",
      "\n",
      "Setting up...\n",
      "\n",
      "DECODER has been set up and is ready for use!\n"
     ]
    }
   ],
   "source": [
    "myID = '095'\n",
    "mynoise = 0\n",
    "\n",
    "try:\n",
    "    print('Deleting previous decoder...\\n')\n",
    "    D.close()\n",
    "except:\n",
    "    print('Setting up...\\n')\n",
    "#D = DECODER(myID,num_classes=8,datashape=100,batch_size=200,learning_rate=0.001)\n",
    "D = DECODER(myID,num_classes=16,datashape=100,batch_size=200,learning_rate=0.001)\n",
    "\n",
    "load_model_safeguard_disengaged = False\n",
    "if load_model_safeguard_disengaged:\n",
    "    D.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "(60000, 100)\n",
      "(60000, 1)\n",
      "Loaded 60000 data samples and corresponding labels\n",
      "\n",
      "Launching training with 59600 steps\n",
      "\n",
      "Iteration 0 out of 59600\n",
      "Training step  0  --> Real class:  [[  7.   6.   1.  13.   1.   9.   4.   9.   9.   5.  15.   0.   4.  14.\n",
      "   15.   1.  13.   7.   3.   9.  10.  12.  10.  10.  13.  12.   4.  15.\n",
      "    5.   9.   2.   8.   4.  11.   1.   4.  14.  13.   9.   1.  13.  12.\n",
      "    2.   6.   8.  13.   5.   2.  11.   8.  12.   7.  15.   8.  14.  15.\n",
      "   15.  10.  13.  13.   3.   8.  13.  14.  10.  12.  13.  14.  12.   9.\n",
      "   14.   7.   4.   5.  10.   1.  12.   5.   7.  11.  15.   6.   4.   7.\n",
      "   10.   1.   2.  14.  11.  14.   7.   6.  10.   3.   6.  14.  13.   2.\n",
      "   15.  13.  10.   4.  12.   7.   8.  11.  13.  10.   0.   2.  14.   8.\n",
      "    8.   8.   9.   9.  11.   0.   5.   1.  14.   3.  10.  14.   8.   2.\n",
      "    4.  10.  13.  13.   1.   5.  12.  12.   8.  14.  11.   0.  12.   8.\n",
      "    9.  15.  11.  15.  10.  12.  11.   9.   3.  15.  13.   4.   3.   1.\n",
      "    3.   3.   8.  13.   5.   6.   5.  15.  14.   2.   7.  15.   4.   5.\n",
      "    6.  14.   8.   7.   9.   9.   9.   6.   3.   4.   4.   3.  14.  12.\n",
      "   12.   4.   0.  12.  11.  13.  13.   9.   9.  12.   2.   4.   1.  13.\n",
      "   13.   8.   7.   9.]] , prediction:  [ 7 11  7  7  7  7  7  7  7  7  7  7 11  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7 11  7  7  3  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7]\n",
      "Training step 0 --> loss=2.923683\n",
      "\n",
      "Iteration 200 out of 59600\n",
      "Iteration 400 out of 59600\n",
      "Iteration 600 out of 59600\n",
      "Iteration 800 out of 59600\n",
      "Iteration 1000 out of 59600\n",
      "Training step  1000  --> Real class:  [[ 11.   6.   2.   4.   9.   1.   2.  14.  11.  10.   9.   9.  12.   1.\n",
      "   12.  14.   8.   5.  13.   9.  13.   9.  14.   4.   1.  11.  10.  11.\n",
      "   12.   4.  12.   9.   9.   7.   6.  14.   7.   2.   9.  12.   2.   3.\n",
      "   11.  13.  13.   7.   3.   1.   0.   3.  15.   6.  15.   3.  14.   7.\n",
      "    1.   8.  10.   8.   6.   8.   7.   9.   5.   7.   2.   3.  11.   2.\n",
      "   12.  12.   7.   2.  14.  15.  14.   1.   2.  14.   0.   6.  13.   6.\n",
      "    1.   7.   6.  15.  11.  14.   7.   4.   6.   3.   4.  15.   0.   7.\n",
      "    3.  12.   2.   1.  14.   1.   5.   2.  13.  10.  15.   1.   4.   5.\n",
      "    2.   7.   0.   2.   0.  15.   8.  12.  12.  15.   7.   9.  12.  11.\n",
      "   11.   7.   3.   5.   6.  11.   3.   9.   5.   9.  15.   7.  11.  12.\n",
      "    9.   9.   8.  14.  11.   1.  13.   7.   3.  14.   1.   9.   2.  14.\n",
      "   13.   8.   6.  13.   6.   2.   7.  15.   9.  15.   1.   5.   9.   2.\n",
      "    0.  12.  10.  15.  11.  12.  14.   3.  15.  13.  12.   7.   1.  13.\n",
      "   15.   8.  15.  14.  14.   5.  12.  12.   4.   9.  12.   5.  15.  11.\n",
      "    5.   1.   2.   0.]] , prediction:  [ 8  8 13  8  8  8  8 13  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8 13  8  8  8  8  8  8 13  8  8 13  8  8  8  8 13  8  8  8  8  8  8 13\n",
      " 13 13  8  8  8  8  8  8  8  8 13  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  3  8  8  8 13  8  8  8 13  8  8  8  8  8  8  8  8 13  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8 13  8  8 13  8 13\n",
      "  8  8  8  8  8  8  8  8  8 13 13  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8 13 13  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8 13  8  8  8\n",
      " 13 13  8  8  8  3  8  8  8  8  8 13  8 13  8  8  8  8  8  8  8  8  8  8  8]\n",
      "Training step 1000 --> loss=2.855391\n",
      "\n",
      "Iteration 1200 out of 59600\n",
      "Iteration 1400 out of 59600\n",
      "Iteration 1600 out of 59600\n",
      "Iteration 1800 out of 59600\n",
      "Iteration 2000 out of 59600\n",
      "Training step  2000  --> Real class:  [[  9.   2.   7.  14.   6.  14.  14.   3.  13.   6.   4.  14.   7.   9.\n",
      "   14.   1.  12.  14.   3.   7.   3.   2.   1.   7.   4.  12.  14.  13.\n",
      "    1.   6.   5.  15.   5.  13.  10.   3.   5.   7.   9.   0.   7.  13.\n",
      "   13.  12.   7.  12.   8.  10.  13.  14.  14.   4.  11.   7.  12.   5.\n",
      "    8.   1.   3.  12.  11.  12.  10.   4.   5.  13.  13.   1.   2.   6.\n",
      "   14.  13.   3.   9.   1.   7.  11.   7.   0.   3.  13.   7.   7.   4.\n",
      "    8.   5.   8.  13.  14.   5.   2.  14.   1.   6.  10.   6.   8.   3.\n",
      "    4.  11.   3.  15.   2.  14.   4.  15.   9.   2.   3.   8.   0.  11.\n",
      "   13.   8.   1.  11.   7.   3.   3.  15.   8.   4.  14.   6.  12.   9.\n",
      "   13.  13.   8.  14.  12.  13.  15.  15.  15.  10.  12.  10.   1.  14.\n",
      "    2.   9.   4.   3.   3.   5.   6.  14.  14.   5.  12.  10.   4.  14.\n",
      "   13.   3.   2.   1.   8.   5.  15.   7.  10.   9.  13.   5.  14.   0.\n",
      "    1.  15.   2.   2.   6.   9.  13.  15.  12.   4.   2.  15.   8.   7.\n",
      "    6.   9.  13.   3.  12.   5.   0.   9.  14.   7.   2.   3.  12.   7.\n",
      "   11.   9.   1.  10.]] , prediction:  [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2 12  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 12  2  2  2  2 12  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2 14  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2 14  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2]\n",
      "Training step 2000 --> loss=2.753527\n",
      "\n",
      "Iteration 2200 out of 59600\n",
      "Iteration 2400 out of 59600\n",
      "Iteration 2600 out of 59600\n",
      "Iteration 2800 out of 59600\n",
      "Iteration 3000 out of 59600\n",
      "Training step  3000  --> Real class:  [[ 10.  13.   9.   7.  15.  11.  10.   8.   6.   1.   9.   6.   7.  12.\n",
      "    6.   5.  10.  15.  14.   4.   1.  14.  15.   5.  10.   8.   4.  10.\n",
      "    9.   6.   1.  12.   7.  14.  11.  14.  13.  10.   8.   1.   7.   6.\n",
      "   11.   7.  15.  14.   4.   9.   5.  11.  14.  13.   9.   7.  10.  10.\n",
      "   12.  10.   3.   4.  10.   2.   3.   7.   7.   0.  10.   8.  14.   3.\n",
      "    1.  13.  10.   0.  14.   9.  10.   3.   2.  15.   2.   3.   4.   4.\n",
      "    6.  12.  11.  11.   5.  10.  10.  13.   3.   2.   0.   8.  13.  13.\n",
      "    6.   4.  15.  11.  15.  11.   9.  11.   7.  14.   2.  15.   8.   9.\n",
      "   13.  15.  15.   1.  15.   5.  12.  12.   8.  10.  12.   8.  15.  13.\n",
      "   12.   8.  12.   5.   4.   8.  12.   3.   9.  10.  15.   8.  11.   3.\n",
      "   15.   2.   1.  14.  11.   9.   2.   1.   5.   3.   3.  15.   0.  10.\n",
      "    8.   7.   3.  11.  10.   2.  13.  15.  13.   2.   5.   5.   1.  10.\n",
      "   15.  11.  15.  13.   6.  14.  13.  14.   8.   5.  14.  12.   6.   3.\n",
      "    2.   9.  11.  11.  12.   6.   6.   8.  10.  10.  15.   4.  11.   7.\n",
      "   12.   7.  14.   9.]] , prediction:  [ 3  3  5  5  3  5  3  5  3  3  5  3  3  5  3  5  3  3  3  5  3  3  3  3  5\n",
      "  3  5  5  5  5  3  5  3  5  3  5  5  3  5  3  3  3  3  3  3  3  5  3  5  3\n",
      "  5  5  3  3  5  3  3 14  3  5  3  3  3  3  3  3  3  5  5  3  3  5 14  3  3\n",
      "  5  5  3  5  5  3  3  5  5  5  5  3  5  3 14  3  5  3  5  3  3  5  3  3  5\n",
      "  3  5  3  3  3  5  3  3  3  3  3  5  3  3  5  3  5  5  5  5  5  3  3  3  5\n",
      "  3  3  5  5  5  5  5  5  3  3  5  3  3  3  3  3  3  3  5  5  3  3  3  5  3\n",
      "  3  3  5  5  3  5  3  3  3  5  5  3  5  5  5  5  3  3  3  3  5  5  5  5  5\n",
      "  5  5  3 14  5  3  3  3  5  3 14  5  3  3  5  5  5  5  3  3  3  5  3  3  3]\n",
      "Training step 3000 --> loss=2.707146\n",
      "\n",
      "Iteration 3200 out of 59600\n",
      "Iteration 3400 out of 59600\n",
      "Iteration 3600 out of 59600\n",
      "Iteration 3800 out of 59600\n",
      "Iteration 4000 out of 59600\n",
      "Training step  4000  --> Real class:  [[ 10.   9.   8.   6.   5.   9.   1.   1.   6.   1.  13.   9.  10.   1.\n",
      "   15.   9.   9.   5.   3.  13.  11.  13.  12.  14.  14.   3.  13.  12.\n",
      "   12.  15.   2.  15.   4.  14.   2.   6.  13.  14.  12.  15.   3.   0.\n",
      "   11.   1.  14.   3.  13.   7.   3.   3.   9.   3.   2.   6.   7.   1.\n",
      "    8.   0.   6.   1.  12.   7.  12.   3.  12.   8.   3.   2.   9.  15.\n",
      "   15.   4.   9.   2.   4.   4.  10.   6.  10.   3.   8.   0.  14.  13.\n",
      "    5.   1.   3.   1.   4.   8.   1.   4.   5.   2.   1.   0.   1.   9.\n",
      "    9.  13.   5.  13.   8.   6.  15.  11.   1.  10.   5.   1.   2.   9.\n",
      "   15.   6.  13.  13.   6.   8.   3.   8.   1.   5.   1.   7.  15.   0.\n",
      "    4.  15.  15.  15.  13.   5.   4.  10.   6.  10.   8.   6.   3.  15.\n",
      "    6.   7.   4.  13.   1.   1.   2.   3.   2.   4.  11.   8.  15.   0.\n",
      "    6.   2.   9.  15.  13.  11.   7.   4.   1.   2.   7.  12.   2.   8.\n",
      "   11.   6.   6.   1.   0.  11.  13.   3.   8.  14.   7.   2.  11.   9.\n",
      "   10.  13.  10.   9.  14.   3.   7.  13.   2.   6.  10.  11.   4.  10.\n",
      "   13.   0.   0.   8.]] , prediction:  [15 15  8  3 15 15 15 15 15 15 10 15 15 15 15 15 15 15 15 15 15 15 15 10 15\n",
      "  3 10 15 15 15 15 15 15 15 15 15 15 10 15 10 15 15 15 15 10  3 15 15 10  3\n",
      " 15 15 15 15 15 15 15  8  3 15 10  3 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 10 15 10  3 15 15 15 15 10 15 15 15 15 15 15 15 15 15 15  8 15 15 15 15\n",
      " 10 15  8 10 10 15 15 15 10  8  3 15 15 15 15 15 10 15 15 15  3 15 15 15 15\n",
      "  8 10 15 15 10 10 10 15 10  3 15 15 10 15 15 15  3 15 15 15 15  3  3 15 10\n",
      " 15 15 15 15 11 15 15  3 15  3 15 15 15 15 15 15 15  8 15 15 15 15  8 15 15\n",
      " 15  8 15  3 15 10 15 10  3 15  8 10 15 10 10 15 15 15 10 15 15 15 15  8 15]\n",
      "Training step 4000 --> loss=2.687761\n",
      "\n",
      "Iteration 4200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4400 out of 59600\n",
      "Iteration 4600 out of 59600\n",
      "Iteration 4800 out of 59600\n",
      "Iteration 5000 out of 59600\n",
      "Training step  5000  --> Real class:  [[  5.  12.  12.   9.   9.  15.   6.   6.   2.   0.   3.   6.  13.  12.\n",
      "   15.   9.   6.  15.  15.   0.  10.   2.   5.   2.   2.  14.   3.   1.\n",
      "    9.   8.  14.   8.   1.   5.  10.  15.   0.  12.  12.   6.   9.   0.\n",
      "    7.   7.   8.   3.   4.   6.   7.   7.   3.  10.  11.   4.  15.  13.\n",
      "    3.   6.  10.  11.   5.   1.   7.   5.   2.   0.  14.   1.  15.   9.\n",
      "   13.   4.  12.   2.  11.   5.  13.  11.   3.   5.   6.   2.   3.   5.\n",
      "    5.  12.   9.   0.   1.  15.  10.   2.   7.   3.  13.   2.  15.  10.\n",
      "   14.  13.   1.  11.   6.   2.   6.   2.  14.  12.   4.   2.   4.  15.\n",
      "    3.  15.   8.   6.   0.  13.   6.  10.  13.  11.   5.   3.   7.   6.\n",
      "   13.  10.  14.   2.  14.   3.   4.   0.   4.   3.   2.   4.  14.   4.\n",
      "    1.   1.   2.  15.  13.  15.  15.   3.   8.  12.   3.  10.  14.   3.\n",
      "    2.  12.   5.   7.   1.   2.  15.   9.   7.   7.  14.   0.  12.  13.\n",
      "    7.  14.   1.  11.   8.  11.  15.  14.  11.   8.   6.  15.   2.  10.\n",
      "   10.   5.  13.  11.   1.   3.   8.   2.  14.  10.   5.   1.  15.   2.\n",
      "   13.   4.  13.   1.]] , prediction:  [ 6  6  6  6  9 14  6  6  2  8  3  3 14  6  2  8  6  6  3  8 14  6 14  6  6\n",
      " 14  2  9  1  6 14  4  8  6  2  6  8  4  6 14  6  8  3  3  8  6  7  6  6  6\n",
      "  6 14 11  6 14  6  6  3 11  9  6  9  6  6  6  1 14  9  6  9  6  4  6 14 11\n",
      "  6  6  3  3  6  3 14  6  6  6  6  6  8  8 14 14  6 14  6  6  6  6 14  6  6\n",
      "  8  6  6  6  6  6  6  6  6  6  6  6  2  6  6 14  8 14  3  6 14  3 14  6  3\n",
      "  6  6 10  6  6  6  3  6  8  4  6  6  6  6  6  8  9  6 14 14  3  3  6  8  6\n",
      "  6  6  6  2  6  4  6  3  3  6  6  6  3  6  6  8  4  6  6  6  2  2  6  3  2\n",
      "  6  2  8  6  6  6  6  2  6  6  3  9  6  8  6 14  2  6  8  6  3  6  6  3  3]\n",
      "Training step 5000 --> loss=2.640845\n",
      "\n",
      "Iteration 5200 out of 59600\n",
      "Iteration 5400 out of 59600\n",
      "Iteration 5600 out of 59600\n",
      "Iteration 5800 out of 59600\n",
      "Iteration 6000 out of 59600\n",
      "Training step  6000  --> Real class:  [[ 13.  11.   4.   3.   7.  11.  10.  11.  11.  13.  15.   6.   2.   4.\n",
      "    3.  13.  11.   7.   4.  14.   7.   5.  10.   3.   5.  10.   4.  11.\n",
      "    2.   5.  11.  11.   5.   1.  10.   9.   5.  11.   1.  14.   9.   9.\n",
      "    9.   3.  14.  10.   3.   7.   4.  11.   3.   3.   8.  13.  11.  10.\n",
      "   10.  14.   1.  13.   1.  15.  14.   9.  10.  10.   1.  10.   0.  13.\n",
      "    1.   7.   2.  12.  10.   8.   7.  10.   6.   6.  13.   2.  12.   4.\n",
      "    5.   3.   7.   6.  12.   0.   3.   7.   6.   2.  11.   9.   5.  11.\n",
      "    3.  11.  15.   6.  13.   4.   9.   6.   0.   1.   6.   4.   2.   3.\n",
      "   14.   3.  13.   7.   8.  11.   4.   5.   0.   5.   9.  14.   6.   1.\n",
      "   12.  11.   0.   2.  15.  14.  10.   0.   5.   5.  13.  14.   8.   5.\n",
      "    5.  10.  13.  13.   6.  15.  12.  12.  10.   4.   5.   8.   7.   6.\n",
      "   13.  15.  15.  10.  11.  12.   2.   8.   2.   6.  14.  14.  12.   9.\n",
      "    8.  11.   9.  11.  10.   3.  10.   5.   8.   3.  10.   6.   4.   0.\n",
      "    3.  12.   1.   8.   8.  10.   8.  11.   1.   4.   6.   1.   6.   6.\n",
      "    6.   2.   7.   4.]] , prediction:  [10  2 12  2  6  3 10  3  2 10 14  6  2  6 10  5  2 10 14 14  3  6  3 10  3\n",
      " 10 10 10 10 10 10  3  7  1  1  1  6  2  3 14  2 10 12  3  2 10  3  5  3  2\n",
      "  3  2 12 10 10  2  2 14  3 12  3 14 10  2  2  2  2 10 12 12  3  3  2 14 10\n",
      " 10  3  2  6 14  7  2  7  5  5  3  3 14 12  8  3 14 10  2  3  2  7  2  2  3\n",
      " 14 14 12  6  1  3  1  1  3 10 10  3 14  2  6  3  1  3 14  5 12  3  1 14  6\n",
      "  3 10  3 12 10 14  7  2  1  3  5  3  7 12 10  2 10 10  5  3  3 12 12  1  6\n",
      " 10 12  3 10  7 10 10 14 10 12  2  1  2 14  3 10 14  1  8 10  2  2 10  2  2\n",
      "  7  1  3  2  6  6  2  2 12  2  1  1  2 12  2  3  6 14  1 14  5 14  2 10  6]\n",
      "Training step 6000 --> loss=2.526022\n",
      "\n",
      "Iteration 6200 out of 59600\n",
      "Iteration 6400 out of 59600\n",
      "Iteration 6600 out of 59600\n",
      "Iteration 6800 out of 59600\n",
      "Iteration 7000 out of 59600\n",
      "Training step  7000  --> Real class:  [[ 14.   5.   5.   8.   8.  12.   7.   3.   1.  10.   2.  13.   5.   2.\n",
      "   14.   5.  10.   0.  10.   4.   2.  10.   1.   4.   2.   6.  11.   1.\n",
      "    2.   2.   3.   3.  14.  13.   6.   0.   7.   2.  10.   1.   7.  13.\n",
      "   15.   6.   1.  11.   8.  15.   6.  12.   2.   5.   4.  14.  10.   4.\n",
      "    7.  11.   4.   0.   2.  10.   5.   9.   9.   2.   8.   8.   9.   2.\n",
      "   10.   7.   7.  15.   4.  13.   2.  11.   6.  11.   4.  11.   1.   7.\n",
      "    2.  10.   2.   9.   4.   2.   8.   8.  14.  13.   4.  11.   6.   5.\n",
      "   12.   2.   8.   5.   2.   1.   3.  13.   1.   2.   0.  11.   9.  14.\n",
      "   14.   0.  14.   9.   2.   6.   6.  11.   9.  13.   1.   5.   1.  10.\n",
      "   10.   8.  14.   2.   2.  10.  11.  12.   4.   2.   1.   5.   0.  14.\n",
      "   14.  13.   7.   5.   7.  10.   9.   2.  12.   0.   3.  10.   1.   0.\n",
      "    2.   5.  15.   3.   5.  10.   6.  15.   3.  12.   9.  14.   4.  14.\n",
      "   14.   9.   7.  10.   8.   9.   3.   6.  13.  10.  13.   9.  11.  14.\n",
      "    7.   4.   7.  12.   5.   0.   1.   4.   6.   5.   8.  15.   9.   2.\n",
      "    9.   2.   4.   3.]] , prediction:  [10  7  7 12  1 12  6  1  1 10  3 10  5 10  7  6 10  1 10 13  2 12  1  4  3\n",
      "  6 10  1  2  2  3  3 10 12  6  1 10  2 10  1  3 12 14  6  9  1 10  3  3  4\n",
      "  2  3  4  6  3 10 10 10  6  1 10 10  7 12  1  3  1 12 10  2 10  6 10 13  4\n",
      " 12  2 10  3  3  4 10  1  3  3 10  2 12  4  2  1  1 14 13  4 10  6  3  0  3\n",
      "  1 13 10  1  3 10  9  3  1 10 12 14 10  1 13  1  3 10  6 10 12 10 12 10 12\n",
      " 10  7  1  7  2  3  1  3 13  4  1  1 13  1 14  7 10  6  6  3 12  1  2  4  1\n",
      "  3 10 10 12 10 13  3  2  5 10  7  7  3  4 12  7  7  7  7  1  6 10 12 13  3\n",
      "  6 10 12  1  1 10 14  6  4  6 10 12  1 12  4 14 10  1  7  1  2  9 10  4  3]\n",
      "Training step 7000 --> loss=2.385384\n",
      "\n",
      "Iteration 7200 out of 59600\n",
      "Iteration 7400 out of 59600\n",
      "Iteration 7600 out of 59600\n",
      "Iteration 7800 out of 59600\n",
      "Iteration 8000 out of 59600\n",
      "Training step  8000  --> Real class:  [[  9.  11.  12.  13.  10.   4.   9.   9.  14.   2.  15.   7.   8.  13.\n",
      "   14.  12.   7.   4.   4.  15.   7.   2.   4.  10.   9.  13.   5.   0.\n",
      "   14.   8.  12.   8.  15.   1.  11.   3.   8.   5.   2.  11.  11.   8.\n",
      "    0.   9.   4.   4.   4.  11.   1.  11.   6.   2.  11.   7.   9.   4.\n",
      "    2.  13.   5.  15.  15.  10.   3.  11.   7.   7.   7.   7.   8.   3.\n",
      "    7.  14.   2.   2.   3.  14.   5.   2.   3.   1.  14.  11.   9.   9.\n",
      "   14.  14.   4.   5.  14.   8.  12.   7.  10.  14.   9.  13.   0.  12.\n",
      "   15.   1.   2.   4.  11.   7.  14.   1.   7.  11.  12.   8.  10.   5.\n",
      "    8.  13.   3.   7.  13.   5.   7.   8.   1.   2.   7.   8.  11.   2.\n",
      "    2.  11.  13.   7.   1.   9.   4.  12.  15.  14.   9.  12.   5.   6.\n",
      "   14.   6.   9.   3.   7.   5.  10.  10.  10.  14.   9.  11.   2.   5.\n",
      "    6.  15.  15.   9.   9.   7.  13.   8.   8.   1.  11.   9.   6.  14.\n",
      "   13.  12.   3.   0.   5.   4.  12.   7.  11.  15.   1.  11.  11.   5.\n",
      "    7.   5.  13.   2.  11.  10.  14.   4.   1.  15.   6.   0.   2.  15.\n",
      "    8.   3.  11.  12.]] , prediction:  [10  3  4 13 10  4 10 10  6  3  7  5  0 13 14  4  7  4  4  7 13  2  7 10  8\n",
      " 13  4  8 14  8  4  8 13  1 10  3  4  4  3  3 15  1  1 10  4  4  4 10  9  3\n",
      "  7  2 10 13  8  4  3 15  6 15  7 10  2  3 13  3 13  5  8  3  3 14 10  2  3\n",
      " 13  4 10  1  1 10  3 10  8 10 14  4  7  7  8  4 13  8  7  8 13  8 13  7  1\n",
      " 10 13 10  7  7  1  6 10  0 13 10 13  8 13  3  3 13  6  3  4  9  7  6  8  7\n",
      "  2  3  2 13  6  1  8  4 13 10 10 15  7  7 13 14 13  9  3  7  4 10 10 10  6\n",
      "  8 10  8  4  6 15 10  1 10  6  1  4  8  1 10 10  6  7  4  8  3  8 13  4 14\n",
      " 13 10  7  9  9 10  7 10  4 13  2  7 10 13  4  9  7  6  1  2  7  8  1  3  4]\n",
      "Training step 8000 --> loss=2.173882\n",
      "\n",
      "Iteration 8200 out of 59600\n",
      "Iteration 8400 out of 59600\n",
      "Iteration 8600 out of 59600\n",
      "Iteration 8800 out of 59600\n",
      "Iteration 9000 out of 59600\n",
      "Training step  9000  --> Real class:  [[  4.  14.   0.   1.   9.   8.   6.   4.   1.   7.  10.   4.   2.  11.\n",
      "    8.   1.  12.  12.   6.  14.   5.   5.  11.   3.   8.   1.  10.   1.\n",
      "   14.   2.  11.  12.   9.  11.   7.   9.   4.   3.  12.  13.   4.   6.\n",
      "   14.   2.   2.  10.   8.  13.   6.  15.  14.   5.   2.  10.  15.   8.\n",
      "    6.   3.   8.   2.  13.  10.  14.   5.   6.  12.   4.   6.   2.   8.\n",
      "    2.  13.   4.   9.   7.   9.   9.   7.   2.   0.   1.   1.   6.   1.\n",
      "   11.   3.  10.  11.   3.   5.   1.   5.   2.  10.   0.   1.   4.   6.\n",
      "    6.  14.   8.  12.   1.   8.   9.   7.  14.  13.   3.  15.   9.   4.\n",
      "    6.   8.   6.  13.   4.  15.  10.   4.  12.   1.   7.  10.  15.   6.\n",
      "    8.  14.  13.   8.   2.  10.   2.   9.  13.  11.  11.  10.   0.  15.\n",
      "    6.  14.   2.  10.   3.  11.  14.   1.   8.   4.  12.  11.  14.  14.\n",
      "   13.   2.  10.   6.  11.   7.  11.  12.   9.   5.  14.  10.  14.   5.\n",
      "    4.  10.  12.   6.   2.  10.   1.  11.  13.  13.  13.   4.   5.  11.\n",
      "    5.   4.  10.   2.   1.   1.  13.  11.   4.   3.  14.   8.   9.   9.\n",
      "   10.   5.  14.   4.]] , prediction:  [ 4 13  8  8  8  8 13  8  9 10  2  4  3 11  8  1 10  4  7 10  4 13 10  3  8\n",
      "  1 10  1 14 10 10  4 13 10  3  9  4  2 13  4  4 10 14  3  3 10  8 15  7  3\n",
      " 10  3 10 10 15 12  6  3  8  3 13 10 10  4  7  4 13  6  3 12  3  4  6  1  3\n",
      "  8 15  3  8  8  1  1  7  8 10  3 10 11  3  7  1 10 10 10  8  8  4  6 13 13\n",
      "  8  4 11  4  9  3 14  1  3  7  8  4  2  8 14 15  4  7  2  4  4  9  2 10 11\n",
      "  4  8 15  9  8 10 10  2  8 13  3 10 10  8 15 10 10  2  8  2 11 13  9  8  4\n",
      " 10 10 10 10 15 10 10 13 11  6 10 12 15 13  7 15 10 13 13 10  4  6  3 10  8\n",
      " 10  0 13 14  4  4 10 13  4 10  2  1  8 12  2  6  3 10 15  9  8  2  5 13  4]\n",
      "Training step 9000 --> loss=1.881076\n",
      "\n",
      "Iteration 9200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9400 out of 59600\n",
      "Iteration 9600 out of 59600\n",
      "Iteration 9800 out of 59600\n",
      "Iteration 10000 out of 59600\n",
      "Training step  10000  --> Real class:  [[ 14.   3.  11.   7.   2.  12.   5.  10.   5.   7.   3.   8.   4.  11.\n",
      "   12.   7.  12.   8.   1.   9.   5.  10.  10.   3.  13.   4.  15.   3.\n",
      "    8.   9.  15.  15.   0.  12.   5.  13.   3.   7.  13.  10.   7.   9.\n",
      "    6.   7.  15.  15.   2.  13.   6.   2.  14.   6.  14.   4.   5.  12.\n",
      "    3.   7.  15.  11.   9.  12.  14.   8.   5.   9.   5.  12.   7.  11.\n",
      "    3.   8.  15.  15.   9.   7.   1.   8.   9.  10.   4.  13.  14.   1.\n",
      "    1.   5.   7.   6.   3.  15.   9.   1.  14.  12.   2.   1.   5.   7.\n",
      "    3.   9.  10.  14.   5.   1.  10.   8.  11.   8.   9.   7.  12.   5.\n",
      "   13.  11.   5.   7.   3.   1.   4.   7.   8.  13.  13.   2.  10.   6.\n",
      "    8.  12.   4.   9.  12.   3.   1.   6.  10.   3.  10.   4.   9.   4.\n",
      "    0.  15.   5.  15.   2.   6.  14.   4.  15.  15.  13.  12.  11.   8.\n",
      "    4.  15.  12.   8.   4.   9.   1.   5.  13.   1.   7.  12.   9.   0.\n",
      "   11.  13.   6.  12.   4.   6.   4.   0.  11.  14.   3.  11.  15.  12.\n",
      "    1.   6.  15.   3.   1.  15.   6.   1.   4.   6.   7.   2.   8.   1.\n",
      "    4.  15.  15.  13.]] , prediction:  [14  3 11  7  2  0  4  9  4  5  1 12  6 11  8  7  4  8  1  8  5 10 14  3  9\n",
      "  4 11  3  8  9 14 14  8  4  4 14  1  7 12  7  6  9  6  7  7  7 11 11  6  2\n",
      " 14 11 14  4  5  6  3  7 14  7 11 12 14  1  4  9  5  0  3 11  2  8  7 14  9\n",
      " 14  1  8  8 11  4  5 14  1  1  5  3  6 11  7  8  1 14  8  2  9  5  7  2  8\n",
      " 14  7  4  8 14  8 11  8 11 14 12  5 15  9  5  7  3  1  4  6  8  4  9  2  9\n",
      " 14  8 14  4  9 14  2  1  6  8  3 14  4  9  4  8  7  5  7  2  7 14  6 14  7\n",
      "  9  8 11  8  6  1  1  8  4  9  1  5 13  1  5 12  9  8 11  1 14  4  4 14  4\n",
      "  1 11 14  3 11  7 14  1  6  7  2  1 14  7  9  4  4  6 11  8  1  6  5  7  4]\n",
      "Training step 10000 --> loss=1.625160\n",
      "\n",
      "Iteration 10200 out of 59600\n",
      "Iteration 10400 out of 59600\n",
      "Iteration 10600 out of 59600\n",
      "Iteration 10800 out of 59600\n",
      "Iteration 11000 out of 59600\n",
      "Training step  11000  --> Real class:  [[  1.   3.  13.  10.   7.   0.  11.   4.  14.  15.  11.   1.  10.  12.\n",
      "   14.   3.   2.  12.  15.   3.   0.   8.   3.  14.   3.  15.  11.   2.\n",
      "   15.   6.  11.  15.   4.   5.   5.   9.  11.  15.   3.   6.   5.   1.\n",
      "    3.   7.   6.   5.   8.   1.   6.   6.  13.  15.  10.  13.  14.  11.\n",
      "    8.   3.   0.   5.  14.  14.   6.   6.   6.   1.   6.   3.   2.   3.\n",
      "   13.  13.   8.  15.   1.   7.  12.   3.   3.   1.   8.   9.  14.  15.\n",
      "    5.  12.  13.   4.   5.   3.  12.  14.  14.   7.  15.   0.  13.   9.\n",
      "    2.  11.  11.   8.   6.   3.  14.  10.   9.  12.   8.  13.  11.   7.\n",
      "   12.  14.   8.  14.  15.   3.  10.  10.  12.  10.   4.   9.   2.   1.\n",
      "    6.  15.  12.   3.   6.  15.   7.  11.   8.   6.  14.  10.  13.  13.\n",
      "    9.   3.   7.   2.   8.   9.  14.   5.  13.  10.  10.  12.   8.  11.\n",
      "   13.  11.   6.  14.  11.  13.  14.   3.  13.   9.  15.   3.   1.   1.\n",
      "    1.   7.  13.   6.  13.   6.   4.   9.   8.   8.   7.   5.   4.  14.\n",
      "   13.  12.   7.  11.  15.   1.  14.   7.   7.   3.  14.   5.  13.   2.\n",
      "   15.   4.  15.  12.]] , prediction:  [ 9  3 13 10  6  0 11 10 10 10 15  9 10  8 14  7  3 12  7  2  0  8  3 15  2\n",
      " 10  7  2  7 10 11 15 14  9  4  9 11 15  2 14  5  1  3  6  6 10  8  1  2  6\n",
      " 15  6 10 13 10 11  0  3  0  4 10 14  6  6  6  9  6  3 10  2 12 15  8  6  1\n",
      "  7 12  2  3  1  8  9 10 15  5 12 12  4  5  3 12 14 10 15  7 12  5 10  2  1\n",
      " 10  8  6  3  7 10  8 12  8 13 11  7 12 12  8 14 15  3  8 10 12 10  4  9 10\n",
      "  9  6  6  4  3  6 14  3 10 12 10 13 10 15 15  9  2  6  2  8  9 15 13  9 10\n",
      " 10 12 12 11  5 11 13 10  7 10 10  3  5  9 15  2  9  1  1  5 12  3 10  6  4\n",
      " 11  8  8  6  4  4 15 15 12  6 10 15  1  6  7  3 11  4  6 13  2 15  4 15  4]\n",
      "Training step 11000 --> loss=1.451105\n",
      "\n",
      "Iteration 11200 out of 59600\n",
      "Iteration 11400 out of 59600\n",
      "Iteration 11600 out of 59600\n",
      "Iteration 11800 out of 59600\n",
      "Iteration 12000 out of 59600\n",
      "Training step  12000  --> Real class:  [[  9.   7.   6.  11.   1.  11.   9.   8.   4.   9.   7.   2.  10.  15.\n",
      "   13.   8.   5.   7.   6.  11.   5.   9.   6.   6.   3.   6.  15.  11.\n",
      "   10.   3.   1.  15.  14.  15.   9.  15.  10.   2.   1.  13.  12.   2.\n",
      "    2.   1.  12.   4.   0.  14.   6.   5.  13.   6.   0.   5.   8.   2.\n",
      "    2.   6.   2.   0.   4.   5.   8.  11.  15.   7.  13.   9.   9.  14.\n",
      "   10.   0.  14.   9.   3.   8.   2.  14.  10.  12.   9.   2.   7.   2.\n",
      "    9.   0.   6.   7.   1.  13.   0.  10.  14.   0.  11.  14.  10.   2.\n",
      "    6.   5.   1.   5.  13.   3.  13.   9.   9.  13.   7.   3.   8.   1.\n",
      "   14.   7.  12.   4.   4.   0.   7.  15.  12.   8.   3.   6.  13.   7.\n",
      "    7.   6.   9.   8.  12.   3.   4.   4.   8.  12.   4.  13.   7.   5.\n",
      "    4.   9.   4.   1.  12.  11.  12.   7.  12.  14.  12.  14.   4.  11.\n",
      "   13.  14.   1.  12.   5.  14.  13.  12.   6.  13.  15.  10.  10.  15.\n",
      "    6.  11.  11.  11.   2.  11.  12.  14.   1.  14.  11.   5.  12.  15.\n",
      "    4.  15.   1.   6.   6.   0.   8.  15.   4.  12.   7.   6.   8.  14.\n",
      "    7.   2.   3.  13.]] , prediction:  [13  7 15 10  1 11  9  8  4  1 15  2 10 15  9  8 13  7  6 11 15 13  6  6  3\n",
      "  6 14  3 10  3  1 15 15 15 13 14 14  3  1 15  4 10  2  9 12  4  0 14  6 15\n",
      " 15 14  0 15  8  2  2  7  2  8  6 15 12 11 15  7 15  9  8 15  8  0 14  9  3\n",
      "  8  2 15  8 12  9  3  6  3  9  0 14 15  1 15  8 14 15  0 11 15 10  1  6 15\n",
      "  1  1 15  3 15  9  9  1  7  3  8  3 14  7 12  4  6  0  6 15 14  8  3  6 15\n",
      " 15  7  6  9  8 12  3  4  0  8 12  4 13  6  5  4  9  4  1  8 15 12  3 12 14\n",
      " 12 12  4 11 14 14  1  4  4 15 13 12  6  9 15  1 10  7 15 10 11 14  2 10  0\n",
      " 14  1 14 11 15 12 15 14 15  1 14 14  0  8 15  4 14 15 14  8 14  7  3  3 13]\n",
      "Training step 12000 --> loss=1.245240\n",
      "\n",
      "Iteration 12200 out of 59600\n",
      "Iteration 12400 out of 59600\n",
      "Iteration 12600 out of 59600\n",
      "Iteration 12800 out of 59600\n",
      "Iteration 13000 out of 59600\n",
      "Training step  13000  --> Real class:  [[  7.   9.   4.   8.   6.   4.  10.  15.   7.  10.   2.   1.   2.   5.\n",
      "    8.  13.   8.   9.   4.   5.   3.  11.  11.   8.   9.  12.  14.  13.\n",
      "    3.   6.   4.  15.   5.  15.   5.  14.   5.  14.   2.   7.   3.  14.\n",
      "   12.   4.   5.  13.   2.  10.  10.   8.  13.  12.   9.  15.   7.  14.\n",
      "    4.   1.   7.   9.   3.   5.  14.  14.   5.  10.  11.   1.   6.  11.\n",
      "    4.   9.   7.  13.   9.   3.   7.  14.   2.   3.   9.   9.   9.   6.\n",
      "   13.   5.   8.   0.  15.  13.  13.  14.   6.  11.   3.   7.  10.   5.\n",
      "   14.  14.  14.   3.  11.   4.  12.   1.   1.   5.   8.   7.   9.  13.\n",
      "    7.   1.   8.  12.   2.   0.   3.  10.  11.   8.   9.   8.   8.  10.\n",
      "    7.   4.  10.   8.  12.   1.   0.   3.   4.   9.   3.   7.  14.   5.\n",
      "    7.   7.   5.  14.   8.   7.   6.   6.  11.   4.   8.   5.  15.   4.\n",
      "   10.  11.  10.   1.   7.   8.   3.  13.   5.  15.  14.   4.   6.   0.\n",
      "    2.  13.   7.   2.  10.  14.  15.  11.   3.   2.  15.  15.   8.  15.\n",
      "    5.   2.  11.  14.   9.  15.   7.   2.   2.   4.   2.  15.   7.   2.\n",
      "    7.   4.  12.   9.]] , prediction:  [ 5  9  4 12  6  4 10 15  3 11  2  1  2  5  8 12 12  9  4  5 11 11 11 12  8\n",
      " 12 10 12  3  6  5 15  7  7  5 14  5 14 10  3  3 15 12  4  5  9  3  9 10 12\n",
      " 15 12  9 15 11 14  6  1  6  9 11  5 14 14  3  7 11  1  7 11  4  9  7  5  9\n",
      "  3  6 14 10  3  9 11  9  6  5  4  8  0 15  5  7 14  6 10  3  3 11  5 12 15\n",
      " 14 11 11  6 12  3  3  5  8  6  9 15  3  1  8 12  2  0  3 14 11  8  9  8  8\n",
      " 10  7  4 10  8  8  1  0  3  4  9  3  3 14  5  3  7  4 15  0  5  3  7 11  4\n",
      "  9  5 15  4 10 11 10  1  5  8  3 15  5 15 14  4  6  8  2 15  3  2  9 14  3\n",
      "  9  3  3 15 14  8  7  3  2 11 14 11  5  7  2  3  5  2  7  6  2  6  4 12  1]\n",
      "Training step 13000 --> loss=1.137625\n",
      "\n",
      "Iteration 13200 out of 59600\n",
      "Iteration 13400 out of 59600\n",
      "Iteration 13600 out of 59600\n",
      "Iteration 13800 out of 59600\n",
      "Iteration 14000 out of 59600\n",
      "Training step  14000  --> Real class:  [[ 13.  11.   9.  13.   4.   8.  13.  14.   3.  11.   2.   9.   4.   2.\n",
      "    7.   2.  13.   2.  13.   0.  12.  10.   9.   0.   7.  10.   6.   7.\n",
      "   13.  11.  12.  11.  11.  10.   4.  10.  11.  13.   7.  11.   0.   1.\n",
      "   12.  12.   1.   0.   1.   3.   2.   2.   4.   1.   6.  13.   5.   1.\n",
      "    7.   1.   2.  10.   6.   9.  14.   2.   3.   9.  14.  13.   2.   9.\n",
      "   14.   1.   8.   6.   1.   2.   9.  14.   5.  11.   0.  14.  11.  11.\n",
      "   10.  10.  13.   6.  11.   1.   3.  11.  10.   5.   1.  15.   7.  12.\n",
      "    4.   9.   7.  13.   3.   4.  14.   4.   6.   6.   3.   7.   1.   3.\n",
      "   13.  14.  11.  12.   5.   6.   7.   6.  15.  13.   3.  11.  13.   6.\n",
      "    4.   6.  15.  14.   1.   6.   6.   2.   8.   9.  12.  12.   6.  11.\n",
      "    6.   7.   9.   3.   5.   8.  13.   9.  10.   3.   4.   1.   4.  10.\n",
      "   13.   4.   1.  14.   2.   7.  13.  13.   1.   7.   1.   3.   9.  14.\n",
      "   13.   1.  13.   9.   4.   0.   3.  13.  12.   8.   5.  13.   1.   3.\n",
      "    3.  13.   8.   0.   4.  11.   0.  13.  14.  10.  13.  11.  15.  15.\n",
      "    6.   9.  13.   3.]] , prediction:  [12 10  9  9  4  8  5 14  3 11  2  9 13  2  5  2 13  1  9  8  8 14  9  0  7\n",
      " 10  5 15  5 11  4 10 10 10  4 10 10  5 15 15  0  9 12 12  1  8  1  2  2  2\n",
      "  4  1 14 13  4  1  7  1  2 10  5  9 14  2  1  8 14 13  2  9 14  1  8 14  1\n",
      "  2  8 14  5 11  8 14 11 10 10 14 13 14  7  1  3 11 10  5  1 14  7 12  4  8\n",
      "  7 13  3  4  5  4 14 14  3  7  1  3 13 14 11 12  5  6  3  6 11  5  3 10 12\n",
      "  6  6  6 15 10  1  6  4  2  8  9 13 12  6 11  6  5  1  7  5  8 13  9 10  7\n",
      "  4  1  4 10 13  4  1 14  2  7 13 13  1  3  1  3  9  7  5  1  5  9  4  8  2\n",
      "  9 12  8  5  5  1  3 15 13  8  8  4 11  8  5 10  8 13 11 15 14  5  9 13  3]\n",
      "Training step 14000 --> loss=0.942912\n",
      "\n",
      "Iteration 14200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14400 out of 59600\n",
      "Iteration 14600 out of 59600\n",
      "Iteration 14800 out of 59600\n",
      "Iteration 15000 out of 59600\n",
      "Training step  15000  --> Real class:  [[ 14.   8.  13.   7.  14.   1.  14.   1.   3.   5.   4.  14.   8.   5.\n",
      "    9.   3.  14.   6.   9.  12.   4.  15.   0.   1.  13.   5.   3.  11.\n",
      "    3.   2.  11.   6.   7.  11.   1.   6.   6.  10.  12.  14.  14.  10.\n",
      "    6.  12.   9.  10.   7.  10.  15.   1.   6.  14.   1.  12.   7.   4.\n",
      "    3.   6.   1.  12.  11.  10.  12.   5.  10.   7.   3.  14.   7.  13.\n",
      "    2.  15.   9.   9.  10.  15.  13.   9.   9.  15.   1.  15.  14.   2.\n",
      "   12.  10.   3.   1.   1.   4.  11.   1.  12.   2.  15.  10.   6.   6.\n",
      "   11.   8.   8.   3.   7.  11.  12.  13.  13.  10.  14.   6.  10.  13.\n",
      "   10.  14.   6.   7.   5.   2.   6.  15.   3.   5.   4.   3.   9.   3.\n",
      "    6.  11.  10.   6.  13.   4.   3.   2.   7.  10.   1.  12.  14.  14.\n",
      "   15.   3.   1.   0.  12.   5.   0.  11.  10.  12.  14.  13.   0.   2.\n",
      "    9.  14.   0.   8.  14.  11.  10.  12.  13.  13.   1.   7.   1.   8.\n",
      "    6.   4.  12.  12.  15.   1.   5.   2.  11.  10.  15.   2.   7.   6.\n",
      "   15.   6.  11.  12.  13.  10.   6.   3.  13.   2.  10.   8.   6.  13.\n",
      "   14.   1.  15.   1.]] , prediction:  [14  8 13  7 14  1 14  1  2  5  4 14  8  4 13  3 10  6  9 12  4 15  0  1 13\n",
      "  5  1 11  3  2 11  6  6 11  1  6  6 10 12 10 15 10  6  0  9 14  7 10 15  1\n",
      "  6 14  9  4  6  4  3  6  9 12 11 10 12  5 10  7  3 14  5 13  3 15  9  9 14\n",
      " 13 15  9  9 15  1 15 14 10 12 10 11  1  1  4  1  1 12  2  7 15  6  2  3  8\n",
      "  8  3  6  3 14 13 13 10 13  6 15 13 10 14  6  6  5  2  6 15  3  5  4  3  9\n",
      "  2  2 15 10  6 13  4  3  3  6 15  1  6 14  6 14  3  1  0 12  5 12 11 10 12\n",
      " 12  5  0  2  9 14  0  8 14 11 10 12 13  5  1  3  1  8  6  4 12 12 15  1  4\n",
      "  3  9 10 15  2  7  6  7  7 11 12  9 10  2  3 13  2 10 12  6 13  2  1  7  1]\n",
      "Training step 15000 --> loss=0.889821\n",
      "\n",
      "Iteration 15200 out of 59600\n",
      "Iteration 15400 out of 59600\n",
      "Iteration 15600 out of 59600\n",
      "Iteration 15800 out of 59600\n",
      "Iteration 16000 out of 59600\n",
      "Training step  16000  --> Real class:  [[ 11.   4.   9.   7.   8.   0.  14.  14.  11.   0.   1.  12.   6.  12.\n",
      "   10.   8.   4.  10.  15.   7.  13.   4.   5.  13.   1.   9.  10.   5.\n",
      "    5.  11.  11.   6.   6.   6.   4.  10.  10.   9.   7.   4.  12.   3.\n",
      "    4.  15.  14.  12.  14.  10.   6.   0.   8.   2.  14.   1.  13.  11.\n",
      "    1.   3.  15.   9.   6.  11.   5.   3.   9.   6.   6.  10.   8.   8.\n",
      "    4.  11.  10.   0.   1.   3.  15.   2.   9.   8.   1.  11.   3.  13.\n",
      "   15.  10.   5.  13.  15.  15.   1.   9.   2.  12.  12.   0.   9.   9.\n",
      "    2.  12.  13.   4.   0.   7.  13.   7.  11.  11.   4.  12.   4.  12.\n",
      "   15.  11.   5.   7.  15.  13.  11.   9.   6.   0.   6.   4.   5.  12.\n",
      "   10.   5.  10.   5.  12.   8.   2.   4.   2.   1.   3.  12.   6.  10.\n",
      "    2.   5.  11.   6.  10.   3.   8.  14.   3.   2.   0.   5.  13.  11.\n",
      "    3.   6.   5.   2.  10.   2.  12.  15.   8.  10.  12.   8.  11.   4.\n",
      "    1.  15.   1.   9.   9.  11.   9.  14.  13.  15.   5.  12.   1.  10.\n",
      "    3.   4.  10.  13.   8.   7.  15.   4.   2.   0.   7.  10.   4.   5.\n",
      "    4.  10.   7.  15.]] , prediction:  [11  4  9  7  8  0 15 10 11  0  9 12  6 12 15 12  5 10 14  7  5  4  5 13  1\n",
      "  9 10  5  5 11 11  6  6  6  4 10 15  9  5  4 12  3  4 15 14 12 14 10  6  0\n",
      "  8  2 10  9 13  3  1  3 10  9  6 11  5  3 13  4  4 10  8  8  4 11 10  0  1\n",
      "  3  6  2 13  8  9 11  7 13  7 10  5 13 15 15  1  5  2 12 12  0  1  8  2  8\n",
      " 13  4  0  7 13  7 11 13  4 12  4  8 15 11  5  7  7 12 11  9  7  0  6  4  4\n",
      " 14 10  5 10 13 12  8  2  4  2  1  2 12  6 15  2  7  7 13 10  3  8 10  7  2\n",
      "  0  5 13 11  3  6  5  3 10  2 12  7  8 13 12  8 11 13  1 13  1  9  9 11  9\n",
      " 14 13 15  5  4  1 13  3  6 10 13  8  7 15  4  2  0  7 10  4  5  4 10  7 13]\n",
      "Training step 16000 --> loss=0.759144\n",
      "\n",
      "Iteration 16200 out of 59600\n",
      "Iteration 16400 out of 59600\n",
      "Iteration 16600 out of 59600\n",
      "Iteration 16800 out of 59600\n",
      "Iteration 17000 out of 59600\n",
      "Training step  17000  --> Real class:  [[  2.   9.  15.   1.   9.   4.   5.   0.   4.  10.   7.   3.  13.  12.\n",
      "   14.   1.   6.  15.   5.   4.   4.   3.   3.  11.   1.   3.  12.   1.\n",
      "    6.   1.  13.   2.   8.  10.   7.  13.   6.   2.   3.  13.   2.   2.\n",
      "   10.  12.   4.   8.   6.   0.   0.  14.   8.  15.   3.   7.  15.   7.\n",
      "   11.   0.  15.   7.  11.  12.  10.   5.   3.   8.  13.   3.  15.   7.\n",
      "    3.   2.   9.   1.   8.  15.   8.   7.   1.   7.   7.   7.   4.   0.\n",
      "    7.  12.   7.   9.  11.  13.   2.  15.  15.  12.   1.   1.   5.   4.\n",
      "   12.   4.  13.  15.   1.   5.  10.  15.   4.   8.   3.   8.   3.  11.\n",
      "    3.   6.  10.   6.  13.  11.   4.  13.   8.   9.  13.   9.  15.  15.\n",
      "    1.   7.  12.  12.  10.   7.   0.   6.  11.   4.  13.   9.  12.   2.\n",
      "    5.   0.   9.  10.  15.  14.  15.   9.  11.  15.  10.  11.   4.  15.\n",
      "    5.  15.   6.   5.   7.   5.  12.  13.  12.  11.   2.   7.  13.  13.\n",
      "    0.   4.   2.   2.  14.  15.   4.   7.  13.   4.   7.   2.   9.   1.\n",
      "    7.  10.   7.   1.  15.  10.   9.  14.  12.  15.   8.  11.   2.   5.\n",
      "    4.   3.  15.  12.]] , prediction:  [11  9 15  1  9  4  7  0 12 10  7  3 13 12 14  0  6 14  5  4  4  3  3  9  3\n",
      "  3 12  1  6  1  9  2  8  8  7 15  6  2  3 13  2  2 10 12  5  8  6  0  0 14\n",
      "  8 15  3  7 15  7 11  0 15  7 11 12 15 13  3  0 13  2  7  3  3  2  9  1  8\n",
      " 15  8  7  1  7  7  7 12  0  7  8  7  9 11 13  2  7 15 14  1  1  5  6 12  4\n",
      "  5 14  1  5 10 15  4 12  3  8  3 11  3  6 14  6 13 11  4 13  8  9 13  9 14\n",
      " 15  3  3 12 14 14  7  0  6 11  4 13  8 12  2  4  0  9 10 15 12 15  9 11 15\n",
      " 10 11  6 15  5 15  6  5  7  5 12 15 12 11  2  5 13  9  0 12  2  2 12  7  4\n",
      "  7 13 12  7  2  9  3  7 10  3  1 11 10  9 14 12  7  8 11  2  7 12  3 15 12]\n",
      "Training step 17000 --> loss=0.706473\n",
      "\n",
      "Iteration 17200 out of 59600\n",
      "Iteration 17400 out of 59600\n",
      "Iteration 17600 out of 59600\n",
      "Iteration 17800 out of 59600\n",
      "Iteration 18000 out of 59600\n",
      "Training step  18000  --> Real class:  [[  9.   9.   4.   4.  13.  15.   2.  14.   0.  11.   2.   7.   4.  13.\n",
      "    3.  13.   2.  10.  10.   3.   3.   6.  10.   8.  11.   1.  10.   9.\n",
      "    7.   0.  12.   8.  13.  14.   4.  15.  14.   9.  14.   4.   5.   2.\n",
      "   15.   5.   3.   8.  13.   7.   4.  15.   2.   9.  10.   6.   3.  12.\n",
      "   14.   5.  15.   5.   8.   6.  11.  13.   7.   4.   5.   8.  13.   2.\n",
      "    1.   7.   8.   6.   8.   5.   4.  15.  12.   3.   5.   8.  13.   2.\n",
      "    8.  10.   2.   2.   8.   5.  13.   0.  14.  13.  13.   2.   6.  14.\n",
      "    7.  15.   7.   1.   0.  13.   9.  12.  11.   7.  12.  14.  11.   9.\n",
      "    3.  15.  11.   5.  10.   9.  12.  13.  11.   8.  10.  10.   3.   7.\n",
      "    5.   9.   2.   5.   6.  11.   6.  15.   1.   0.  12.  10.   2.  13.\n",
      "    5.   3.   1.  10.  15.  11.  10.   4.   5.  14.   1.   6.  12.  11.\n",
      "    9.   2.  15.  13.  10.   4.  14.   6.   6.   4.   5.  14.  10.   3.\n",
      "    4.   5.  15.   3.   6.   8.   8.   4.  15.   9.  14.  14.   8.   5.\n",
      "    1.  11.  15.  15.   3.   6.   3.  11.   4.  14.  13.  10.  10.   4.\n",
      "    1.  10.   3.   4.]] , prediction:  [ 9  9  4  4 13 13  2 14  0 11  2  7  4 12  3 13  2 10 10  3  3  6 10  8 11\n",
      "  1 10  9  7  0 14  8 13 10  4 15  6  9 14  4  1  2 14  5  2  8 13  7  6 13\n",
      "  2  9 10  6  1 14  4  5 15  5  8  6 11  9  7  4  6  8 13  2  1  7  8 14  8\n",
      "  5  4 15 12  3  5  8 13  2  8 10  2  2  8  5 13  0 14 13 15  2  7 12  3 15\n",
      "  6  1  0 13  9 14 11  7  8 14 11  9  3 13 11  5 11  9 12 13 11  8 10 10  1\n",
      "  7  5  9  2  5 14 11  6 15  1  0 14  2  1 13  5  1  1 10 14  1 10  4  4 12\n",
      "  1 14 12 11  9  2 14 13 10  4 12  4  6  4 13  4 10  3 12  5 13  1 14  8  8\n",
      "  4  1  9  6 10  8  5  1 15 14 15  7  6  3 11  4 14 13 10 10  4  1 10  1  4]\n",
      "Training step 18000 --> loss=0.724671\n",
      "\n",
      "Iteration 18200 out of 59600\n",
      "Iteration 18400 out of 59600\n",
      "Iteration 18600 out of 59600\n",
      "Iteration 18800 out of 59600\n",
      "Iteration 19000 out of 59600\n",
      "Training step  19000  --> Real class:  [[ 11.   5.   1.   6.   6.  15.  14.  11.   8.  12.  12.  13.  15.  10.\n",
      "    3.   4.   7.   3.  10.  12.   0.   9.  15.   7.   6.   4.  14.  13.\n",
      "    4.   6.   2.   7.   3.  15.  14.  14.   6.   9.  14.   6.   4.  12.\n",
      "   10.   8.  12.   1.   6.   3.   8.   0.   8.   9.  13.   4.   9.  10.\n",
      "    4.   9.   7.   0.   8.   3.   8.   9.   2.  11.   9.  12.   2.   7.\n",
      "   15.   2.   0.   1.  11.   5.   1.   5.  14.   9.   5.   4.  12.  13.\n",
      "    8.  11.  15.  10.   5.   6.   7.  10.   4.   1.   1.  10.  10.   4.\n",
      "   14.   3.   6.  10.  10.   1.   4.  10.  11.   1.   9.  14.  10.   7.\n",
      "    5.  14.   3.   2.   4.   5.  12.   5.   2.  14.   3.   5.   9.   3.\n",
      "   14.   2.   5.   2.   8.  15.  13.   6.   2.   0.   1.  13.   1.   1.\n",
      "    0.   8.   8.  15.   4.   5.   4.  12.   0.  13.  15.   2.   7.   0.\n",
      "   11.  12.   5.   1.  13.   6.   8.  13.  10.   2.   3.  11.   6.   1.\n",
      "   15.   0.   8.   7.  13.  10.   2.   3.   5.   6.   9.   5.  11.  14.\n",
      "   15.   8.   2.  12.   1.   4.  11.  13.   1.  13.  12.   3.   0.   4.\n",
      "    2.   3.  12.   3.]] , prediction:  [11  1  1  6  6 15 12 13  8 12 12 13 15 14  3  4  6  3 10 12  0  9 15  7 14\n",
      "  4 14 13  4  6  2  7  3 15 14 14  6  9 14  6  4 12 15  8 12  1  6  1  8  0\n",
      "  8 13 13  4  9 10  4 13  7  0  8  3  8  9  2 11  8  4  3  7 15  2  0  1 11\n",
      "  7  1  4 14  9  5  4 14 13  8 15 15 10  4 14  7 10  4  1  1 10 15  4 14  3\n",
      " 15 10 10  1  4 10 15  1 13 15 10  7  5 14  3  2  4  5 12  5  2 14  3  5  9\n",
      "  3 14  2 13  2  8 15  5 15  3  8  3 13  1  1  0  8  8 15  4  5  4  8  0 13\n",
      " 15  2  7  0 11 12  5  1 13  6  8  7 10  2  3 11  6  1 13  0 13  6 13 15  2\n",
      "  3  5  6  9  5 15 14 11  8  2 12  1  4 11 13  1 13 12  3  0  4  2  3 12  3]\n",
      "Training step 19000 --> loss=0.579384\n",
      "\n",
      "Iteration 19200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19400 out of 59600\n",
      "Iteration 19600 out of 59600\n",
      "Iteration 19800 out of 59600\n",
      "Iteration 20000 out of 59600\n",
      "Training step  20000  --> Real class:  [[  9.  10.  10.  13.  14.   4.  13.  12.   5.  12.  13.   5.  14.   6.\n",
      "    2.  13.   0.  14.  10.   1.   1.   9.  10.  13.   3.   1.   7.  15.\n",
      "   15.   3.  11.   8.   3.   5.  13.   4.   5.  12.   4.   4.   5.   9.\n",
      "    1.  15.   5.  15.   2.   8.   3.   5.  10.  13.  11.  12.   2.  15.\n",
      "    0.  15.   7.   3.   9.   9.   5.   6.   8.   9.   3.   8.   1.  14.\n",
      "   15.   6.   3.   6.   3.  10.   6.   9.  13.   9.   5.   8.  15.  12.\n",
      "    1.   4.   9.   0.   0.  10.  11.  10.   1.  14.   7.  10.   2.   6.\n",
      "    1.   1.  13.   4.   4.   6.   3.   1.  11.  13.  15.  11.   7.   8.\n",
      "   10.   9.   2.   2.   9.   5.   1.   1.   5.  10.  12.   1.   5.  13.\n",
      "    2.   9.   6.  14.  11.   3.   4.   5.  13.  13.  10.   1.   5.   3.\n",
      "    8.  13.   9.   8.   9.  14.   5.   7.   3.   6.  12.   5.   6.   0.\n",
      "    5.  11.  11.  13.  12.   8.   0.  13.   2.   8.   9.   9.  11.   3.\n",
      "   13.  12.  13.   6.  13.  14.   6.   2.   8.  10.   8.   7.   3.  10.\n",
      "   13.  10.   0.  13.   7.  15.   4.  15.   0.   3.   9.  14.   8.  10.\n",
      "   10.   7.   2.   8.]] , prediction:  [ 9 11 10  9 14  4  9 12  5 12 13  5 14  6  2 13  0 14 10  1  1  9 11 13  1\n",
      "  1  7 15 15  3 11  8  3  1 13  4  5 12  4  4  5  9  1 11  5 15 11  8  3  5\n",
      " 10 13  1 12  2  7  0 15  7  1  9  9 13  6  8 13  3  8  1 14 15  2  1  6  3\n",
      " 10  6 13 13  9  5  8 15 12  1  4  9  0  0 10 11 10  1 14  7 11  2  6  1  1\n",
      " 13  4  4  6  3  1 11  5 15  1  7  8 10  9  2  2  9  5  1  1  5 11 12  1  5\n",
      "  5  2 11  6 14 11  3  6  5 13 13 10  1  5  3 12 13  8 14  9 14  5  7  3  6\n",
      " 12  5  2  0  4 11 11 13 12  8  0  5  2  8  9  9 11  3 13 12 13  6 13 11  6\n",
      "  2  8 10  8  3  3 11 13 11  0 13  7 15  4 15  0  3  9 14  8 10 10  7  2  8]\n",
      "Training step 20000 --> loss=0.582267\n",
      "\n",
      "Iteration 20200 out of 59600\n",
      "Iteration 20400 out of 59600\n",
      "Iteration 20600 out of 59600\n",
      "Iteration 20800 out of 59600\n",
      "Iteration 21000 out of 59600\n",
      "Training step  21000  --> Real class:  [[  7.   2.  13.  13.  13.   8.   8.   5.  13.   9.  14.   8.   9.   0.\n",
      "    0.   6.   3.  15.   7.  10.  11.   8.  10.  15.   0.  10.  13.   2.\n",
      "    2.   6.   4.   3.  13.   6.  14.  11.  12.  11.  10.   6.  13.  11.\n",
      "   12.   3.   5.  10.   7.   1.  12.   1.   6.  13.  15.  12.   6.  14.\n",
      "   15.   2.   5.  14.   6.   8.   9.   5.  12.  13.  11.   2.   6.   2.\n",
      "    6.   1.  13.  15.   3.   5.   7.  13.  11.  10.   4.  14.   7.   7.\n",
      "    0.   2.   9.   4.   8.  11.  11.   0.   5.   7.  11.   6.  14.   6.\n",
      "   12.   9.   2.  14.   5.   5.   0.  11.  14.   6.   5.   9.  11.   4.\n",
      "    1.  15.   3.  11.   2.   0.  13.  12.  11.   3.  15.  12.   9.  14.\n",
      "   11.  10.  13.   4.   2.  10.  12.  10.   2.   8.   9.   9.  13.  13.\n",
      "    0.  11.   9.  13.  13.  15.   1.   0.   9.   7.   3.  14.  15.   4.\n",
      "    8.  10.  10.  15.   2.  12.  10.  13.   8.   8.   5.   3.   3.   7.\n",
      "    0.  14.   5.   3.   1.  13.   4.   3.   4.   3.   9.   7.  10.   4.\n",
      "    5.  10.   9.   5.  14.  13.   2.   7.  10.   3.   2.   4.   9.  14.\n",
      "   12.   1.   1.   5.]] , prediction:  [ 6  2 13 13  5  8  8  1 13  9 14  8  9  0  0  6  3 15  7 10 11  8 10 11  0\n",
      " 10  5  2  2  4  4  3 13  6 14  9 12  7 10  6 13 11 12  3  5 10  7  1 12  1\n",
      "  6 13  7 12  6 14 11  2  5 14  6  8 13  5 12 13 11  2  6  2  6  1 13 15  3\n",
      "  5  7 13 11 10  4 14  7  7  0  2  9  4  8 11 11  0  5  5 11  6 14  6 12  9\n",
      "  2 14  5  5  8 11 14  6  5  9 11  4  1  7  3 10  2  0  9 12 11  3 13 12  9\n",
      " 14 10 10 13  4  2 14 12 10  2  8  9 13 13 13  0  3  9 13 13 11  1  0  9  7\n",
      "  3 14  7  6  8 10 10 15  2 12 10 13  8  8  5  3  3  7  0 14  5  3  1 13  4\n",
      "  2  4  3  9  7 10  4  5 10  9  5 14 13  2  5 10  3  2  6 13 10 12  1  1  5]\n",
      "Training step 21000 --> loss=0.487277\n",
      "\n",
      "Iteration 21200 out of 59600\n",
      "Iteration 21400 out of 59600\n",
      "Iteration 21600 out of 59600\n",
      "Iteration 21800 out of 59600\n",
      "Iteration 22000 out of 59600\n",
      "Training step  22000  --> Real class:  [[  8.   7.   8.   7.   6.   0.   7.   8.  11.   4.  11.  12.   3.   0.\n",
      "   10.  13.   7.   2.  13.  15.  13.   9.   2.  14.   7.   8.  11.   2.\n",
      "    5.   8.   1.  14.  15.   1.   7.   3.  14.   6.   0.  10.  10.  11.\n",
      "    5.  14.   8.   5.  15.   9.   1.   9.  13.   5.   8.   8.   2.  12.\n",
      "    9.   1.   8.  14.  10.   8.  15.   1.   6.   9.   1.   8.  14.   6.\n",
      "   11.  10.  12.   2.   6.   0.   9.  15.   9.   2.   1.   7.   6.   2.\n",
      "   11.   2.   0.   6.   9.  12.  10.   8.  11.   8.   9.   8.   4.   3.\n",
      "    3.   3.   3.  10.  10.  15.  11.  13.   8.  15.   8.   8.  15.  15.\n",
      "   14.  13.  12.   2.   1.  12.  11.   2.   5.   9.  12.  11.   6.   6.\n",
      "    3.   7.   8.   7.  14.  14.   5.   2.  14.  11.  11.   8.  15.  14.\n",
      "    1.   4.   5.   2.  13.  13.  14.  14.  14.   4.   4.   1.  13.   1.\n",
      "    3.  14.   3.   7.  10.  12.   3.   2.  10.   2.  14.   5.   7.  12.\n",
      "    5.   1.   4.  11.  15.   6.  14.   5.   6.   0.   9.  15.   6.   3.\n",
      "   12.   9.   8.  14.   7.   2.   8.   1.  12.  10.   9.   4.   2.   2.\n",
      "    3.   6.   8.  10.]] , prediction:  [ 8  7  8  7  6  0  7  8 11  4 11 12  3  0 10 13  7  2 13 15 15  8  2 15  7\n",
      "  8 11  2  5  8  1 14 15  1  7  3 14  6  0 10 10 11  5 10  8  5 15  9  1  9\n",
      " 13  4 12  8  2 12  9  1  8 15 10  8 15  1  2  9  1  8 14  6 11 10 12  2  6\n",
      "  0  9 15  9 10  1 15  2  2 11  2  0  6  9 14 10  8 11  8  9  8  4  3  3  2\n",
      "  3 10 10 15 11 13  8  7  8  8 15 15 14  5 12  2  1 12 11  2  5  9  4 15  6\n",
      "  6  3  5  8  7 14 14  5  2 10 10 10  8 15 14  1  6  5  2 13 13 14 14 14  4\n",
      "  4  1 15  1  3 14  3  7 15 12  3  2 10  2 15  5  7 12  5  1  4  3 15  6 14\n",
      "  5  2  0  9 15  6  3 12  9  8 15  6  2  8  1  4 10  9  4  2  2  3  6  8 10]\n",
      "Training step 22000 --> loss=0.514195\n",
      "\n",
      "Iteration 22200 out of 59600\n",
      "Iteration 22400 out of 59600\n",
      "Iteration 22600 out of 59600\n",
      "Iteration 22800 out of 59600\n",
      "Iteration 23000 out of 59600\n",
      "Training step  23000  --> Real class:  [[  2.   5.   1.   1.   8.  15.  14.   9.   4.   3.   6.  15.   6.   6.\n",
      "   13.  15.   3.  13.   5.   3.   3.  12.  15.  13.   1.   6.  13.  15.\n",
      "   15.   1.   0.   8.   1.   1.   7.   0.   3.   1.  15.   1.   5.  14.\n",
      "   12.  14.  12.  13.   2.  15.   5.  10.  15.   2.  14.   0.   8.   7.\n",
      "    6.   9.  11.   7.  12.  13.  15.  15.  11.   3.   0.  11.  15.  10.\n",
      "    8.  10.  12.   2.   7.   1.  10.  14.   1.   4.  14.   1.  15.   4.\n",
      "   15.  10.   3.   2.   8.  11.  13.   2.  14.   5.   8.   9.  14.   7.\n",
      "   10.   9.   3.   4.   9.  12.   9.  11.   8.  15.   5.   1.   2.  13.\n",
      "    6.   5.   2.   9.   4.  11.   2.  12.   4.   8.   2.  11.  13.  10.\n",
      "    9.   2.  12.   8.   6.   9.   4.   2.  13.   3.  14.   3.  15.   4.\n",
      "    3.  13.   7.   7.   8.   3.  12.  14.   4.   1.   4.  14.   8.   9.\n",
      "    7.  11.   3.   4.   9.   3.   4.   3.  14.  11.   7.   3.   3.   8.\n",
      "   13.  15.   8.  10.   9.  13.  13.  12.   7.  11.   2.   0.   2.  15.\n",
      "    7.  10.   7.   7.   9.   6.   8.   9.   5.   9.  10.   8.   9.   6.\n",
      "    4.  15.   3.  12.]] , prediction:  [ 2  5  1  1  8 15 14  9  4  3  6 14  6  6 13 15  3 13  5  2  3 12 15 14  0\n",
      "  6 13 15 15  1  0  8  1  1  6  0  3  0 15  1  5 14 12 14 14 12  2 15  5 10\n",
      " 15  2 10  0  8  7 14  9 11  7 12 15 15 15 11  3  0 11  7 10  8 10 12  2  6\n",
      "  1 10 10  1  4 14  1 15  4 14 10  3  2  8  3 13  2 14  5  8 13 14  6 10  9\n",
      "  2  4  9 12  8 11  8 15  1  1  2 13  6  5  2  9  4  2  2 12 12  8  2 11 13\n",
      " 10  9  2 12  0  6  9  6  2 13  3 14  3 15  4  3 15  7  6  8  3 12 14  4  1\n",
      "  4 15  8  1  7 11  3  4  9  3  4  3 14 11  7  3  3  8  5 15  8 10  9 13 13\n",
      "  8  7 11  2  0  2 15  7 10  7  7  9  6  8  9  5  9 10  8  9  6  4 15  3 14]\n",
      "Training step 23000 --> loss=0.503403\n",
      "\n",
      "Iteration 23200 out of 59600\n",
      "Iteration 23400 out of 59600\n",
      "Iteration 23600 out of 59600\n",
      "Iteration 23800 out of 59600\n",
      "Iteration 24000 out of 59600\n",
      "Training step  24000  --> Real class:  [[ 11.   8.   7.  12.   9.   8.  15.   5.   6.   4.   2.   4.  10.   3.\n",
      "   11.   1.   0.   5.   8.   2.  11.   5.   1.  11.  10.  10.   0.  11.\n",
      "    2.   5.   0.   9.   9.   1.   4.   9.  11.  10.   4.  14.   0.   6.\n",
      "   11.   7.   9.   3.  13.   7.  10.   8.  10.  12.   8.   8.  12.   2.\n",
      "    4.   6.   5.  15.   0.   3.   5.   8.   6.   7.   5.   7.   6.  13.\n",
      "    5.  11.  10.  11.  12.   2.   4.   5.  15.  11.  15.   1.  11.   8.\n",
      "    1.   1.   8.   4.  12.  13.  11.   1.   7.  12.   7.   6.   1.   6.\n",
      "    4.   7.   3.   6.  15.   2.   9.   8.  11.   3.   4.   4.  13.   4.\n",
      "   14.  11.  12.   6.   3.  14.   1.   7.   6.   2.   1.  10.   3.   0.\n",
      "    1.   6.   7.  10.   2.   6.   7.   6.   3.  11.  15.   8.   4.   3.\n",
      "    7.   5.  10.   5.   5.   6.  10.   8.   4.  12.  12.   6.  10.  13.\n",
      "    1.  14.  10.  12.  10.   3.   9.   7.  12.   4.  13.  13.   2.   8.\n",
      "    8.  15.  15.  14.   6.   3.   3.   5.   5.   2.  12.  13.  14.   1.\n",
      "    9.   6.   1.  13.  13.  14.  15.  15.   5.  12.  10.   3.   2.   4.\n",
      "    4.   5.  12.   2.]] , prediction:  [11  8  7 12  9  8 13  7  5  4  2  4 10  3 11  1  0  5  8  2 11  5  1 11 10\n",
      " 10  0 11  2  5 12  9  9  1  4  9 11 10  6 14  0  6 11  7  9  3 13  7 10  8\n",
      " 10 12 12  8 12  2  4  6  5 15  0  3  5  8  6  7  5  7  6 13  7 11  2 11 12\n",
      "  2  4  5  7 11 15  1 11  8  1  1  8  4 12 13 11  1  7 12  7  6  1  5  4  7\n",
      "  3  6 13  2  9  8 11  7  4  4  9  4 10 11 12  6  3 14  1  7  6  2  1 10  3\n",
      "  0  1  6  7 10  2  6  7  6  3 11  7 12  4  3  7  5 10  5  5  6 10  8  4 12\n",
      " 12  6 10 13  1 14 10 12 10  3  9 13 12  4  8 13  2  8  8 11 13 14  6  3  3\n",
      "  5  5  2 12  9 14  1  9  7  1 13 13 14 15  7  5 12 10  3  2  4  4  5 12  2]\n",
      "Training step 24000 --> loss=0.452573\n",
      "\n",
      "Iteration 24200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24400 out of 59600\n",
      "Iteration 24600 out of 59600\n",
      "Iteration 24800 out of 59600\n",
      "Iteration 25000 out of 59600\n",
      "Training step  25000  --> Real class:  [[  4.   2.   9.   0.  14.  11.  12.   8.  12.  10.   9.  12.  11.  10.\n",
      "    0.  12.   1.   7.  14.  13.  14.   8.   3.   2.   8.   7.   7.   2.\n",
      "   15.  11.   2.   1.   1.   8.   7.  13.  11.   9.   7.  12.   4.  11.\n",
      "    2.   5.   7.  12.  12.  15.   2.   9.  12.   1.   4.   7.   6.  15.\n",
      "   15.   1.  13.   7.   5.   7.   6.   3.   7.   5.   8.  13.  11.   6.\n",
      "   14.   2.   9.   5.   2.   5.   1.   6.  14.   5.  14.  12.   0.  15.\n",
      "    5.  13.   8.  10.   2.   1.  15.  15.   5.   5.   1.   8.  15.  11.\n",
      "    7.  12.  12.   3.   5.  12.  10.   6.   7.   8.   8.   2.  12.   3.\n",
      "   14.  10.  13.   6.   5.   5.   7.  13.  14.   0.  14.   8.  15.   0.\n",
      "    3.   5.   3.  14.   1.  13.  15.  15.  10.   0.   5.  13.  13.  10.\n",
      "    2.   3.  12.  11.   9.   5.  11.  13.  11.   1.   8.   7.   7.  15.\n",
      "    1.   5.   6.  13.   1.  12.  13.   2.   2.  10.  11.   7.   9.   8.\n",
      "   15.   1.  13.  15.   2.  15.   3.   2.  12.   2.   6.  12.   7.   9.\n",
      "    1.  13.  14.  13.  11.   9.   9.   3.  11.   2.   6.  10.   9.   5.\n",
      "    1.  13.   3.  15.]] , prediction:  [ 4  2  9  8 14 15 12  8 12 10  9 12 11 10  0 12  1  7 10 13 14  8  3  3  8\n",
      "  5  7  2 14 11  2  1  1 14  5 13 10  9  7 12  4 11  2  5  7 12 12 15  2  9\n",
      " 12  1  4  7  6  7 15  1 13  7  5  7  6  3 15  5  8 13 11  7 14  2  9  5  2\n",
      "  5  9  7 14  5 14 12  0 13  5  9  8 10  2  1 13 15  5  5  1  8 15 11  7  8\n",
      " 12  3 13 12  9  6  7  8  8  2 12  3 14 10 13  6  5  5  3 14 14  0 14  8 15\n",
      "  0  3  5  3 14  1 13 15 14 10  8  5 13 13 10  2  3 12 10  9  5 11 13 11  1\n",
      "  8  7  7 15  1  5  6 13  1 12 13  2  6 10 11  3  9  8 15  1 13 15  2 15  3\n",
      "  2 12  2  4 12  7  9  9 13 14 13 11  9  9  3 11  2  6 10  9  5  1 13  3 15]\n",
      "Training step 25000 --> loss=0.427718\n",
      "\n",
      "Iteration 25200 out of 59600\n",
      "Iteration 25400 out of 59600\n",
      "Iteration 25600 out of 59600\n",
      "Iteration 25800 out of 59600\n",
      "Iteration 26000 out of 59600\n",
      "Training step  26000  --> Real class:  [[  1.   1.   0.   3.  15.   0.   1.   4.  10.   5.  13.  12.   2.  10.\n",
      "    2.   5.   1.   1.   1.  13.  13.  11.   8.  15.   6.  11.  12.  15.\n",
      "    8.   4.   9.  14.   5.  15.   1.  13.   1.   7.   0.   8.  14.   1.\n",
      "    1.   4.   0.  11.   7.  10.   6.  14.   5.  12.   4.   8.   6.   9.\n",
      "   15.  12.   4.  15.   2.   2.  11.   8.   3.  10.   1.   8.   5.   0.\n",
      "   15.   7.   2.   6.  10.   8.  13.   4.   4.  15.   7.   6.  13.  11.\n",
      "   11.  13.   4.   1.  13.  13.   9.  13.   6.   6.  13.  10.   6.  15.\n",
      "    3.  15.   5.   1.   5.   9.   2.  14.  12.  14.   7.   9.   4.   9.\n",
      "   12.   6.   3.  11.  10.   2.  13.   4.   3.   5.  13.   4.  11.  14.\n",
      "    9.   7.  15.   0.  11.   8.  12.  11.   2.   9.   1.   3.   9.   4.\n",
      "   14.   3.   2.  15.   3.  11.  15.   8.   5.   4.   8.   9.   1.   3.\n",
      "    1.   6.   7.   3.  10.  11.   4.  14.  13.   3.  10.   6.   8.  12.\n",
      "    1.  10.  14.   9.  14.  12.  11.  14.  12.   1.   1.  12.   8.   9.\n",
      "    7.   9.  15.   7.   2.   4.  15.   0.   6.  13.  10.  14.  10.  14.\n",
      "    5.   4.   0.  12.]] , prediction:  [ 1  1  0  3 15  0  1  4 10  7 13 12  2 10  2  5  1  1  1 13 13 11  8 15  6\n",
      " 11 12 15  8  6  9 14  4  7  1 15  1  7  0  8 14  1  1  4  0 11  7 15  6 14\n",
      "  5  6  4 12  6  9 15 12  4 15  2  2 11  8  3 10  1 12  5  0 15  3  2  6 10\n",
      "  8 13  4  4 15  7 14 15 15 11 13  4  1 13 13  9 13  6  6 12 14  6 15  3 15\n",
      "  5  1  5 13 11  6 12 14  7  9  4 13 12  6  3 11 10  2 13  4  3  5 13  4 11\n",
      " 14  9  5 15  0 11  8  4 10  2  9  1  3  9  4 14  3  2 15  3 11 15 12  7  4\n",
      "  8  9  1  3  1  6  7  3 10 11  4 14 13  3 10  6  8 12  1 11 14 13 14 12 11\n",
      " 12 12  1  1 15  8  9  7 13 15  7  2  4 15  0  6 13 10 14 10 14  5  6  0 12]\n",
      "Training step 26000 --> loss=0.395086\n",
      "\n",
      "Iteration 26200 out of 59600\n",
      "Iteration 26400 out of 59600\n",
      "Iteration 26600 out of 59600\n",
      "Iteration 26800 out of 59600\n",
      "Iteration 27000 out of 59600\n",
      "Training step  27000  --> Real class:  [[ 15.  11.   7.   3.   6.  13.   3.  11.   2.  12.   5.   8.  11.  10.\n",
      "    3.   8.  11.  13.   8.   7.   0.  13.   2.   5.  14.   7.   2.  15.\n",
      "   15.   5.   8.  14.   0.   3.   8.  15.   2.  12.  11.   0.  12.  13.\n",
      "    4.   4.   7.   4.  12.  11.  10.   4.  15.   1.  12.  14.   5.   5.\n",
      "    9.  11.   5.   8.   1.   5.   3.   0.   2.  15.  13.  10.   5.   9.\n",
      "    9.  15.   6.  14.   7.   5.  15.   2.   3.   9.  11.   2.   6.  14.\n",
      "    1.   2.   5.  13.   5.  14.   7.   3.  13.   0.   2.  13.   9.   3.\n",
      "   14.  13.  10.   4.   1.  12.  12.  12.   5.   8.  11.  15.  11.   1.\n",
      "    7.   5.  10.   3.   2.  10.   4.   1.  13.   2.   4.   1.   1.   1.\n",
      "    3.  11.  10.   4.  15.  12.  15.  10.   3.   3.   8.   1.   7.   8.\n",
      "   12.   1.   6.  15.   6.   4.   2.   2.   5.   9.  14.   9.   9.   5.\n",
      "   12.  12.   7.   8.   7.  14.   0.  14.  12.   6.   5.   1.   6.  14.\n",
      "    2.  14.   7.  15.   7.   1.  13.   1.  13.   7.   9.  15.  15.   2.\n",
      "    8.  15.   6.   3.   3.   5.  15.  13.  10.   6.  15.  12.   1.  12.\n",
      "    7.  14.  12.  15.]] , prediction:  [14 10  5  3  6 13  3  3  2 12  4  8 11 10  1  8 11 13  0  7  0 13  2  4 14\n",
      "  7  2  7 15  5  8 14  0  7  8 14  2 12 10  0 12 13  4  4  7  4 12 11 10  4\n",
      " 14  1 12 14  5  5  9 11 13  8  1  5  3  0  2 15 13 10  5 13  9 14  6 14  7\n",
      "  5 15  2  2  9  3  2  6 14  1  2  5  5  5 14  7  3 13  0  2 13  9  3  6 13\n",
      " 10  4  1 12 14 12  5  8 11 14 11  1  7  5 10  3  2 10  4  1 13  2  6  1  1\n",
      "  1  3 11 10  4 14  4  7 10  3  3  8  1  7  8 12  1  6  7  6  4  2  2 13  1\n",
      " 14  9  1  5  4 12  6  8  7 14  0 14 12  6  5  1  6 10  2 14  7 11  7  1 13\n",
      "  1 12  7  8 14 15 10  8 15  6  3  3  5 15 13 10  6 11 12  1 12  7 14 12 15]\n",
      "Training step 27000 --> loss=0.505216\n",
      "\n",
      "Iteration 27200 out of 59600\n",
      "Iteration 27400 out of 59600\n",
      "Iteration 27600 out of 59600\n",
      "Iteration 27800 out of 59600\n",
      "Iteration 28000 out of 59600\n",
      "Training step  28000  --> Real class:  [[  5.   7.  15.  12.  14.  10.   5.   7.  14.  12.  15.  13.   9.   5.\n",
      "    8.  13.   1.   1.  14.  15.  15.  12.   9.  11.  15.   4.   0.   1.\n",
      "    5.   2.   7.   1.   6.  12.  12.   0.   4.   8.  14.   3.   7.  12.\n",
      "   15.   1.  10.   4.  15.  14.   0.  12.  12.  10.  14.   8.   0.  13.\n",
      "    9.  14.   0.   5.   0.   7.   5.  15.   6.  10.   6.   6.   5.   9.\n",
      "   13.  10.   8.   9.   5.   8.   2.   4.  10.   3.   2.  14.   2.   9.\n",
      "    3.   5.   2.  12.   7.   5.   9.  15.  10.   7.  14.  13.  11.   8.\n",
      "    4.   2.   8.  10.  11.  10.   3.   2.   7.  12.   8.   5.  14.  13.\n",
      "   12.   5.  11.   8.   7.   8.  13.   6.  11.   3.  11.   5.   7.   2.\n",
      "    7.   8.   7.   4.  15.   5.   3.  10.  12.  11.   6.   3.   1.  10.\n",
      "   14.   7.   1.  13.   5.  11.   7.  15.  14.   9.   7.   6.   5.  12.\n",
      "    0.  11.  15.   4.  11.   7.  10.   7.  11.   3.  14.  10.  10.   1.\n",
      "    4.   4.  12.  12.   6.  11.   8.   2.  10.  13.  11.   4.  14.   6.\n",
      "    1.   4.   2.   2.  12.  15.  11.  11.   3.   9.   8.   1.  14.   0.\n",
      "   14.   0.  12.  13.]] , prediction:  [ 5  6 15 12 14 15  5  7 14 12 15 13  9  5  8 12  1  1  6 15 15 12  9 11 15\n",
      "  4  0  0  5  2  7  1  6 12  4  0  4  8 10  3  7 12 15  0 10  4 15 14  0 12\n",
      " 12 10 15  8  0 13  8 14  0  5  0  7  5 15  6 10  6  6  5  9 13 10  8  9  5\n",
      "  8  2  4 10  3  2 15  2  9  3  4  2 12  7  5  9 15 10  5 14 13 11  8 12  2\n",
      "  8 10 11  8  3  2  5 12  0  5 15 13 12  5 11 12  3  8  5  4 11  3 11  5  7\n",
      "  2  3  8  5  4 15  5  3 10 12 11 14  3  1 10 12  7  1 13  5 11  6 15 12  9\n",
      "  3  6  5 12  0 11 15  4 11  7 10  7 11  3 12 10 15  1  4  4  4 12  6 11  8\n",
      "  6 10 13 11  4 15  6  1  4  2  2 12 15 11 11  3  9  8  1 14  0 15  0 12 13]\n",
      "Training step 28000 --> loss=0.430187\n",
      "\n",
      "Iteration 28200 out of 59600\n",
      "Iteration 28400 out of 59600\n",
      "Iteration 28600 out of 59600\n",
      "Iteration 28800 out of 59600\n",
      "Iteration 29000 out of 59600\n",
      "Training step  29000  --> Real class:  [[  3.   6.  10.  12.  10.  12.  14.   4.   3.   6.   7.  10.   9.   8.\n",
      "    7.   3.   9.  13.  13.  11.  10.  14.   4.   0.  10.   4.   7.   2.\n",
      "    2.   9.   9.   7.   4.   0.  14.  13.  14.  14.  15.   7.  13.   5.\n",
      "    5.   3.  10.   4.   7.   5.   1.  12.   2.   3.  15.   1.   9.  10.\n",
      "    7.   1.   9.  13.  12.  13.   3.   5.  11.   4.  10.   6.   2.   9.\n",
      "   14.  14.  13.  15.   9.   5.   1.   8.   6.  15.   3.  10.  14.   2.\n",
      "    3.   4.   1.   1.   5.   3.   4.  14.  14.  15.   0.   7.   9.  14.\n",
      "    7.   3.  14.   5.   4.  14.  10.  11.   1.  12.   4.   0.   1.  13.\n",
      "    5.  14.  15.  11.  13.  14.   4.   4.  14.  13.  10.   2.  14.   8.\n",
      "   13.   3.   6.   9.   1.  14.  13.   6.   6.   9.   6.   8.  10.  15.\n",
      "    1.  11.   4.  15.   5.   5.  12.  15.  10.   5.  11.  14.  10.  10.\n",
      "    9.  15.   4.   0.   4.   6.   5.   3.   3.  10.   6.   8.   1.   9.\n",
      "   11.  12.  14.  11.   5.   6.  15.  10.   2.   5.   1.   6.   4.   1.\n",
      "   11.  14.  13.   2.   7.  13.   9.  11.   7.   6.  11.  10.  12.   5.\n",
      "    4.   8.   5.   0.]] , prediction:  [ 3  6 10 12 10  8 14 14  3  6  7 10  9  8  6  2  9 13 13 11 10 14  4  8 10\n",
      "  4  5  2  2  9  9  7  6  0 14 13 14 14 15  7 13  5  5  3 10  4  7  5  1 14\n",
      "  2  3 15  1  9 10  7  0  9 13 12 13  3  5 10  4 10  6  2  9 14 14  8 15  9\n",
      "  5  1  8  6 15  3 10 14  3  3  4  1  1  5  3  4 14 14 15  0  7  9 14  7  3\n",
      " 15  5  4 14 10 11  1 12  4  0  1 13  7 14 14 15 13 14  4  4 14 13 10  2 14\n",
      "  8 13  3  6  9  1 14 13  4  2  1  6  8 10 14  1 10  4 14  5  5 12 14 10  5\n",
      " 11 14 10 10  9 14  4  0  4  6  5  3  3 10  6  8  1  9 11 12 14 11  5  6 14\n",
      " 10  2  5  9  6  4  1 15 14 15  2  7 13  9 11  7  6 11 15 12  5  4  8  5  0]\n",
      "Training step 29000 --> loss=0.406837\n",
      "\n",
      "Iteration 29200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29400 out of 59600\n",
      "Iteration 29600 out of 59600\n",
      "Iteration 29800 out of 59600\n",
      "Iteration 30000 out of 59600\n",
      "Training step  30000  --> Real class:  [[  2.  11.  12.   5.   3.   3.   5.   5.   3.  13.   0.   9.   4.   5.\n",
      "    5.   9.   7.   1.   8.  10.   6.  11.   6.   0.  14.  15.   8.   3.\n",
      "   14.  11.   5.  14.   2.  11.  13.   9.   4.   0.  15.   6.   1.   2.\n",
      "   12.   7.  10.   8.   9.   6.   3.   7.  14.  11.   4.  13.  11.  10.\n",
      "   12.  14.   3.   1.   2.   2.  14.   8.   8.   4.  13.   1.  10.   3.\n",
      "    8.   9.  12.   1.  14.  11.   8.  13.   9.  11.   4.  11.  10.  12.\n",
      "   14.   1.   4.   3.   4.   9.   0.   2.   9.   8.   1.   2.  15.  15.\n",
      "   13.   1.   8.   6.   2.   6.  12.   2.   7.   3.  13.   9.   0.   3.\n",
      "    2.  12.  10.  10.   6.  15.   9.   2.  15.   1.   0.  15.   1.  13.\n",
      "   13.   6.   2.  10.   4.   5.   9.   5.  14.  13.  15.   8.   2.   6.\n",
      "    9.   9.   2.   8.   4.   9.   3.   9.  10.   7.   4.   2.  14.   6.\n",
      "    0.   5.  12.  15.   6.  11.   4.   2.   4.   5.   8.   6.  13.  12.\n",
      "    4.   2.  14.  10.   3.  12.  13.   5.   5.   7.   4.  12.   3.  12.\n",
      "   14.   1.   5.  15.  12.  13.   2.   7.  11.  13.   6.   9.   1.   8.\n",
      "    0.  11.   2.   0.]] , prediction:  [ 2 10  8  5  3  2  5  5  3 13  0  9  4  5  5  9  6  1  8 10  6 11  6  0 10\n",
      " 14  8  1 14 11  5 14  2 11  4  9  4  0 15  6  1  2 14  7 14  8  9  4  3  3\n",
      " 14  9  4 13 11 10  4 14  3  1  2  2 14 12  8  4 13  1 10  3  8  9 12  1 14\n",
      " 11  8 13  9 11  4 11 10 12 14  1  4  3  6  9  0  2  9  8  1  2 14 15 13  1\n",
      "  8  6  2  6 12  2  7  3 13  8  0  3  2 10 11 10  6 15  9  2 10  1  0 15  1\n",
      " 13 13  6  2 10  4  5  9  5  6 13 15  8  2  6  9  8  2  8  4  9  3  9 10  7\n",
      "  4  2 14  6  0  5 12 15  6 11  4  2  4  5  8  6 13  8  4  2 14 10  3 12 13\n",
      "  5  5  7  4 12  3 12 14  1  5 15 12 13  2  7  9 13  6  9  1  8  0 11  2  0]\n",
      "Training step 30000 --> loss=0.368113\n",
      "\n",
      "Iteration 30200 out of 59600\n",
      "Iteration 30400 out of 59600\n",
      "Iteration 30600 out of 59600\n",
      "Iteration 30800 out of 59600\n",
      "Iteration 31000 out of 59600\n",
      "Training step  31000  --> Real class:  [[ 12.   9.   1.  15.  11.   4.   1.   2.   3.  10.  13.  12.   1.  14.\n",
      "    5.   6.   1.  13.  15.  11.   9.   1.   1.   9.   8.  10.  10.   8.\n",
      "    4.   8.   9.   7.   1.   8.   9.   3.  14.   9.   7.  15.  13.  13.\n",
      "   15.   4.   8.   5.  10.   5.   4.   8.  14.   6.   7.   9.  11.   1.\n",
      "    9.  12.  15.  13.   3.   8.   8.   9.   5.   1.   7.   6.   7.   6.\n",
      "    3.   7.   6.  10.  10.   1.   2.  13.  10.   1.  13.   7.   8.  12.\n",
      "   14.   7.  10.   3.   6.   7.   3.   5.  10.  12.   3.  15.   0.   6.\n",
      "    6.   2.   3.   5.  14.  12.  10.  14.   5.   2.   9.   7.   1.   5.\n",
      "   15.  12.   9.   3.   4.   1.   7.   1.  14.  10.  10.  14.   0.   3.\n",
      "   14.   5.  12.   1.   2.   8.   2.  10.   7.  14.   4.  13.   5.   8.\n",
      "    4.  15.   4.   8.   8.   1.   8.  10.   8.   5.   4.   6.   2.  12.\n",
      "   10.  12.   5.  15.   0.   2.  10.  15.   6.   3.  10.  11.   7.   1.\n",
      "    3.   1.  12.   8.  14.  10.  10.  14.  15.  15.  10.  11.  11.  15.\n",
      "    6.   5.   4.  14.   1.  11.   5.   3.   2.   3.  15.  10.   6.   2.\n",
      "    2.   0.  13.   1.]] , prediction:  [12  9  1 11 11  4  1  2  3 10 13 12  1 14  5  6  1 13 15 11  9  1  1  9  8\n",
      " 10 10  8  4  0  9  7  1  8  9  3 14  9  7  5 13  5 15  4  8  5 10  5  0  8\n",
      " 14  6  7  9 11  1 13 12 15 13  3  8  8  9  5  1  7  6  7 14  3  5  6 10 10\n",
      "  1  2 13 10  1 13  5  8 12 14  7 10  3  6  7  3 15 10 12  3 15  0  6 14  2\n",
      "  3  5 14 12 10 14  5  2  9  7  1  5 15  8  9  3  4  1  6  1  6 10 10 14  0\n",
      "  3 14  5 12  0  2  8  2 10  7 14  4 13  5  8  4  7  4  8  8  1  0 10  8  5\n",
      "  4  6  2 12 10 12  5 15  0  2 15 15  2  3 10 11  5  1  3  1 12  8 15 10 10\n",
      " 14 15 15 10 11 11 10  6  5  4 14  1 10  5  3 10  3 14 10  6  2  2  0 13  1]\n",
      "Training step 31000 --> loss=0.329591\n",
      "\n",
      "Iteration 31200 out of 59600\n",
      "Iteration 31400 out of 59600\n",
      "Iteration 31600 out of 59600\n",
      "Iteration 31800 out of 59600\n",
      "Iteration 32000 out of 59600\n",
      "Training step  32000  --> Real class:  [[  9.  15.   3.   3.  10.   8.  12.  14.  11.   7.   7.  14.  14.   0.\n",
      "   14.  14.   4.   1.  11.  12.  11.   7.   8.   6.  11.  12.   5.  15.\n",
      "    5.  12.   2.   3.   9.   8.   5.  13.   2.   5.  14.   4.   8.   4.\n",
      "    1.   7.   6.   3.   7.   8.  12.   8.   6.  15.   6.   5.   5.  11.\n",
      "   10.   1.   3.   7.  15.  15.   4.  11.  14.  11.   3.  10.   6.   7.\n",
      "    7.   1.   2.   6.  10.  14.  12.   5.  13.   9.  15.  10.   5.   7.\n",
      "    8.   6.  12.   3.   7.   7.   9.   9.   2.   8.   9.   8.   2.  10.\n",
      "    5.  13.   9.  11.  15.  12.   1.   4.   3.   6.  14.   2.  15.   2.\n",
      "   15.  12.  13.   1.  13.   6.   9.  11.   8.  13.   6.   2.   0.   8.\n",
      "   12.   7.  10.   9.  11.   1.   6.  10.   8.   8.  14.  14.   3.   8.\n",
      "    8.   4.  10.   4.   6.  12.  10.  11.  15.  14.  14.   2.  14.  15.\n",
      "   13.   4.  13.   5.  14.  13.   3.  10.   7.   2.   8.   2.  11.  10.\n",
      "    0.   9.  14.   3.   9.  10.   7.   2.   7.  14.  15.  13.   3.   1.\n",
      "   15.   2.  15.   9.   6.   0.   0.  13.   1.   4.   6.  11.  12.  15.\n",
      "   10.  11.  10.  14.]] , prediction:  [13 15  2  3 10  8 12 14 11  7  6 14 14  0 14 14  4  1 10  4 11  5  8 14 11\n",
      " 12  5 15  5 12  2  3  9  8  5 13  2  5 14  4  8  4  1  7  6  3  7  8 12  8\n",
      "  7 13  6  5  5 11 10  1  3  6 15 15  4 11 14 11  3 10  6  7  7  1  2  6 10\n",
      "  6 12  5 13  9 15 10  5  7  8  6  8  3  7  5  9  9  2  8  9  8  2 10  5 12\n",
      "  9 11 15 12  1  4  3  6 14  2 15 10 15 12 13  1 15  6  9 11  8  1  6  2  0\n",
      "  8 12  7 10  1 11  1  6 10  8  8 14 14  3  8  8  4 11  4  6 12 10 11 15 14\n",
      " 14  2 14 15 13  4 13  5 14 13  3  6  7  2  8  2  1 10  0  9 14  3  9 10  7\n",
      "  2  5 14 11 13  3  1 15  2 15  9  6  0  0 13  1  4  6 11 12 15 10 11 10 14]\n",
      "Training step 32000 --> loss=0.328695\n",
      "\n",
      "Iteration 32200 out of 59600\n",
      "Iteration 32400 out of 59600\n",
      "Iteration 32600 out of 59600\n",
      "Iteration 32800 out of 59600\n",
      "Iteration 33000 out of 59600\n",
      "Training step  33000  --> Real class:  [[  4.  14.  12.   5.   8.  14.  14.   9.   2.   4.   3.   6.   3.   4.\n",
      "   11.  12.   4.   1.   5.  10.  14.   6.  15.  10.  11.   4.  10.   4.\n",
      "   12.   5.   9.   5.   8.   8.   7.   4.  11.   8.  11.   0.   6.   4.\n",
      "   11.   2.  14.  13.   2.   2.   9.   3.  10.  13.   4.   2.   3.   9.\n",
      "    9.  11.   2.   6.   3.  12.   9.   6.  12.  13.  14.   1.   3.  10.\n",
      "    4.   5.   6.   9.   1.   0.   2.   0.   4.   4.  12.   9.   9.  15.\n",
      "   11.   4.  10.   4.  13.  15.   5.   4.  14.  15.   6.  10.   4.   2.\n",
      "   13.   0.   2.  10.   9.  10.  13.  15.  10.   6.   4.  15.   3.  13.\n",
      "    6.  13.   5.   8.   6.   9.  14.  14.  12.  14.   6.   1.  15.  10.\n",
      "   10.  13.  11.   2.   7.  11.  12.   1.  12.   2.  14.  10.  10.  11.\n",
      "   13.   7.   9.   8.   0.  10.   0.   1.   7.   8.  12.   1.  15.   5.\n",
      "   13.   9.  13.   5.   7.  12.   7.  13.   5.   6.  15.   0.   3.   7.\n",
      "   15.   8.   7.  15.   1.   2.  14.   1.   1.   8.   2.  13.  10.   4.\n",
      "    7.  10.  12.   8.   0.   9.   6.  14.   6.   5.   8.  13.  14.   7.\n",
      "    8.  12.  12.  15.]] , prediction:  [ 4 10 12  5  8 14 10  9  2  4  3  6  3  4 11 12  4  1  5 10 14  6  7 10 11\n",
      "  4 10  4 12  5  9  5  8  8  7  4 11  8 11  0  6  4 11  2 14 13  2  2  9  3\n",
      " 10 13  4  2  3  9  9 11  2  6  3 12  9  6 12 13 14  1  3 10  4  5  7  9  1\n",
      "  0  2  0  4  4 12  9  9 15 11  4 10  4 13 15  5  4 14 15  6 10  4  2 13  0\n",
      "  2 10  9 14 13 15 10  6  4 15  3 13  6 13  5  8  6  8 14 14 12 14  6  1 15\n",
      " 10 10 13 11  2  7 11 12  1 12  2 14 10 10 11 13  7  9  8  0 10  0  1  7  8\n",
      " 12  1 10  5 13  9 13  5  7  4  7 13  5  6 13  0  3  7 15  8  7  7  1  2 14\n",
      "  1  1  8  2 13 10  4  7 10 14  8  0  9  6  6  6  7  8 13 14 15  0 12 12  5]\n",
      "Training step 33000 --> loss=0.296442\n",
      "\n",
      "Iteration 33200 out of 59600\n",
      "Iteration 33400 out of 59600\n",
      "Iteration 33600 out of 59600\n",
      "Iteration 33800 out of 59600\n",
      "Iteration 34000 out of 59600\n",
      "Training step  34000  --> Real class:  [[ 11.  14.  15.  12.   8.   5.  13.   7.   6.   0.   1.   8.   3.   2.\n",
      "   11.  11.   5.   6.  10.  11.  11.   3.   6.  14.   4.   6.   0.  14.\n",
      "   10.   6.   4.  14.  14.  15.   4.   9.   7.   8.   5.  15.  14.   3.\n",
      "    7.   1.  13.   4.  12.   8.   3.   9.  13.   3.  10.  11.   3.   8.\n",
      "    7.  15.  15.  11.   2.  12.  12.   2.  13.   3.   2.   1.  15.   2.\n",
      "   15.  11.   6.  14.  11.  14.   7.   4.   8.  10.  15.   6.  13.  11.\n",
      "   11.   3.   9.  15.  13.  12.  11.   7.  12.   4.   0.  14.   2.  15.\n",
      "    2.   1.   1.   0.   0.  11.  10.   0.   8.  12.   1.   4.  10.   5.\n",
      "   11.   2.   1.   7.  11.   6.   6.   8.   3.  14.   3.  15.   3.   3.\n",
      "    8.   8.   5.   5.   2.   6.   6.   5.   8.  15.  11.  11.  14.  13.\n",
      "    4.   2.   1.   5.   5.   2.  14.   3.   6.   9.  13.  15.   5.   9.\n",
      "    4.  10.   5.  13.   4.   6.   2.   2.   4.  13.  12.   4.   8.   4.\n",
      "    9.  11.  14.   3.  15.   1.  14.   3.   9.   7.   3.   7.  12.  12.\n",
      "    5.   4.   3.   3.  13.   7.  15.   5.   5.   3.   0.  14.   8.   1.\n",
      "   11.  13.   8.   1.]] , prediction:  [11 14 15 12  8  5 13  7  6  0  1  8  3  2  9 11  5  6 10 10 11  3  6 14  4\n",
      "  6  0 14 10  6  4 12 14 15  4  9  7  8  5 15 14  3  3  1 12  4 12  8  3  9\n",
      " 13  3 10 11  3  8  7 15 15 11  2 12 12  2 13  3  2  1  7  2 15 15  6 14 11\n",
      " 14  5  4  8 10 15  6 13 11 11  3  9 15 13 12 15  6 12  4  0 14  2 13  2  1\n",
      "  1  0  0 11 10  0  8 12  1  4 10  5 11  2  1  7 10  6  6  8  3 14  3 15  3\n",
      "  3  8  8  5  5  2  6  6  5  8 15 11 11 14 13  4  2  1  4  5  2 14  3  4  9\n",
      " 13 10  5  9  4 10  5 13  4  6  2  2  4 12  8  4  8  4  9 11 14  3 15  1 14\n",
      "  3  9  5  3  5 12 12  5  6  3  3 13  7 15  5  7  3  0 14  8  1 11 15  8  1]\n",
      "Training step 34000 --> loss=0.357284\n",
      "\n",
      "Iteration 34200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34400 out of 59600\n",
      "Iteration 34600 out of 59600\n",
      "Iteration 34800 out of 59600\n",
      "Iteration 35000 out of 59600\n",
      "Training step  35000  --> Real class:  [[ 15.   2.  15.  10.   5.   8.   9.   4.  13.   3.   7.  14.   3.  10.\n",
      "   13.   2.   2.   3.  15.  12.   7.   5.  11.   0.   6.   3.   4.   2.\n",
      "    4.   8.  13.   6.   6.   3.   1.   5.  13.   8.  14.  15.   6.  11.\n",
      "    9.  10.   4.   8.   2.   1.  13.  10.   8.   9.  12.   8.  12.   3.\n",
      "    3.   5.  11.  14.   5.   3.   6.  10.   7.  11.   1.   0.   7.  15.\n",
      "    9.   5.   1.   2.  14.   5.   8.   4.  14.  12.  15.   6.  11.   6.\n",
      "    2.   9.   9.  10.  14.   2.   6.  10.   1.  13.  12.   1.   4.   1.\n",
      "    1.   8.   3.   3.  11.   6.  14.   1.  12.   5.   8.  13.  10.  13.\n",
      "    4.   1.  12.   3.   1.  15.   4.   9.   8.   0.   2.   6.  11.   5.\n",
      "    9.  12.   9.   7.  11.   3.  13.   2.  11.  14.  14.   9.   8.  14.\n",
      "    0.   4.  10.  12.   9.  10.  10.   2.   1.   8.  13.  13.   7.   8.\n",
      "    7.   6.  10.  13.   4.   4.  15.  11.  10.   6.  15.   0.   5.   4.\n",
      "   13.   6.   5.  11.   6.  11.   2.   5.   9.  11.  10.   1.   5.  12.\n",
      "    6.   8.  10.  15.  13.   1.   4.   7.   3.   4.  12.   9.   9.   3.\n",
      "   13.  13.   1.  11.]] , prediction:  [15  2  7 10  5  8  9  4 15  3  7 14  3 10 13  2  2  3 11 12  7  5  3  0  6\n",
      "  2  4  2  4  8 11  6  2  3  1  5 13  8 14 15  6  3  9 10  6  8  2  1 13 10\n",
      "  8  9 14  8 12  3  2  5 11 14  5  3 14 10  7 11  1  0  7 14  9  5  1  6 10\n",
      "  7  8  4 14  4 15  6 11  6  2  9  9 10 14  2  6  6  1 13 12  1  4  1  1  8\n",
      "  3  3 11  6 14  1 12  7  8 13 10 13  4  1 12  3  1 15  4  9  8  0  2  6 11\n",
      "  5  9 12  1  7 11  3 13  2 11 14 14  9  8 14  0  4 10 12  9 10 10  2  1  8\n",
      " 13 13  7  0  7  6 10 13  4  4 11 11 10  6 15  0  5  4 13  7  5 11  6 11  2\n",
      "  4  9 11 10  1  5 12  6  8 10 15 15  1  4  7  3  4 12  9  9  3 13 15  1 11]\n",
      "Training step 35000 --> loss=0.342494\n",
      "\n",
      "Iteration 35200 out of 59600\n",
      "Iteration 35400 out of 59600\n",
      "Iteration 35600 out of 59600\n",
      "Iteration 35800 out of 59600\n",
      "Iteration 36000 out of 59600\n",
      "Training step  36000  --> Real class:  [[  5.   5.   5.   3.  15.  10.   4.   7.   5.   8.   5.  13.   9.  13.\n",
      "   14.  11.  12.   3.   6.  12.  12.  11.   7.   8.   3.  14.   3.   7.\n",
      "   10.  11.   2.   3.  10.   1.   4.  12.  10.   7.  11.   5.   2.   3.\n",
      "   13.  13.   0.  10.   8.   7.   1.  10.  15.   1.   5.  11.   9.   6.\n",
      "    6.  14.  10.  11.  15.   9.  15.  12.   5.   5.   5.   3.  12.  15.\n",
      "    2.   3.   7.   4.   2.   5.   3.   4.   0.   2.  10.   9.  11.   3.\n",
      "   14.   9.  14.  15.   9.  15.   9.   4.  15.   9.  14.  15.  12.  11.\n",
      "    5.   4.   7.   9.   5.  14.  15.  13.  12.   3.   9.   4.   7.   6.\n",
      "   13.  15.  15.   6.   7.   5.  11.   7.  13.  11.  12.   0.   9.   1.\n",
      "   12.  15.   1.   7.   7.   3.   7.   4.  11.   2.   8.  15.  13.   6.\n",
      "    8.  11.   4.  10.  11.   0.   6.   9.   8.   4.   5.  15.  14.   3.\n",
      "    2.   2.   4.   3.  12.  15.  15.   4.   3.   9.   7.   8.  12.   0.\n",
      "    0.   1.  15.   9.   9.  11.   9.   7.   1.   1.  10.   7.   7.  13.\n",
      "    5.   6.   3.   8.  15.   3.  10.  11.  13.  10.   3.   7.  12.   3.\n",
      "   15.  11.   8.   2.]] , prediction:  [ 5  5  5  3 15 10 12  7  5  8  5 13  9 13 14 11 12  3  6 12 12 11  7  8  3\n",
      " 14  3  7 10 11  2  3 11  1  6 12 10  7 11  5  2  3 13 13  0 10  8  7  1 10\n",
      " 15  1  5 11  9  6  6 14 10 11 15  9 15 12  5  5  5  3 12 15  2  3  7  4  2\n",
      "  5  3  4  0  2 10  9 11  3 14  9 14 15  9 15  9  4 15  9 14 15  4 11  5  4\n",
      "  7  9  5 14  7 13 12  3  9  4  7  6 13 14 15  6  7  5 11  7 13 11 12  0  9\n",
      "  1 12 15  1  7  7  3  7  4  1  2  8 15 13  6  8 11  4 10 11  0  6  9  8 12\n",
      "  5 15 14  3  2  2  4  3 12 15 15  4  3  9  7  8 12  0  0  1 15  9  9 11  9\n",
      "  7  1  1 10  6  7 13  5  6  3  8 11  3 10 11 13 10  3  7 12  3 15 11  8  2]\n",
      "Training step 36000 --> loss=0.242818\n",
      "\n",
      "Iteration 36200 out of 59600\n",
      "Iteration 36400 out of 59600\n",
      "Iteration 36600 out of 59600\n",
      "Iteration 36800 out of 59600\n",
      "Iteration 37000 out of 59600\n",
      "Training step  37000  --> Real class:  [[ 14.  12.   8.   2.  10.   1.  11.   0.   9.  12.   2.   2.  14.   8.\n",
      "    1.  10.   4.   3.   6.  13.   1.   7.   1.  11.   9.   7.  12.   9.\n",
      "    1.   5.  12.  11.   1.  14.   8.  10.   3.   9.   1.   6.   5.   8.\n",
      "    9.   2.   2.  14.   8.   7.   7.   2.   9.   4.  11.   4.  13.   6.\n",
      "   15.  13.  11.   6.  14.   4.  14.  15.   9.   0.  14.   3.   4.  10.\n",
      "    2.  13.   2.  12.  14.  12.   2.  14.   6.   9.  13.   6.  10.   3.\n",
      "    6.  15.  10.   1.   0.   0.   8.   2.   1.  11.  12.   4.   2.  15.\n",
      "    5.   3.   4.   4.   5.   5.  10.   9.   7.  11.  11.   4.  10.   1.\n",
      "   13.   5.  12.  12.   6.   9.   2.   7.   1.   1.  13.  11.  13.  14.\n",
      "    7.   9.  12.   5.   8.   9.   3.   1.   3.   7.  15.   3.   2.   4.\n",
      "    4.  12.  12.  10.   6.   3.   2.   6.   0.   2.  12.  13.  14.   3.\n",
      "   13.   1.   7.   7.  11.  11.  12.  15.   9.  14.  14.   3.   2.  11.\n",
      "    5.   0.   7.   8.   4.   1.  14.  11.  11.  12.   6.   4.  11.   3.\n",
      "   13.   8.   6.   3.   1.  11.  12.   9.   2.   2.  11.   0.   2.   7.\n",
      "   11.   7.  13.   5.]] , prediction:  [14  4  8  2  8  1 11  0  9 12  3  2 15  8  1 10  4  3  6 13  1  5  1 11  9\n",
      "  7  8  9  1  5 12 11  1 14  8 10  3  9  1  6  5  8  1  2  2 14  8  7  7  2\n",
      "  9  4 11  4 13  6 15 13 11  6 14  4 14 15  9  0 14  3  4 10  2 13  2 12 14\n",
      " 12  2 14  6  9 13  6 10  3  6 15 10  1  0  0  8  2  1 11 12  4  2 15  7  3\n",
      "  6  4  5  5 10  9  7 11 11  4 10  1 13  5 12 12  6  9  2  7  1  1 13 11 13\n",
      " 14  7  9 12  7  8  9  3  1  3  7 15  3  2  4  4 12 12 10  6  3  2  6  0  2\n",
      " 12 13 14  3 13  1  7  7 11  9 12 15  8  6 14  3  2 11  5  0  7  8  4  1 14\n",
      " 11 10 12  6  4 11 11 13  8  6  3  1 11 12  9  2  2 11  0  2  7 11  7 13  5]\n",
      "Training step 37000 --> loss=0.252190\n",
      "\n",
      "Iteration 37200 out of 59600\n",
      "Iteration 37400 out of 59600\n",
      "Iteration 37600 out of 59600\n",
      "Iteration 37800 out of 59600\n",
      "Iteration 38000 out of 59600\n",
      "Training step  38000  --> Real class:  [[ 14.   8.   7.  15.  11.  11.   3.   5.   9.  12.   4.  15.  15.  11.\n",
      "    3.   1.   9.   5.   9.  11.   0.   4.   1.   8.   3.   9.  11.  12.\n",
      "    8.   9.   8.   2.   6.   2.   3.   7.  14.   1.   4.   3.   9.  11.\n",
      "    5.  12.   9.   7.   1.   9.   3.  10.   3.  13.   2.  10.   1.   5.\n",
      "    5.  13.   6.  14.   4.  14.   5.  10.   6.  13.   6.   3.   7.   5.\n",
      "    3.   1.   7.   0.  11.  12.  12.   1.   9.   3.  14.   1.   0.   7.\n",
      "   11.  10.   3.  11.   1.   7.   2.   1.   7.  10.   4.  13.   8.  13.\n",
      "   10.  14.   2.  10.  10.  13.  15.   5.   3.   0.  13.   0.   1.  13.\n",
      "    6.   7.   6.   8.  12.   7.  15.   3.  13.   1.  14.  15.  13.   1.\n",
      "    4.   9.   8.   8.   8.   8.   0.   8.   9.  15.  15.  13.   6.   6.\n",
      "    9.  12.  10.  15.   7.  15.  12.   9.  12.  10.   5.   9.  14.   9.\n",
      "   10.   9.  15.   3.  13.  11.   6.   9.   2.   1.  10.   9.   2.  11.\n",
      "    5.  13.  14.  13.  13.   4.  10.  10.   8.   6.   7.   3.   8.   4.\n",
      "    4.   6.  14.   6.  11.  10.   7.   3.   1.   8.   5.   7.   6.   9.\n",
      "    9.  13.  12.  10.]] , prediction:  [14  8  7 11 11 11  3  5  9 12  4 15 15 11  3  1  9  5  9 11  0  4  1  8  3\n",
      "  9 11 12  8  9 12  2  6  2  3  7 14  1  4  3  9 11  5  8  9  7  1  9  3 10\n",
      "  3 13  2 10  1  5  4 13  6 14  4 14  5 14  6 13  6  3  7  5  3  1  7  0 11\n",
      " 12 12  1  9  3 14  1  0  7 11 10  3 11  1  7  2  9  7 10  4 13  8 13 10 14\n",
      "  2 10 10 13 15  5  3  0 13  0  1 13  6  7  6  8 12  3 15  3 13  1 14 14 13\n",
      "  1  4  9  8  8  8  8  0  8  9 13 14  9  6  6  9 12 10 11  7 14 12  9 12 10\n",
      "  5  9 14  9 10  9 15  3 13 11  6  9  2  1 10  9  2  3  5 13 14 13 13  4 10\n",
      " 10  8  6  6  3  8  4  4  6 14  7 11 10  7  3  1  8  5  7  6  9  9 13 12 10]\n",
      "Training step 38000 --> loss=0.255535\n",
      "\n",
      "Iteration 38200 out of 59600\n",
      "Iteration 38400 out of 59600\n",
      "Iteration 38600 out of 59600\n",
      "Iteration 38800 out of 59600\n",
      "Iteration 39000 out of 59600\n",
      "Training step  39000  --> Real class:  [[  8.  13.  14.   5.  11.   3.  15.  11.  12.  12.   8.   4.   8.   6.\n",
      "    2.  15.  12.   9.  14.   6.   5.  12.   7.   6.   5.   7.  11.  11.\n",
      "    3.   6.   4.   1.   2.   9.   8.  11.  15.   9.   8.   5.   4.   5.\n",
      "   14.   4.   7.   1.   7.   0.   3.  13.  13.  15.   1.  13.   5.  15.\n",
      "    6.   1.   3.   3.   2.   4.   6.   8.   2.  14.   8.   4.  12.   6.\n",
      "   14.   8.   3.   5.   7.   3.  10.   5.  13.   7.   2.   8.   8.   5.\n",
      "   11.   1.   2.   0.  10.  12.  10.  10.   1.   8.  14.   6.   1.   3.\n",
      "   13.   3.   4.   4.  11.  14.   2.   7.  15.   5.  12.  11.  12.   2.\n",
      "   14.  10.  10.   0.   3.   7.   4.   4.  15.   9.   5.  10.  11.   8.\n",
      "    7.   9.  10.   3.   2.  10.  14.   0.   1.   9.   0.  15.   8.   1.\n",
      "   12.   5.   4.  15.   9.   5.  13.   1.   7.  15.   0.   6.   7.   2.\n",
      "   10.   6.  13.  14.   4.  15.  15.   4.   5.   1.  12.   1.   2.   8.\n",
      "    4.   8.  11.  14.  13.   0.   1.   2.   7.   9.  15.   3.   5.  13.\n",
      "    1.   8.   2.   6.   1.   7.  15.  10.   7.   2.   7.   9.  14.   4.\n",
      "    2.  15.   7.   2.]] , prediction:  [ 8 13 14  5 11  3 15 11 12 12  8  4  8  6  2 15 12  9 14  6  5  8  7  6  5\n",
      "  5 11 11  2  6  4  1  2  9  8 11 15  9  8  5  4  5 14  4  7  1  7  0  2 13\n",
      " 13 15  1 13  1 15  6  1  3  3  2  4  6  8  2 14  8  4 12  6 14  8  3  5  7\n",
      "  2 10  5 15  7  2  8  8  5 11  1  2  0 15 12 10 15  1  8 14  7  1  3 13  3\n",
      "  4  4 11 14  2  7 15  5 12 11  8  2 14 10 10  0  3  7  4  6 15  9  5 10 11\n",
      "  8  7  9 10  3  2 10 14  0  1  9  0 15  8  1 12  5  4 15  9  5 13  1  7 15\n",
      "  0  6  7  2 10  6 13 14  4 15 15  4  5  0 12  1  2  8  4  8 11 14 13  0  1\n",
      "  2  7  9 15  3  5 13  1  8  2  6  1  7 15 10  7  2  7 13 14  4  2 15  7  2]\n",
      "Training step 39000 --> loss=0.234185\n",
      "\n",
      "Iteration 39200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39400 out of 59600\n",
      "Iteration 39600 out of 59600\n",
      "Iteration 39800 out of 59600\n",
      "Iteration 40000 out of 59600\n",
      "Training step  40000  --> Real class:  [[  5.   9.   9.   3.  11.  12.   0.   1.   7.   4.   3.   7.   4.   1.\n",
      "   11.  10.  15.   6.  15.   8.   5.   6.   2.   4.   4.  10.   7.   8.\n",
      "    9.   9.   9.   2.   7.   1.   0.   1.  14.   7.   0.   5.  15.  14.\n",
      "    2.   1.  15.  12.  10.  14.   0.  15.   6.   2.   5.   8.   3.   9.\n",
      "   13.   9.   7.   1.   2.   3.   6.   3.  14.   1.  12.   4.   3.   8.\n",
      "    9.   8.   9.  13.  10.   5.   5.   5.  13.   3.  13.   1.   0.  10.\n",
      "    2.  15.   4.  11.   8.  13.   3.  13.  14.   4.   2.  11.   4.   0.\n",
      "   12.  11.  12.   8.   5.   5.  10.  10.   6.   1.   0.  11.   3.   4.\n",
      "    7.  10.   7.   5.  10.  11.  12.   1.   7.  15.  10.   2.   7.   7.\n",
      "   10.  12.   0.  13.   5.  12.   3.   0.   8.  12.   2.   6.  12.  10.\n",
      "   14.   9.   1.  10.  13.   2.   1.   2.  11.   1.  11.   6.   4.  11.\n",
      "   11.  12.   3.   7.   4.   1.   2.   1.   2.   3.   3.  15.   6.   2.\n",
      "   12.   5.   2.  15.   5.  15.   9.   7.   8.   2.  11.   2.  13.  14.\n",
      "    1.   5.  12.   5.   3.   6.  13.   2.  15.   0.   3.   5.   9.  14.\n",
      "    1.  13.   8.  15.]] , prediction:  [ 5  9  9  3 11 12  0  1  7  4  1  7  4  1 11 10 10  6 15  8  5  4  2  4  4\n",
      " 10  7  8  9  9  9  2  7  1  0  1  6  7  0 13 15 14  2  1 15 12 10 14  0 14\n",
      "  6  2  5  8  3  9 13  9  7  1  2  3  6  3 14  1 14  4  3  8  9  8  9 13 10\n",
      "  5  5  5 13  3 13  1  0 10  2 15  4 11  8 13  3 13 14  4  2 11  4  0 12 11\n",
      " 14  8  5  5 10 10  4  1  0 11  3  4  5 10  7  5 10 11 12  1  7 15 10  2  7\n",
      "  7 10 12  0 15  5 12  3  0  8 12  2  6 12 10  6  9  1 10 13  2  1  2 11  1\n",
      " 11  6  4 11 11 12  3  7  6  1  2  1  2  3  3 15  6  2 12  5  2 15  5 15  9\n",
      "  7  8  2 11  2 13 14  1  5 12  7  3  6 13  2 15  0  3  5  9 14  1  5  8 15]\n",
      "Training step 40000 --> loss=0.241560\n",
      "\n",
      "Iteration 40200 out of 59600\n",
      "Iteration 40400 out of 59600\n",
      "Iteration 40600 out of 59600\n",
      "Iteration 40800 out of 59600\n",
      "Iteration 41000 out of 59600\n",
      "Training step  41000  --> Real class:  [[  7.  12.   8.  13.   1.   9.  13.   5.  14.   3.  13.   0.  15.   3.\n",
      "    4.  14.   3.  10.  14.   5.  14.   7.   0.   8.  12.   8.   1.   8.\n",
      "   12.   8.   4.   0.   6.   6.   1.  13.   7.   7.  12.  12.  15.   2.\n",
      "   13.  13.   7.  14.   3.   7.  11.   8.   3.   4.  14.   4.  14.  10.\n",
      "    7.   2.  12.   1.  12.   3.  11.  13.   8.  15.   2.  10.   6.   6.\n",
      "    1.  11.  14.  11.   0.   9.   4.  12.   8.   6.   6.  14.  12.   4.\n",
      "   15.  14.   1.   9.  15.   1.   8.  13.   3.  11.   1.  11.  11.   5.\n",
      "    4.   9.   8.  14.  11.   4.  13.  12.  12.  11.   2.   4.   8.   0.\n",
      "    7.   1.  10.   5.   9.  10.   5.  11.   9.   3.   5.   6.   6.  10.\n",
      "    2.   5.   2.   1.  10.   3.   5.  12.  11.   7.  15.   7.   1.   7.\n",
      "    3.   4.  14.   7.  13.   9.  14.  15.  11.  14.   7.  14.  11.   5.\n",
      "   12.  13.   6.   9.  12.   5.   8.  12.  11.  10.  11.   7.  12.   8.\n",
      "    4.   4.   0.  11.   1.  13.   9.   0.   5.  14.  14.   2.   7.  14.\n",
      "    9.   7.   8.  15.  14.   5.   8.   4.  15.   5.   9.  11.  14.   9.\n",
      "   12.  15.   1.   2.]] , prediction:  [ 7 12  8 13  1  9 13  5 14  3 13  0 14  3  4 14  3 10 14  5 15  7  0  8 12\n",
      "  8  1  8 12  8  4  0  6  6  1 13  7  7 12 12 15  2  5  5  7 14  3  7 11  8\n",
      "  3  4  6  4 12 10  7  2 12  1 12  3 11 13  8 15  2 10  6  6  1 11  6 10  0\n",
      "  9  4 12  8  6  6 14 12  4 15 14  1  9 15  1  0 13  3 11  1 11 11  5  6  8\n",
      "  8 14 11  4 12 12 12 11  2  4  8  0  7  1 10  5  9 10  5 11  9  3  5  6  6\n",
      " 10  2  5  2  1 10  3  5  8 11  7 11  7  1  7  3  4 14  7 13  9 10 15 11 14\n",
      "  7 14  9  5 12 13  6  9 12  5  8 12  3 10 11  7 12  8  4  4  0 11  1 13  9\n",
      "  0  5 14  6  2  7 14  9  7  8 15 14  5  8  4 15  5  9 11 15  9 12  6  1  2]\n",
      "Training step 41000 --> loss=0.282696\n",
      "\n",
      "Iteration 41200 out of 59600\n",
      "Iteration 41400 out of 59600\n",
      "Iteration 41600 out of 59600\n",
      "Iteration 41800 out of 59600\n",
      "Iteration 42000 out of 59600\n",
      "Training step  42000  --> Real class:  [[  3.   6.  15.  13.  13.   4.   1.  11.  11.  15.   7.   5.  11.  15.\n",
      "   13.  11.   5.   2.  10.   3.   1.   9.   7.  11.  15.   3.   8.  12.\n",
      "    5.  12.  10.   5.   7.  15.   2.  11.  12.   9.  14.   3.  10.   1.\n",
      "    4.  15.   3.   9.   2.   0.   1.  15.   8.   1.  10.  10.   1.   6.\n",
      "    3.  11.  12.   1.   0.   8.  11.   3.   3.   2.  15.   5.  10.   9.\n",
      "    1.   9.   3.   3.   5.   5.  12.  15.   9.   7.   3.  10.   5.   5.\n",
      "    9.   5.  11.   9.   1.   0.  14.  10.   8.  13.   0.  14.  13.   2.\n",
      "    5.   1.  15.   3.  11.   0.   1.  15.  12.  11.   3.   6.   1.  12.\n",
      "   11.  15.   3.  13.   9.   7.   1.   2.  10.   6.  10.   3.   1.  15.\n",
      "    4.  14.  12.   3.   1.   9.  10.  15.   3.  14.   1.   1.  10.   1.\n",
      "    7.  13.  13.   1.   3.  13.   4.   1.  13.   5.   9.   6.   9.   1.\n",
      "    8.   6.   6.   0.   6.   8.   7.   3.   5.  13.   7.  12.   3.  11.\n",
      "   13.  10.  14.   1.   6.   6.  12.  11.   8.   7.   7.   6.   3.   7.\n",
      "   12.  15.   9.   4.   2.   1.   3.   8.   2.   3.  10.   8.   6.   7.\n",
      "   12.   1.   0.   4.]] , prediction:  [ 3 14 15 15 13  4  1 11 10 15  7  5 11 15 13 11  5  2 10  3  1  9  7 11 15\n",
      "  3  8 12  5 14 10  5  7 15  2 11 14  9 14  3 10  1  4 15  3  9  2  0  1 15\n",
      "  8  1 10 10  1  6  3 11 12  1  0  8 11  3  3  2  7  5 10  9  1  9  3  3  5\n",
      "  5 12 15  1  7  3 10  5  5  9  5  1  9  1  0 14 10  8 13  0 14 10  2  5  1\n",
      " 15  3 11  0  1 15  0 11  3  7  1 12 11 10  3 13  9  7  1  2 10  6 10  1  1\n",
      " 15  4 14 12  3  1  9 10 15  3 14  1  1 10  1  7 13 13  1  3 13  4  1 13  5\n",
      "  9  6  9  1  8  6  6  0  7  8  7  3  5 13  7 12  3 11 13 10 14  1  6  6 14\n",
      " 11  8  7  7  6  2  7 12 10  9  4  2  1  3  8  2  3 10  8  6  7  4  1  0  4]\n",
      "Training step 42000 --> loss=0.307868\n",
      "\n",
      "Iteration 42200 out of 59600\n",
      "Iteration 42400 out of 59600\n",
      "Iteration 42600 out of 59600\n",
      "Iteration 42800 out of 59600\n",
      "Iteration 43000 out of 59600\n",
      "Training step  43000  --> Real class:  [[  2.   4.   4.   3.   3.  10.   7.  11.   2.   6.   7.   2.  14.  12.\n",
      "   13.  15.   5.  13.   9.  14.   7.   9.   1.   4.   9.  12.  13.  10.\n",
      "   11.   6.   5.  13.   0.   0.   7.   8.  13.   4.  15.  11.  10.   3.\n",
      "    3.   5.   3.  15.  11.   1.  11.   8.  12.   1.  15.  15.  11.   2.\n",
      "    2.  10.   3.   9.   1.   5.   4.   6.  15.   4.   0.  13.   7.   7.\n",
      "    8.   5.   6.  12.   3.   7.   0.   8.  12.  11.   6.  15.   7.  12.\n",
      "    1.   1.   7.   5.   4.   4.   6.  13.   9.   1.  12.   6.   5.   0.\n",
      "   15.   0.  11.   9.   9.   4.   3.  15.   3.   2.   5.   7.  15.  11.\n",
      "    9.   5.   9.   7.  12.  13.   8.   1.   5.   8.   6.  10.  10.   8.\n",
      "   14.   0.   2.   9.  14.   9.  11.  14.   4.   8.   3.  11.   6.   0.\n",
      "    5.   8.   9.   4.  14.   7.  14.  12.  10.   7.   2.   5.   2.   7.\n",
      "    5.   3.   6.  10.   7.  13.   2.   0.   1.  14.  11.   0.  13.   1.\n",
      "   12.  11.  11.   9.   5.   9.   6.   6.   7.  10.   7.   3.   9.   5.\n",
      "    9.  12.   1.   5.   3.   6.   6.   7.  10.   1.   9.   6.  15.   4.\n",
      "    5.   7.  10.   3.]] , prediction:  [ 2  4  4  3  3 10  7 11  2  6  7  2 14 12 13  5  5 13  9 14  6  9  1  4  9\n",
      " 12 13 10 11  6  5 13  0  0  7  8 13  4  6 11 10  3  3  5  3 15 11  0 11  8\n",
      " 12  1 15 15 11  2  2 10  3  9  1  5  4  6 15  4  0 13  7  7  8  5  6 12  3\n",
      "  3  0  8  8 11  6 10  7 12  1  1  7  5  4  4  6 13  9  1 12  6  5  0 15  0\n",
      " 11  9  9  4  3 15  3  2  5  7 15 11  9  5  9  7 12 13  8  1  5  8  6 10 10\n",
      "  8 14  0  2  9 14  9 11 14  4  8  3 11  6  0  5  8  9  4 13  7 14 12 10  7\n",
      "  2  5  2  7  5  3  6 10  7 13  2  0  1 14 11  0 13  9 12 11 11  9  5  9  6\n",
      "  6  7 10  7  3  9  5  9 12  1  5  3  6  6  7 15  1  9  6 15  4  5  7 10  3]\n",
      "Training step 43000 --> loss=0.198557\n",
      "\n",
      "Iteration 43200 out of 59600\n",
      "Iteration 43400 out of 59600\n",
      "Iteration 43600 out of 59600\n",
      "Iteration 43800 out of 59600\n",
      "Iteration 44000 out of 59600\n",
      "Training step  44000  --> Real class:  [[  9.   3.   6.  10.   9.   7.   4.   1.  13.  15.  13.   8.  14.   2.\n",
      "   11.   5.   7.  15.   5.  11.  14.   8.  12.  12.  13.   6.   2.  14.\n",
      "   11.  14.  14.   9.   4.   1.   2.   3.   3.   9.  15.   4.   4.   7.\n",
      "   12.   3.  14.  15.  13.   8.   0.  11.  10.   8.   9.   1.   9.   8.\n",
      "    8.   9.   5.  11.   1.   3.   9.   8.  13.   2.   1.   9.   2.  11.\n",
      "   15.  11.  12.   1.   2.   9.  15.   5.   6.  13.  14.  14.   1.   4.\n",
      "    9.  12.  13.  14.  13.   9.  14.   6.   5.   6.  10.   1.   1.   4.\n",
      "   15.   7.  13.  13.   6.  15.   3.  11.  12.   4.  13.   4.   2.   7.\n",
      "    3.   8.   1.   3.   9.  10.  14.  14.   7.  14.  10.   8.   9.  11.\n",
      "    4.   8.   8.  10.   6.  13.  11.   9.  10.  14.   6.   2.   7.   1.\n",
      "   14.  14.  13.   6.   6.   2.   5.  15.  11.   2.   2.   4.   5.   2.\n",
      "    2.  11.   8.   7.  14.   8.   1.  14.   4.   6.  11.  10.  13.   3.\n",
      "    7.  13.   0.  11.   3.  10.   0.  14.   0.   5.  11.   4.   7.  11.\n",
      "   15.   6.  11.  12.  12.  14.   6.  15.   9.  11.   8.  15.  11.   1.\n",
      "    6.   1.   0.  12.]] , prediction:  [ 9  3  6 10  9  7  4  1 13 15 12  8 14  2 11  5  7 14  4 11 14  8 12 12 13\n",
      "  6  2 14 11 14 14  9  4  1  2  3  3  9 15  4  4  5 12  3 14 15 13  8  0 11\n",
      " 10  8  9  1  9  8  0  9  5 11  1  3  9  8 15  2  5  9  2 11 14 11 12  1  2\n",
      "  9 15  5  6 13 14 15  1  4  9 12  9 14 13  9 14  6  5  6 10  1  1  4 15  3\n",
      " 13 13  6 15  3 11 12  4 13  4  2  7  3  8  1  3  9 10 14 14  7 14 10  8  9\n",
      " 11  4  8  8 10  6 13 11  9 14 14  6  2  7  1 14 14 13  6  6  2  5 15 11  2\n",
      "  2  4  5  2  2 11  8  5 14  8  1 14  4  6 11 10 13  3  7 15  0 11  3 10  0\n",
      " 14  0  5 11  4  7 11 15  6 11 12 12 14  6 15  9 11  8 15  9  1  6  1  0 12]\n",
      "Training step 44000 --> loss=0.227752\n",
      "\n",
      "Iteration 44200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44400 out of 59600\n",
      "Iteration 44600 out of 59600\n",
      "Iteration 44800 out of 59600\n",
      "Iteration 45000 out of 59600\n",
      "Training step  45000  --> Real class:  [[  8.  11.  13.   2.  10.  12.  11.   4.   3.  10.   9.   0.  14.   8.\n",
      "   11.   3.   7.   3.  13.   8.   4.  12.   1.   2.   2.  14.   3.  15.\n",
      "   11.   7.  13.   5.   3.   0.  11.   5.   9.  13.  11.   4.  13.  14.\n",
      "    5.   7.  14.   9.   3.  14.   6.  14.   5.   8.   1.   8.   9.  14.\n",
      "   13.   1.   7.   6.  13.   3.   3.   3.   9.   3.  10.   2.   7.  12.\n",
      "    9.   5.  10.  13.   6.  14.  13.   9.   3.   3.   6.  15.  14.  11.\n",
      "   11.   6.  15.  11.   1.  15.   1.  13.   4.  10.  11.   3.   3.  11.\n",
      "   13.   8.   9.   8.   1.   8.   4.  13.   9.   8.  10.   7.   1.  10.\n",
      "   14.  13.   7.   7.  11.   0.   2.   3.  12.  10.   3.  12.   2.  15.\n",
      "    2.   2.   1.   0.  10.  13.  10.   5.  11.   1.   3.   7.  12.  10.\n",
      "    1.   9.   8.   8.   2.   0.  11.   4.   5.   9.  11.   5.   7.   2.\n",
      "    7.   2.   7.  12.   4.  13.  13.  15.  10.  14.   2.   0.  11.   5.\n",
      "    9.  12.  11.   5.   6.   5.  14.   8.  14.  10.  14.   9.  14.   5.\n",
      "    2.   4.  14.  10.   3.   4.  13.   3.   0.  10.  15.   6.  11.  14.\n",
      "    3.   8.  11.   9.]] , prediction:  [ 8 11 13  2 10 12 11  4  3 10  9  0 14  8 11  3  7  3 13  8  4 12  1  2  2\n",
      " 14  3 15 11  7 13  5  3  0 11  5  1 13 11  4 13 14  5  7 14  9  3 14  6 10\n",
      "  5  8  1  8  9 14 13  1  7  6 13  3  3  3  9  3 14  2  7 12  9  5 10 13  6\n",
      " 14 13  9  3  1  6 15 14 11 11  6 15 11  1 15  1 13  4 10 11  3  3 11 13  8\n",
      "  9  8  1  8  4 13  9  8 10  7  1 10 13 13  7  7  9  0  2  3 12 10  3 12  2\n",
      " 15  2  2  1  0 10 13 10  5 11  1  3  7 12 10  1  9  8  8  2  0 11  4  5  9\n",
      " 11  5  7  2  7  2  7 12  4 13 13 15 10 14  2  0 11  5  9 12 11  5 14  5 10\n",
      "  8 14 10 14  8 14  5  2  4 14 10  3  4 13  3  0 10 11  6 11 14  3  8 11  1]\n",
      "Training step 45000 --> loss=0.212597\n",
      "\n",
      "Iteration 45200 out of 59600\n",
      "Iteration 45400 out of 59600\n",
      "Iteration 45600 out of 59600\n",
      "Iteration 45800 out of 59600\n",
      "Iteration 46000 out of 59600\n",
      "Training step  46000  --> Real class:  [[  6.   5.  14.   2.  13.   6.  12.  14.   3.   8.   2.   9.   8.   8.\n",
      "    7.  11.  13.   3.   8.   9.   8.   6.   6.   0.  12.   6.  15.   6.\n",
      "    3.  12.   3.  15.   9.  13.   2.  14.  10.  15.  11.   7.   3.   9.\n",
      "    3.   4.   3.  14.   3.   2.   2.   9.   8.  13.  10.  13.   7.  13.\n",
      "    2.   7.   3.   5.   4.  15.   3.   9.  10.   6.   4.   7.   9.   4.\n",
      "   12.  10.   5.  11.   9.  13.  15.   1.  10.   8.   9.   5.   6.  11.\n",
      "    6.  14.  10.   4.  15.   2.   8.   6.   3.   8.   5.   1.  15.   4.\n",
      "    3.   5.   6.  13.  13.  14.   8.   5.   4.   6.  14.  12.  14.   2.\n",
      "    2.   3.  10.   9.  13.  14.   9.   6.  14.   2.   7.   8.  10.   8.\n",
      "    4.   2.  10.  14.  14.  11.   8.  11.  13.  12.  12.  13.  15.  14.\n",
      "    7.  10.   0.   3.   7.   8.   5.  15.   0.   1.   4.  11.   8.   7.\n",
      "    4.   3.   5.   3.   4.  13.   7.  15.   8.  14.  13.   3.   0.   2.\n",
      "   12.   7.  14.  12.  14.   4.   7.  11.   0.  13.  10.  12.   9.  15.\n",
      "    3.   3.  15.   7.  11.  14.   2.  13.   5.   6.  14.   9.   9.  15.\n",
      "   14.  15.  15.  14.]] , prediction:  [ 6  5 14  2 13  6 12 14  3  8  2  9  8  8  5 11 13  3  8  9  8  6  6  0 12\n",
      "  6 15  6  3 14  3 15  9 13  2  6 10 15 11  7  2  9  3  4  3 14  3  2  2  9\n",
      "  8 13 10  5  7 13  2  7  3  5  4 15  3  9 10  6  4  3  9  4 12 10  5 11  9\n",
      " 12 15  1 10  8  9  5  6 11  6 14 10  4 15  2  8  6  3  8  5  1 15  4  3  5\n",
      "  6 13 13 14  8  5  4  6 14 12 14  2  2  3 10  9 13 14  9  6 14  2  7  8 10\n",
      "  8  4  2 10 14 14 11  8 11 13 12 12 13 14 14  7 10  0  3  7  8  5 15  0  1\n",
      "  4 11  8  7  4  3  5  3  4 13  5 14  8 14 13  3  0  2 12  7 14 12 14  4  7\n",
      " 11  0 13 10 12  9 11  3  3 11  6  1 14  2 13  5  6 14  9  9 15 14  7 15 14]\n",
      "Training step 46000 --> loss=0.228123\n",
      "\n",
      "Iteration 46200 out of 59600\n",
      "Iteration 46400 out of 59600\n",
      "Iteration 46600 out of 59600\n",
      "Iteration 46800 out of 59600\n",
      "Iteration 47000 out of 59600\n",
      "Training step  47000  --> Real class:  [[  2.   8.   8.  13.  11.   4.   2.   0.   6.   2.  13.   9.   1.   3.\n",
      "   11.   0.   4.  14.  10.  14.   3.   5.   3.  11.   7.   9.   0.  14.\n",
      "   12.   4.   7.   0.   5.   7.  13.   3.   1.  11.  12.   5.   9.   3.\n",
      "    4.   1.   2.   7.  14.   7.   5.   4.   8.   2.  14.   7.  10.   7.\n",
      "   12.  13.   5.   1.   9.  15.   6.  11.   1.   6.   3.   9.  14.   2.\n",
      "    3.   3.   6.  10.   8.   2.   7.  13.   3.   3.   9.   9.   5.  15.\n",
      "    5.   2.  12.   5.  11.   9.  13.   4.   7.   1.  12.   8.   2.   7.\n",
      "    1.  14.  10.   4.   0.   7.  12.   6.   9.  13.  11.  14.  12.   7.\n",
      "   11.   9.  10.   3.   5.   8.   8.   8.   7.  10.  10.   8.  10.  13.\n",
      "    7.   7.  10.  10.   7.   2.  10.  10.   4.   2.   0.   6.  13.   4.\n",
      "    3.   3.   6.   6.   8.   0.  15.  13.   3.   5.   9.  11.   7.  14.\n",
      "    8.   9.   3.   1.   1.   6.   6.   1.  12.  10.   9.   9.   2.   7.\n",
      "   13.   6.  14.  11.   0.  10.   2.   6.  12.   4.   8.   4.   7.   1.\n",
      "   10.   3.  10.   3.  12.  14.   5.  15.   7.  10.  14.   3.   1.  12.\n",
      "    5.   9.  12.  14.]] , prediction:  [ 2  8  8 13 11  4  2  0  6  2 13  9  1  3 11  0  4 14 10 14  3  5  3 11  7\n",
      "  9  0 14 12  4  7  0  5  7 15  3  1  3 12  5 13  2  4  1  2  7 14  7  5  4\n",
      "  8  2  6  7 10  3 12 13  5  1  9  6  6 11  1  6  3  9 14  2  3  3  6 10  8\n",
      "  2  7 13  3  3  9  9  5 11  5  2 12  5 11  9 13  4  7  1  4  8  2  7  1 14\n",
      " 10  4  0  7 12  6  9 13 11 14 12  6 11  9 10  1  5  8  8  8  7 10 10  8 10\n",
      " 13  7  7 10 10  7 11 10 10  6  2  0  6 15  4  3  3  6  6  8  8 15 13  3  5\n",
      "  9 11  7 14  8  9  3  1  1  6  6  1 12 10  8  8  2  7 13  6 14 11  0 10  2\n",
      "  6 12  4  8  6  6  1 11  3 10  3 12 14 15 15  6 10 14  3  1 12  5  9 12 14]\n",
      "Training step 47000 --> loss=0.277896\n",
      "\n",
      "Iteration 47200 out of 59600\n",
      "Iteration 47400 out of 59600\n",
      "Iteration 47600 out of 59600\n",
      "Iteration 47800 out of 59600\n",
      "Iteration 48000 out of 59600\n",
      "Training step  48000  --> Real class:  [[ 12.  14.   9.   9.   2.  14.   9.  11.   9.   9.   9.   3.   5.  13.\n",
      "   13.   3.  10.   8.   6.   2.   3.   4.   3.  15.  15.   8.  11.   6.\n",
      "   13.   2.   4.   4.  10.   9.   5.   1.  12.   4.  12.   5.  15.   2.\n",
      "    3.   9.   1.   4.  15.   6.   2.   3.   9.   7.  12.   0.  13.   8.\n",
      "    2.   8.   2.  12.   7.   9.  13.   4.   9.   7.   8.   5.   5.  10.\n",
      "   15.   2.  10.   9.   9.   9.   7.  10.  11.   6.   9.   6.   4.   2.\n",
      "   15.   6.  11.   0.  12.  11.   8.   9.   1.  13.   7.  14.  14.   7.\n",
      "    6.  14.   5.   3.   2.  14.  13.   5.  11.   8.  11.   6.   5.   4.\n",
      "    5.   7.  12.   3.   2.   1.   4.  10.   3.  12.  12.   2.   5.  10.\n",
      "    8.   3.   9.   8.   8.   6.   1.  12.   5.  11.  11.   5.   2.  12.\n",
      "    1.  11.  11.  14.   2.   3.   7.   2.   1.  13.   7.   1.  12.   0.\n",
      "    1.   7.   2.   7.   5.  10.   2.  11.   1.  14.   9.   3.   9.   8.\n",
      "    7.  12.   7.  13.   9.   6.   0.  10.  14.   7.   3.   5.   1.  11.\n",
      "    4.   4.   7.  14.   6.   9.   7.   1.   2.   8.   1.   2.   7.  15.\n",
      "    6.  12.   6.   3.]] , prediction:  [12  6  9  9  2 14  8 11  9  9  9  3  5 13 13  3 10  8  6  2  3  4  3 15 15\n",
      "  8 11  6 12  2  4  4 10  9  5  1 12  4 12  5 15  2  3  8  1  4 15  6  2  3\n",
      "  9  7 12  0 13  8  2  8  2 12  7  9 13  4  9  7  8  5  5 10 15  2 10  9  9\n",
      "  9  7 10 11  6  9  2  4  2 15  6 11  0 12 11  8  1  1 13  7 14 14  7  6 14\n",
      "  5  3  2 14 13  5 11  8 11  6  5  4  5  7 12  3  2  1  4 10  3 12 12  2  5\n",
      " 10  8  3  9  8  8  6  1 12  5 11 11  5  2 12  3 11 11 14  2  3  7  2  1 13\n",
      "  7  1 12  0  3  7  2  3  5 10  2 11  1 14  9  3  9  8  7 12  7 13  9  6  0\n",
      " 10 14  7  3  5  1 11  4  4  7 14  6  9  7  1  2  8  1  2  7 13  6 12  6  3]\n",
      "Training step 48000 --> loss=0.173325\n",
      "\n",
      "Iteration 48200 out of 59600\n",
      "Iteration 48400 out of 59600\n",
      "Iteration 48600 out of 59600\n",
      "Iteration 48800 out of 59600\n",
      "Iteration 49000 out of 59600\n",
      "Training step  49000  --> Real class:  [[ 13.  13.   5.  12.   4.  11.  13.   6.   4.  10.  12.   1.   8.  11.\n",
      "   12.   9.  10.  12.   5.   3.   7.   0.   5.  15.   5.  11.  15.   2.\n",
      "   14.   3.   5.   5.  11.   1.  15.   5.   6.   3.  13.   2.  11.   3.\n",
      "    5.   3.   8.   1.  14.  13.   3.   4.   6.  10.  15.   7.  14.   1.\n",
      "   14.   2.  14.  12.   7.   6.   6.   5.  11.  13.   4.   5.   4.   3.\n",
      "   15.  11.   2.  15.  13.  11.   8.   6.   8.  13.  15.  14.   5.   7.\n",
      "   11.   6.  15.  15.   4.  11.   9.  12.   5.  12.   0.  13.   6.  14.\n",
      "    7.   2.  14.   7.   9.   4.   5.  11.  13.  10.   4.   2.   6.   0.\n",
      "    3.  11.  10.   7.   8.   9.  14.  14.   8.   1.   3.  10.   5.   8.\n",
      "   15.   8.  11.   1.   5.   0.   1.   6.   5.  12.   4.   6.  12.  14.\n",
      "    4.  12.  12.   5.   8.  13.   2.  15.   2.   4.   6.   5.   9.   1.\n",
      "   14.  10.  11.   7.   7.  13.   3.  14.  10.   4.   2.  13.   5.   2.\n",
      "    4.   8.   2.   0.   2.   8.   8.  12.   3.  14.   5.   9.  15.   5.\n",
      "    0.  12.   2.  11.  12.   9.  14.   2.   2.   7.   9.   5.  12.  12.\n",
      "    5.  13.  13.  12.]] , prediction:  [13 13  5 12  4 11 13  6  0 10 12  1  8 11 12  9 10 12  5  3  7  0  5  7  5\n",
      " 11 13  2 14  3  7  5 11  1 13  5  6  3 13  2 11  3  5  3  8  1 14 13  3  4\n",
      "  6 10 15  7 14  1 14  2 14 12  7  6  6  5 11 13  4  5  4  3 15 11  2  7 13\n",
      " 11  8  6  8 13 15 14  5  7 11  6 15 15  4 11  9 12  5 14  0 13  2 14  7  2\n",
      " 14  7  9  4  5 11 13 10  4 10  6  0  3 11 10  7  8  9 14 14  8  1  3 10  5\n",
      "  8 15  8 11  1  1  0  1  6  5 12  4  6  4 14  4 12  4  5  8 13  2 15  2  4\n",
      "  6  5  9  1 14 10 11  7  7 13  3 14 10  6  2 13  5  2  4  8  2  0  2  8  8\n",
      " 12  1 14  5  9 15  5  0 12  2 11 12  9 14  2  2  7  9  5 12 12  5 13 13 12]\n",
      "Training step 49000 --> loss=0.245322\n",
      "\n",
      "Iteration 49200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49400 out of 59600\n",
      "Iteration 49600 out of 59600\n",
      "Iteration 49800 out of 59600\n",
      "Iteration 50000 out of 59600\n",
      "Training step  50000  --> Real class:  [[  6.   3.  11.  15.   9.  13.  15.   7.   2.   7.   4.   5.  15.  13.\n",
      "    7.   1.   6.   1.   6.   8.   2.   2.   7.   2.   6.   3.  11.   7.\n",
      "    0.  15.  10.  15.   2.   2.   1.   1.   1.  13.   5.   6.  14.   5.\n",
      "    4.  14.   1.   1.   2.  13.  15.   2.  15.   9.   3.   1.  15.  14.\n",
      "    7.   2.  12.   1.   5.   9.   2.   1.  13.   5.   8.  12.   9.  12.\n",
      "    2.  14.  10.   4.  13.  10.  10.   6.   8.  11.   7.   1.   6.   9.\n",
      "   14.  15.  15.  11.  13.   3.   2.   3.   7.   9.  12.  11.   2.  11.\n",
      "    5.  15.   1.   1.   6.   3.   8.  14.  13.  11.   8.   2.   4.  14.\n",
      "    9.   3.   5.   7.  11.   5.  15.   6.  13.   3.   9.   6.   5.   4.\n",
      "    2.   1.   1.   9.  10.   5.   9.   7.  13.   6.   2.   6.  15.  11.\n",
      "    6.  11.  15.   0.   4.   5.   5.  10.   7.   1.   5.   5.  12.  14.\n",
      "    2.   3.   5.  11.   0.   4.  14.   6.  11.  14.   5.   3.   9.  15.\n",
      "   12.   2.   2.  14.   2.  15.  13.   3.   7.   4.   4.   7.   2.   4.\n",
      "   15.   2.   6.  10.  12.   1.   8.   8.   6.   5.   6.   0.  11.   3.\n",
      "   13.  13.   6.  13.]] , prediction:  [ 6  3 11 15  9 13 15  7  2  7  4 13 15 13  7  1  6  1  6  8  2  2  7  2  6\n",
      "  3 11  7  0 15 10 15  2  2  1  3  1 13 13  6 14  5  4 14  1  1  2  5 11  2\n",
      " 15  9  3  1 15 14  7  2 12  1  5  9  2  1 13  5  8 12  9 12  2 14 10  4 13\n",
      " 10 10  6  8 11  7  1  6  9 14 15 15 11 13  3  2  3  7  9 12 11  2 11  5 15\n",
      "  1  1  6  3  8 13 12 11  8  2  4 14  9  3  5  6 11  5 15  6 13  3  9  6  5\n",
      "  4  2  1  1  9 10  5  9  7 13  6  2  6 15 11  6 11 15  0  6  5  5 11  7  1\n",
      "  5  5 12 10  2  3  5 11  0  4 14  6 11 14  5  3  9 15 12  2  2 14  2 15 13\n",
      "  3  7  4  4  7  2  4 15  2  6 10 12  1  8  8  6 13  6  0 11  3  9 13  6 13]\n",
      "Training step 50000 --> loss=0.191488\n",
      "\n",
      "Iteration 50200 out of 59600\n",
      "Iteration 50400 out of 59600\n",
      "Iteration 50600 out of 59600\n",
      "Iteration 50800 out of 59600\n",
      "Iteration 51000 out of 59600\n",
      "Training step  51000  --> Real class:  [[ 15.  11.  15.   1.   8.   4.   1.   6.  14.  14.   1.   3.  14.  14.\n",
      "    2.   2.   5.  15.  13.  15.   4.  11.   7.  15.   6.   7.   7.   4.\n",
      "   10.  11.  10.  13.  12.   0.   6.   3.   1.  15.   4.   9.  10.   3.\n",
      "    8.   5.   1.   4.   3.   6.  14.  13.  10.   5.   8.   2.   9.   8.\n",
      "   10.  11.  13.  11.  15.  13.  15.  11.   4.   8.   4.   8.   0.   2.\n",
      "   12.  11.  13.   8.   2.   8.  10.  10.  12.  15.   1.   5.   3.   4.\n",
      "    5.   1.   7.   1.   2.   6.  15.  14.   6.  11.   9.   5.   5.   3.\n",
      "    6.  12.  14.   8.  10.   6.  12.  11.  10.  14.  12.  10.   5.   5.\n",
      "    3.   5.   5.  11.  12.   2.  11.  11.   6.   7.   1.  13.  14.   4.\n",
      "    9.   8.   2.   5.   5.   3.  11.   1.   9.  10.  14.   5.   1.   0.\n",
      "    6.   2.  13.  10.   9.   9.   2.  10.   9.   4.   1.   7.   1.  14.\n",
      "   12.  12.   7.  11.   8.  14.   8.  15.  14.   1.  10.  14.   2.   6.\n",
      "    6.   7.   5.  11.  10.   5.   4.   8.  14.   8.   3.  13.  15.   2.\n",
      "    4.   4.  13.   1.   4.  10.   1.  15.   0.   9.  10.   6.   4.   5.\n",
      "   12.   3.   6.  13.]] , prediction:  [15 11 15  1  8  4  1  6 14 14  1  3 14 14  2  2  5 15 13 15  4 11  7 15  6\n",
      "  7  7  4 10 11 10 13 12  0  6  3  1 15  4  9 10  3  8  5  1  4  3  6 14 13\n",
      " 10  5  8  2  9  8 10 11 13 11 15 13 14 11  4  8  4  8  0  2 12 11 13  8  2\n",
      "  8 10 10 12 15  1  5  3  4  5  1  7  1  2  6 15 14  6 11  9  5  5  3  6 12\n",
      " 14  8 10  6 12 11 10 14 12 10  5  5  3  5  5 11 12  2 11 11  6  7  1 13 14\n",
      "  4  9  8  2  5  5  3 11  1  8 10 14  5  1  0  6  2 13 10  9  9  2 10  9  4\n",
      "  1  7  1 14 12 12  7 11  8 14  8 15 14  1 10 14  2  6  6  7  5 11 10  5  4\n",
      "  8 14  8  3 13 14  2  4  4 13  1  4 10  1 15  0  9 10 14  4  5 12  3  6 13]\n",
      "Training step 51000 --> loss=0.119443\n",
      "\n",
      "Iteration 51200 out of 59600\n",
      "Iteration 51400 out of 59600\n",
      "Iteration 51600 out of 59600\n",
      "Iteration 51800 out of 59600\n",
      "Iteration 52000 out of 59600\n",
      "Training step  52000  --> Real class:  [[  4.  14.   3.  12.  10.   3.  11.  11.  10.   9.   5.   0.   2.  10.\n",
      "   13.   1.  11.   9.  14.  11.   8.   7.   2.   8.   9.   6.  14.  14.\n",
      "    6.  14.   1.   8.   5.   9.   0.   8.   1.  13.   1.   6.   5.   5.\n",
      "    4.   4.  10.   5.   9.  10.   6.   3.   6.   5.  13.  13.   4.   6.\n",
      "    2.   3.   8.   4.  12.   3.  11.  10.   3.  13.  10.   1.   9.   4.\n",
      "   12.  14.   4.   1.  14.  15.   8.   6.   9.   8.   7.   8.   8.  12.\n",
      "    8.   3.   8.  12.   3.  12.  12.   4.   9.  14.  15.   9.   7.  10.\n",
      "   14.   5.   8.   9.   1.  14.  10.   6.   3.   4.   7.  10.   3.   1.\n",
      "    3.  13.   9.   8.   4.  13.  15.   9.  13.  14.   5.   1.  13.   4.\n",
      "    0.   5.   5.  13.  12.   6.   6.  15.   4.   9.  12.   4.   1.   0.\n",
      "   13.   7.  14.   3.  12.   9.   3.   2.   3.   7.   5.   3.  12.  13.\n",
      "   11.   1.  15.   3.   4.   2.   5.  13.   3.  14.   9.   2.   1.  14.\n",
      "    9.  14.   7.   7.  12.  10.   2.  15.  15.   8.   9.   2.   3.   5.\n",
      "    2.  14.   3.   8.   2.   2.  10.   7.   8.   8.  13.   1.   1.  13.\n",
      "   10.   4.   1.  13.]] , prediction:  [ 4 14  3 12 10  3 11 11 10  9  5  0  2 10 13  1 11  9 14 11  8  7  2  8  9\n",
      "  6 14 14 14 14  1  8  5  9  0  8  1 13  1  6  5  5  4  4 10  5  9 10  6  3\n",
      " 14  5 13 12  4  6  2  3  8  4 12  3 11 10  3 13 15  1 13  4 12 14  4  1 14\n",
      " 15  8  6  9  8  7  8  8 12  8  3  8 12  3 12 12  4  9 14 11  9  7 10 14  7\n",
      "  8  9  1 14 10  6  3  4  7 10  3  1 11  5  9  8  4 13 15  9 13 14  5  1 13\n",
      "  4  0  5  5 13 12  6  6 15  4  9 12  4  1  0 13  7 14  3 12  9  3  2  3  7\n",
      "  7  3 12 13 11  1 15  3  4  2  5 13  3 14  9  2  1 14  9 14  7  7 12 15  2\n",
      " 13 15  8  1  2  7  4  2 14  3  8  2  2 10  7  8  8 13  1  1 13 10  4  1 13]\n",
      "Training step 52000 --> loss=0.215275\n",
      "\n",
      "Iteration 52200 out of 59600\n",
      "Iteration 52400 out of 59600\n",
      "Iteration 52600 out of 59600\n",
      "Iteration 52800 out of 59600\n",
      "Iteration 53000 out of 59600\n",
      "Training step  53000  --> Real class:  [[  7.   2.   1.  12.  14.   1.   9.   6.   4.   6.   7.   1.  15.  14.\n",
      "    1.  14.  11.   9.  12.   5.   6.   8.   2.  14.   8.   1.   0.   9.\n",
      "    6.   9.   3.   1.   1.  15.   5.  11.  11.  15.   7.  14.   1.   8.\n",
      "    9.   9.   6.  10.   8.   7.   4.  11.   4.   4.  10.   2.  14.   4.\n",
      "   13.   9.  14.   3.   1.   1.  15.  14.   8.   8.  14.  13.   3.   2.\n",
      "    7.  15.  11.  14.   4.   3.   4.   7.  11.  14.   2.  11.   3.  13.\n",
      "   11.   4.   3.   1.   2.   4.   5.   7.   7.   9.  11.  10.  11.   1.\n",
      "    7.   3.  10.   4.   3.   4.  15.   6.  13.   8.  11.  11.  14.   9.\n",
      "    2.   4.  13.  14.   8.   6.   4.   3.   8.  12.  15.   9.   2.   4.\n",
      "   11.  13.  13.   5.  11.   8.  10.   6.   8.   5.   1.   4.   4.  10.\n",
      "    6.   0.   2.   8.  15.  11.   6.   8.   6.   2.   2.   7.   1.  11.\n",
      "   10.   7.   6.  13.   1.   7.   3.  10.   7.   1.   3.   8.   2.   8.\n",
      "    9.   3.  11.  10.  13.   9.  15.  14.   6.   3.  15.   7.  10.  10.\n",
      "    2.   3.   7.   6.   7.  11.   9.   4.   3.  14.   9.  15.  15.   9.\n",
      "   15.   0.  11.   5.]] , prediction:  [ 7  2  1 12  6  1  9  6  4  6  7  1 15 14  1 14 11  9 12  5  6  8  2 14  8\n",
      "  1  0  9  6  9  3  1  1 15  5 11 11 15  7 14  1  8  9  9  6 10  8  7  4 11\n",
      "  4  4 10  2 14  4 13  9 14  3  1  1 15 14  8  8 14 13  3  2  7 15 11 14  4\n",
      "  3  4  7 11 14  2 11  3  9 11  4  3  1  2  4  5  7  7  9 11 10 11  1  7  3\n",
      " 10  4  3  4 15  6  9  8 11 11 14  9  2  4 13 14  8  6  4  3  8 12 15  9  2\n",
      "  4 11 13 13  5 11  8 10  6  8  5  1  4  4 10  6  0  2  8 15 11  6  8  6  2\n",
      "  2  7  1 11 10  7  6 13  1  7  3 10  5  1  3  8  2  8  9  3 11 10 13  9 15\n",
      " 14  6  3 15  7 10 10  2  3  7  6  7 11  9  4 11 14  9 15 15  9 15  0 11  5]\n",
      "Training step 53000 --> loss=0.137596\n",
      "\n",
      "Iteration 53200 out of 59600\n",
      "Iteration 53400 out of 59600\n",
      "Iteration 53600 out of 59600\n",
      "Iteration 53800 out of 59600\n",
      "Iteration 54000 out of 59600\n",
      "Training step  54000  --> Real class:  [[  4.  12.  15.   4.   6.   8.   7.   4.  11.   9.   5.   8.   6.  15.\n",
      "   10.   1.   5.   2.   8.   9.  13.   7.   9.  14.   9.  15.  15.   4.\n",
      "   12.  13.  15.  11.  12.  12.  12.   7.  10.   1.  12.  11.   6.   7.\n",
      "   14.  12.   3.  13.   8.  15.  12.   0.  13.   2.  14.   9.   9.   6.\n",
      "   12.  13.   5.  12.   3.  15.   4.  10.   5.   0.  13.   6.  12.   0.\n",
      "   11.  14.   3.   7.   6.   2.  12.   2.   5.   8.  14.   4.  10.   2.\n",
      "    0.   9.   5.   4.  10.  10.  11.   4.  13.   6.   7.  11.   1.   4.\n",
      "   10.   6.   8.  13.  10.   4.  11.   4.   4.   0.   8.   0.   2.   1.\n",
      "   11.  11.  14.   8.   7.   5.   2.  11.  15.  12.  15.   9.   6.   2.\n",
      "    6.  10.  10.  10.   3.  12.  14.  10.   9.   6.   8.   3.  15.  13.\n",
      "    7.   7.  11.  11.  14.  12.   1.  10.   3.  11.   0.   4.   7.  14.\n",
      "    5.   7.  12.   1.  13.   5.   4.  15.   5.   5.  12.  13.  12.   8.\n",
      "    2.   5.   6.   6.  11.   9.  15.  12.   2.   2.   6.  10.  15.   6.\n",
      "    5.   8.   3.   2.   6.   4.   1.  15.   5.   0.   6.  10.  15.   2.\n",
      "    5.   7.   1.   6.]] , prediction:  [ 4 12  7  4  6  8  7  4 11  9  5  8  6 15 10  1  5  2  8  9 13  7  9 14  9\n",
      " 15 15  4 12 13 15 11  8 12 12  7  6  1 12 11  6  7 14 12  3 13  8 15 12  0\n",
      "  5  2 14  9  9  6 12 13  5 12  3 15  4 10  5  0 13  6 12  0 11 14  3  5  6\n",
      "  2 12  2  5  8 14  4 10  2  0  9  5  4 10 10 11  4 13 14  7 11  1  4 10  6\n",
      "  8 13 10  4 11  4  4  8  8  0  2  1 11  1  6  8  7  5  2 11 14 12 15  9  6\n",
      "  2  6 10 10 10  3 12 14  6  9  6  8  3 15 13  7  7 11 11 14 12  1 14  3 11\n",
      "  0  4  7 14  5  7 12  1 13 13  4 15  5  5 12 13 12  8  2  5  6  6 11  9 15\n",
      " 12  2  2  2 10 15  6  5  8  3  2  6  4  1 15  5  0  6 10 15  2  5  7  1  6]\n",
      "Training step 54000 --> loss=0.199313\n",
      "\n",
      "Iteration 54200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 54400 out of 59600\n",
      "Iteration 54600 out of 59600\n",
      "Iteration 54800 out of 59600\n",
      "Iteration 55000 out of 59600\n",
      "Training step  55000  --> Real class:  [[  9.  11.   4.  11.  11.   3.   2.  11.  12.   8.   6.  13.  11.   8.\n",
      "    3.   1.  15.   6.  13.  14.   5.   9.  11.  12.  14.  12.  14.  15.\n",
      "   10.   1.   5.  10.   5.   3.   5.  10.  11.  12.  12.  12.   4.   4.\n",
      "    7.  14.  10.  15.   8.   3.  10.  10.   6.   5.   1.  11.  12.  10.\n",
      "   11.   4.   3.   2.  11.   2.   9.   6.   3.   1.   6.  11.  14.  11.\n",
      "    2.   4.   7.   5.   5.  14.   4.   7.  13.  11.  11.   4.  15.   3.\n",
      "   12.   8.   9.   5.   5.   9.   3.  12.   2.   1.   2.   7.  12.  15.\n",
      "    8.  11.  12.  12.  11.   5.  10.   3.  14.  10.   5.   7.  15.  15.\n",
      "   11.   4.  10.   6.  14.   2.   5.  10.   3.   4.   4.  12.  14.  12.\n",
      "    4.   2.   6.  15.   6.   1.   3.  12.   7.   9.  11.  12.  14.   5.\n",
      "    2.   4.  10.   3.  13.   6.  11.   0.   1.   5.   6.  15.   9.  13.\n",
      "    8.   7.  15.   6.   3.   5.   4.  12.  11.   1.  14.  15.   7.   8.\n",
      "    2.   8.   8.   2.  10.  12.   7.   6.   8.   3.  12.   7.   6.   2.\n",
      "    5.  11.   7.   4.   5.  10.   2.   4.  12.  10.   3.   7.   2.  12.\n",
      "   12.  11.   6.  14.]] , prediction:  [ 9 11  4 11 11  3  2 11 12  8  6 13 11  8  3  1 15 15 13  6  4  9 11 12 14\n",
      " 12 14 15 10  1  5 10  5  3  5 10 11 12 12 12  4  4  7 14 10 15  8  3 10 10\n",
      "  6  5  1 11 12 10 11  4  3  2 11  2  9  6  3  1  6 11 14 11  2  4  7  5  5\n",
      " 12  4  7 13 11 11  4 15  3 12  8  9  5  5  9  3 12  2  1  2  7 12 15  8 11\n",
      " 12 12 11  5 10  3 10 10  5  7 15 15 11  4 10  6 14  2  5 10  3  4  4 12 10\n",
      " 12  4  2  4 15  4  1  3 12  7  9 11 12 14  7  2  4 10  3 13  6 11  0  1  5\n",
      "  6 15  1 13  8  7 15  6  3 15  4 12 11  1 14 15  7  8  2  8  8  2 10 12  7\n",
      "  7  8  3 12  7  6  2  5 11  7  4  5 10  2  0 12 10  3  7  2 12 12 11  6 14]\n",
      "Training step 55000 --> loss=0.223794\n",
      "\n",
      "Iteration 55200 out of 59600\n",
      "Iteration 55400 out of 59600\n",
      "Iteration 55600 out of 59600\n",
      "Iteration 55800 out of 59600\n",
      "Iteration 56000 out of 59600\n",
      "Training step  56000  --> Real class:  [[  9.   0.   5.  14.   0.   1.   1.  11.   5.  10.   5.  11.  14.   7.\n",
      "    2.   1.  15.  15.  13.  14.   9.   9.   8.   1.  10.  10.  11.  10.\n",
      "    1.   7.   9.   1.   7.  14.   3.   5.   7.   9.   2.  15.  14.   7.\n",
      "    2.   4.   5.  13.  14.   8.   1.   7.   5.   4.  12.  11.  11.   5.\n",
      "   11.  12.   7.   2.   6.  10.  12.  12.   1.  11.  11.   8.   7.   1.\n",
      "    2.  13.  10.   9.   1.   3.   2.   3.  14.  13.   6.  11.  12.  10.\n",
      "    8.   4.   0.  12.   2.  11.  14.  13.  11.   2.   4.   1.   4.  14.\n",
      "    5.   8.  15.   8.   8.   4.   5.   0.  13.   3.   1.  13.   9.  14.\n",
      "   12.   4.   1.   1.   5.   9.  12.  12.  12.  13.   7.   9.   1.   0.\n",
      "   12.  14.  12.   3.   4.   3.   8.  11.   6.   6.   4.   8.   4.   8.\n",
      "   10.  14.  11.   3.  10.  15.   5.   5.   3.  14.   2.  15.   3.   8.\n",
      "    8.   2.  13.   6.   3.   2.   8.   7.  10.   3.   6.  10.   1.   8.\n",
      "    4.   8.  15.   2.   7.  12.  15.  15.  15.   8.   6.   1.  10.   7.\n",
      "    7.  13.  13.   4.   7.   4.  13.   8.   0.   7.   1.   1.  15.   4.\n",
      "    8.   8.  13.   5.]] , prediction:  [ 9  0  5 14  0  1  1 11  5 10  5 11 14  7  2  1 15 15 13 14  9  9  8  1 10\n",
      " 10 11 10  1  7  9  1  7 14  3  5  6  9  2  6 14  7  2  4 13 13 14  8  1  5\n",
      "  5  6 12 11 11  5 11 12  7  2  6 14 12 12  1 11 11  8  7  1  2 13 10  9  1\n",
      "  3  2  3 14 13  6 11 12 10  8  6  0 12  2 11 14 13 11  2  4  1  4 14  5  8\n",
      " 14  8  8  6  5  0 15  3  1 13  9 14 12  4  1  1  5  9 12 12 12 13  7  9  1\n",
      "  0 12 14 12  3  4  3  8 11  6  6  4  8  4  8 10 14 11  3 10 15  5  5  3 14\n",
      "  2 15  3  8  0  2 13  6  3  2  8  7 10  3  7 10  1  8  4  8 15  2 15 12 15\n",
      " 15 15  8  6  1 14  7  7 13  5  4  7  4 13  8  0  7  1  1 15  6  8  8  5  5]\n",
      "Training step 56000 --> loss=0.244275\n",
      "\n",
      "Iteration 56200 out of 59600\n",
      "Iteration 56400 out of 59600\n",
      "Iteration 56600 out of 59600\n",
      "Iteration 56800 out of 59600\n",
      "Iteration 57000 out of 59600\n",
      "Training step  57000  --> Real class:  [[  8.   8.   3.   1.   1.  10.  15.   3.  15.  15.  13.  14.   0.   2.\n",
      "    0.  10.  10.   7.   1.   3.  11.   7.   1.   1.  12.   3.   8.   2.\n",
      "    1.   1.   6.   7.   3.   1.   4.   9.  14.  13.  12.   4.   5.   0.\n",
      "    3.   0.  12.   7.  15.   9.  14.  11.  10.  12.   1.  10.   8.   7.\n",
      "    0.  11.  11.  11.  11.   4.   2.   5.   1.  13.  10.  10.   7.  11.\n",
      "    9.   5.   9.   8.   8.   2.   7.  13.   5.  12.  13.   2.   2.  13.\n",
      "    3.   7.   1.   9.   8.   1.   1.   2.   1.  12.   9.  14.  14.   5.\n",
      "   10.  14.   5.   6.  13.   6.   4.   1.  11.   3.   8.   5.  10.  12.\n",
      "    9.  10.   4.   9.   9.  14.   4.  12.  13.   9.   7.   1.   1.   0.\n",
      "   14.  10.   8.  15.   8.   1.  14.  13.  11.  12.   1.   2.   2.   0.\n",
      "    1.  12.   6.   8.   1.  11.   6.   3.   2.  12.  11.   7.  15.   4.\n",
      "   13.  12.   1.   7.   4.  13.   3.   2.   2.   7.  14.   5.  10.   7.\n",
      "    6.  10.  12.  15.   9.  12.   2.   6.   3.  11.   6.  12.   1.  10.\n",
      "    4.  11.   9.   9.   5.  14.   7.   2.   1.   6.  12.   5.  13.  13.\n",
      "    0.   5.  11.   7.]] , prediction:  [ 8  8  3  1  1 10 15  3 15 15 13 14  0  2  0 10 10  7  1  3 11  7  1  1 12\n",
      "  3  8  2  1  1  4  7  3  1  4  9 14 13 12  4  5  0  3  0 12  7  7  9 14  3\n",
      " 10 12  1 10  8  7  0 11 11 11 11  4  2  5  1 13  2 15  7  3  9  5  9  8  8\n",
      "  2  7 13  5 12 15  2  2 15  3  7  1  9  8  1  1  2  1 12  9 14  6  5 10 14\n",
      "  5  6 13  6  4  1 11  3  8  5 10 12  9 10  4  9  9 14  4 12  8  9  3  1  1\n",
      "  0 14 10  8 15  8  1 14  9 11  8  1  2  2  0  1 12  6  8  1 10  6  3  2 12\n",
      " 11  7  7  4 13 12  1  7  4 13  3  2  2  7 14  5 10  7  6 10 12 15  9 12  2\n",
      "  6  3 11  6 12  1 10  4 11  9  9  5 14  7  2  1  6 12  5 15 13  0  5 11  7]\n",
      "Training step 57000 --> loss=0.231723\n",
      "\n",
      "Iteration 57200 out of 59600\n",
      "Iteration 57400 out of 59600\n",
      "Iteration 57600 out of 59600\n",
      "Iteration 57800 out of 59600\n",
      "Iteration 58000 out of 59600\n",
      "Training step  58000  --> Real class:  [[  6.  14.   1.   0.   7.   2.   6.   9.   7.   9.  12.   4.   1.   8.\n",
      "    9.   1.   3.  12.   8.   9.  10.  10.  14.   8.  11.  10.   4.  13.\n",
      "    4.  15.   3.   6.  11.   9.   5.   1.   7.   1.   7.  12.   2.  13.\n",
      "   12.  10.   8.   7.   5.   4.   9.   4.   2.   1.   6.   0.  15.   3.\n",
      "    2.   7.   8.   0.   6.  12.   3.  13.  15.  13.  13.   5.   0.   3.\n",
      "    3.  12.  11.   6.   8.  15.  12.   6.  15.   7.  11.  12.  10.   4.\n",
      "   12.   3.   4.  13.   2.  14.  15.  13.   1.   2.  15.   6.   4.   2.\n",
      "    8.  13.   9.  10.   2.   5.  14.   7.   7.  13.   4.   2.  12.  12.\n",
      "   13.  15.  14.  11.  12.  11.   1.   5.   3.   1.  11.   5.  11.   3.\n",
      "    5.   1.   0.   9.  15.   5.  13.   4.  10.   5.   9.   0.  15.   6.\n",
      "    6.  11.   4.  13.   2.   8.   9.   4.   3.   1.   5.   3.   6.  14.\n",
      "    3.  10.   4.  10.   3.   5.   6.   8.  12.  11.   1.  14.  15.   1.\n",
      "    4.   9.  14.   6.   8.  10.  12.  13.   0.  15.   1.   1.  14.   6.\n",
      "   12.   2.   5.   9.   1.   8.  13.   1.  11.  13.  12.  13.  10.   9.\n",
      "   13.  10.   7.   4.]] , prediction:  [ 6 14  1  0  7  2  6  9  7  9 12 12  1  8  9  1  3  8  9  9 10 10 14  8 11\n",
      " 14  4 13  4 15  3  6 11  9  5  1  7  1  7 12  2 13 12 10  8  7  5  4  9  4\n",
      "  2  1  6  0 15  3  2  7  8  0  6 12  3 13 15 13 13  5  0  3  3 12 11  6  8\n",
      " 15 12  6 15  7 11  4 10  4 12  3  4 13  2 14 15 13  1  2 15  6  4  2  8 13\n",
      "  9 10  2  5 14  7  7 13  4  2  4 12  5 15 14 11 14 11  1  5  3  1 11  5 11\n",
      "  3  5  1  0  9 14  5 13  4 10  5  9  0 15  6  6 11  4 13  2  8  9  4  3  1\n",
      "  5  3  6 14  3 10  4 10  3  5  6  8 14 11  1 14 15  1  4  9 14  6  8 14 12\n",
      " 13  0 15  1  1 14  6 12  2  5  9  1  8 13  1 11 13 12 13 10  9  4 10  7  4]\n",
      "Training step 58000 --> loss=0.227889\n",
      "\n",
      "Iteration 58200 out of 59600\n",
      "Iteration 58400 out of 59600\n",
      "Iteration 58600 out of 59600\n",
      "Iteration 58800 out of 59600\n",
      "Iteration 59000 out of 59600\n",
      "Training step  59000  --> Real class:  [[  9.  13.   4.   6.   7.   7.   2.  14.  15.  13.   1.   5.   3.   7.\n",
      "    6.  13.  13.   5.  10.  11.   7.  10.   8.   8.   1.   3.   3.  14.\n",
      "    6.  10.   1.   2.  14.   5.  10.   5.  12.   7.   8.   6.  12.   2.\n",
      "    0.   9.  13.   7.   5.  12.  14.   1.   9.   0.   4.   6.  12.   8.\n",
      "    3.   4.  12.   7.  12.  14.  14.   2.  13.   6.   6.  12.   4.   6.\n",
      "   12.  11.   9.   2.   4.   3.  11.  12.   4.   4.  10.   9.  13.   7.\n",
      "   10.  11.  11.   5.  10.   4.   9.   3.  12.   8.   7.  14.  15.  12.\n",
      "    7.   8.   8.  10.  13.   6.   8.  11.   1.   6.   7.  14.   3.   8.\n",
      "   13.   3.   6.  10.   7.   5.  12.   5.  12.   2.   2.   9.   8.   2.\n",
      "    5.   2.   7.   6.  13.  12.   7.  11.  11.  14.  15.   0.  11.   3.\n",
      "    1.  14.  10.  12.  12.  13.  11.   1.   0.   2.   4.  14.   3.   1.\n",
      "    7.  10.   5.  12.   6.   9.   9.  12.   3.   8.  15.   4.  11.  10.\n",
      "   15.   5.   2.   1.   5.   7.   6.   8.   6.  14.   9.   4.   9.   2.\n",
      "    1.  11.   1.   8.  13.   4.   9.  11.   5.  15.   7.   2.   6.   6.\n",
      "    4.  13.   3.  14.]] , prediction:  [ 9 13  4  6  7  7  2 14 13 12  1  5  3  7  6 13 13  5 10 11  7 10  8  8  1\n",
      "  3  3 14  6  8  1  2 14  5 10  5 12  7  8  6 12  2  0  9 13  7  5 12 14  1\n",
      "  9  0  4  6 12  8 11  4 12  7 12 14 12  2 13  6  6 12  4  6 12 11  9  2  4\n",
      "  3 11 12  4  4 10  9 13  6 10 11 11  5 10  4  9  3 12  8  7  6 15 12  7 12\n",
      "  8 10 13  6  8 11  1  6  7 14  3  8 13  3  6 10  7  5 12  5 12  2  2  9  8\n",
      "  2  5  2  7  6 13 12  7 11 11 14 15  0 11  3  1 14 10 12 12 13 11  1  0  2\n",
      "  4 14  3  1  7 15  5 12  6  9  9 12  3  8 15  4 10 10 13  5  2  1  5  7  6\n",
      "  8  6  6  9  4  9  2  1 11  1  8  5  4  9 11  5 15  7  2  6  6  4 13  3 14]\n",
      "Training step 59000 --> loss=0.179753\n",
      "\n",
      "Iteration 59200 out of 59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 59400 out of 59600\n",
      "Iteration 59600 out of 59600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.30962324142456  seconds have elapsed during training\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    t = time.time()\n",
    "    ls = D.train(training_data_path, training_label_path,noise=mynoise, plot_step=250,fuzzify=0,use_data_subset=-1)\n",
    "    plt.plot(ls)\n",
    "    plt.show()\n",
    "    elapsed = time.time() - t\n",
    "    print(elapsed,' seconds have elapsed during training')\n",
    "except:\n",
    "    print('Some error occurred, probably test data file size exceeds maximum permitted size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "(60000, 100)\n",
      "(60000, 1)\n",
      "Loaded 7000 data samples and corresponding labels\n",
      "\n",
      "k=0: Avg loss so far = nan\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=1: Avg loss so far = 4.000000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=2: Avg loss so far = 2.000000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=3: Avg loss so far = 1.333333\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=4: Avg loss so far = 1.000000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=5: Avg loss so far = 0.800000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=6: Avg loss so far = 0.666667\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=7: Avg loss so far = 0.571429\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=8: Avg loss so far = 0.500000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=9: Avg loss so far = 0.444444\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=10: Avg loss so far = 0.400000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=11: Avg loss so far = 0.363636\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=12: Avg loss so far = 0.333333\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=13: Avg loss so far = 0.307692\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=14: Avg loss so far = 0.285714\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=15: Avg loss so far = 0.266667\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=16: Avg loss so far = 0.250000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=17: Avg loss so far = 0.235294\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=18: Avg loss so far = 0.222222\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=19: Avg loss so far = 0.210526\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=20: Avg loss so far = 0.200000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=21: Avg loss so far = 0.190476\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=22: Avg loss so far = 0.181818\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=23: Avg loss so far = 0.173913\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=24: Avg loss so far = 0.166667\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=25: Avg loss so far = 0.160000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=26: Avg loss so far = 0.153846\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=27: Avg loss so far = 0.148148\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=28: Avg loss so far = 0.142857\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=29: Avg loss so far = 0.137931\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=30: Avg loss so far = 0.133333\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=31: Avg loss so far = 0.129032\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=32: Avg loss so far = 0.125000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=33: Avg loss so far = 0.121212\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=34: Avg loss so far = 0.117647\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=35: Avg loss so far = 0.114286\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=36: Avg loss so far = 0.111111\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=37: Avg loss so far = 0.108108\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=38: Avg loss so far = 0.105263\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=39: Avg loss so far = 0.102564\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=40: Avg loss so far = 0.100000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=41: Avg loss so far = 0.097561\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=42: Avg loss so far = 0.095238\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=43: Avg loss so far = 0.093023\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=44: Avg loss so far = 0.090909\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=45: Avg loss so far = 0.088889\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=46: Avg loss so far = 0.086957\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=47: Avg loss so far = 0.085106\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=48: Avg loss so far = 0.083333\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=49: Avg loss so far = 0.081633\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=50: Avg loss so far = 0.080000\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=51: Avg loss so far = 0.078431\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=52: Avg loss so far = 0.076923\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=53: Avg loss so far = 0.075472\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=54: Avg loss so far = 0.074074\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=55: Avg loss so far = 0.072727\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=56: Avg loss so far = 0.071429\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=57: Avg loss so far = 0.070175\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=58: Avg loss so far = 0.068966\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=59: Avg loss so far = 0.067797\n",
      "     Misclassifications: 1\n",
      "\n",
      "k=60: Avg loss so far = 0.066667\n",
      "     Misclassifications: 2\n",
      "\n",
      "k=61: Avg loss so far = 1.114754\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=62: Avg loss so far = 1.161290\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=63: Avg loss so far = 1.142857\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=64: Avg loss so far = 1.125000\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=65: Avg loss so far = 1.107692\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=66: Avg loss so far = 1.090909\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=67: Avg loss so far = 1.074627\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=68: Avg loss so far = 1.058824\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=69: Avg loss so far = 1.043478\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=70: Avg loss so far = 1.028571\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=71: Avg loss so far = 1.014085\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=72: Avg loss so far = 1.000000\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=73: Avg loss so far = 0.986301\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=74: Avg loss so far = 0.972973\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=75: Avg loss so far = 0.960000\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=76: Avg loss so far = 0.947368\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=77: Avg loss so far = 0.935065\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=78: Avg loss so far = 0.923077\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=79: Avg loss so far = 0.911392\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=80: Avg loss so far = 0.900000\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=81: Avg loss so far = 0.888889\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=82: Avg loss so far = 0.878049\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=83: Avg loss so far = 0.867470\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=84: Avg loss so far = 0.857143\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=85: Avg loss so far = 0.847059\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=86: Avg loss so far = 0.837209\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=87: Avg loss so far = 0.827586\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=88: Avg loss so far = 0.818182\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=89: Avg loss so far = 0.808989\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=90: Avg loss so far = 0.800000\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=91: Avg loss so far = 0.791209\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=92: Avg loss so far = 0.782609\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=93: Avg loss so far = 0.774194\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=94: Avg loss so far = 0.765957\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=95: Avg loss so far = 0.757895\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=96: Avg loss so far = 0.750000\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=97: Avg loss so far = 0.742268\n",
      "     Misclassifications: 3\n",
      "\n",
      "k=98: Avg loss so far = 0.734694\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=99: Avg loss so far = 0.737374\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=100: Avg loss so far = 0.730000\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=101: Avg loss so far = 0.722772\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=102: Avg loss so far = 0.715686\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=103: Avg loss so far = 0.708738\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=104: Avg loss so far = 0.701923\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=105: Avg loss so far = 0.695238\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=106: Avg loss so far = 0.688679\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=107: Avg loss so far = 0.682243\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=108: Avg loss so far = 0.675926\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=109: Avg loss so far = 0.669725\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=110: Avg loss so far = 0.663636\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=111: Avg loss so far = 0.657658\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=112: Avg loss so far = 0.651786\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=113: Avg loss so far = 0.646018\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=114: Avg loss so far = 0.640351\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=115: Avg loss so far = 0.634783\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=116: Avg loss so far = 0.629310\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=117: Avg loss so far = 0.623932\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=118: Avg loss so far = 0.618644\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=119: Avg loss so far = 0.613445\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=120: Avg loss so far = 0.608333\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=121: Avg loss so far = 0.603306\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=122: Avg loss so far = 0.598361\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=123: Avg loss so far = 0.593496\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=124: Avg loss so far = 0.588710\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=125: Avg loss so far = 0.584000\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=126: Avg loss so far = 0.579365\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=127: Avg loss so far = 0.574803\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=128: Avg loss so far = 0.570312\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=129: Avg loss so far = 0.565891\n",
      "     Misclassifications: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=130: Avg loss so far = 0.561538\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=131: Avg loss so far = 0.557252\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=132: Avg loss so far = 0.553030\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=133: Avg loss so far = 0.548872\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=134: Avg loss so far = 0.544776\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=135: Avg loss so far = 0.540741\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=136: Avg loss so far = 0.536765\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=137: Avg loss so far = 0.532847\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=138: Avg loss so far = 0.528986\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=139: Avg loss so far = 0.525180\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=140: Avg loss so far = 0.521429\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=141: Avg loss so far = 0.517730\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=142: Avg loss so far = 0.514085\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=143: Avg loss so far = 0.510490\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=144: Avg loss so far = 0.506944\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=145: Avg loss so far = 0.503448\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=146: Avg loss so far = 0.500000\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=147: Avg loss so far = 0.496599\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=148: Avg loss so far = 0.493243\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=149: Avg loss so far = 0.489933\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=150: Avg loss so far = 0.486667\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=151: Avg loss so far = 0.483444\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=152: Avg loss so far = 0.480263\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=153: Avg loss so far = 0.477124\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=154: Avg loss so far = 0.474026\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=155: Avg loss so far = 0.470968\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=156: Avg loss so far = 0.467949\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=157: Avg loss so far = 0.464968\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=158: Avg loss so far = 0.462025\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=159: Avg loss so far = 0.459119\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=160: Avg loss so far = 0.456250\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=161: Avg loss so far = 0.453416\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=162: Avg loss so far = 0.450617\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=163: Avg loss so far = 0.447853\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=164: Avg loss so far = 0.445122\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=165: Avg loss so far = 0.442424\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=166: Avg loss so far = 0.439759\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=167: Avg loss so far = 0.437126\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=168: Avg loss so far = 0.434524\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=169: Avg loss so far = 0.431953\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=170: Avg loss so far = 0.429412\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=171: Avg loss so far = 0.426901\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=172: Avg loss so far = 0.424419\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=173: Avg loss so far = 0.421965\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=174: Avg loss so far = 0.419540\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=175: Avg loss so far = 0.417143\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=176: Avg loss so far = 0.414773\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=177: Avg loss so far = 0.412429\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=178: Avg loss so far = 0.410112\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=179: Avg loss so far = 0.407821\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=180: Avg loss so far = 0.405556\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=181: Avg loss so far = 0.403315\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=182: Avg loss so far = 0.401099\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=183: Avg loss so far = 0.398907\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=184: Avg loss so far = 0.396739\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=185: Avg loss so far = 0.394595\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=186: Avg loss so far = 0.392473\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=187: Avg loss so far = 0.390374\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=188: Avg loss so far = 0.388298\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=189: Avg loss so far = 0.386243\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=190: Avg loss so far = 0.384211\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=191: Avg loss so far = 0.382199\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=192: Avg loss so far = 0.380208\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=193: Avg loss so far = 0.378238\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=194: Avg loss so far = 0.376289\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=195: Avg loss so far = 0.374359\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=196: Avg loss so far = 0.372449\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=197: Avg loss so far = 0.370558\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=198: Avg loss so far = 0.368687\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=199: Avg loss so far = 0.366834\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=200: Avg loss so far = 0.365000\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=201: Avg loss so far = 0.363184\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=202: Avg loss so far = 0.361386\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=203: Avg loss so far = 0.359606\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=204: Avg loss so far = 0.357843\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=205: Avg loss so far = 0.356098\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=206: Avg loss so far = 0.354369\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=207: Avg loss so far = 0.352657\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=208: Avg loss so far = 0.350962\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=209: Avg loss so far = 0.349282\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=210: Avg loss so far = 0.347619\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=211: Avg loss so far = 0.345972\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=212: Avg loss so far = 0.344340\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=213: Avg loss so far = 0.342723\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=214: Avg loss so far = 0.341121\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=215: Avg loss so far = 0.339535\n",
      "     Misclassifications: 4\n",
      "\n",
      "k=216: Avg loss so far = 0.337963\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=217: Avg loss so far = 0.354839\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=218: Avg loss so far = 0.353211\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=219: Avg loss so far = 0.351598\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=220: Avg loss so far = 0.350000\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=221: Avg loss so far = 0.348416\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=222: Avg loss so far = 0.346847\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=223: Avg loss so far = 0.345291\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=224: Avg loss so far = 0.343750\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=225: Avg loss so far = 0.342222\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=226: Avg loss so far = 0.340708\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=227: Avg loss so far = 0.339207\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=228: Avg loss so far = 0.337719\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=229: Avg loss so far = 0.336245\n",
      "     Misclassifications: 5\n",
      "\n",
      "k=230: Avg loss so far = 0.334783\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=231: Avg loss so far = 0.337662\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=232: Avg loss so far = 0.336207\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=233: Avg loss so far = 0.334764\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=234: Avg loss so far = 0.333333\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=235: Avg loss so far = 0.331915\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=236: Avg loss so far = 0.330508\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=237: Avg loss so far = 0.329114\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=238: Avg loss so far = 0.327731\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=239: Avg loss so far = 0.326360\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=240: Avg loss so far = 0.325000\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=241: Avg loss so far = 0.323651\n",
      "     Misclassifications: 6\n",
      "\n",
      "k=242: Avg loss so far = 0.322314\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=243: Avg loss so far = 0.325103\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=244: Avg loss so far = 0.323770\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=245: Avg loss so far = 0.322449\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=246: Avg loss so far = 0.321138\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=247: Avg loss so far = 0.319838\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=248: Avg loss so far = 0.318548\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=249: Avg loss so far = 0.317269\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=250: Avg loss so far = 0.316000\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=251: Avg loss so far = 0.314741\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=252: Avg loss so far = 0.313492\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=253: Avg loss so far = 0.312253\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=254: Avg loss so far = 0.311024\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=255: Avg loss so far = 0.309804\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=256: Avg loss so far = 0.308594\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=257: Avg loss so far = 0.307393\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=258: Avg loss so far = 0.306202\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=259: Avg loss so far = 0.305019\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=260: Avg loss so far = 0.303846\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=261: Avg loss so far = 0.302682\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=262: Avg loss so far = 0.301527\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=263: Avg loss so far = 0.300380\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=264: Avg loss so far = 0.299242\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=265: Avg loss so far = 0.298113\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=266: Avg loss so far = 0.296992\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=267: Avg loss so far = 0.295880\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=268: Avg loss so far = 0.294776\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=269: Avg loss so far = 0.293680\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=270: Avg loss so far = 0.292593\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=271: Avg loss so far = 0.291513\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=272: Avg loss so far = 0.290441\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=273: Avg loss so far = 0.289377\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=274: Avg loss so far = 0.288321\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=275: Avg loss so far = 0.287273\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=276: Avg loss so far = 0.286232\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=277: Avg loss so far = 0.285199\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=278: Avg loss so far = 0.284173\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=279: Avg loss so far = 0.283154\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=280: Avg loss so far = 0.282143\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=281: Avg loss so far = 0.281139\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=282: Avg loss so far = 0.280142\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=283: Avg loss so far = 0.279152\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=284: Avg loss so far = 0.278169\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=285: Avg loss so far = 0.277193\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=286: Avg loss so far = 0.276224\n",
      "     Misclassifications: 7\n",
      "\n",
      "k=287: Avg loss so far = 0.275261\n",
      "     Misclassifications: 8\n",
      "\n",
      "k=288: Avg loss so far = 0.288194\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=289: Avg loss so far = 0.290657\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=290: Avg loss so far = 0.289655\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=291: Avg loss so far = 0.288660\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=292: Avg loss so far = 0.287671\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=293: Avg loss so far = 0.286689\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=294: Avg loss so far = 0.285714\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=295: Avg loss so far = 0.284746\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=296: Avg loss so far = 0.283784\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=297: Avg loss so far = 0.282828\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=298: Avg loss so far = 0.281879\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=299: Avg loss so far = 0.280936\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=300: Avg loss so far = 0.280000\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=301: Avg loss so far = 0.279070\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=302: Avg loss so far = 0.278146\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=303: Avg loss so far = 0.277228\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=304: Avg loss so far = 0.276316\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=305: Avg loss so far = 0.275410\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=306: Avg loss so far = 0.274510\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=307: Avg loss so far = 0.273616\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=308: Avg loss so far = 0.272727\n",
      "     Misclassifications: 9\n",
      "\n",
      "k=309: Avg loss so far = 0.271845\n",
      "     Misclassifications: 10\n",
      "\n",
      "k=310: Avg loss so far = 0.477419\n",
      "     Misclassifications: 10\n",
      "\n",
      "k=311: Avg loss so far = 0.475884\n",
      "     Misclassifications: 10\n",
      "\n",
      "k=312: Avg loss so far = 0.474359\n",
      "     Misclassifications: 10\n",
      "\n",
      "k=313: Avg loss so far = 0.472843\n",
      "     Misclassifications: 10\n",
      "\n",
      "k=314: Avg loss so far = 0.471338\n",
      "     Misclassifications: 10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=315: Avg loss so far = 0.469841\n",
      "     Misclassifications: 10\n",
      "\n",
      "k=316: Avg loss so far = 0.468354\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=317: Avg loss so far = 0.517350\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=318: Avg loss so far = 0.515723\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=319: Avg loss so far = 0.514107\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=320: Avg loss so far = 0.512500\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=321: Avg loss so far = 0.510903\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=322: Avg loss so far = 0.509317\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=323: Avg loss so far = 0.507740\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=324: Avg loss so far = 0.506173\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=325: Avg loss so far = 0.504615\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=326: Avg loss so far = 0.503067\n",
      "     Misclassifications: 11\n",
      "\n",
      "k=327: Avg loss so far = 0.501529\n",
      "     Misclassifications: 12\n",
      "\n",
      "k=328: Avg loss so far = 0.548780\n",
      "     Misclassifications: 12\n",
      "\n",
      "k=329: Avg loss so far = 0.547112\n",
      "     Misclassifications: 12\n",
      "\n",
      "k=330: Avg loss so far = 0.545455\n",
      "     Misclassifications: 12\n",
      "\n",
      "k=331: Avg loss so far = 0.543807\n",
      "     Misclassifications: 12\n",
      "\n",
      "k=332: Avg loss so far = 0.542169\n",
      "     Misclassifications: 12\n",
      "\n",
      "k=333: Avg loss so far = 0.540541\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=334: Avg loss so far = 0.550898\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=335: Avg loss so far = 0.549254\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=336: Avg loss so far = 0.547619\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=337: Avg loss so far = 0.545994\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=338: Avg loss so far = 0.544379\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=339: Avg loss so far = 0.542773\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=340: Avg loss so far = 0.541176\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=341: Avg loss so far = 0.539589\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=342: Avg loss so far = 0.538012\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=343: Avg loss so far = 0.536443\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=344: Avg loss so far = 0.534884\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=345: Avg loss so far = 0.533333\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=346: Avg loss so far = 0.531792\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=347: Avg loss so far = 0.530259\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=348: Avg loss so far = 0.528736\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=349: Avg loss so far = 0.527221\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=350: Avg loss so far = 0.525714\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=351: Avg loss so far = 0.524217\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=352: Avg loss so far = 0.522727\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=353: Avg loss so far = 0.521246\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=354: Avg loss so far = 0.519774\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=355: Avg loss so far = 0.518310\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=356: Avg loss so far = 0.516854\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=357: Avg loss so far = 0.515406\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=358: Avg loss so far = 0.513966\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=359: Avg loss so far = 0.512535\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=360: Avg loss so far = 0.511111\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=361: Avg loss so far = 0.509695\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=362: Avg loss so far = 0.508287\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=363: Avg loss so far = 0.506887\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=364: Avg loss so far = 0.505495\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=365: Avg loss so far = 0.504110\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=366: Avg loss so far = 0.502732\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=367: Avg loss so far = 0.501362\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=368: Avg loss so far = 0.500000\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=369: Avg loss so far = 0.498645\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=370: Avg loss so far = 0.497297\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=371: Avg loss so far = 0.495957\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=372: Avg loss so far = 0.494624\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=373: Avg loss so far = 0.493298\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=374: Avg loss so far = 0.491979\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=375: Avg loss so far = 0.490667\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=376: Avg loss so far = 0.489362\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=377: Avg loss so far = 0.488064\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=378: Avg loss so far = 0.486772\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=379: Avg loss so far = 0.485488\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=380: Avg loss so far = 0.484211\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=381: Avg loss so far = 0.482940\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=382: Avg loss so far = 0.481675\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=383: Avg loss so far = 0.480418\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=384: Avg loss so far = 0.479167\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=385: Avg loss so far = 0.477922\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=386: Avg loss so far = 0.476684\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=387: Avg loss so far = 0.475452\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=388: Avg loss so far = 0.474227\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=389: Avg loss so far = 0.473008\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=390: Avg loss so far = 0.471795\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=391: Avg loss so far = 0.470588\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=392: Avg loss so far = 0.469388\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=393: Avg loss so far = 0.468193\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=394: Avg loss so far = 0.467005\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=395: Avg loss so far = 0.465823\n",
      "     Misclassifications: 13\n",
      "\n",
      "k=396: Avg loss so far = 0.464646\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=397: Avg loss so far = 0.465995\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=398: Avg loss so far = 0.464824\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=399: Avg loss so far = 0.463659\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=400: Avg loss so far = 0.462500\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=401: Avg loss so far = 0.461347\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=402: Avg loss so far = 0.460199\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=403: Avg loss so far = 0.459057\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=404: Avg loss so far = 0.457921\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=405: Avg loss so far = 0.456790\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=406: Avg loss so far = 0.455665\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=407: Avg loss so far = 0.454545\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=408: Avg loss so far = 0.453431\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=409: Avg loss so far = 0.452323\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=410: Avg loss so far = 0.451220\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=411: Avg loss so far = 0.450122\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=412: Avg loss so far = 0.449029\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=413: Avg loss so far = 0.447942\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=414: Avg loss so far = 0.446860\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=415: Avg loss so far = 0.445783\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=416: Avg loss so far = 0.444712\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=417: Avg loss so far = 0.443645\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=418: Avg loss so far = 0.442584\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=419: Avg loss so far = 0.441527\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=420: Avg loss so far = 0.440476\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=421: Avg loss so far = 0.439430\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=422: Avg loss so far = 0.438389\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=423: Avg loss so far = 0.437352\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=424: Avg loss so far = 0.436321\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=425: Avg loss so far = 0.435294\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=426: Avg loss so far = 0.434272\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=427: Avg loss so far = 0.433255\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=428: Avg loss so far = 0.432243\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=429: Avg loss so far = 0.431235\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=430: Avg loss so far = 0.430233\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=431: Avg loss so far = 0.429234\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=432: Avg loss so far = 0.428241\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=433: Avg loss so far = 0.427252\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=434: Avg loss so far = 0.426267\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=435: Avg loss so far = 0.425287\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=436: Avg loss so far = 0.424312\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=437: Avg loss so far = 0.423341\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=438: Avg loss so far = 0.422374\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=439: Avg loss so far = 0.421412\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=440: Avg loss so far = 0.420455\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=441: Avg loss so far = 0.419501\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=442: Avg loss so far = 0.418552\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=443: Avg loss so far = 0.417607\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=444: Avg loss so far = 0.416667\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=445: Avg loss so far = 0.415730\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=446: Avg loss so far = 0.414798\n",
      "     Misclassifications: 14\n",
      "\n",
      "k=447: Avg loss so far = 0.413870\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=448: Avg loss so far = 0.555804\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=449: Avg loss so far = 0.554566\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=450: Avg loss so far = 0.553333\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=451: Avg loss so far = 0.552106\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=452: Avg loss so far = 0.550885\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=453: Avg loss so far = 0.549669\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=454: Avg loss so far = 0.548458\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=455: Avg loss so far = 0.547253\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=456: Avg loss so far = 0.546053\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=457: Avg loss so far = 0.544858\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=458: Avg loss so far = 0.543668\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=459: Avg loss so far = 0.542484\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=460: Avg loss so far = 0.541304\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=461: Avg loss so far = 0.540130\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=462: Avg loss so far = 0.538961\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=463: Avg loss so far = 0.537797\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=464: Avg loss so far = 0.536638\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=465: Avg loss so far = 0.535484\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=466: Avg loss so far = 0.534335\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=467: Avg loss so far = 0.533191\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=468: Avg loss so far = 0.532051\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=469: Avg loss so far = 0.530917\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=470: Avg loss so far = 0.529787\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=471: Avg loss so far = 0.528662\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=472: Avg loss so far = 0.527542\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=473: Avg loss so far = 0.526427\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=474: Avg loss so far = 0.525316\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=475: Avg loss so far = 0.524211\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=476: Avg loss so far = 0.523109\n",
      "     Misclassifications: 15\n",
      "\n",
      "k=477: Avg loss so far = 0.522013\n",
      "     Misclassifications: 16\n",
      "\n",
      "k=478: Avg loss so far = 0.523013\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=479: Avg loss so far = 0.530271\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=480: Avg loss so far = 0.529167\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=481: Avg loss so far = 0.528067\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=482: Avg loss so far = 0.526971\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=483: Avg loss so far = 0.525880\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=484: Avg loss so far = 0.524793\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=485: Avg loss so far = 0.523711\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=486: Avg loss so far = 0.522634\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=487: Avg loss so far = 0.521561\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=488: Avg loss so far = 0.520492\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=489: Avg loss so far = 0.519427\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=490: Avg loss so far = 0.518367\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=491: Avg loss so far = 0.517312\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=492: Avg loss so far = 0.516260\n",
      "     Misclassifications: 17\n",
      "\n",
      "k=493: Avg loss so far = 0.515213\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=494: Avg loss so far = 0.516194\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=495: Avg loss so far = 0.515152\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=496: Avg loss so far = 0.514113\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=497: Avg loss so far = 0.513078\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=498: Avg loss so far = 0.512048\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=499: Avg loss so far = 0.511022\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=500: Avg loss so far = 0.510000\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=501: Avg loss so far = 0.508982\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=502: Avg loss so far = 0.507968\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=503: Avg loss so far = 0.506958\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=504: Avg loss so far = 0.505952\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=505: Avg loss so far = 0.504950\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=506: Avg loss so far = 0.503953\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=507: Avg loss so far = 0.502959\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=508: Avg loss so far = 0.501969\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=509: Avg loss so far = 0.500982\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=510: Avg loss so far = 0.500000\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=511: Avg loss so far = 0.499022\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=512: Avg loss so far = 0.498047\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=513: Avg loss so far = 0.497076\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=514: Avg loss so far = 0.496109\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=515: Avg loss so far = 0.495146\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=516: Avg loss so far = 0.494186\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=517: Avg loss so far = 0.493230\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=518: Avg loss so far = 0.492278\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=519: Avg loss so far = 0.491329\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=520: Avg loss so far = 0.490385\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=521: Avg loss so far = 0.489443\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=522: Avg loss so far = 0.488506\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=523: Avg loss so far = 0.487572\n",
      "     Misclassifications: 18\n",
      "\n",
      "k=524: Avg loss so far = 0.486641\n",
      "     Misclassifications: 19\n",
      "\n",
      "k=525: Avg loss so far = 0.487619\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=526: Avg loss so far = 0.608365\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=527: Avg loss so far = 0.607211\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=528: Avg loss so far = 0.606061\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=529: Avg loss so far = 0.604915\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=530: Avg loss so far = 0.603774\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=531: Avg loss so far = 0.602637\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=532: Avg loss so far = 0.601504\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=533: Avg loss so far = 0.600375\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=534: Avg loss so far = 0.599251\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=535: Avg loss so far = 0.598131\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=536: Avg loss so far = 0.597015\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=537: Avg loss so far = 0.595903\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=538: Avg loss so far = 0.594796\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=539: Avg loss so far = 0.593692\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=540: Avg loss so far = 0.592593\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=541: Avg loss so far = 0.591497\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=542: Avg loss so far = 0.590406\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=543: Avg loss so far = 0.589319\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=544: Avg loss so far = 0.588235\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=545: Avg loss so far = 0.587156\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=546: Avg loss so far = 0.586081\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=547: Avg loss so far = 0.585009\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=548: Avg loss so far = 0.583942\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=549: Avg loss so far = 0.582878\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=550: Avg loss so far = 0.581818\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=551: Avg loss so far = 0.580762\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=552: Avg loss so far = 0.579710\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=553: Avg loss so far = 0.578662\n",
      "     Misclassifications: 20\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=554: Avg loss so far = 0.577617\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=555: Avg loss so far = 0.576577\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=556: Avg loss so far = 0.575540\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=557: Avg loss so far = 0.574506\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=558: Avg loss so far = 0.573477\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=559: Avg loss so far = 0.572451\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=560: Avg loss so far = 0.571429\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=561: Avg loss so far = 0.570410\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=562: Avg loss so far = 0.569395\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=563: Avg loss so far = 0.568384\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=564: Avg loss so far = 0.567376\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=565: Avg loss so far = 0.566372\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=566: Avg loss so far = 0.565371\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=567: Avg loss so far = 0.564374\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=568: Avg loss so far = 0.563380\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=569: Avg loss so far = 0.562390\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=570: Avg loss so far = 0.561404\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=571: Avg loss so far = 0.560420\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=572: Avg loss so far = 0.559441\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=573: Avg loss so far = 0.558464\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=574: Avg loss so far = 0.557491\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=575: Avg loss so far = 0.556522\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=576: Avg loss so far = 0.555556\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=577: Avg loss so far = 0.554593\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=578: Avg loss so far = 0.553633\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=579: Avg loss so far = 0.552677\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=580: Avg loss so far = 0.551724\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=581: Avg loss so far = 0.550775\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=582: Avg loss so far = 0.549828\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=583: Avg loss so far = 0.548885\n",
      "     Misclassifications: 20\n",
      "\n",
      "k=584: Avg loss so far = 0.547945\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=585: Avg loss so far = 0.553846\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=586: Avg loss so far = 0.552901\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=587: Avg loss so far = 0.551959\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=588: Avg loss so far = 0.551020\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=589: Avg loss so far = 0.550085\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=590: Avg loss so far = 0.549153\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=591: Avg loss so far = 0.548223\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=592: Avg loss so far = 0.547297\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=593: Avg loss so far = 0.546374\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=594: Avg loss so far = 0.545455\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=595: Avg loss so far = 0.544538\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=596: Avg loss so far = 0.543624\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=597: Avg loss so far = 0.542714\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=598: Avg loss so far = 0.541806\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=599: Avg loss so far = 0.540902\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=600: Avg loss so far = 0.540000\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=601: Avg loss so far = 0.539101\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=602: Avg loss so far = 0.538206\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=603: Avg loss so far = 0.537313\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=604: Avg loss so far = 0.536424\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=605: Avg loss so far = 0.535537\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=606: Avg loss so far = 0.534653\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=607: Avg loss so far = 0.533773\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=608: Avg loss so far = 0.532895\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=609: Avg loss so far = 0.532020\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=610: Avg loss so far = 0.531148\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=611: Avg loss so far = 0.530278\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=612: Avg loss so far = 0.529412\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=613: Avg loss so far = 0.528548\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=614: Avg loss so far = 0.527687\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=615: Avg loss so far = 0.526829\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=616: Avg loss so far = 0.525974\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=617: Avg loss so far = 0.525122\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=618: Avg loss so far = 0.524272\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=619: Avg loss so far = 0.523425\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=620: Avg loss so far = 0.522581\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=621: Avg loss so far = 0.521739\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=622: Avg loss so far = 0.520900\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=623: Avg loss so far = 0.520064\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=624: Avg loss so far = 0.519231\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=625: Avg loss so far = 0.518400\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=626: Avg loss so far = 0.517572\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=627: Avg loss so far = 0.516746\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=628: Avg loss so far = 0.515924\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=629: Avg loss so far = 0.515103\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=630: Avg loss so far = 0.514286\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=631: Avg loss so far = 0.513471\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=632: Avg loss so far = 0.512658\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=633: Avg loss so far = 0.511848\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=634: Avg loss so far = 0.511041\n",
      "     Misclassifications: 21\n",
      "\n",
      "k=635: Avg loss so far = 0.510236\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=636: Avg loss so far = 0.610063\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=637: Avg loss so far = 0.609105\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=638: Avg loss so far = 0.608150\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=639: Avg loss so far = 0.607199\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=640: Avg loss so far = 0.606250\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=641: Avg loss so far = 0.605304\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=642: Avg loss so far = 0.604361\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=643: Avg loss so far = 0.603421\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=644: Avg loss so far = 0.602484\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=645: Avg loss so far = 0.601550\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=646: Avg loss so far = 0.600619\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=647: Avg loss so far = 0.599691\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=648: Avg loss so far = 0.598765\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=649: Avg loss so far = 0.597843\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=650: Avg loss so far = 0.596923\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=651: Avg loss so far = 0.596006\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=652: Avg loss so far = 0.595092\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=653: Avg loss so far = 0.594181\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=654: Avg loss so far = 0.593272\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=655: Avg loss so far = 0.592366\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=656: Avg loss so far = 0.591463\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=657: Avg loss so far = 0.590563\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=658: Avg loss so far = 0.589666\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=659: Avg loss so far = 0.588771\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=660: Avg loss so far = 0.587879\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=661: Avg loss so far = 0.586989\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=662: Avg loss so far = 0.586103\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=663: Avg loss so far = 0.585219\n",
      "     Misclassifications: 22\n",
      "\n",
      "k=664: Avg loss so far = 0.584337\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=665: Avg loss so far = 0.589474\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=666: Avg loss so far = 0.588589\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=667: Avg loss so far = 0.587706\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=668: Avg loss so far = 0.586826\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=669: Avg loss so far = 0.585949\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=670: Avg loss so far = 0.585075\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=671: Avg loss so far = 0.584203\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=672: Avg loss so far = 0.583333\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=673: Avg loss so far = 0.582467\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=674: Avg loss so far = 0.581602\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=675: Avg loss so far = 0.580741\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=676: Avg loss so far = 0.579882\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=677: Avg loss so far = 0.579025\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=678: Avg loss so far = 0.578171\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=679: Avg loss so far = 0.577320\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=680: Avg loss so far = 0.576471\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=681: Avg loss so far = 0.575624\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=682: Avg loss so far = 0.574780\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=683: Avg loss so far = 0.573939\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=684: Avg loss so far = 0.573099\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=685: Avg loss so far = 0.572263\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=686: Avg loss so far = 0.571429\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=687: Avg loss so far = 0.570597\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=688: Avg loss so far = 0.569767\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=689: Avg loss so far = 0.568940\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=690: Avg loss so far = 0.568116\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=691: Avg loss so far = 0.567294\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=692: Avg loss so far = 0.566474\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=693: Avg loss so far = 0.565657\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=694: Avg loss so far = 0.564841\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=695: Avg loss so far = 0.564029\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=696: Avg loss so far = 0.563218\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=697: Avg loss so far = 0.562410\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=698: Avg loss so far = 0.561605\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=699: Avg loss so far = 0.560801\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=700: Avg loss so far = 0.560000\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=701: Avg loss so far = 0.559201\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=702: Avg loss so far = 0.558405\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=703: Avg loss so far = 0.557610\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=704: Avg loss so far = 0.556818\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=705: Avg loss so far = 0.556028\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=706: Avg loss so far = 0.555241\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=707: Avg loss so far = 0.554455\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=708: Avg loss so far = 0.553672\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=709: Avg loss so far = 0.552891\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=710: Avg loss so far = 0.552113\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=711: Avg loss so far = 0.551336\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=712: Avg loss so far = 0.550562\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=713: Avg loss so far = 0.549790\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=714: Avg loss so far = 0.549020\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=715: Avg loss so far = 0.548252\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=716: Avg loss so far = 0.547486\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=717: Avg loss so far = 0.546722\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=718: Avg loss so far = 0.545961\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=719: Avg loss so far = 0.545202\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=720: Avg loss so far = 0.544444\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=721: Avg loss so far = 0.543689\n",
      "     Misclassifications: 23\n",
      "\n",
      "k=722: Avg loss so far = 0.542936\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=723: Avg loss so far = 0.543568\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=724: Avg loss so far = 0.542818\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=725: Avg loss so far = 0.542069\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=726: Avg loss so far = 0.541322\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=727: Avg loss so far = 0.540578\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=728: Avg loss so far = 0.539835\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=729: Avg loss so far = 0.539095\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=730: Avg loss so far = 0.538356\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=731: Avg loss so far = 0.537620\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=732: Avg loss so far = 0.536885\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=733: Avg loss so far = 0.536153\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=734: Avg loss so far = 0.535422\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=735: Avg loss so far = 0.534694\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=736: Avg loss so far = 0.533967\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=737: Avg loss so far = 0.533243\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=738: Avg loss so far = 0.532520\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=739: Avg loss so far = 0.531800\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=740: Avg loss so far = 0.531081\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=741: Avg loss so far = 0.530364\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=742: Avg loss so far = 0.529650\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=743: Avg loss so far = 0.528937\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=744: Avg loss so far = 0.528226\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=745: Avg loss so far = 0.527517\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=746: Avg loss so far = 0.526810\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=747: Avg loss so far = 0.526104\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=748: Avg loss so far = 0.525401\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=749: Avg loss so far = 0.524700\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=750: Avg loss so far = 0.524000\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=751: Avg loss so far = 0.523302\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=752: Avg loss so far = 0.522606\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=753: Avg loss so far = 0.521912\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=754: Avg loss so far = 0.521220\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=755: Avg loss so far = 0.520530\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=756: Avg loss so far = 0.519841\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=757: Avg loss so far = 0.519155\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=758: Avg loss so far = 0.518470\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=759: Avg loss so far = 0.517787\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=760: Avg loss so far = 0.517105\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=761: Avg loss so far = 0.516426\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=762: Avg loss so far = 0.515748\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=763: Avg loss so far = 0.515072\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=764: Avg loss so far = 0.514398\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=765: Avg loss so far = 0.513725\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=766: Avg loss so far = 0.513055\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=767: Avg loss so far = 0.512386\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=768: Avg loss so far = 0.511719\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=769: Avg loss so far = 0.511053\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=770: Avg loss so far = 0.510390\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=771: Avg loss so far = 0.509728\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=772: Avg loss so far = 0.509067\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=773: Avg loss so far = 0.508409\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=774: Avg loss so far = 0.507752\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=775: Avg loss so far = 0.507097\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=776: Avg loss so far = 0.506443\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=777: Avg loss so far = 0.505792\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=778: Avg loss so far = 0.505141\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=779: Avg loss so far = 0.504493\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=780: Avg loss so far = 0.503846\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=781: Avg loss so far = 0.503201\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=782: Avg loss so far = 0.502558\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=783: Avg loss so far = 0.501916\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=784: Avg loss so far = 0.501276\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=785: Avg loss so far = 0.500637\n",
      "     Misclassifications: 24\n",
      "\n",
      "k=786: Avg loss so far = 0.500000\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=787: Avg loss so far = 0.500635\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=788: Avg loss so far = 0.500000\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=789: Avg loss so far = 0.499366\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=790: Avg loss so far = 0.498734\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=791: Avg loss so far = 0.498104\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=792: Avg loss so far = 0.497475\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=793: Avg loss so far = 0.496847\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=794: Avg loss so far = 0.496222\n",
      "     Misclassifications: 25\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=795: Avg loss so far = 0.495597\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=796: Avg loss so far = 0.494975\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=797: Avg loss so far = 0.494354\n",
      "     Misclassifications: 25\n",
      "\n",
      "k=798: Avg loss so far = 0.493734\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=799: Avg loss so far = 0.573217\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=800: Avg loss so far = 0.572500\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=801: Avg loss so far = 0.571785\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=802: Avg loss so far = 0.571072\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=803: Avg loss so far = 0.570361\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=804: Avg loss so far = 0.569652\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=805: Avg loss so far = 0.568944\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=806: Avg loss so far = 0.568238\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=807: Avg loss so far = 0.567534\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=808: Avg loss so far = 0.566832\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=809: Avg loss so far = 0.566131\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=810: Avg loss so far = 0.565432\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=811: Avg loss so far = 0.564735\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=812: Avg loss so far = 0.564039\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=813: Avg loss so far = 0.563346\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=814: Avg loss so far = 0.562654\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=815: Avg loss so far = 0.561963\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=816: Avg loss so far = 0.561275\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=817: Avg loss so far = 0.560588\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=818: Avg loss so far = 0.559902\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=819: Avg loss so far = 0.559219\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=820: Avg loss so far = 0.558537\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=821: Avg loss so far = 0.557856\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=822: Avg loss so far = 0.557178\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=823: Avg loss so far = 0.556501\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=824: Avg loss so far = 0.555825\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=825: Avg loss so far = 0.555152\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=826: Avg loss so far = 0.554479\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=827: Avg loss so far = 0.553809\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=828: Avg loss so far = 0.553140\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=829: Avg loss so far = 0.552473\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=830: Avg loss so far = 0.551807\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=831: Avg loss so far = 0.551143\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=832: Avg loss so far = 0.550481\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=833: Avg loss so far = 0.549820\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=834: Avg loss so far = 0.549161\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=835: Avg loss so far = 0.548503\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=836: Avg loss so far = 0.547847\n",
      "     Misclassifications: 26\n",
      "\n",
      "k=837: Avg loss so far = 0.547192\n",
      "     Misclassifications: 27\n",
      "\n",
      "k=838: Avg loss so far = 0.547733\n",
      "     Misclassifications: 27\n",
      "\n",
      "k=839: Avg loss so far = 0.547080\n",
      "     Misclassifications: 27\n",
      "\n",
      "k=840: Avg loss so far = 0.546429\n",
      "     Misclassifications: 27\n",
      "\n",
      "k=841: Avg loss so far = 0.545779\n",
      "     Misclassifications: 27\n",
      "\n",
      "k=842: Avg loss so far = 0.545131\n",
      "     Misclassifications: 27\n",
      "\n",
      "k=843: Avg loss so far = 0.544484\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=844: Avg loss so far = 0.619668\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=845: Avg loss so far = 0.618935\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=846: Avg loss so far = 0.618203\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=847: Avg loss so far = 0.617473\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=848: Avg loss so far = 0.616745\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=849: Avg loss so far = 0.616019\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=850: Avg loss so far = 0.615294\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=851: Avg loss so far = 0.614571\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=852: Avg loss so far = 0.613850\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=853: Avg loss so far = 0.613130\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=854: Avg loss so far = 0.612412\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=855: Avg loss so far = 0.611696\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=856: Avg loss so far = 0.610981\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=857: Avg loss so far = 0.610268\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=858: Avg loss so far = 0.609557\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=859: Avg loss so far = 0.608847\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=860: Avg loss so far = 0.608140\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=861: Avg loss so far = 0.607433\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=862: Avg loss so far = 0.606729\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=863: Avg loss so far = 0.606025\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=864: Avg loss so far = 0.605324\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=865: Avg loss so far = 0.604624\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=866: Avg loss so far = 0.603926\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=867: Avg loss so far = 0.603230\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=868: Avg loss so far = 0.602535\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=869: Avg loss so far = 0.601841\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=870: Avg loss so far = 0.601149\n",
      "     Misclassifications: 28\n",
      "\n",
      "k=871: Avg loss so far = 0.600459\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=872: Avg loss so far = 0.604358\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=873: Avg loss so far = 0.603666\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=874: Avg loss so far = 0.602975\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=875: Avg loss so far = 0.602286\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=876: Avg loss so far = 0.601598\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=877: Avg loss so far = 0.600912\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=878: Avg loss so far = 0.600228\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=879: Avg loss so far = 0.599545\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=880: Avg loss so far = 0.598864\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=881: Avg loss so far = 0.598184\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=882: Avg loss so far = 0.597506\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=883: Avg loss so far = 0.596829\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=884: Avg loss so far = 0.596154\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=885: Avg loss so far = 0.595480\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=886: Avg loss so far = 0.594808\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=887: Avg loss so far = 0.594138\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=888: Avg loss so far = 0.593468\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=889: Avg loss so far = 0.592801\n",
      "     Misclassifications: 29\n",
      "\n",
      "k=890: Avg loss so far = 0.592135\n",
      "     Misclassifications: 30\n",
      "\n",
      "k=891: Avg loss so far = 0.595960\n",
      "     Misclassifications: 30\n",
      "\n",
      "k=892: Avg loss so far = 0.595291\n",
      "     Misclassifications: 30\n",
      "\n",
      "k=893: Avg loss so far = 0.594625\n",
      "     Misclassifications: 30\n",
      "\n",
      "k=894: Avg loss so far = 0.593960\n",
      "     Misclassifications: 30\n",
      "\n",
      "k=895: Avg loss so far = 0.593296\n",
      "     Misclassifications: 30\n",
      "\n",
      "k=896: Avg loss so far = 0.592634\n",
      "     Misclassifications: 30\n",
      "\n",
      "k=897: Avg loss so far = 0.591973\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=898: Avg loss so far = 0.592428\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=899: Avg loss so far = 0.591769\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=900: Avg loss so far = 0.591111\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=901: Avg loss so far = 0.590455\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=902: Avg loss so far = 0.589800\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=903: Avg loss so far = 0.589147\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=904: Avg loss so far = 0.588496\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=905: Avg loss so far = 0.587845\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=906: Avg loss so far = 0.587196\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=907: Avg loss so far = 0.586549\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=908: Avg loss so far = 0.585903\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=909: Avg loss so far = 0.585259\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=910: Avg loss so far = 0.584615\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=911: Avg loss so far = 0.583974\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=912: Avg loss so far = 0.583333\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=913: Avg loss so far = 0.582694\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=914: Avg loss so far = 0.582057\n",
      "     Misclassifications: 31\n",
      "\n",
      "k=915: Avg loss so far = 0.581421\n",
      "     Misclassifications: 32\n",
      "\n",
      "k=916: Avg loss so far = 0.650655\n",
      "     Misclassifications: 32\n",
      "\n",
      "k=917: Avg loss so far = 0.649945\n",
      "     Misclassifications: 32\n",
      "\n",
      "k=918: Avg loss so far = 0.649237\n",
      "     Misclassifications: 32\n",
      "\n",
      "k=919: Avg loss so far = 0.648531\n",
      "     Misclassifications: 32\n",
      "\n",
      "k=920: Avg loss so far = 0.647826\n",
      "     Misclassifications: 32\n",
      "\n",
      "k=921: Avg loss so far = 0.647123\n",
      "     Misclassifications: 32\n",
      "\n",
      "k=922: Avg loss so far = 0.646421\n",
      "     Misclassifications: 32\n",
      "\n",
      "k=923: Avg loss so far = 0.645720\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=924: Avg loss so far = 0.753247\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=925: Avg loss so far = 0.752432\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=926: Avg loss so far = 0.751620\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=927: Avg loss so far = 0.750809\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=928: Avg loss so far = 0.750000\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=929: Avg loss so far = 0.749193\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=930: Avg loss so far = 0.748387\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=931: Avg loss so far = 0.747583\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=932: Avg loss so far = 0.746781\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=933: Avg loss so far = 0.745981\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=934: Avg loss so far = 0.745182\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=935: Avg loss so far = 0.744385\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=936: Avg loss so far = 0.743590\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=937: Avg loss so far = 0.742796\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=938: Avg loss so far = 0.742004\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=939: Avg loss so far = 0.741214\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=940: Avg loss so far = 0.740426\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=941: Avg loss so far = 0.739639\n",
      "     Misclassifications: 33\n",
      "\n",
      "k=942: Avg loss so far = 0.738854\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=943: Avg loss so far = 0.755037\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=944: Avg loss so far = 0.754237\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=945: Avg loss so far = 0.753439\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=946: Avg loss so far = 0.752643\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=947: Avg loss so far = 0.751848\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=948: Avg loss so far = 0.751055\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=949: Avg loss so far = 0.750263\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=950: Avg loss so far = 0.749474\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=951: Avg loss so far = 0.748686\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=952: Avg loss so far = 0.747899\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=953: Avg loss so far = 0.747114\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=954: Avg loss so far = 0.746331\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=955: Avg loss so far = 0.745550\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=956: Avg loss so far = 0.744770\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=957: Avg loss so far = 0.743992\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=958: Avg loss so far = 0.743215\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=959: Avg loss so far = 0.742440\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=960: Avg loss so far = 0.741667\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=961: Avg loss so far = 0.740895\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=962: Avg loss so far = 0.740125\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=963: Avg loss so far = 0.739356\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=964: Avg loss so far = 0.738589\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=965: Avg loss so far = 0.737824\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=966: Avg loss so far = 0.737060\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=967: Avg loss so far = 0.736298\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=968: Avg loss so far = 0.735537\n",
      "     Misclassifications: 34\n",
      "\n",
      "k=969: Avg loss so far = 0.734778\n",
      "     Misclassifications: 35\n",
      "\n",
      "k=970: Avg loss so far = 0.800000\n",
      "     Misclassifications: 35\n",
      "\n",
      "k=971: Avg loss so far = 0.799176\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=972: Avg loss so far = 0.814815\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=973: Avg loss so far = 0.813977\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=974: Avg loss so far = 0.813142\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=975: Avg loss so far = 0.812308\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=976: Avg loss so far = 0.811475\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=977: Avg loss so far = 0.810645\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=978: Avg loss so far = 0.809816\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=979: Avg loss so far = 0.808989\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=980: Avg loss so far = 0.808163\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=981: Avg loss so far = 0.807339\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=982: Avg loss so far = 0.806517\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=983: Avg loss so far = 0.805697\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=984: Avg loss so far = 0.804878\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=985: Avg loss so far = 0.804061\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=986: Avg loss so far = 0.803245\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=987: Avg loss so far = 0.802432\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=988: Avg loss so far = 0.801619\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=989: Avg loss so far = 0.800809\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=990: Avg loss so far = 0.800000\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=991: Avg loss so far = 0.799193\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=992: Avg loss so far = 0.798387\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=993: Avg loss so far = 0.797583\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=994: Avg loss so far = 0.796781\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=995: Avg loss so far = 0.795980\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=996: Avg loss so far = 0.795181\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=997: Avg loss so far = 0.794383\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=998: Avg loss so far = 0.793587\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=999: Avg loss so far = 0.792793\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=1000: Avg loss so far = 0.792000\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=1001: Avg loss so far = 0.791209\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=1002: Avg loss so far = 0.790419\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=1003: Avg loss so far = 0.789631\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=1004: Avg loss so far = 0.788845\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=1005: Avg loss so far = 0.788060\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=1006: Avg loss so far = 0.787276\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=1007: Avg loss so far = 0.786495\n",
      "     Misclassifications: 36\n",
      "\n",
      "k=1008: Avg loss so far = 0.785714\n",
      "     Misclassifications: 37\n",
      "\n",
      "k=1009: Avg loss so far = 0.848365\n",
      "     Misclassifications: 37\n",
      "\n",
      "k=1010: Avg loss so far = 0.847525\n",
      "     Misclassifications: 37\n",
      "\n",
      "k=1011: Avg loss so far = 0.846686\n",
      "     Misclassifications: 37\n",
      "\n",
      "k=1012: Avg loss so far = 0.845850\n",
      "     Misclassifications: 37\n",
      "\n",
      "k=1013: Avg loss so far = 0.845015\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1014: Avg loss so far = 0.907298\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1015: Avg loss so far = 0.906404\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1016: Avg loss so far = 0.905512\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1017: Avg loss so far = 0.904621\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1018: Avg loss so far = 0.903733\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1019: Avg loss so far = 0.902846\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1020: Avg loss so far = 0.901961\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1021: Avg loss so far = 0.901077\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1022: Avg loss so far = 0.900196\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1023: Avg loss so far = 0.899316\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1024: Avg loss so far = 0.898438\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1025: Avg loss so far = 0.897561\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1026: Avg loss so far = 0.896686\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1027: Avg loss so far = 0.895813\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1028: Avg loss so far = 0.894942\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1029: Avg loss so far = 0.894072\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1030: Avg loss so far = 0.893204\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1031: Avg loss so far = 0.892338\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1032: Avg loss so far = 0.891473\n",
      "     Misclassifications: 38\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1033: Avg loss so far = 0.890610\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1034: Avg loss so far = 0.889749\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1035: Avg loss so far = 0.888889\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1036: Avg loss so far = 0.888031\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1037: Avg loss so far = 0.887175\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1038: Avg loss so far = 0.886320\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1039: Avg loss so far = 0.885467\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1040: Avg loss so far = 0.884615\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1041: Avg loss so far = 0.883766\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1042: Avg loss so far = 0.882917\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1043: Avg loss so far = 0.882071\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1044: Avg loss so far = 0.881226\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1045: Avg loss so far = 0.880383\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1046: Avg loss so far = 0.879541\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1047: Avg loss so far = 0.878701\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1048: Avg loss so far = 0.877863\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1049: Avg loss so far = 0.877026\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1050: Avg loss so far = 0.876190\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1051: Avg loss so far = 0.875357\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1052: Avg loss so far = 0.874525\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1053: Avg loss so far = 0.873694\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1054: Avg loss so far = 0.872865\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1055: Avg loss so far = 0.872038\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1056: Avg loss so far = 0.871212\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1057: Avg loss so far = 0.870388\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1058: Avg loss so far = 0.869565\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1059: Avg loss so far = 0.868744\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1060: Avg loss so far = 0.867925\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1061: Avg loss so far = 0.867107\n",
      "     Misclassifications: 38\n",
      "\n",
      "k=1062: Avg loss so far = 0.866290\n",
      "     Misclassifications: 39\n",
      "\n",
      "k=1063: Avg loss so far = 0.869238\n",
      "     Misclassifications: 39\n",
      "\n",
      "k=1064: Avg loss so far = 0.868421\n",
      "     Misclassifications: 39\n",
      "\n",
      "k=1065: Avg loss so far = 0.867606\n",
      "     Misclassifications: 39\n",
      "\n",
      "k=1066: Avg loss so far = 0.866792\n",
      "     Misclassifications: 39\n",
      "\n",
      "k=1067: Avg loss so far = 0.865979\n",
      "     Misclassifications: 39\n",
      "\n",
      "k=1068: Avg loss so far = 0.865169\n",
      "     Misclassifications: 39\n",
      "\n",
      "k=1069: Avg loss so far = 0.864359\n",
      "     Misclassifications: 39\n",
      "\n",
      "k=1070: Avg loss so far = 0.863551\n",
      "     Misclassifications: 39\n",
      "\n",
      "k=1071: Avg loss so far = 0.862745\n",
      "     Misclassifications: 40\n",
      "\n",
      "k=1072: Avg loss so far = 0.876866\n",
      "     Misclassifications: 40\n",
      "\n",
      "k=1073: Avg loss so far = 0.876048\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1074: Avg loss so far = 0.934823\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1075: Avg loss so far = 0.933953\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1076: Avg loss so far = 0.933086\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1077: Avg loss so far = 0.932219\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1078: Avg loss so far = 0.931354\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1079: Avg loss so far = 0.930491\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1080: Avg loss so far = 0.929630\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1081: Avg loss so far = 0.928770\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1082: Avg loss so far = 0.927911\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1083: Avg loss so far = 0.927054\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1084: Avg loss so far = 0.926199\n",
      "     Misclassifications: 41\n",
      "\n",
      "k=1085: Avg loss so far = 0.925346\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1086: Avg loss so far = 0.925414\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1087: Avg loss so far = 0.924563\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1088: Avg loss so far = 0.923713\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1089: Avg loss so far = 0.922865\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1090: Avg loss so far = 0.922018\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1091: Avg loss so far = 0.921173\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1092: Avg loss so far = 0.920330\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1093: Avg loss so far = 0.919488\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1094: Avg loss so far = 0.918647\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1095: Avg loss so far = 0.917808\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1096: Avg loss so far = 0.916971\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1097: Avg loss so far = 0.916135\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1098: Avg loss so far = 0.915301\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1099: Avg loss so far = 0.914468\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1100: Avg loss so far = 0.913636\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1101: Avg loss so far = 0.912807\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1102: Avg loss so far = 0.911978\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1103: Avg loss so far = 0.911151\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1104: Avg loss so far = 0.910326\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1105: Avg loss so far = 0.909502\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1106: Avg loss so far = 0.908680\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1107: Avg loss so far = 0.907859\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1108: Avg loss so far = 0.907040\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1109: Avg loss so far = 0.906222\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1110: Avg loss so far = 0.905405\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1111: Avg loss so far = 0.904590\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1112: Avg loss so far = 0.903777\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1113: Avg loss so far = 0.902965\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1114: Avg loss so far = 0.902154\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1115: Avg loss so far = 0.901345\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1116: Avg loss so far = 0.900538\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1117: Avg loss so far = 0.899731\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1118: Avg loss so far = 0.898927\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1119: Avg loss so far = 0.898123\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1120: Avg loss so far = 0.897321\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1121: Avg loss so far = 0.896521\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1122: Avg loss so far = 0.895722\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1123: Avg loss so far = 0.894924\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1124: Avg loss so far = 0.894128\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1125: Avg loss so far = 0.893333\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1126: Avg loss so far = 0.892540\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1127: Avg loss so far = 0.891748\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1128: Avg loss so far = 0.890957\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1129: Avg loss so far = 0.890168\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1130: Avg loss so far = 0.889381\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1131: Avg loss so far = 0.888594\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1132: Avg loss so far = 0.887809\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1133: Avg loss so far = 0.887026\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1134: Avg loss so far = 0.886243\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1135: Avg loss so far = 0.885463\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1136: Avg loss so far = 0.884683\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1137: Avg loss so far = 0.883905\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1138: Avg loss so far = 0.883128\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1139: Avg loss so far = 0.882353\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1140: Avg loss so far = 0.881579\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1141: Avg loss so far = 0.880806\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1142: Avg loss so far = 0.880035\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1143: Avg loss so far = 0.879265\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1144: Avg loss so far = 0.878497\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1145: Avg loss so far = 0.877729\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1146: Avg loss so far = 0.876963\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1147: Avg loss so far = 0.876199\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1148: Avg loss so far = 0.875436\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1149: Avg loss so far = 0.874674\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1150: Avg loss so far = 0.873913\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1151: Avg loss so far = 0.873154\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1152: Avg loss so far = 0.872396\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1153: Avg loss so far = 0.871639\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1154: Avg loss so far = 0.870884\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1155: Avg loss so far = 0.870130\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1156: Avg loss so far = 0.869377\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1157: Avg loss so far = 0.868626\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1158: Avg loss so far = 0.867876\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1159: Avg loss so far = 0.867127\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1160: Avg loss so far = 0.866379\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1161: Avg loss so far = 0.865633\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1162: Avg loss so far = 0.864888\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1163: Avg loss so far = 0.864144\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1164: Avg loss so far = 0.863402\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1165: Avg loss so far = 0.862661\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1166: Avg loss so far = 0.861921\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1167: Avg loss so far = 0.861183\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1168: Avg loss so far = 0.860445\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1169: Avg loss so far = 0.859709\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1170: Avg loss so far = 0.858974\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1171: Avg loss so far = 0.858241\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1172: Avg loss so far = 0.857509\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1173: Avg loss so far = 0.856777\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1174: Avg loss so far = 0.856048\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1175: Avg loss so far = 0.855319\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1176: Avg loss so far = 0.854592\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1177: Avg loss so far = 0.853866\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1178: Avg loss so far = 0.853141\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1179: Avg loss so far = 0.852417\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1180: Avg loss so far = 0.851695\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1181: Avg loss so far = 0.850974\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1182: Avg loss so far = 0.850254\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1183: Avg loss so far = 0.849535\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1184: Avg loss so far = 0.848818\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1185: Avg loss so far = 0.848101\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1186: Avg loss so far = 0.847386\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1187: Avg loss so far = 0.846672\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1188: Avg loss so far = 0.845960\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1189: Avg loss so far = 0.845248\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1190: Avg loss so far = 0.844538\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1191: Avg loss so far = 0.843829\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1192: Avg loss so far = 0.843121\n",
      "     Misclassifications: 42\n",
      "\n",
      "k=1193: Avg loss so far = 0.842414\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1194: Avg loss so far = 0.845059\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1195: Avg loss so far = 0.844351\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1196: Avg loss so far = 0.843645\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1197: Avg loss so far = 0.842941\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1198: Avg loss so far = 0.842237\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1199: Avg loss so far = 0.841535\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1200: Avg loss so far = 0.840833\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1201: Avg loss so far = 0.840133\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1202: Avg loss so far = 0.839434\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1203: Avg loss so far = 0.838736\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1204: Avg loss so far = 0.838040\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1205: Avg loss so far = 0.837344\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1206: Avg loss so far = 0.836650\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1207: Avg loss so far = 0.835957\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1208: Avg loss so far = 0.835265\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1209: Avg loss so far = 0.834574\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1210: Avg loss so far = 0.833884\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1211: Avg loss so far = 0.833196\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1212: Avg loss so far = 0.832508\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1213: Avg loss so far = 0.831822\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1214: Avg loss so far = 0.831137\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1215: Avg loss so far = 0.830453\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1216: Avg loss so far = 0.829770\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1217: Avg loss so far = 0.829088\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1218: Avg loss so far = 0.828407\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1219: Avg loss so far = 0.827728\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1220: Avg loss so far = 0.827049\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1221: Avg loss so far = 0.826372\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1222: Avg loss so far = 0.825696\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1223: Avg loss so far = 0.825020\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1224: Avg loss so far = 0.824346\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1225: Avg loss so far = 0.823673\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1226: Avg loss so far = 0.823002\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1227: Avg loss so far = 0.822331\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1228: Avg loss so far = 0.821661\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1229: Avg loss so far = 0.820993\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1230: Avg loss so far = 0.820325\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1231: Avg loss so far = 0.819659\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1232: Avg loss so far = 0.818994\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1233: Avg loss so far = 0.818329\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1234: Avg loss so far = 0.817666\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1235: Avg loss so far = 0.817004\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1236: Avg loss so far = 0.816343\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1237: Avg loss so far = 0.815683\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1238: Avg loss so far = 0.815024\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1239: Avg loss so far = 0.814366\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1240: Avg loss so far = 0.813710\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1241: Avg loss so far = 0.813054\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1242: Avg loss so far = 0.812399\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1243: Avg loss so far = 0.811746\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1244: Avg loss so far = 0.811093\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1245: Avg loss so far = 0.810442\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1246: Avg loss so far = 0.809791\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1247: Avg loss so far = 0.809142\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1248: Avg loss so far = 0.808494\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1249: Avg loss so far = 0.807846\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1250: Avg loss so far = 0.807200\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1251: Avg loss so far = 0.806555\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1252: Avg loss so far = 0.805911\n",
      "     Misclassifications: 43\n",
      "\n",
      "k=1253: Avg loss so far = 0.805267\n",
      "     Misclassifications: 44\n",
      "\n",
      "k=1254: Avg loss so far = 0.855662\n",
      "     Misclassifications: 44\n",
      "\n",
      "k=1255: Avg loss so far = 0.854980\n",
      "     Misclassifications: 44\n",
      "\n",
      "k=1256: Avg loss so far = 0.854299\n",
      "     Misclassifications: 44\n",
      "\n",
      "k=1257: Avg loss so far = 0.853620\n",
      "     Misclassifications: 44\n",
      "\n",
      "k=1258: Avg loss so far = 0.852941\n",
      "     Misclassifications: 44\n",
      "\n",
      "k=1259: Avg loss so far = 0.852264\n",
      "     Misclassifications: 45\n",
      "\n",
      "k=1260: Avg loss so far = 0.902381\n",
      "     Misclassifications: 46\n",
      "\n",
      "k=1261: Avg loss so far = 0.902458\n",
      "     Misclassifications: 46\n",
      "\n",
      "k=1262: Avg loss so far = 0.901743\n",
      "     Misclassifications: 46\n",
      "\n",
      "k=1263: Avg loss so far = 0.901029\n",
      "     Misclassifications: 46\n",
      "\n",
      "k=1264: Avg loss so far = 0.900316\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1265: Avg loss so far = 0.902767\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1266: Avg loss so far = 0.902054\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1267: Avg loss so far = 0.901342\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1268: Avg loss so far = 0.900631\n",
      "     Misclassifications: 47\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1269: Avg loss so far = 0.899921\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1270: Avg loss so far = 0.899213\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1271: Avg loss so far = 0.898505\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1272: Avg loss so far = 0.897799\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1273: Avg loss so far = 0.897093\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1274: Avg loss so far = 0.896389\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1275: Avg loss so far = 0.895686\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1276: Avg loss so far = 0.894984\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1277: Avg loss so far = 0.894283\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1278: Avg loss so far = 0.893584\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1279: Avg loss so far = 0.892885\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1280: Avg loss so far = 0.892188\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1281: Avg loss so far = 0.891491\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1282: Avg loss so far = 0.890796\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1283: Avg loss so far = 0.890101\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1284: Avg loss so far = 0.889408\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1285: Avg loss so far = 0.888716\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1286: Avg loss so far = 0.888025\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1287: Avg loss so far = 0.887335\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1288: Avg loss so far = 0.886646\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1289: Avg loss so far = 0.885958\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1290: Avg loss so far = 0.885271\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1291: Avg loss so far = 0.884586\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1292: Avg loss so far = 0.883901\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1293: Avg loss so far = 0.883217\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1294: Avg loss so far = 0.882535\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1295: Avg loss so far = 0.881853\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1296: Avg loss so far = 0.881173\n",
      "     Misclassifications: 47\n",
      "\n",
      "k=1297: Avg loss so far = 0.880493\n",
      "     Misclassifications: 48\n",
      "\n",
      "k=1298: Avg loss so far = 0.929122\n",
      "     Misclassifications: 48\n",
      "\n",
      "k=1299: Avg loss so far = 0.928406\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1300: Avg loss so far = 0.976923\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1301: Avg loss so far = 0.976172\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1302: Avg loss so far = 0.975422\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1303: Avg loss so far = 0.974674\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1304: Avg loss so far = 0.973926\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1305: Avg loss so far = 0.973180\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1306: Avg loss so far = 0.972435\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1307: Avg loss so far = 0.971691\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1308: Avg loss so far = 0.970948\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1309: Avg loss so far = 0.970206\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1310: Avg loss so far = 0.969466\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1311: Avg loss so far = 0.968726\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1312: Avg loss so far = 0.967988\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1313: Avg loss so far = 0.967251\n",
      "     Misclassifications: 49\n",
      "\n",
      "k=1314: Avg loss so far = 0.966514\n",
      "     Misclassifications: 50\n",
      "\n",
      "k=1315: Avg loss so far = 1.041825\n",
      "     Misclassifications: 50\n",
      "\n",
      "k=1316: Avg loss so far = 1.041033\n",
      "     Misclassifications: 50\n",
      "\n",
      "k=1317: Avg loss so far = 1.040243\n",
      "     Misclassifications: 50\n",
      "\n",
      "k=1318: Avg loss so far = 1.039454\n",
      "     Misclassifications: 50\n",
      "\n",
      "k=1319: Avg loss so far = 1.038666\n",
      "     Misclassifications: 50\n",
      "\n",
      "k=1320: Avg loss so far = 1.037879\n",
      "     Misclassifications: 50\n",
      "\n",
      "k=1321: Avg loss so far = 1.037093\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1322: Avg loss so far = 1.037065\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1323: Avg loss so far = 1.036281\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1324: Avg loss so far = 1.035498\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1325: Avg loss so far = 1.034717\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1326: Avg loss so far = 1.033937\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1327: Avg loss so far = 1.033157\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1328: Avg loss so far = 1.032380\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1329: Avg loss so far = 1.031603\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1330: Avg loss so far = 1.030827\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1331: Avg loss so far = 1.030053\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1332: Avg loss so far = 1.029279\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1333: Avg loss so far = 1.028507\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1334: Avg loss so far = 1.027736\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1335: Avg loss so far = 1.026966\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1336: Avg loss so far = 1.026198\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1337: Avg loss so far = 1.025430\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1338: Avg loss so far = 1.024664\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1339: Avg loss so far = 1.023898\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1340: Avg loss so far = 1.023134\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1341: Avg loss so far = 1.022371\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1342: Avg loss so far = 1.021610\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1343: Avg loss so far = 1.020849\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1344: Avg loss so far = 1.020089\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1345: Avg loss so far = 1.019331\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1346: Avg loss so far = 1.018574\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1347: Avg loss so far = 1.017817\n",
      "     Misclassifications: 51\n",
      "\n",
      "k=1348: Avg loss so far = 1.017062\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1349: Avg loss so far = 1.063751\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1350: Avg loss so far = 1.062963\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1351: Avg loss so far = 1.062176\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1352: Avg loss so far = 1.061391\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1353: Avg loss so far = 1.060606\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1354: Avg loss so far = 1.059823\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1355: Avg loss so far = 1.059041\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1356: Avg loss so far = 1.058260\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1357: Avg loss so far = 1.057480\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1358: Avg loss so far = 1.056701\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1359: Avg loss so far = 1.055923\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1360: Avg loss so far = 1.055147\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1361: Avg loss so far = 1.054372\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1362: Avg loss so far = 1.053598\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1363: Avg loss so far = 1.052825\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1364: Avg loss so far = 1.052053\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1365: Avg loss so far = 1.051282\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1366: Avg loss so far = 1.050512\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1367: Avg loss so far = 1.049744\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1368: Avg loss so far = 1.048977\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1369: Avg loss so far = 1.048210\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1370: Avg loss so far = 1.047445\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1371: Avg loss so far = 1.046681\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1372: Avg loss so far = 1.045918\n",
      "     Misclassifications: 52\n",
      "\n",
      "k=1373: Avg loss so far = 1.045157\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1374: Avg loss so far = 1.090975\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1375: Avg loss so far = 1.090182\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1376: Avg loss so far = 1.089390\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1377: Avg loss so far = 1.088598\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1378: Avg loss so far = 1.087808\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1379: Avg loss so far = 1.087020\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1380: Avg loss so far = 1.086232\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1381: Avg loss so far = 1.085445\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1382: Avg loss so far = 1.084660\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1383: Avg loss so far = 1.083876\n",
      "     Misclassifications: 53\n",
      "\n",
      "k=1384: Avg loss so far = 1.083092\n",
      "     Misclassifications: 54\n",
      "\n",
      "k=1385: Avg loss so far = 1.085199\n",
      "     Misclassifications: 54\n",
      "\n",
      "k=1386: Avg loss so far = 1.084416\n",
      "     Misclassifications: 54\n",
      "\n",
      "k=1387: Avg loss so far = 1.083634\n",
      "     Misclassifications: 54\n",
      "\n",
      "k=1388: Avg loss so far = 1.082853\n",
      "     Misclassifications: 54\n",
      "\n",
      "k=1389: Avg loss so far = 1.082073\n",
      "     Misclassifications: 54\n",
      "\n",
      "k=1390: Avg loss so far = 1.081295\n",
      "     Misclassifications: 54\n",
      "\n",
      "k=1391: Avg loss so far = 1.080518\n",
      "     Misclassifications: 54\n",
      "\n",
      "k=1392: Avg loss so far = 1.079741\n",
      "     Misclassifications: 54\n",
      "\n",
      "k=1393: Avg loss so far = 1.078966\n",
      "     Misclassifications: 55\n",
      "\n",
      "k=1394: Avg loss so far = 1.078910\n",
      "     Misclassifications: 55\n",
      "\n",
      "k=1395: Avg loss so far = 1.078136\n",
      "     Misclassifications: 55\n",
      "\n",
      "k=1396: Avg loss so far = 1.077364\n",
      "     Misclassifications: 55\n",
      "\n",
      "k=1397: Avg loss so far = 1.076593\n",
      "     Misclassifications: 56\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1398: Avg loss so far = 1.121602\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1399: Avg loss so far = 1.120801\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1400: Avg loss so far = 1.120000\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1401: Avg loss so far = 1.119201\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1402: Avg loss so far = 1.118402\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1403: Avg loss so far = 1.117605\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1404: Avg loss so far = 1.116809\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1405: Avg loss so far = 1.116014\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1406: Avg loss so far = 1.115220\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1407: Avg loss so far = 1.114428\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1408: Avg loss so far = 1.113636\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1409: Avg loss so far = 1.112846\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1410: Avg loss so far = 1.112057\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1411: Avg loss so far = 1.111269\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1412: Avg loss so far = 1.110482\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1413: Avg loss so far = 1.109696\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1414: Avg loss so far = 1.108911\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1415: Avg loss so far = 1.108127\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1416: Avg loss so far = 1.107345\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1417: Avg loss so far = 1.106563\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1418: Avg loss so far = 1.105783\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1419: Avg loss so far = 1.105004\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1420: Avg loss so far = 1.104225\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1421: Avg loss so far = 1.103448\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1422: Avg loss so far = 1.102672\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1423: Avg loss so far = 1.101897\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1424: Avg loss so far = 1.101124\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1425: Avg loss so far = 1.100351\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1426: Avg loss so far = 1.099579\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1427: Avg loss so far = 1.098809\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1428: Avg loss so far = 1.098039\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1429: Avg loss so far = 1.097271\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1430: Avg loss so far = 1.096503\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1431: Avg loss so far = 1.095737\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1432: Avg loss so far = 1.094972\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1433: Avg loss so far = 1.094208\n",
      "     Misclassifications: 56\n",
      "\n",
      "k=1434: Avg loss so far = 1.093445\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1435: Avg loss so far = 1.103833\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1436: Avg loss so far = 1.103064\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1437: Avg loss so far = 1.102296\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1438: Avg loss so far = 1.101530\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1439: Avg loss so far = 1.100764\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1440: Avg loss so far = 1.100000\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1441: Avg loss so far = 1.099237\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1442: Avg loss so far = 1.098474\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1443: Avg loss so far = 1.097713\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1444: Avg loss so far = 1.096953\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1445: Avg loss so far = 1.096194\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1446: Avg loss so far = 1.095436\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1447: Avg loss so far = 1.094679\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1448: Avg loss so far = 1.093923\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1449: Avg loss so far = 1.093168\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1450: Avg loss so far = 1.092414\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1451: Avg loss so far = 1.091661\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1452: Avg loss so far = 1.090909\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1453: Avg loss so far = 1.090158\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1454: Avg loss so far = 1.089409\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1455: Avg loss so far = 1.088660\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1456: Avg loss so far = 1.087912\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1457: Avg loss so far = 1.087165\n",
      "     Misclassifications: 57\n",
      "\n",
      "k=1458: Avg loss so far = 1.086420\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1459: Avg loss so far = 1.129541\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1460: Avg loss so far = 1.128767\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1461: Avg loss so far = 1.127995\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1462: Avg loss so far = 1.127223\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1463: Avg loss so far = 1.126452\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1464: Avg loss so far = 1.125683\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1465: Avg loss so far = 1.124915\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1466: Avg loss so far = 1.124147\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1467: Avg loss so far = 1.123381\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1468: Avg loss so far = 1.122616\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1469: Avg loss so far = 1.121852\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1470: Avg loss so far = 1.121088\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1471: Avg loss so far = 1.120326\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1472: Avg loss so far = 1.119565\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1473: Avg loss so far = 1.118805\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1474: Avg loss so far = 1.118046\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1475: Avg loss so far = 1.117288\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1476: Avg loss so far = 1.116531\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1477: Avg loss so far = 1.115775\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1478: Avg loss so far = 1.115020\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1479: Avg loss so far = 1.114266\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1480: Avg loss so far = 1.113514\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1481: Avg loss so far = 1.112762\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1482: Avg loss so far = 1.112011\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1483: Avg loss so far = 1.111261\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1484: Avg loss so far = 1.110512\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1485: Avg loss so far = 1.109764\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1486: Avg loss so far = 1.109017\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1487: Avg loss so far = 1.108272\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1488: Avg loss so far = 1.107527\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1489: Avg loss so far = 1.106783\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1490: Avg loss so far = 1.106040\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1491: Avg loss so far = 1.105298\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1492: Avg loss so far = 1.104558\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1493: Avg loss so far = 1.103818\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1494: Avg loss so far = 1.103079\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1495: Avg loss so far = 1.102341\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1496: Avg loss so far = 1.101604\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1497: Avg loss so far = 1.100868\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1498: Avg loss so far = 1.100134\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1499: Avg loss so far = 1.099400\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1500: Avg loss so far = 1.098667\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1501: Avg loss so far = 1.097935\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1502: Avg loss so far = 1.097204\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1503: Avg loss so far = 1.096474\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1504: Avg loss so far = 1.095745\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1505: Avg loss so far = 1.095017\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1506: Avg loss so far = 1.094290\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1507: Avg loss so far = 1.093563\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1508: Avg loss so far = 1.092838\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1509: Avg loss so far = 1.092114\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1510: Avg loss so far = 1.091391\n",
      "     Misclassifications: 58\n",
      "\n",
      "k=1511: Avg loss so far = 1.090668\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1512: Avg loss so far = 1.132275\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1513: Avg loss so far = 1.131527\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1514: Avg loss so far = 1.130779\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1515: Avg loss so far = 1.130033\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1516: Avg loss so far = 1.129288\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1517: Avg loss so far = 1.128543\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1518: Avg loss so far = 1.127800\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1519: Avg loss so far = 1.127057\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1520: Avg loss so far = 1.126316\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1521: Avg loss so far = 1.125575\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1522: Avg loss so far = 1.124836\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1523: Avg loss so far = 1.124097\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1524: Avg loss so far = 1.123360\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1525: Avg loss so far = 1.122623\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1526: Avg loss so far = 1.121887\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1527: Avg loss so far = 1.121153\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1528: Avg loss so far = 1.120419\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1529: Avg loss so far = 1.119686\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1530: Avg loss so far = 1.118954\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1531: Avg loss so far = 1.118223\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1532: Avg loss so far = 1.117493\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1533: Avg loss so far = 1.116765\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1534: Avg loss so far = 1.116037\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1535: Avg loss so far = 1.115309\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1536: Avg loss so far = 1.114583\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1537: Avg loss so far = 1.113858\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1538: Avg loss so far = 1.113134\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1539: Avg loss so far = 1.112411\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1540: Avg loss so far = 1.111688\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1541: Avg loss so far = 1.110967\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1542: Avg loss so far = 1.110246\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1543: Avg loss so far = 1.109527\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1544: Avg loss so far = 1.108808\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1545: Avg loss so far = 1.108091\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1546: Avg loss so far = 1.107374\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1547: Avg loss so far = 1.106658\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1548: Avg loss so far = 1.105943\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1549: Avg loss so far = 1.105229\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1550: Avg loss so far = 1.104516\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1551: Avg loss so far = 1.103804\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1552: Avg loss so far = 1.103093\n",
      "     Misclassifications: 59\n",
      "\n",
      "k=1553: Avg loss so far = 1.102382\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1554: Avg loss so far = 1.111969\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1555: Avg loss so far = 1.111254\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1556: Avg loss so far = 1.110540\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1557: Avg loss so far = 1.109827\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1558: Avg loss so far = 1.109114\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1559: Avg loss so far = 1.108403\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1560: Avg loss so far = 1.107692\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1561: Avg loss so far = 1.106983\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1562: Avg loss so far = 1.106274\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1563: Avg loss so far = 1.105566\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1564: Avg loss so far = 1.104859\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1565: Avg loss so far = 1.104153\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1566: Avg loss so far = 1.103448\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1567: Avg loss so far = 1.102744\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1568: Avg loss so far = 1.102041\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1569: Avg loss so far = 1.101338\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1570: Avg loss so far = 1.100637\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1571: Avg loss so far = 1.099936\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1572: Avg loss so far = 1.099237\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1573: Avg loss so far = 1.098538\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1574: Avg loss so far = 1.097840\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1575: Avg loss so far = 1.097143\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1576: Avg loss so far = 1.096447\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1577: Avg loss so far = 1.095751\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1578: Avg loss so far = 1.095057\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1579: Avg loss so far = 1.094364\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1580: Avg loss so far = 1.093671\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1581: Avg loss so far = 1.092979\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1582: Avg loss so far = 1.092288\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1583: Avg loss so far = 1.091598\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1584: Avg loss so far = 1.090909\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1585: Avg loss so far = 1.090221\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1586: Avg loss so far = 1.089533\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1587: Avg loss so far = 1.088847\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1588: Avg loss so far = 1.088161\n",
      "     Misclassifications: 60\n",
      "\n",
      "k=1589: Avg loss so far = 1.087476\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1590: Avg loss so far = 1.096855\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1591: Avg loss so far = 1.096166\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1592: Avg loss so far = 1.095477\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1593: Avg loss so far = 1.094790\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1594: Avg loss so far = 1.094103\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1595: Avg loss so far = 1.093417\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1596: Avg loss so far = 1.092732\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1597: Avg loss so far = 1.092048\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1598: Avg loss so far = 1.091364\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1599: Avg loss so far = 1.090682\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1600: Avg loss so far = 1.090000\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1601: Avg loss so far = 1.089319\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1602: Avg loss so far = 1.088639\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1603: Avg loss so far = 1.087960\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1604: Avg loss so far = 1.087282\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1605: Avg loss so far = 1.086604\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1606: Avg loss so far = 1.085928\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1607: Avg loss so far = 1.085252\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1608: Avg loss so far = 1.084577\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1609: Avg loss so far = 1.083903\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1610: Avg loss so far = 1.083230\n",
      "     Misclassifications: 61\n",
      "\n",
      "k=1611: Avg loss so far = 1.082557\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1612: Avg loss so far = 1.121588\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1613: Avg loss so far = 1.120893\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1614: Avg loss so far = 1.120198\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1615: Avg loss so far = 1.119505\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1616: Avg loss so far = 1.118812\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1617: Avg loss so far = 1.118120\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1618: Avg loss so far = 1.117429\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1619: Avg loss so far = 1.116739\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1620: Avg loss so far = 1.116049\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1621: Avg loss so far = 1.115361\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1622: Avg loss so far = 1.114673\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1623: Avg loss so far = 1.113986\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1624: Avg loss so far = 1.113300\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1625: Avg loss so far = 1.112615\n",
      "     Misclassifications: 62\n",
      "\n",
      "k=1626: Avg loss so far = 1.111931\n",
      "     Misclassifications: 63\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1627: Avg loss so far = 1.111862\n",
      "     Misclassifications: 63\n",
      "\n",
      "k=1628: Avg loss so far = 1.111179\n",
      "     Misclassifications: 63\n",
      "\n",
      "k=1629: Avg loss so far = 1.110497\n",
      "     Misclassifications: 63\n",
      "\n",
      "k=1630: Avg loss so far = 1.109816\n",
      "     Misclassifications: 63\n",
      "\n",
      "k=1631: Avg loss so far = 1.109135\n",
      "     Misclassifications: 63\n",
      "\n",
      "k=1632: Avg loss so far = 1.108456\n",
      "     Misclassifications: 63\n",
      "\n",
      "k=1633: Avg loss so far = 1.107777\n",
      "     Misclassifications: 63\n",
      "\n",
      "k=1634: Avg loss so far = 1.107099\n",
      "     Misclassifications: 63\n",
      "\n",
      "k=1635: Avg loss so far = 1.106422\n",
      "     Misclassifications: 64\n",
      "\n",
      "k=1636: Avg loss so far = 1.108191\n",
      "     Misclassifications: 64\n",
      "\n",
      "k=1637: Avg loss so far = 1.107514\n",
      "     Misclassifications: 64\n",
      "\n",
      "k=1638: Avg loss so far = 1.106838\n",
      "     Misclassifications: 64\n",
      "\n",
      "k=1639: Avg loss so far = 1.106162\n",
      "     Misclassifications: 64\n",
      "\n",
      "k=1640: Avg loss so far = 1.105488\n",
      "     Misclassifications: 64\n",
      "\n",
      "k=1641: Avg loss so far = 1.104814\n",
      "     Misclassifications: 64\n",
      "\n",
      "k=1642: Avg loss so far = 1.104141\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1643: Avg loss so far = 1.104078\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1644: Avg loss so far = 1.103406\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1645: Avg loss so far = 1.102736\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1646: Avg loss so far = 1.102066\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1647: Avg loss so far = 1.101396\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1648: Avg loss so far = 1.100728\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1649: Avg loss so far = 1.100061\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1650: Avg loss so far = 1.099394\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1651: Avg loss so far = 1.098728\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1652: Avg loss so far = 1.098063\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1653: Avg loss so far = 1.097399\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1654: Avg loss so far = 1.096735\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1655: Avg loss so far = 1.096073\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1656: Avg loss so far = 1.095411\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1657: Avg loss so far = 1.094750\n",
      "     Misclassifications: 65\n",
      "\n",
      "k=1658: Avg loss so far = 1.094089\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1659: Avg loss so far = 1.132007\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1660: Avg loss so far = 1.131325\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1661: Avg loss so far = 1.130644\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1662: Avg loss so far = 1.129964\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1663: Avg loss so far = 1.129284\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1664: Avg loss so far = 1.128606\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1665: Avg loss so far = 1.127928\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1666: Avg loss so far = 1.127251\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1667: Avg loss so far = 1.126575\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1668: Avg loss so far = 1.125899\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1669: Avg loss so far = 1.125225\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1670: Avg loss so far = 1.124551\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1671: Avg loss so far = 1.123878\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1672: Avg loss so far = 1.123206\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1673: Avg loss so far = 1.122534\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1674: Avg loss so far = 1.121864\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1675: Avg loss so far = 1.121194\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1676: Avg loss so far = 1.120525\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1677: Avg loss so far = 1.119857\n",
      "     Misclassifications: 66\n",
      "\n",
      "k=1678: Avg loss so far = 1.119190\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1679: Avg loss so far = 1.128052\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1680: Avg loss so far = 1.127381\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1681: Avg loss so far = 1.126710\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1682: Avg loss so far = 1.126040\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1683: Avg loss so far = 1.125371\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1684: Avg loss so far = 1.124703\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1685: Avg loss so far = 1.124036\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1686: Avg loss so far = 1.123369\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1687: Avg loss so far = 1.122703\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1688: Avg loss so far = 1.122038\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1689: Avg loss so far = 1.121374\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1690: Avg loss so far = 1.120710\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1691: Avg loss so far = 1.120047\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1692: Avg loss so far = 1.119385\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1693: Avg loss so far = 1.118724\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1694: Avg loss so far = 1.118064\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1695: Avg loss so far = 1.117404\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1696: Avg loss so far = 1.116745\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1697: Avg loss so far = 1.116087\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1698: Avg loss so far = 1.115430\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1699: Avg loss so far = 1.114773\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1700: Avg loss so far = 1.114118\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1701: Avg loss so far = 1.113463\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1702: Avg loss so far = 1.112808\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1703: Avg loss so far = 1.112155\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1704: Avg loss so far = 1.111502\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1705: Avg loss so far = 1.110850\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1706: Avg loss so far = 1.110199\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1707: Avg loss so far = 1.109549\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1708: Avg loss so far = 1.108899\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1709: Avg loss so far = 1.108250\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1710: Avg loss so far = 1.107602\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1711: Avg loss so far = 1.106955\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1712: Avg loss so far = 1.106308\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1713: Avg loss so far = 1.105663\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1714: Avg loss so far = 1.105018\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1715: Avg loss so far = 1.104373\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1716: Avg loss so far = 1.103730\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1717: Avg loss so far = 1.103087\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1718: Avg loss so far = 1.102445\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1719: Avg loss so far = 1.101803\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1720: Avg loss so far = 1.101163\n",
      "     Misclassifications: 67\n",
      "\n",
      "k=1721: Avg loss so far = 1.100523\n",
      "     Misclassifications: 68\n",
      "\n",
      "k=1722: Avg loss so far = 1.137050\n",
      "     Misclassifications: 68\n",
      "\n",
      "k=1723: Avg loss so far = 1.136390\n",
      "     Misclassifications: 68\n",
      "\n",
      "k=1724: Avg loss so far = 1.135731\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1725: Avg loss so far = 1.135652\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1726: Avg loss so far = 1.134994\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1727: Avg loss so far = 1.134337\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1728: Avg loss so far = 1.133681\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1729: Avg loss so far = 1.133025\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1730: Avg loss so far = 1.132370\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1731: Avg loss so far = 1.131716\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1732: Avg loss so far = 1.131062\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1733: Avg loss so far = 1.130410\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1734: Avg loss so far = 1.129758\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1735: Avg loss so far = 1.129107\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1736: Avg loss so far = 1.128456\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1737: Avg loss so far = 1.127807\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1738: Avg loss so far = 1.127158\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1739: Avg loss so far = 1.126509\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1740: Avg loss so far = 1.125862\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1741: Avg loss so far = 1.125215\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1742: Avg loss so far = 1.124569\n",
      "     Misclassifications: 69\n",
      "\n",
      "k=1743: Avg loss so far = 1.123924\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1744: Avg loss so far = 1.125573\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1745: Avg loss so far = 1.124928\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1746: Avg loss so far = 1.124284\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1747: Avg loss so far = 1.123641\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1748: Avg loss so far = 1.122998\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1749: Avg loss so far = 1.122356\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1750: Avg loss so far = 1.121714\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1751: Avg loss so far = 1.121074\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1752: Avg loss so far = 1.120434\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1753: Avg loss so far = 1.119795\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1754: Avg loss so far = 1.119156\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1755: Avg loss so far = 1.118519\n",
      "     Misclassifications: 70\n",
      "\n",
      "k=1756: Avg loss so far = 1.117882\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1757: Avg loss so far = 1.117814\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1758: Avg loss so far = 1.117179\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1759: Avg loss so far = 1.116543\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1760: Avg loss so far = 1.115909\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1761: Avg loss so far = 1.115275\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1762: Avg loss so far = 1.114642\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1763: Avg loss so far = 1.114010\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1764: Avg loss so far = 1.113379\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1765: Avg loss so far = 1.112748\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1766: Avg loss so far = 1.112118\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1767: Avg loss so far = 1.111488\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1768: Avg loss so far = 1.110860\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1769: Avg loss so far = 1.110232\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1770: Avg loss so far = 1.109605\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1771: Avg loss so far = 1.108978\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1772: Avg loss so far = 1.108352\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1773: Avg loss so far = 1.107727\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1774: Avg loss so far = 1.107103\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1775: Avg loss so far = 1.106479\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1776: Avg loss so far = 1.105856\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1777: Avg loss so far = 1.105234\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1778: Avg loss so far = 1.104612\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1779: Avg loss so far = 1.103991\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1780: Avg loss so far = 1.103371\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1781: Avg loss so far = 1.102751\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1782: Avg loss so far = 1.102132\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1783: Avg loss so far = 1.101514\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1784: Avg loss so far = 1.100897\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1785: Avg loss so far = 1.100280\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1786: Avg loss so far = 1.099664\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1787: Avg loss so far = 1.099049\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1788: Avg loss so far = 1.098434\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1789: Avg loss so far = 1.097820\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1790: Avg loss so far = 1.097207\n",
      "     Misclassifications: 71\n",
      "\n",
      "k=1791: Avg loss so far = 1.096594\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1792: Avg loss so far = 1.098214\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1793: Avg loss so far = 1.097602\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1794: Avg loss so far = 1.096990\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1795: Avg loss so far = 1.096379\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1796: Avg loss so far = 1.095768\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1797: Avg loss so far = 1.095159\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1798: Avg loss so far = 1.094549\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1799: Avg loss so far = 1.093941\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1800: Avg loss so far = 1.093333\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1801: Avg loss so far = 1.092726\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1802: Avg loss so far = 1.092120\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1803: Avg loss so far = 1.091514\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1804: Avg loss so far = 1.090909\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1805: Avg loss so far = 1.090305\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1806: Avg loss so far = 1.089701\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1807: Avg loss so far = 1.089098\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1808: Avg loss so far = 1.088496\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1809: Avg loss so far = 1.087894\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1810: Avg loss so far = 1.087293\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1811: Avg loss so far = 1.086692\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1812: Avg loss so far = 1.086093\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1813: Avg loss so far = 1.085494\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1814: Avg loss so far = 1.084895\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1815: Avg loss so far = 1.084298\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1816: Avg loss so far = 1.083700\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1817: Avg loss so far = 1.083104\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1818: Avg loss so far = 1.082508\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1819: Avg loss so far = 1.081913\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1820: Avg loss so far = 1.081319\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1821: Avg loss so far = 1.080725\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1822: Avg loss so far = 1.080132\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1823: Avg loss so far = 1.079539\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1824: Avg loss so far = 1.078947\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1825: Avg loss so far = 1.078356\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1826: Avg loss so far = 1.077766\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1827: Avg loss so far = 1.077176\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1828: Avg loss so far = 1.076586\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1829: Avg loss so far = 1.075998\n",
      "     Misclassifications: 72\n",
      "\n",
      "k=1830: Avg loss so far = 1.075410\n",
      "     Misclassifications: 73\n",
      "\n",
      "k=1831: Avg loss so far = 1.109776\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1832: Avg loss so far = 1.111354\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1833: Avg loss so far = 1.110747\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1834: Avg loss so far = 1.110142\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1835: Avg loss so far = 1.109537\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1836: Avg loss so far = 1.108932\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1837: Avg loss so far = 1.108329\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1838: Avg loss so far = 1.107726\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1839: Avg loss so far = 1.107123\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1840: Avg loss so far = 1.106522\n",
      "     Misclassifications: 74\n",
      "\n",
      "k=1841: Avg loss so far = 1.105921\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1842: Avg loss so far = 1.107492\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1843: Avg loss so far = 1.106891\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1844: Avg loss so far = 1.106291\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1845: Avg loss so far = 1.105691\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1846: Avg loss so far = 1.105092\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1847: Avg loss so far = 1.104494\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1848: Avg loss so far = 1.103896\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1849: Avg loss so far = 1.103299\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1850: Avg loss so far = 1.102703\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1851: Avg loss so far = 1.102107\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1852: Avg loss so far = 1.101512\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1853: Avg loss so far = 1.100917\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1854: Avg loss so far = 1.100324\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1855: Avg loss so far = 1.099730\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1856: Avg loss so far = 1.099138\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1857: Avg loss so far = 1.098546\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1858: Avg loss so far = 1.097955\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1859: Avg loss so far = 1.097364\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1860: Avg loss so far = 1.096774\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1861: Avg loss so far = 1.096185\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1862: Avg loss so far = 1.095596\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1863: Avg loss so far = 1.095008\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1864: Avg loss so far = 1.094421\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1865: Avg loss so far = 1.093834\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1866: Avg loss so far = 1.093248\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1867: Avg loss so far = 1.092662\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1868: Avg loss so far = 1.092077\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1869: Avg loss so far = 1.091493\n",
      "     Misclassifications: 75\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1870: Avg loss so far = 1.090909\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1871: Avg loss so far = 1.090326\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1872: Avg loss so far = 1.089744\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1873: Avg loss so far = 1.089162\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1874: Avg loss so far = 1.088581\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1875: Avg loss so far = 1.088000\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1876: Avg loss so far = 1.087420\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1877: Avg loss so far = 1.086841\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1878: Avg loss so far = 1.086262\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1879: Avg loss so far = 1.085684\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1880: Avg loss so far = 1.085106\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1881: Avg loss so far = 1.084530\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1882: Avg loss so far = 1.083953\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1883: Avg loss so far = 1.083378\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1884: Avg loss so far = 1.082803\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1885: Avg loss so far = 1.082228\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1886: Avg loss so far = 1.081654\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1887: Avg loss so far = 1.081081\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1888: Avg loss so far = 1.080508\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1889: Avg loss so far = 1.079936\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1890: Avg loss so far = 1.079365\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1891: Avg loss so far = 1.078794\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1892: Avg loss so far = 1.078224\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1893: Avg loss so far = 1.077655\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1894: Avg loss so far = 1.077086\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1895: Avg loss so far = 1.076517\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1896: Avg loss so far = 1.075949\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1897: Avg loss so far = 1.075382\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1898: Avg loss so far = 1.074816\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1899: Avg loss so far = 1.074250\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1900: Avg loss so far = 1.073684\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1901: Avg loss so far = 1.073119\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1902: Avg loss so far = 1.072555\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1903: Avg loss so far = 1.071992\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1904: Avg loss so far = 1.071429\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1905: Avg loss so far = 1.070866\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1906: Avg loss so far = 1.070304\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1907: Avg loss so far = 1.069743\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1908: Avg loss so far = 1.069182\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1909: Avg loss so far = 1.068622\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1910: Avg loss so far = 1.068063\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1911: Avg loss so far = 1.067504\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1912: Avg loss so far = 1.066946\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1913: Avg loss so far = 1.066388\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1914: Avg loss so far = 1.065831\n",
      "     Misclassifications: 75\n",
      "\n",
      "k=1915: Avg loss so far = 1.065274\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1916: Avg loss so far = 1.073069\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1917: Avg loss so far = 1.072509\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1918: Avg loss so far = 1.071950\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1919: Avg loss so far = 1.071391\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1920: Avg loss so far = 1.070833\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1921: Avg loss so far = 1.070276\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1922: Avg loss so far = 1.069719\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1923: Avg loss so far = 1.069163\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1924: Avg loss so far = 1.068607\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1925: Avg loss so far = 1.068052\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1926: Avg loss so far = 1.067497\n",
      "     Misclassifications: 76\n",
      "\n",
      "k=1927: Avg loss so far = 1.066943\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1928: Avg loss so far = 1.066909\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1929: Avg loss so far = 1.066356\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1930: Avg loss so far = 1.065803\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1931: Avg loss so far = 1.065251\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1932: Avg loss so far = 1.064700\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1933: Avg loss so far = 1.064149\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1934: Avg loss so far = 1.063599\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1935: Avg loss so far = 1.063049\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1936: Avg loss so far = 1.062500\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1937: Avg loss so far = 1.061951\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1938: Avg loss so far = 1.061404\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1939: Avg loss so far = 1.060856\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1940: Avg loss so far = 1.060309\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1941: Avg loss so far = 1.059763\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1942: Avg loss so far = 1.059217\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1943: Avg loss so far = 1.058672\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1944: Avg loss so far = 1.058128\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1945: Avg loss so far = 1.057584\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1946: Avg loss so far = 1.057040\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1947: Avg loss so far = 1.056497\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1948: Avg loss so far = 1.055955\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1949: Avg loss so far = 1.055413\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1950: Avg loss so far = 1.054872\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1951: Avg loss so far = 1.054331\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1952: Avg loss so far = 1.053791\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1953: Avg loss so far = 1.053251\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1954: Avg loss so far = 1.052712\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1955: Avg loss so far = 1.052174\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1956: Avg loss so far = 1.051636\n",
      "     Misclassifications: 77\n",
      "\n",
      "k=1957: Avg loss so far = 1.051099\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1958: Avg loss so far = 1.052605\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1959: Avg loss so far = 1.052067\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1960: Avg loss so far = 1.051531\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1961: Avg loss so far = 1.050994\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1962: Avg loss so far = 1.050459\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1963: Avg loss so far = 1.049924\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1964: Avg loss so far = 1.049389\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1965: Avg loss so far = 1.048855\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1966: Avg loss so far = 1.048321\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1967: Avg loss so far = 1.047789\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1968: Avg loss so far = 1.047256\n",
      "     Misclassifications: 78\n",
      "\n",
      "k=1969: Avg loss so far = 1.046724\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1970: Avg loss so far = 1.046701\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1971: Avg loss so far = 1.046169\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1972: Avg loss so far = 1.045639\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1973: Avg loss so far = 1.045109\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1974: Avg loss so far = 1.044580\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1975: Avg loss so far = 1.044051\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1976: Avg loss so far = 1.043522\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1977: Avg loss so far = 1.042994\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1978: Avg loss so far = 1.042467\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1979: Avg loss so far = 1.041940\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1980: Avg loss so far = 1.041414\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1981: Avg loss so far = 1.040888\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1982: Avg loss so far = 1.040363\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1983: Avg loss so far = 1.039839\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1984: Avg loss so far = 1.039315\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1985: Avg loss so far = 1.038791\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1986: Avg loss so far = 1.038268\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1987: Avg loss so far = 1.037745\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1988: Avg loss so far = 1.037223\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1989: Avg loss so far = 1.036702\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1990: Avg loss so far = 1.036181\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1991: Avg loss so far = 1.035660\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1992: Avg loss so far = 1.035141\n",
      "     Misclassifications: 79\n",
      "\n",
      "k=1993: Avg loss so far = 1.034621\n",
      "     Misclassifications: 80\n",
      "\n",
      "k=1994: Avg loss so far = 1.066199\n",
      "     Misclassifications: 80\n",
      "\n",
      "k=1995: Avg loss so far = 1.065664\n",
      "     Misclassifications: 80\n",
      "\n",
      "k=1996: Avg loss so far = 1.065130\n",
      "     Misclassifications: 80\n",
      "\n",
      "k=1997: Avg loss so far = 1.064597\n",
      "     Misclassifications: 80\n",
      "\n",
      "k=1998: Avg loss so far = 1.064064\n",
      "     Misclassifications: 80\n",
      "\n",
      "k=1999: Avg loss so far = 1.063532\n",
      "     Misclassifications: 80\n",
      "\n",
      "k=2000: Avg loss so far = 1.063000\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2001: Avg loss so far = 1.074963\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2002: Avg loss so far = 1.074426\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2003: Avg loss so far = 1.073889\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2004: Avg loss so far = 1.073353\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2005: Avg loss so far = 1.072818\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2006: Avg loss so far = 1.072283\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2007: Avg loss so far = 1.071749\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2008: Avg loss so far = 1.071215\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2009: Avg loss so far = 1.070682\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2010: Avg loss so far = 1.070149\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2011: Avg loss so far = 1.069617\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2012: Avg loss so far = 1.069085\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2013: Avg loss so far = 1.068554\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2014: Avg loss so far = 1.068024\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2015: Avg loss so far = 1.067494\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2016: Avg loss so far = 1.066964\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2017: Avg loss so far = 1.066435\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2018: Avg loss so far = 1.065907\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2019: Avg loss so far = 1.065379\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2020: Avg loss so far = 1.064851\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2021: Avg loss so far = 1.064325\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2022: Avg loss so far = 1.063798\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2023: Avg loss so far = 1.063272\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2024: Avg loss so far = 1.062747\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2025: Avg loss so far = 1.062222\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2026: Avg loss so far = 1.061698\n",
      "     Misclassifications: 81\n",
      "\n",
      "k=2027: Avg loss so far = 1.061174\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2028: Avg loss so far = 1.068540\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2029: Avg loss so far = 1.068014\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2030: Avg loss so far = 1.067488\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2031: Avg loss so far = 1.066962\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2032: Avg loss so far = 1.066437\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2033: Avg loss so far = 1.065912\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2034: Avg loss so far = 1.065388\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2035: Avg loss so far = 1.064865\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2036: Avg loss so far = 1.064342\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2037: Avg loss so far = 1.063819\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2038: Avg loss so far = 1.063297\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2039: Avg loss so far = 1.062776\n",
      "     Misclassifications: 82\n",
      "\n",
      "k=2040: Avg loss so far = 1.062255\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2041: Avg loss so far = 1.063694\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2042: Avg loss so far = 1.063173\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2043: Avg loss so far = 1.062653\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2044: Avg loss so far = 1.062133\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2045: Avg loss so far = 1.061614\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2046: Avg loss so far = 1.061095\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2047: Avg loss so far = 1.060576\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2048: Avg loss so far = 1.060059\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2049: Avg loss so far = 1.059541\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2050: Avg loss so far = 1.059024\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2051: Avg loss so far = 1.058508\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2052: Avg loss so far = 1.057992\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2053: Avg loss so far = 1.057477\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2054: Avg loss so far = 1.056962\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2055: Avg loss so far = 1.056448\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2056: Avg loss so far = 1.055934\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2057: Avg loss so far = 1.055421\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2058: Avg loss so far = 1.054908\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2059: Avg loss so far = 1.054395\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2060: Avg loss so far = 1.053883\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2061: Avg loss so far = 1.053372\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2062: Avg loss so far = 1.052861\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2063: Avg loss so far = 1.052351\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2064: Avg loss so far = 1.051841\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2065: Avg loss so far = 1.051332\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2066: Avg loss so far = 1.050823\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2067: Avg loss so far = 1.050314\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2068: Avg loss so far = 1.049807\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2069: Avg loss so far = 1.049299\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2070: Avg loss so far = 1.048792\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2071: Avg loss so far = 1.048286\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2072: Avg loss so far = 1.047780\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2073: Avg loss so far = 1.047274\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2074: Avg loss so far = 1.046770\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2075: Avg loss so far = 1.046265\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2076: Avg loss so far = 1.045761\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2077: Avg loss so far = 1.045258\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2078: Avg loss so far = 1.044755\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2079: Avg loss so far = 1.044252\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2080: Avg loss so far = 1.043750\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2081: Avg loss so far = 1.043248\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2082: Avg loss so far = 1.042747\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2083: Avg loss so far = 1.042247\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2084: Avg loss so far = 1.041747\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2085: Avg loss so far = 1.041247\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2086: Avg loss so far = 1.040748\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2087: Avg loss so far = 1.040249\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2088: Avg loss so far = 1.039751\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2089: Avg loss so far = 1.039253\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2090: Avg loss so far = 1.038756\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2091: Avg loss so far = 1.038259\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2092: Avg loss so far = 1.037763\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2093: Avg loss so far = 1.037267\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2094: Avg loss so far = 1.036772\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2095: Avg loss so far = 1.036277\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2096: Avg loss so far = 1.035782\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2097: Avg loss so far = 1.035289\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2098: Avg loss so far = 1.034795\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2099: Avg loss so far = 1.034302\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2100: Avg loss so far = 1.033810\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2101: Avg loss so far = 1.033317\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2102: Avg loss so far = 1.032826\n",
      "     Misclassifications: 83\n",
      "\n",
      "k=2103: Avg loss so far = 1.032335\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2104: Avg loss so far = 1.033745\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2105: Avg loss so far = 1.033254\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2106: Avg loss so far = 1.032764\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2107: Avg loss so far = 1.032273\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2108: Avg loss so far = 1.031784\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2109: Avg loss so far = 1.031294\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2110: Avg loss so far = 1.030806\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2111: Avg loss so far = 1.030317\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2112: Avg loss so far = 1.029830\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2113: Avg loss so far = 1.029342\n",
      "     Misclassifications: 84\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2114: Avg loss so far = 1.028855\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2115: Avg loss so far = 1.028369\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2116: Avg loss so far = 1.027883\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2117: Avg loss so far = 1.027397\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2118: Avg loss so far = 1.026912\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2119: Avg loss so far = 1.026428\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2120: Avg loss so far = 1.025943\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2121: Avg loss so far = 1.025460\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2122: Avg loss so far = 1.024976\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2123: Avg loss so far = 1.024494\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2124: Avg loss so far = 1.024011\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2125: Avg loss so far = 1.023529\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2126: Avg loss so far = 1.023048\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2127: Avg loss so far = 1.022567\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2128: Avg loss so far = 1.022086\n",
      "     Misclassifications: 84\n",
      "\n",
      "k=2129: Avg loss so far = 1.021606\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2130: Avg loss so far = 1.023005\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2131: Avg loss so far = 1.022525\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2132: Avg loss so far = 1.022045\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2133: Avg loss so far = 1.021566\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2134: Avg loss so far = 1.021087\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2135: Avg loss so far = 1.020609\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2136: Avg loss so far = 1.020131\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2137: Avg loss so far = 1.019654\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2138: Avg loss so far = 1.019177\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2139: Avg loss so far = 1.018700\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2140: Avg loss so far = 1.018224\n",
      "     Misclassifications: 85\n",
      "\n",
      "k=2141: Avg loss so far = 1.017749\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2142: Avg loss so far = 1.019141\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2143: Avg loss so far = 1.018665\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2144: Avg loss so far = 1.018190\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2145: Avg loss so far = 1.017716\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2146: Avg loss so far = 1.017241\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2147: Avg loss so far = 1.016768\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2148: Avg loss so far = 1.016294\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2149: Avg loss so far = 1.015821\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2150: Avg loss so far = 1.015349\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2151: Avg loss so far = 1.014877\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2152: Avg loss so far = 1.014405\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2153: Avg loss so far = 1.013934\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2154: Avg loss so far = 1.013463\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2155: Avg loss so far = 1.012993\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2156: Avg loss so far = 1.012523\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2157: Avg loss so far = 1.012054\n",
      "     Misclassifications: 86\n",
      "\n",
      "k=2158: Avg loss so far = 1.011585\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2159: Avg loss so far = 1.040760\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2160: Avg loss so far = 1.040278\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2161: Avg loss so far = 1.039796\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2162: Avg loss so far = 1.039315\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2163: Avg loss so far = 1.038835\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2164: Avg loss so far = 1.038355\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2165: Avg loss so far = 1.037875\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2166: Avg loss so far = 1.037396\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2167: Avg loss so far = 1.036917\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2168: Avg loss so far = 1.036439\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2169: Avg loss so far = 1.035961\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2170: Avg loss so far = 1.035484\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2171: Avg loss so far = 1.035007\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2172: Avg loss so far = 1.034530\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2173: Avg loss so far = 1.034054\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2174: Avg loss so far = 1.033579\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2175: Avg loss so far = 1.033103\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2176: Avg loss so far = 1.032629\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2177: Avg loss so far = 1.032154\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2178: Avg loss so far = 1.031680\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2179: Avg loss so far = 1.031207\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2180: Avg loss so far = 1.030734\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2181: Avg loss so far = 1.030261\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2182: Avg loss so far = 1.029789\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2183: Avg loss so far = 1.029317\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2184: Avg loss so far = 1.028846\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2185: Avg loss so far = 1.028375\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2186: Avg loss so far = 1.027905\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2187: Avg loss so far = 1.027435\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2188: Avg loss so far = 1.026965\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2189: Avg loss so far = 1.026496\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2190: Avg loss so far = 1.026027\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2191: Avg loss so far = 1.025559\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2192: Avg loss so far = 1.025091\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2193: Avg loss so far = 1.024624\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2194: Avg loss so far = 1.024157\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2195: Avg loss so far = 1.023690\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2196: Avg loss so far = 1.023224\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2197: Avg loss so far = 1.022758\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2198: Avg loss so far = 1.022293\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2199: Avg loss so far = 1.021828\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2200: Avg loss so far = 1.021364\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2201: Avg loss so far = 1.020900\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2202: Avg loss so far = 1.020436\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2203: Avg loss so far = 1.019973\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2204: Avg loss so far = 1.019510\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2205: Avg loss so far = 1.019048\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2206: Avg loss so far = 1.018586\n",
      "     Misclassifications: 87\n",
      "\n",
      "k=2207: Avg loss so far = 1.018124\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2208: Avg loss so far = 1.019475\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2209: Avg loss so far = 1.019013\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2210: Avg loss so far = 1.018552\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2211: Avg loss so far = 1.018091\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2212: Avg loss so far = 1.017631\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2213: Avg loss so far = 1.017171\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2214: Avg loss so far = 1.016712\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2215: Avg loss so far = 1.016253\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2216: Avg loss so far = 1.015794\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2217: Avg loss so far = 1.015336\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2218: Avg loss so far = 1.014878\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2219: Avg loss so far = 1.014421\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2220: Avg loss so far = 1.013964\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2221: Avg loss so far = 1.013507\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2222: Avg loss so far = 1.013051\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2223: Avg loss so far = 1.012596\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2224: Avg loss so far = 1.012140\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2225: Avg loss so far = 1.011685\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2226: Avg loss so far = 1.011231\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2227: Avg loss so far = 1.010777\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2228: Avg loss so far = 1.010323\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2229: Avg loss so far = 1.009870\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2230: Avg loss so far = 1.009417\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2231: Avg loss so far = 1.008965\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2232: Avg loss so far = 1.008513\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2233: Avg loss so far = 1.008061\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2234: Avg loss so far = 1.007610\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2235: Avg loss so far = 1.007159\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2236: Avg loss so far = 1.006708\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2237: Avg loss so far = 1.006258\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2238: Avg loss so far = 1.005809\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2239: Avg loss so far = 1.005360\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2240: Avg loss so far = 1.004911\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2241: Avg loss so far = 1.004462\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2242: Avg loss so far = 1.004014\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2243: Avg loss so far = 1.003567\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2244: Avg loss so far = 1.003119\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2245: Avg loss so far = 1.002673\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2246: Avg loss so far = 1.002226\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2247: Avg loss so far = 1.001780\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2248: Avg loss so far = 1.001335\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2249: Avg loss so far = 1.000889\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2250: Avg loss so far = 1.000444\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2251: Avg loss so far = 1.000000\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2252: Avg loss so far = 0.999556\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2253: Avg loss so far = 0.999112\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2254: Avg loss so far = 0.998669\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2255: Avg loss so far = 0.998226\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2256: Avg loss so far = 0.997784\n",
      "     Misclassifications: 88\n",
      "\n",
      "k=2257: Avg loss so far = 0.997342\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2258: Avg loss so far = 0.997343\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2259: Avg loss so far = 0.996901\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2260: Avg loss so far = 0.996460\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2261: Avg loss so far = 0.996019\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2262: Avg loss so far = 0.995579\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2263: Avg loss so far = 0.995139\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2264: Avg loss so far = 0.994700\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2265: Avg loss so far = 0.994260\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2266: Avg loss so far = 0.993822\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2267: Avg loss so far = 0.993383\n",
      "     Misclassifications: 89\n",
      "\n",
      "k=2268: Avg loss so far = 0.992945\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2269: Avg loss so far = 0.992948\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2270: Avg loss so far = 0.992511\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2271: Avg loss so far = 0.992074\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2272: Avg loss so far = 0.991637\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2273: Avg loss so far = 0.991201\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2274: Avg loss so far = 0.990765\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2275: Avg loss so far = 0.990330\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2276: Avg loss so far = 0.989895\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2277: Avg loss so far = 0.989460\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2278: Avg loss so far = 0.989025\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2279: Avg loss so far = 0.988591\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2280: Avg loss so far = 0.988158\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2281: Avg loss so far = 0.987725\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2282: Avg loss so far = 0.987292\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2283: Avg loss so far = 0.986859\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2284: Avg loss so far = 0.986427\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2285: Avg loss so far = 0.985996\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2286: Avg loss so far = 0.985564\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2287: Avg loss so far = 0.985133\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2288: Avg loss so far = 0.984703\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2289: Avg loss so far = 0.984273\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2290: Avg loss so far = 0.983843\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2291: Avg loss so far = 0.983413\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2292: Avg loss so far = 0.982984\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2293: Avg loss so far = 0.982556\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2294: Avg loss so far = 0.982127\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2295: Avg loss so far = 0.981699\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2296: Avg loss so far = 0.981272\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2297: Avg loss so far = 0.980845\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2298: Avg loss so far = 0.980418\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2299: Avg loss so far = 0.979991\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2300: Avg loss so far = 0.979565\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2301: Avg loss so far = 0.979140\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2302: Avg loss so far = 0.978714\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2303: Avg loss so far = 0.978289\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2304: Avg loss so far = 0.977865\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2305: Avg loss so far = 0.977440\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2306: Avg loss so far = 0.977016\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2307: Avg loss so far = 0.976593\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2308: Avg loss so far = 0.976170\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2309: Avg loss so far = 0.975747\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2310: Avg loss so far = 0.975325\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2311: Avg loss so far = 0.974903\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2312: Avg loss so far = 0.974481\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2313: Avg loss so far = 0.974060\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2314: Avg loss so far = 0.973639\n",
      "     Misclassifications: 90\n",
      "\n",
      "k=2315: Avg loss so far = 0.973218\n",
      "     Misclassifications: 91\n",
      "\n",
      "k=2316: Avg loss so far = 1.000432\n",
      "     Misclassifications: 91\n",
      "\n",
      "k=2317: Avg loss so far = 1.000000\n",
      "     Misclassifications: 91\n",
      "\n",
      "k=2318: Avg loss so far = 0.999569\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2319: Avg loss so far = 0.999569\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2320: Avg loss so far = 0.999138\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2321: Avg loss so far = 0.998707\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2322: Avg loss so far = 0.998277\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2323: Avg loss so far = 0.997848\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2324: Avg loss so far = 0.997418\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2325: Avg loss so far = 0.996989\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2326: Avg loss so far = 0.996561\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2327: Avg loss so far = 0.996132\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2328: Avg loss so far = 0.995704\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2329: Avg loss so far = 0.995277\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2330: Avg loss so far = 0.994850\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2331: Avg loss so far = 0.994423\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2332: Avg loss so far = 0.993997\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2333: Avg loss so far = 0.993571\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2334: Avg loss so far = 0.993145\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2335: Avg loss so far = 0.992719\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2336: Avg loss so far = 0.992295\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2337: Avg loss so far = 0.991870\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2338: Avg loss so far = 0.991446\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2339: Avg loss so far = 0.991022\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2340: Avg loss so far = 0.990598\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2341: Avg loss so far = 0.990175\n",
      "     Misclassifications: 92\n",
      "\n",
      "k=2342: Avg loss so far = 0.989752\n",
      "     Misclassifications: 93\n",
      "\n",
      "k=2343: Avg loss so far = 0.991037\n",
      "     Misclassifications: 93\n",
      "\n",
      "k=2344: Avg loss so far = 0.990614\n",
      "     Misclassifications: 93\n",
      "\n",
      "k=2345: Avg loss so far = 0.990192\n",
      "     Misclassifications: 93\n",
      "\n",
      "k=2346: Avg loss so far = 0.989770\n",
      "     Misclassifications: 93\n",
      "\n",
      "k=2347: Avg loss so far = 0.989348\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2348: Avg loss so far = 1.016184\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2349: Avg loss so far = 1.015751\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2350: Avg loss so far = 1.015319\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2351: Avg loss so far = 1.014887\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2352: Avg loss so far = 1.014456\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2353: Avg loss so far = 1.014025\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2354: Avg loss so far = 1.013594\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2355: Avg loss so far = 1.013163\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2356: Avg loss so far = 1.012733\n",
      "     Misclassifications: 94\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2357: Avg loss so far = 1.012304\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2358: Avg loss so far = 1.011874\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2359: Avg loss so far = 1.011446\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2360: Avg loss so far = 1.011017\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2361: Avg loss so far = 1.010589\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2362: Avg loss so far = 1.010161\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2363: Avg loss so far = 1.009733\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2364: Avg loss so far = 1.009306\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2365: Avg loss so far = 1.008879\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2366: Avg loss so far = 1.008453\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2367: Avg loss so far = 1.008027\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2368: Avg loss so far = 1.007601\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2369: Avg loss so far = 1.007176\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2370: Avg loss so far = 1.006751\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2371: Avg loss so far = 1.006326\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2372: Avg loss so far = 1.005902\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2373: Avg loss so far = 1.005478\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2374: Avg loss so far = 1.005055\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2375: Avg loss so far = 1.004632\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2376: Avg loss so far = 1.004209\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2377: Avg loss so far = 1.003786\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2378: Avg loss so far = 1.003364\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2379: Avg loss so far = 1.002942\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2380: Avg loss so far = 1.002521\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2381: Avg loss so far = 1.002100\n",
      "     Misclassifications: 94\n",
      "\n",
      "k=2382: Avg loss so far = 1.001679\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2383: Avg loss so far = 1.002937\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2384: Avg loss so far = 1.002517\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2385: Avg loss so far = 1.002096\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2386: Avg loss so far = 1.001676\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2387: Avg loss so far = 1.001257\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2388: Avg loss so far = 1.000838\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2389: Avg loss so far = 1.000419\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2390: Avg loss so far = 1.000000\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2391: Avg loss so far = 0.999582\n",
      "     Misclassifications: 95\n",
      "\n",
      "k=2392: Avg loss so far = 0.999164\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2393: Avg loss so far = 1.000418\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2394: Avg loss so far = 1.000000\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2395: Avg loss so far = 0.999582\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2396: Avg loss so far = 0.999165\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2397: Avg loss so far = 0.998748\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2398: Avg loss so far = 0.998332\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2399: Avg loss so far = 0.997916\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2400: Avg loss so far = 0.997500\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2401: Avg loss so far = 0.997085\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2402: Avg loss so far = 0.996669\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2403: Avg loss so far = 0.996255\n",
      "     Misclassifications: 96\n",
      "\n",
      "k=2404: Avg loss so far = 0.995840\n",
      "     Misclassifications: 97\n",
      "\n",
      "k=2405: Avg loss so far = 0.997089\n",
      "     Misclassifications: 97\n",
      "\n",
      "k=2406: Avg loss so far = 0.996675\n",
      "     Misclassifications: 97\n",
      "\n",
      "k=2407: Avg loss so far = 0.996261\n",
      "     Misclassifications: 97\n",
      "\n",
      "k=2408: Avg loss so far = 0.995847\n",
      "     Misclassifications: 97\n",
      "\n",
      "k=2409: Avg loss so far = 0.995434\n",
      "     Misclassifications: 97\n",
      "\n",
      "k=2410: Avg loss so far = 0.995021\n",
      "     Misclassifications: 97\n",
      "\n",
      "k=2411: Avg loss so far = 0.994608\n",
      "     Misclassifications: 97\n",
      "\n",
      "k=2412: Avg loss so far = 0.994196\n",
      "     Misclassifications: 97\n",
      "\n",
      "k=2413: Avg loss so far = 0.993784\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2414: Avg loss so far = 1.019884\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2415: Avg loss so far = 1.019462\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2416: Avg loss so far = 1.019040\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2417: Avg loss so far = 1.018618\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2418: Avg loss so far = 1.018197\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2419: Avg loss so far = 1.017776\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2420: Avg loss so far = 1.017355\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2421: Avg loss so far = 1.016935\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2422: Avg loss so far = 1.016515\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2423: Avg loss so far = 1.016096\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2424: Avg loss so far = 1.015677\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2425: Avg loss so far = 1.015258\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2426: Avg loss so far = 1.014839\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2427: Avg loss so far = 1.014421\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2428: Avg loss so far = 1.014003\n",
      "     Misclassifications: 98\n",
      "\n",
      "k=2429: Avg loss so far = 1.013586\n",
      "     Misclassifications: 99\n",
      "\n",
      "k=2430: Avg loss so far = 1.014815\n",
      "     Misclassifications: 99\n",
      "\n",
      "k=2431: Avg loss so far = 1.014397\n",
      "     Misclassifications: 99\n",
      "\n",
      "k=2432: Avg loss so far = 1.013980\n",
      "     Misclassifications: 99\n",
      "\n",
      "k=2433: Avg loss so far = 1.013564\n",
      "     Misclassifications: 99\n",
      "\n",
      "k=2434: Avg loss so far = 1.013147\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2435: Avg loss so far = 1.014374\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2436: Avg loss so far = 1.013957\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2437: Avg loss so far = 1.013541\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2438: Avg loss so far = 1.013126\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2439: Avg loss so far = 1.012710\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2440: Avg loss so far = 1.012295\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2441: Avg loss so far = 1.011880\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2442: Avg loss so far = 1.011466\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2443: Avg loss so far = 1.011052\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2444: Avg loss so far = 1.010638\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2445: Avg loss so far = 1.010225\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2446: Avg loss so far = 1.009812\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2447: Avg loss so far = 1.009399\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2448: Avg loss so far = 1.008987\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2449: Avg loss so far = 1.008575\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2450: Avg loss so far = 1.008163\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2451: Avg loss so far = 1.007752\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2452: Avg loss so far = 1.007341\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2453: Avg loss so far = 1.006930\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2454: Avg loss so far = 1.006520\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2455: Avg loss so far = 1.006110\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2456: Avg loss so far = 1.005700\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2457: Avg loss so far = 1.005291\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2458: Avg loss so far = 1.004882\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2459: Avg loss so far = 1.004473\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2460: Avg loss so far = 1.004065\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2461: Avg loss so far = 1.003657\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2462: Avg loss so far = 1.003249\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2463: Avg loss so far = 1.002842\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2464: Avg loss so far = 1.002435\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2465: Avg loss so far = 1.002028\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2466: Avg loss so far = 1.001622\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2467: Avg loss so far = 1.001216\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2468: Avg loss so far = 1.000810\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2469: Avg loss so far = 1.000405\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2470: Avg loss so far = 1.000000\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2471: Avg loss so far = 0.999595\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2472: Avg loss so far = 0.999191\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2473: Avg loss so far = 0.998787\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2474: Avg loss so far = 0.998383\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2475: Avg loss so far = 0.997980\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2476: Avg loss so far = 0.997577\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2477: Avg loss so far = 0.997174\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2478: Avg loss so far = 0.996772\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2479: Avg loss so far = 0.996370\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2480: Avg loss so far = 0.995968\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2481: Avg loss so far = 0.995566\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2482: Avg loss so far = 0.995165\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2483: Avg loss so far = 0.994764\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2484: Avg loss so far = 0.994364\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2485: Avg loss so far = 0.993964\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2486: Avg loss so far = 0.993564\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2487: Avg loss so far = 0.993164\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2488: Avg loss so far = 0.992765\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2489: Avg loss so far = 0.992366\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2490: Avg loss so far = 0.991968\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2491: Avg loss so far = 0.991570\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2492: Avg loss so far = 0.991172\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2493: Avg loss so far = 0.990774\n",
      "     Misclassifications: 100\n",
      "\n",
      "k=2494: Avg loss so far = 0.990377\n",
      "     Misclassifications: 101\n",
      "\n",
      "k=2495: Avg loss so far = 0.991583\n",
      "     Misclassifications: 101\n",
      "\n",
      "k=2496: Avg loss so far = 0.991186\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2497: Avg loss so far = 1.016420\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2498: Avg loss so far = 1.016013\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2499: Avg loss so far = 1.015606\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2500: Avg loss so far = 1.015200\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2501: Avg loss so far = 1.014794\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2502: Avg loss so far = 1.014388\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2503: Avg loss so far = 1.013983\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2504: Avg loss so far = 1.013578\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2505: Avg loss so far = 1.013174\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2506: Avg loss so far = 1.012769\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2507: Avg loss so far = 1.012365\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2508: Avg loss so far = 1.011962\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2509: Avg loss so far = 1.011558\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2510: Avg loss so far = 1.011155\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2511: Avg loss so far = 1.010753\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2512: Avg loss so far = 1.010350\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2513: Avg loss so far = 1.009948\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2514: Avg loss so far = 1.009547\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2515: Avg loss so far = 1.009145\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2516: Avg loss so far = 1.008744\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2517: Avg loss so far = 1.008343\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2518: Avg loss so far = 1.007943\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2519: Avg loss so far = 1.007543\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2520: Avg loss so far = 1.007143\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2521: Avg loss so far = 1.006743\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2522: Avg loss so far = 1.006344\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2523: Avg loss so far = 1.005945\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2524: Avg loss so far = 1.005547\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2525: Avg loss so far = 1.005149\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2526: Avg loss so far = 1.004751\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2527: Avg loss so far = 1.004353\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2528: Avg loss so far = 1.003956\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2529: Avg loss so far = 1.003559\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2530: Avg loss so far = 1.003162\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2531: Avg loss so far = 1.002766\n",
      "     Misclassifications: 102\n",
      "\n",
      "k=2532: Avg loss so far = 1.002370\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2533: Avg loss so far = 1.041453\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2534: Avg loss so far = 1.041042\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2535: Avg loss so far = 1.040631\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2536: Avg loss so far = 1.040221\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2537: Avg loss so far = 1.039811\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2538: Avg loss so far = 1.039401\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2539: Avg loss so far = 1.038992\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2540: Avg loss so far = 1.038583\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2541: Avg loss so far = 1.038174\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2542: Avg loss so far = 1.037766\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2543: Avg loss so far = 1.037357\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2544: Avg loss so far = 1.036950\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2545: Avg loss so far = 1.036542\n",
      "     Misclassifications: 103\n",
      "\n",
      "k=2546: Avg loss so far = 1.036135\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2547: Avg loss so far = 1.045544\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2548: Avg loss so far = 1.045133\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2549: Avg loss so far = 1.044723\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2550: Avg loss so far = 1.044314\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2551: Avg loss so far = 1.043904\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2552: Avg loss so far = 1.043495\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2553: Avg loss so far = 1.043087\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2554: Avg loss so far = 1.042678\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2555: Avg loss so far = 1.042270\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2556: Avg loss so far = 1.041862\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2557: Avg loss so far = 1.041455\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2558: Avg loss so far = 1.041048\n",
      "     Misclassifications: 104\n",
      "\n",
      "k=2559: Avg loss so far = 1.040641\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2560: Avg loss so far = 1.079297\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2561: Avg loss so far = 1.078875\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2562: Avg loss so far = 1.078454\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2563: Avg loss so far = 1.078034\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2564: Avg loss so far = 1.077613\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2565: Avg loss so far = 1.077193\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2566: Avg loss so far = 1.076773\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2567: Avg loss so far = 1.076354\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2568: Avg loss so far = 1.075935\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2569: Avg loss so far = 1.075516\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2570: Avg loss so far = 1.075097\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2571: Avg loss so far = 1.074679\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2572: Avg loss so far = 1.074261\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2573: Avg loss so far = 1.073844\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2574: Avg loss so far = 1.073427\n",
      "     Misclassifications: 105\n",
      "\n",
      "k=2575: Avg loss so far = 1.073010\n",
      "     Misclassifications: 106\n",
      "\n",
      "k=2576: Avg loss so far = 1.078804\n",
      "     Misclassifications: 106\n",
      "\n",
      "k=2577: Avg loss so far = 1.078386\n",
      "     Misclassifications: 106\n",
      "\n",
      "k=2578: Avg loss so far = 1.077967\n",
      "     Misclassifications: 106\n",
      "\n",
      "k=2579: Avg loss so far = 1.077549\n",
      "     Misclassifications: 106\n",
      "\n",
      "k=2580: Avg loss so far = 1.077132\n",
      "     Misclassifications: 106\n",
      "\n",
      "k=2581: Avg loss so far = 1.076714\n",
      "     Misclassifications: 107\n",
      "\n",
      "k=2582: Avg loss so far = 1.082494\n",
      "     Misclassifications: 107\n",
      "\n",
      "k=2583: Avg loss so far = 1.082075\n",
      "     Misclassifications: 108\n",
      "\n",
      "k=2584: Avg loss so far = 1.106424\n",
      "     Misclassifications: 108\n",
      "\n",
      "k=2585: Avg loss so far = 1.105996\n",
      "     Misclassifications: 108\n",
      "\n",
      "k=2586: Avg loss so far = 1.105568\n",
      "     Misclassifications: 108\n",
      "\n",
      "k=2587: Avg loss so far = 1.105141\n",
      "     Misclassifications: 108\n",
      "\n",
      "k=2588: Avg loss so far = 1.104714\n",
      "     Misclassifications: 108\n",
      "\n",
      "k=2589: Avg loss so far = 1.104287\n",
      "     Misclassifications: 108\n",
      "\n",
      "k=2590: Avg loss so far = 1.103861\n",
      "     Misclassifications: 108\n",
      "\n",
      "k=2591: Avg loss so far = 1.103435\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2592: Avg loss so far = 1.109182\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2593: Avg loss so far = 1.108754\n",
      "     Misclassifications: 109\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2594: Avg loss so far = 1.108327\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2595: Avg loss so far = 1.107900\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2596: Avg loss so far = 1.107473\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2597: Avg loss so far = 1.107047\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2598: Avg loss so far = 1.106620\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2599: Avg loss so far = 1.106195\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2600: Avg loss so far = 1.105769\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2601: Avg loss so far = 1.105344\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2602: Avg loss so far = 1.104919\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2603: Avg loss so far = 1.104495\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2604: Avg loss so far = 1.104071\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2605: Avg loss so far = 1.103647\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2606: Avg loss so far = 1.103223\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2607: Avg loss so far = 1.102800\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2608: Avg loss so far = 1.102377\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2609: Avg loss so far = 1.101955\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2610: Avg loss so far = 1.101533\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2611: Avg loss so far = 1.101111\n",
      "     Misclassifications: 109\n",
      "\n",
      "k=2612: Avg loss so far = 1.100689\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2613: Avg loss so far = 1.101799\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2614: Avg loss so far = 1.101377\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2615: Avg loss so far = 1.100956\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2616: Avg loss so far = 1.100535\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2617: Avg loss so far = 1.100115\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2618: Avg loss so far = 1.099694\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2619: Avg loss so far = 1.099275\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2620: Avg loss so far = 1.098855\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2621: Avg loss so far = 1.098436\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2622: Avg loss so far = 1.098017\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2623: Avg loss so far = 1.097598\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2624: Avg loss so far = 1.097180\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2625: Avg loss so far = 1.096762\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2626: Avg loss so far = 1.096344\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2627: Avg loss so far = 1.095927\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2628: Avg loss so far = 1.095510\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2629: Avg loss so far = 1.095093\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2630: Avg loss so far = 1.094677\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2631: Avg loss so far = 1.094261\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2632: Avg loss so far = 1.093845\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2633: Avg loss so far = 1.093430\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2634: Avg loss so far = 1.093014\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2635: Avg loss so far = 1.092600\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2636: Avg loss so far = 1.092185\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2637: Avg loss so far = 1.091771\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2638: Avg loss so far = 1.091357\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2639: Avg loss so far = 1.090944\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2640: Avg loss so far = 1.090530\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2641: Avg loss so far = 1.090117\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2642: Avg loss so far = 1.089705\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2643: Avg loss so far = 1.089292\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2644: Avg loss so far = 1.088880\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2645: Avg loss so far = 1.088469\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2646: Avg loss so far = 1.088057\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2647: Avg loss so far = 1.087646\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2648: Avg loss so far = 1.087236\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2649: Avg loss so far = 1.086825\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2650: Avg loss so far = 1.086415\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2651: Avg loss so far = 1.086005\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2652: Avg loss so far = 1.085596\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2653: Avg loss so far = 1.085187\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2654: Avg loss so far = 1.084778\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2655: Avg loss so far = 1.084369\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2656: Avg loss so far = 1.083961\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2657: Avg loss so far = 1.083553\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2658: Avg loss so far = 1.083145\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2659: Avg loss so far = 1.082738\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2660: Avg loss so far = 1.082331\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2661: Avg loss so far = 1.081924\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2662: Avg loss so far = 1.081518\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2663: Avg loss so far = 1.081112\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2664: Avg loss so far = 1.080706\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2665: Avg loss so far = 1.080300\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2666: Avg loss so far = 1.079895\n",
      "     Misclassifications: 110\n",
      "\n",
      "k=2667: Avg loss so far = 1.079490\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2668: Avg loss so far = 1.080585\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2669: Avg loss so far = 1.080180\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2670: Avg loss so far = 1.079775\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2671: Avg loss so far = 1.079371\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2672: Avg loss so far = 1.078967\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2673: Avg loss so far = 1.078563\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2674: Avg loss so far = 1.078160\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2675: Avg loss so far = 1.077757\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2676: Avg loss so far = 1.077354\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2677: Avg loss so far = 1.076952\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2678: Avg loss so far = 1.076550\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2679: Avg loss so far = 1.076148\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2680: Avg loss so far = 1.075746\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2681: Avg loss so far = 1.075345\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2682: Avg loss so far = 1.074944\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2683: Avg loss so far = 1.074543\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2684: Avg loss so far = 1.074143\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2685: Avg loss so far = 1.073743\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2686: Avg loss so far = 1.073343\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2687: Avg loss so far = 1.072944\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2688: Avg loss so far = 1.072545\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2689: Avg loss so far = 1.072146\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2690: Avg loss so far = 1.071747\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2691: Avg loss so far = 1.071349\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2692: Avg loss so far = 1.070951\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2693: Avg loss so far = 1.070553\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2694: Avg loss so far = 1.070156\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2695: Avg loss so far = 1.069759\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2696: Avg loss so far = 1.069362\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2697: Avg loss so far = 1.068966\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2698: Avg loss so far = 1.068569\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2699: Avg loss so far = 1.068173\n",
      "     Misclassifications: 111\n",
      "\n",
      "k=2700: Avg loss so far = 1.067778\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2701: Avg loss so far = 1.068863\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2702: Avg loss so far = 1.068468\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2703: Avg loss so far = 1.068073\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2704: Avg loss so far = 1.067678\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2705: Avg loss so far = 1.067283\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2706: Avg loss so far = 1.066888\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2707: Avg loss so far = 1.066494\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2708: Avg loss so far = 1.066100\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2709: Avg loss so far = 1.065707\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2710: Avg loss so far = 1.065314\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2711: Avg loss so far = 1.064921\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2712: Avg loss so far = 1.064528\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2713: Avg loss so far = 1.064136\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2714: Avg loss so far = 1.063744\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2715: Avg loss so far = 1.063352\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2716: Avg loss so far = 1.062960\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2717: Avg loss so far = 1.062569\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2718: Avg loss so far = 1.062178\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2719: Avg loss so far = 1.061787\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2720: Avg loss so far = 1.061397\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2721: Avg loss so far = 1.061007\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2722: Avg loss so far = 1.060617\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2723: Avg loss so far = 1.060228\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2724: Avg loss so far = 1.059838\n",
      "     Misclassifications: 112\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2725: Avg loss so far = 1.059450\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2726: Avg loss so far = 1.059061\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2727: Avg loss so far = 1.058673\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2728: Avg loss so far = 1.058284\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2729: Avg loss so far = 1.057897\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2730: Avg loss so far = 1.057509\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2731: Avg loss so far = 1.057122\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2732: Avg loss so far = 1.056735\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2733: Avg loss so far = 1.056348\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2734: Avg loss so far = 1.055962\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2735: Avg loss so far = 1.055576\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2736: Avg loss so far = 1.055190\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2737: Avg loss so far = 1.054805\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2738: Avg loss so far = 1.054419\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2739: Avg loss so far = 1.054034\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2740: Avg loss so far = 1.053650\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2741: Avg loss so far = 1.053265\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2742: Avg loss so far = 1.052881\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2743: Avg loss so far = 1.052497\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2744: Avg loss so far = 1.052114\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2745: Avg loss so far = 1.051730\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2746: Avg loss so far = 1.051347\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2747: Avg loss so far = 1.050965\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2748: Avg loss so far = 1.050582\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2749: Avg loss so far = 1.050200\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2750: Avg loss so far = 1.049818\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2751: Avg loss so far = 1.049437\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2752: Avg loss so far = 1.049055\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2753: Avg loss so far = 1.048674\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2754: Avg loss so far = 1.048293\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2755: Avg loss so far = 1.047913\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2756: Avg loss so far = 1.047533\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2757: Avg loss so far = 1.047153\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2758: Avg loss so far = 1.046773\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2759: Avg loss so far = 1.046394\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2760: Avg loss so far = 1.046014\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2761: Avg loss so far = 1.045636\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2762: Avg loss so far = 1.045257\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2763: Avg loss so far = 1.044879\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2764: Avg loss so far = 1.044501\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2765: Avg loss so far = 1.044123\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2766: Avg loss so far = 1.043745\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2767: Avg loss so far = 1.043368\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2768: Avg loss so far = 1.042991\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2769: Avg loss so far = 1.042615\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2770: Avg loss so far = 1.042238\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2771: Avg loss so far = 1.041862\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2772: Avg loss so far = 1.041486\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2773: Avg loss so far = 1.041111\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2774: Avg loss so far = 1.040735\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2775: Avg loss so far = 1.040360\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2776: Avg loss so far = 1.039986\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2777: Avg loss so far = 1.039611\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2778: Avg loss so far = 1.039237\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2779: Avg loss so far = 1.038863\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2780: Avg loss so far = 1.038489\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2781: Avg loss so far = 1.038116\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2782: Avg loss so far = 1.037743\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2783: Avg loss so far = 1.037370\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2784: Avg loss so far = 1.036997\n",
      "     Misclassifications: 112\n",
      "\n",
      "k=2785: Avg loss so far = 1.036625\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2786: Avg loss so far = 1.041996\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2787: Avg loss so far = 1.041622\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2788: Avg loss so far = 1.041248\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2789: Avg loss so far = 1.040875\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2790: Avg loss so far = 1.040502\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2791: Avg loss so far = 1.040129\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2792: Avg loss so far = 1.039756\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2793: Avg loss so far = 1.039384\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2794: Avg loss so far = 1.039012\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2795: Avg loss so far = 1.038640\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2796: Avg loss so far = 1.038269\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2797: Avg loss so far = 1.037898\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2798: Avg loss so far = 1.037527\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2799: Avg loss so far = 1.037156\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2800: Avg loss so far = 1.036786\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2801: Avg loss so far = 1.036416\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2802: Avg loss so far = 1.036046\n",
      "     Misclassifications: 113\n",
      "\n",
      "k=2803: Avg loss so far = 1.035676\n",
      "     Misclassifications: 114\n",
      "\n",
      "k=2804: Avg loss so far = 1.035663\n",
      "     Misclassifications: 114\n",
      "\n",
      "k=2805: Avg loss so far = 1.035294\n",
      "     Misclassifications: 114\n",
      "\n",
      "k=2806: Avg loss so far = 1.034925\n",
      "     Misclassifications: 114\n",
      "\n",
      "k=2807: Avg loss so far = 1.034556\n",
      "     Misclassifications: 114\n",
      "\n",
      "k=2808: Avg loss so far = 1.034188\n",
      "     Misclassifications: 114\n",
      "\n",
      "k=2809: Avg loss so far = 1.033820\n",
      "     Misclassifications: 114\n",
      "\n",
      "k=2810: Avg loss so far = 1.033452\n",
      "     Misclassifications: 114\n",
      "\n",
      "k=2811: Avg loss so far = 1.033084\n",
      "     Misclassifications: 115\n",
      "\n",
      "k=2812: Avg loss so far = 1.034139\n",
      "     Misclassifications: 115\n",
      "\n",
      "k=2813: Avg loss so far = 1.033772\n",
      "     Misclassifications: 115\n",
      "\n",
      "k=2814: Avg loss so far = 1.033404\n",
      "     Misclassifications: 115\n",
      "\n",
      "k=2815: Avg loss so far = 1.033037\n",
      "     Misclassifications: 115\n",
      "\n",
      "k=2816: Avg loss so far = 1.032670\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2817: Avg loss so far = 1.033724\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2818: Avg loss so far = 1.033357\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2819: Avg loss so far = 1.032990\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2820: Avg loss so far = 1.032624\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2821: Avg loss so far = 1.032258\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2822: Avg loss so far = 1.031892\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2823: Avg loss so far = 1.031527\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2824: Avg loss so far = 1.031161\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2825: Avg loss so far = 1.030796\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2826: Avg loss so far = 1.030432\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2827: Avg loss so far = 1.030067\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2828: Avg loss so far = 1.029703\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2829: Avg loss so far = 1.029339\n",
      "     Misclassifications: 116\n",
      "\n",
      "k=2830: Avg loss so far = 1.028975\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2831: Avg loss so far = 1.028965\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2832: Avg loss so far = 1.028602\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2833: Avg loss so far = 1.028239\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2834: Avg loss so far = 1.027876\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2835: Avg loss so far = 1.027513\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2836: Avg loss so far = 1.027151\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2837: Avg loss so far = 1.026789\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2838: Avg loss so far = 1.026427\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2839: Avg loss so far = 1.026066\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2840: Avg loss so far = 1.025704\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2841: Avg loss so far = 1.025343\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2842: Avg loss so far = 1.024982\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2843: Avg loss so far = 1.024622\n",
      "     Misclassifications: 117\n",
      "\n",
      "k=2844: Avg loss so far = 1.024262\n",
      "     Misclassifications: 118\n",
      "\n",
      "k=2845: Avg loss so far = 1.024253\n",
      "     Misclassifications: 118\n",
      "\n",
      "k=2846: Avg loss so far = 1.023893\n",
      "     Misclassifications: 118\n",
      "\n",
      "k=2847: Avg loss so far = 1.023534\n",
      "     Misclassifications: 118\n",
      "\n",
      "k=2848: Avg loss so far = 1.023174\n",
      "     Misclassifications: 118\n",
      "\n",
      "k=2849: Avg loss so far = 1.022815\n",
      "     Misclassifications: 118\n",
      "\n",
      "k=2850: Avg loss so far = 1.022456\n",
      "     Misclassifications: 118\n",
      "\n",
      "k=2851: Avg loss so far = 1.022098\n",
      "     Misclassifications: 118\n",
      "\n",
      "k=2852: Avg loss so far = 1.021739\n",
      "     Misclassifications: 118\n",
      "\n",
      "k=2853: Avg loss so far = 1.021381\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2854: Avg loss so far = 1.021374\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2855: Avg loss so far = 1.021016\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2856: Avg loss so far = 1.020658\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2857: Avg loss so far = 1.020301\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2858: Avg loss so far = 1.019944\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2859: Avg loss so far = 1.019587\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2860: Avg loss so far = 1.019231\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2861: Avg loss so far = 1.018875\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2862: Avg loss so far = 1.018519\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2863: Avg loss so far = 1.018163\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2864: Avg loss so far = 1.017807\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2865: Avg loss so far = 1.017452\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2866: Avg loss so far = 1.017097\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2867: Avg loss so far = 1.016742\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2868: Avg loss so far = 1.016388\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2869: Avg loss so far = 1.016033\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2870: Avg loss so far = 1.015679\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2871: Avg loss so far = 1.015326\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2872: Avg loss so far = 1.014972\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2873: Avg loss so far = 1.014619\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2874: Avg loss so far = 1.014266\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2875: Avg loss so far = 1.013913\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2876: Avg loss so far = 1.013561\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2877: Avg loss so far = 1.013208\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2878: Avg loss so far = 1.012856\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2879: Avg loss so far = 1.012504\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2880: Avg loss so far = 1.012153\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2881: Avg loss so far = 1.011801\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2882: Avg loss so far = 1.011450\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2883: Avg loss so far = 1.011100\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2884: Avg loss so far = 1.010749\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2885: Avg loss so far = 1.010399\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2886: Avg loss so far = 1.010049\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2887: Avg loss so far = 1.009699\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2888: Avg loss so far = 1.009349\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2889: Avg loss so far = 1.009000\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2890: Avg loss so far = 1.008651\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2891: Avg loss so far = 1.008302\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2892: Avg loss so far = 1.007953\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2893: Avg loss so far = 1.007605\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2894: Avg loss so far = 1.007256\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2895: Avg loss so far = 1.006908\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2896: Avg loss so far = 1.006561\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2897: Avg loss so far = 1.006213\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2898: Avg loss so far = 1.005866\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2899: Avg loss so far = 1.005519\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2900: Avg loss so far = 1.005172\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2901: Avg loss so far = 1.004826\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2902: Avg loss so far = 1.004480\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2903: Avg loss so far = 1.004134\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2904: Avg loss so far = 1.003788\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2905: Avg loss so far = 1.003442\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2906: Avg loss so far = 1.003097\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2907: Avg loss so far = 1.002752\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2908: Avg loss so far = 1.002407\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2909: Avg loss so far = 1.002063\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2910: Avg loss so far = 1.001718\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2911: Avg loss so far = 1.001374\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2912: Avg loss so far = 1.001030\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2913: Avg loss so far = 1.000687\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2914: Avg loss so far = 1.000343\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2915: Avg loss so far = 1.000000\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2916: Avg loss so far = 0.999657\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2917: Avg loss so far = 0.999314\n",
      "     Misclassifications: 119\n",
      "\n",
      "k=2918: Avg loss so far = 0.998972\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2919: Avg loss so far = 1.020555\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2920: Avg loss so far = 1.020205\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2921: Avg loss so far = 1.019856\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2922: Avg loss so far = 1.019507\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2923: Avg loss so far = 1.019158\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2924: Avg loss so far = 1.018810\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2925: Avg loss so far = 1.018462\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2926: Avg loss so far = 1.018113\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2927: Avg loss so far = 1.017766\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2928: Avg loss so far = 1.017418\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2929: Avg loss so far = 1.017071\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2930: Avg loss so far = 1.016724\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2931: Avg loss so far = 1.016377\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2932: Avg loss so far = 1.016030\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2933: Avg loss so far = 1.015684\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2934: Avg loss so far = 1.015337\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2935: Avg loss so far = 1.014991\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2936: Avg loss so far = 1.014646\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2937: Avg loss so far = 1.014300\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2938: Avg loss so far = 1.013955\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2939: Avg loss so far = 1.013610\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2940: Avg loss so far = 1.013265\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2941: Avg loss so far = 1.012921\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2942: Avg loss so far = 1.012576\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2943: Avg loss so far = 1.012232\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2944: Avg loss so far = 1.011889\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2945: Avg loss so far = 1.011545\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2946: Avg loss so far = 1.011202\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2947: Avg loss so far = 1.010859\n",
      "     Misclassifications: 120\n",
      "\n",
      "k=2948: Avg loss so far = 1.010516\n",
      "     Misclassifications: 121\n",
      "\n",
      "k=2949: Avg loss so far = 1.031875\n",
      "     Misclassifications: 121\n",
      "\n",
      "k=2950: Avg loss so far = 1.031525\n",
      "     Misclassifications: 121\n",
      "\n",
      "k=2951: Avg loss so far = 1.031176\n",
      "     Misclassifications: 121\n",
      "\n",
      "k=2952: Avg loss so far = 1.030827\n",
      "     Misclassifications: 121\n",
      "\n",
      "k=2953: Avg loss so far = 1.030477\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2954: Avg loss so far = 1.030467\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2955: Avg loss so far = 1.030118\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2956: Avg loss so far = 1.029770\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2957: Avg loss so far = 1.029422\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2958: Avg loss so far = 1.029074\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2959: Avg loss so far = 1.028726\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2960: Avg loss so far = 1.028378\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2961: Avg loss so far = 1.028031\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2962: Avg loss so far = 1.027684\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2963: Avg loss so far = 1.027337\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2964: Avg loss so far = 1.026991\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2965: Avg loss so far = 1.026644\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2966: Avg loss so far = 1.026298\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2967: Avg loss so far = 1.025952\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2968: Avg loss so far = 1.025606\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2969: Avg loss so far = 1.025261\n",
      "     Misclassifications: 122\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2970: Avg loss so far = 1.024916\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2971: Avg loss so far = 1.024571\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2972: Avg loss so far = 1.024226\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2973: Avg loss so far = 1.023882\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2974: Avg loss so far = 1.023537\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2975: Avg loss so far = 1.023193\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2976: Avg loss so far = 1.022849\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2977: Avg loss so far = 1.022506\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2978: Avg loss so far = 1.022163\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2979: Avg loss so far = 1.021819\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2980: Avg loss so far = 1.021477\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2981: Avg loss so far = 1.021134\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2982: Avg loss so far = 1.020791\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2983: Avg loss so far = 1.020449\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2984: Avg loss so far = 1.020107\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2985: Avg loss so far = 1.019765\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2986: Avg loss so far = 1.019424\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2987: Avg loss so far = 1.019083\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2988: Avg loss so far = 1.018742\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2989: Avg loss so far = 1.018401\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2990: Avg loss so far = 1.018060\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2991: Avg loss so far = 1.017720\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2992: Avg loss so far = 1.017380\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2993: Avg loss so far = 1.017040\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2994: Avg loss so far = 1.016700\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2995: Avg loss so far = 1.016361\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2996: Avg loss so far = 1.016021\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2997: Avg loss so far = 1.015682\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2998: Avg loss so far = 1.015344\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=2999: Avg loss so far = 1.015005\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3000: Avg loss so far = 1.014667\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3001: Avg loss so far = 1.014329\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3002: Avg loss so far = 1.013991\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3003: Avg loss so far = 1.013653\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3004: Avg loss so far = 1.013316\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3005: Avg loss so far = 1.012978\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3006: Avg loss so far = 1.012641\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3007: Avg loss so far = 1.012305\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3008: Avg loss so far = 1.011968\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3009: Avg loss so far = 1.011632\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3010: Avg loss so far = 1.011296\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3011: Avg loss so far = 1.010960\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3012: Avg loss so far = 1.010624\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3013: Avg loss so far = 1.010289\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3014: Avg loss so far = 1.009954\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3015: Avg loss so far = 1.009619\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3016: Avg loss so far = 1.009284\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3017: Avg loss so far = 1.008949\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3018: Avg loss so far = 1.008615\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3019: Avg loss so far = 1.008281\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3020: Avg loss so far = 1.007947\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3021: Avg loss so far = 1.007613\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3022: Avg loss so far = 1.007280\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3023: Avg loss so far = 1.006947\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3024: Avg loss so far = 1.006614\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3025: Avg loss so far = 1.006281\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3026: Avg loss so far = 1.005948\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3027: Avg loss so far = 1.005616\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3028: Avg loss so far = 1.005284\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3029: Avg loss so far = 1.004952\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3030: Avg loss so far = 1.004620\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3031: Avg loss so far = 1.004289\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3032: Avg loss so far = 1.003958\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3033: Avg loss so far = 1.003627\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3034: Avg loss so far = 1.003296\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3035: Avg loss so far = 1.002965\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3036: Avg loss so far = 1.002635\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3037: Avg loss so far = 1.002305\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3038: Avg loss so far = 1.001975\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3039: Avg loss so far = 1.001645\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3040: Avg loss so far = 1.001316\n",
      "     Misclassifications: 122\n",
      "\n",
      "k=3041: Avg loss so far = 1.000987\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3042: Avg loss so far = 1.000986\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3043: Avg loss so far = 1.000657\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3044: Avg loss so far = 1.000329\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3045: Avg loss so far = 1.000000\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3046: Avg loss so far = 0.999672\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3047: Avg loss so far = 0.999344\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3048: Avg loss so far = 0.999016\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3049: Avg loss so far = 0.998688\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3050: Avg loss so far = 0.998361\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3051: Avg loss so far = 0.998033\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3052: Avg loss so far = 0.997706\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3053: Avg loss so far = 0.997380\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3054: Avg loss so far = 0.997053\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3055: Avg loss so far = 0.996727\n",
      "     Misclassifications: 123\n",
      "\n",
      "k=3056: Avg loss so far = 0.996401\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3057: Avg loss so far = 0.996402\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3058: Avg loss so far = 0.996076\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3059: Avg loss so far = 0.995750\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3060: Avg loss so far = 0.995425\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3061: Avg loss so far = 0.995100\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3062: Avg loss so far = 0.994775\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3063: Avg loss so far = 0.994450\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3064: Avg loss so far = 0.994125\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3065: Avg loss so far = 0.993801\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3066: Avg loss so far = 0.993477\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3067: Avg loss so far = 0.993153\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3068: Avg loss so far = 0.992829\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3069: Avg loss so far = 0.992506\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3070: Avg loss so far = 0.992182\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3071: Avg loss so far = 0.991859\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3072: Avg loss so far = 0.991536\n",
      "     Misclassifications: 124\n",
      "\n",
      "k=3073: Avg loss so far = 0.991214\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3074: Avg loss so far = 0.992193\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3075: Avg loss so far = 0.991870\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3076: Avg loss so far = 0.991547\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3077: Avg loss so far = 0.991225\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3078: Avg loss so far = 0.990903\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3079: Avg loss so far = 0.990581\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3080: Avg loss so far = 0.990260\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3081: Avg loss so far = 0.989938\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3082: Avg loss so far = 0.989617\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3083: Avg loss so far = 0.989296\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3084: Avg loss so far = 0.988975\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3085: Avg loss so far = 0.988655\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3086: Avg loss so far = 0.988334\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3087: Avg loss so far = 0.988014\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3088: Avg loss so far = 0.987694\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3089: Avg loss so far = 0.987375\n",
      "     Misclassifications: 125\n",
      "\n",
      "k=3090: Avg loss so far = 0.987055\n",
      "     Misclassifications: 126\n",
      "\n",
      "k=3091: Avg loss so far = 1.007441\n",
      "     Misclassifications: 126\n",
      "\n",
      "k=3092: Avg loss so far = 1.007115\n",
      "     Misclassifications: 126\n",
      "\n",
      "k=3093: Avg loss so far = 1.006790\n",
      "     Misclassifications: 126\n",
      "\n",
      "k=3094: Avg loss so far = 1.006464\n",
      "     Misclassifications: 126\n",
      "\n",
      "k=3095: Avg loss so far = 1.006139\n",
      "     Misclassifications: 126\n",
      "\n",
      "k=3096: Avg loss so far = 1.005814\n",
      "     Misclassifications: 126\n",
      "\n",
      "k=3097: Avg loss so far = 1.005489\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3098: Avg loss so far = 1.006456\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3099: Avg loss so far = 1.006131\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3100: Avg loss so far = 1.005806\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3101: Avg loss so far = 1.005482\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3102: Avg loss so far = 1.005158\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3103: Avg loss so far = 1.004834\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3104: Avg loss so far = 1.004510\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3105: Avg loss so far = 1.004187\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3106: Avg loss so far = 1.003863\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3107: Avg loss so far = 1.003540\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3108: Avg loss so far = 1.003218\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3109: Avg loss so far = 1.002895\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3110: Avg loss so far = 1.002572\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3111: Avg loss so far = 1.002250\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3112: Avg loss so far = 1.001928\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3113: Avg loss so far = 1.001606\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3114: Avg loss so far = 1.001285\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3115: Avg loss so far = 1.000963\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3116: Avg loss so far = 1.000642\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3117: Avg loss so far = 1.000321\n",
      "     Misclassifications: 127\n",
      "\n",
      "k=3118: Avg loss so far = 1.000000\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3119: Avg loss so far = 1.000000\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3120: Avg loss so far = 0.999679\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3121: Avg loss so far = 0.999359\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3122: Avg loss so far = 0.999039\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3123: Avg loss so far = 0.998719\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3124: Avg loss so far = 0.998399\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3125: Avg loss so far = 0.998080\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3126: Avg loss so far = 0.997761\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3127: Avg loss so far = 0.997442\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3128: Avg loss so far = 0.997123\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3129: Avg loss so far = 0.996804\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3130: Avg loss so far = 0.996486\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3131: Avg loss so far = 0.996167\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3132: Avg loss so far = 0.995849\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3133: Avg loss so far = 0.995531\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3134: Avg loss so far = 0.995214\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3135: Avg loss so far = 0.994896\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3136: Avg loss so far = 0.994579\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3137: Avg loss so far = 0.994262\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3138: Avg loss so far = 0.993945\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3139: Avg loss so far = 0.993629\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3140: Avg loss so far = 0.993312\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3141: Avg loss so far = 0.992996\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3142: Avg loss so far = 0.992680\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3143: Avg loss so far = 0.992364\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3144: Avg loss so far = 0.992048\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3145: Avg loss so far = 0.991733\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3146: Avg loss so far = 0.991418\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3147: Avg loss so far = 0.991103\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3148: Avg loss so far = 0.990788\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3149: Avg loss so far = 0.990473\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3150: Avg loss so far = 0.990159\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3151: Avg loss so far = 0.989844\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3152: Avg loss so far = 0.989530\n",
      "     Misclassifications: 128\n",
      "\n",
      "k=3153: Avg loss so far = 0.989217\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3154: Avg loss so far = 1.009195\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3155: Avg loss so far = 1.008875\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3156: Avg loss so far = 1.008555\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3157: Avg loss so far = 1.008236\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3158: Avg loss so far = 1.007916\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3159: Avg loss so far = 1.007597\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3160: Avg loss so far = 1.007278\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3161: Avg loss so far = 1.006960\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3162: Avg loss so far = 1.006641\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3163: Avg loss so far = 1.006323\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3164: Avg loss so far = 1.006005\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3165: Avg loss so far = 1.005687\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3166: Avg loss so far = 1.005370\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3167: Avg loss so far = 1.005052\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3168: Avg loss so far = 1.004735\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3169: Avg loss so far = 1.004418\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3170: Avg loss so far = 1.004101\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3171: Avg loss so far = 1.003784\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3172: Avg loss so far = 1.003468\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3173: Avg loss so far = 1.003152\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3174: Avg loss so far = 1.002836\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3175: Avg loss so far = 1.002520\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3176: Avg loss so far = 1.002204\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3177: Avg loss so far = 1.001889\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3178: Avg loss so far = 1.001573\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3179: Avg loss so far = 1.001258\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3180: Avg loss so far = 1.000943\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3181: Avg loss so far = 1.000629\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3182: Avg loss so far = 1.000314\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3183: Avg loss so far = 1.000000\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3184: Avg loss so far = 0.999686\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3185: Avg loss so far = 0.999372\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3186: Avg loss so far = 0.999058\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3187: Avg loss so far = 0.998745\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3188: Avg loss so far = 0.998432\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3189: Avg loss so far = 0.998119\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3190: Avg loss so far = 0.997806\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3191: Avg loss so far = 0.997493\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3192: Avg loss so far = 0.997180\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3193: Avg loss so far = 0.996868\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3194: Avg loss so far = 0.996556\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3195: Avg loss so far = 0.996244\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3196: Avg loss so far = 0.995932\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3197: Avg loss so far = 0.995621\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3198: Avg loss so far = 0.995310\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3199: Avg loss so far = 0.994998\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3200: Avg loss so far = 0.994687\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3201: Avg loss so far = 0.994377\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3202: Avg loss so far = 0.994066\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3203: Avg loss so far = 0.993756\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3204: Avg loss so far = 0.993446\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3205: Avg loss so far = 0.993136\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3206: Avg loss so far = 0.992826\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3207: Avg loss so far = 0.992516\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3208: Avg loss so far = 0.992207\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3209: Avg loss so far = 0.991898\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3210: Avg loss so far = 0.991589\n",
      "     Misclassifications: 129\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3211: Avg loss so far = 0.991280\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3212: Avg loss so far = 0.990971\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3213: Avg loss so far = 0.990663\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3214: Avg loss so far = 0.990355\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3215: Avg loss so far = 0.990047\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3216: Avg loss so far = 0.989739\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3217: Avg loss so far = 0.989431\n",
      "     Misclassifications: 129\n",
      "\n",
      "k=3218: Avg loss so far = 0.989124\n",
      "     Misclassifications: 130\n",
      "\n",
      "k=3219: Avg loss so far = 0.989127\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3220: Avg loss so far = 0.989130\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3221: Avg loss so far = 0.988823\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3222: Avg loss so far = 0.988516\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3223: Avg loss so far = 0.988210\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3224: Avg loss so far = 0.987903\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3225: Avg loss so far = 0.987597\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3226: Avg loss so far = 0.987291\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3227: Avg loss so far = 0.986985\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3228: Avg loss so far = 0.986679\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3229: Avg loss so far = 0.986373\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3230: Avg loss so far = 0.986068\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3231: Avg loss so far = 0.985763\n",
      "     Misclassifications: 131\n",
      "\n",
      "k=3232: Avg loss so far = 0.985458\n",
      "     Misclassifications: 132\n",
      "\n",
      "k=3233: Avg loss so far = 0.986390\n",
      "     Misclassifications: 132\n",
      "\n",
      "k=3234: Avg loss so far = 0.986085\n",
      "     Misclassifications: 132\n",
      "\n",
      "k=3235: Avg loss so far = 0.985781\n",
      "     Misclassifications: 132\n",
      "\n",
      "k=3236: Avg loss so far = 0.985476\n",
      "     Misclassifications: 132\n",
      "\n",
      "k=3237: Avg loss so far = 0.985171\n",
      "     Misclassifications: 132\n",
      "\n",
      "k=3238: Avg loss so far = 0.984867\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3239: Avg loss so far = 0.984872\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3240: Avg loss so far = 0.984568\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3241: Avg loss so far = 0.984264\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3242: Avg loss so far = 0.983961\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3243: Avg loss so far = 0.983657\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3244: Avg loss so far = 0.983354\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3245: Avg loss so far = 0.983051\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3246: Avg loss so far = 0.982748\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3247: Avg loss so far = 0.982445\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3248: Avg loss so far = 0.982143\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3249: Avg loss so far = 0.981841\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3250: Avg loss so far = 0.981538\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3251: Avg loss so far = 0.981237\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3252: Avg loss so far = 0.980935\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3253: Avg loss so far = 0.980633\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3254: Avg loss so far = 0.980332\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3255: Avg loss so far = 0.980031\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3256: Avg loss so far = 0.979730\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3257: Avg loss so far = 0.979429\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3258: Avg loss so far = 0.979128\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3259: Avg loss so far = 0.978828\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3260: Avg loss so far = 0.978528\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3261: Avg loss so far = 0.978228\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3262: Avg loss so far = 0.977928\n",
      "     Misclassifications: 133\n",
      "\n",
      "k=3263: Avg loss so far = 0.977628\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3264: Avg loss so far = 0.982230\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3265: Avg loss so far = 0.981930\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3266: Avg loss so far = 0.981629\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3267: Avg loss so far = 0.981328\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3268: Avg loss so far = 0.981028\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3269: Avg loss so far = 0.980728\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3270: Avg loss so far = 0.980428\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3271: Avg loss so far = 0.980128\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3272: Avg loss so far = 0.979829\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3273: Avg loss so far = 0.979529\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3274: Avg loss so far = 0.979230\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3275: Avg loss so far = 0.978931\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3276: Avg loss so far = 0.978632\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3277: Avg loss so far = 0.978334\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3278: Avg loss so far = 0.978035\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3279: Avg loss so far = 0.977737\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3280: Avg loss so far = 0.977439\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3281: Avg loss so far = 0.977141\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3282: Avg loss so far = 0.976843\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3283: Avg loss so far = 0.976546\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3284: Avg loss so far = 0.976248\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3285: Avg loss so far = 0.975951\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3286: Avg loss so far = 0.975654\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3287: Avg loss so far = 0.975357\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3288: Avg loss so far = 0.975061\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3289: Avg loss so far = 0.974764\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3290: Avg loss so far = 0.974468\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3291: Avg loss so far = 0.974172\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3292: Avg loss so far = 0.973876\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3293: Avg loss so far = 0.973580\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3294: Avg loss so far = 0.973285\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3295: Avg loss so far = 0.972989\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3296: Avg loss so far = 0.972694\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3297: Avg loss so far = 0.972399\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3298: Avg loss so far = 0.972104\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3299: Avg loss so far = 0.971810\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3300: Avg loss so far = 0.971515\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3301: Avg loss so far = 0.971221\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3302: Avg loss so far = 0.970927\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3303: Avg loss so far = 0.970633\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3304: Avg loss so far = 0.970339\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3305: Avg loss so far = 0.970045\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3306: Avg loss so far = 0.969752\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3307: Avg loss so far = 0.969459\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3308: Avg loss so far = 0.969166\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3309: Avg loss so far = 0.968873\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3310: Avg loss so far = 0.968580\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3311: Avg loss so far = 0.968288\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3312: Avg loss so far = 0.967995\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3313: Avg loss so far = 0.967703\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3314: Avg loss so far = 0.967411\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3315: Avg loss so far = 0.967119\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3316: Avg loss so far = 0.966828\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3317: Avg loss so far = 0.966536\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3318: Avg loss so far = 0.966245\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3319: Avg loss so far = 0.965954\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3320: Avg loss so far = 0.965663\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3321: Avg loss so far = 0.965372\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3322: Avg loss so far = 0.965081\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3323: Avg loss so far = 0.964791\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3324: Avg loss so far = 0.964501\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3325: Avg loss so far = 0.964211\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3326: Avg loss so far = 0.963921\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3327: Avg loss so far = 0.963631\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3328: Avg loss so far = 0.963341\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3329: Avg loss so far = 0.963052\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3330: Avg loss so far = 0.962763\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3331: Avg loss so far = 0.962474\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3332: Avg loss so far = 0.962185\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3333: Avg loss so far = 0.961896\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3334: Avg loss so far = 0.961608\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3335: Avg loss so far = 0.961319\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3336: Avg loss so far = 0.961031\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3337: Avg loss so far = 0.960743\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3338: Avg loss so far = 0.960455\n",
      "     Misclassifications: 134\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3339: Avg loss so far = 0.960168\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3340: Avg loss so far = 0.959880\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3341: Avg loss so far = 0.959593\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3342: Avg loss so far = 0.959306\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3343: Avg loss so far = 0.959019\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3344: Avg loss so far = 0.958732\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3345: Avg loss so far = 0.958445\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3346: Avg loss so far = 0.958159\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3347: Avg loss so far = 0.957873\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3348: Avg loss so far = 0.957587\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3349: Avg loss so far = 0.957301\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3350: Avg loss so far = 0.957015\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3351: Avg loss so far = 0.956729\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3352: Avg loss so far = 0.956444\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3353: Avg loss so far = 0.956159\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3354: Avg loss so far = 0.955874\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3355: Avg loss so far = 0.955589\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3356: Avg loss so far = 0.955304\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3357: Avg loss so far = 0.955019\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3358: Avg loss so far = 0.954735\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3359: Avg loss so far = 0.954451\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3360: Avg loss so far = 0.954167\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3361: Avg loss so far = 0.953883\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3362: Avg loss so far = 0.953599\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3363: Avg loss so far = 0.953315\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3364: Avg loss so far = 0.953032\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3365: Avg loss so far = 0.952749\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3366: Avg loss so far = 0.952466\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3367: Avg loss so far = 0.952183\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3368: Avg loss so far = 0.951900\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3369: Avg loss so far = 0.951618\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3370: Avg loss so far = 0.951335\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3371: Avg loss so far = 0.951053\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3372: Avg loss so far = 0.950771\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3373: Avg loss so far = 0.950489\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3374: Avg loss so far = 0.950207\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3375: Avg loss so far = 0.949926\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3376: Avg loss so far = 0.949645\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3377: Avg loss so far = 0.949363\n",
      "     Misclassifications: 134\n",
      "\n",
      "k=3378: Avg loss so far = 0.949082\n",
      "     Misclassifications: 135\n",
      "\n",
      "k=3379: Avg loss so far = 0.967742\n",
      "     Misclassifications: 135\n",
      "\n",
      "k=3380: Avg loss so far = 0.967456\n",
      "     Misclassifications: 135\n",
      "\n",
      "k=3381: Avg loss so far = 0.967169\n",
      "     Misclassifications: 135\n",
      "\n",
      "k=3382: Avg loss so far = 0.966884\n",
      "     Misclassifications: 135\n",
      "\n",
      "k=3383: Avg loss so far = 0.966598\n",
      "     Misclassifications: 135\n",
      "\n",
      "k=3384: Avg loss so far = 0.966312\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3385: Avg loss so far = 0.970753\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3386: Avg loss so far = 0.970467\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3387: Avg loss so far = 0.970180\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3388: Avg loss so far = 0.969894\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3389: Avg loss so far = 0.969608\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3390: Avg loss so far = 0.969322\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3391: Avg loss so far = 0.969036\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3392: Avg loss so far = 0.968750\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3393: Avg loss so far = 0.968464\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3394: Avg loss so far = 0.968179\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3395: Avg loss so far = 0.967894\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3396: Avg loss so far = 0.967609\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3397: Avg loss so far = 0.967324\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3398: Avg loss so far = 0.967039\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3399: Avg loss so far = 0.966755\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3400: Avg loss so far = 0.966471\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3401: Avg loss so far = 0.966186\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3402: Avg loss so far = 0.965902\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3403: Avg loss so far = 0.965619\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3404: Avg loss so far = 0.965335\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3405: Avg loss so far = 0.965051\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3406: Avg loss so far = 0.964768\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3407: Avg loss so far = 0.964485\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3408: Avg loss so far = 0.964202\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3409: Avg loss so far = 0.963919\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3410: Avg loss so far = 0.963636\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3411: Avg loss so far = 0.963354\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3412: Avg loss so far = 0.963072\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3413: Avg loss so far = 0.962789\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3414: Avg loss so far = 0.962507\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3415: Avg loss so far = 0.962225\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3416: Avg loss so far = 0.961944\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3417: Avg loss so far = 0.961662\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3418: Avg loss so far = 0.961381\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3419: Avg loss so far = 0.961100\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3420: Avg loss so far = 0.960819\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3421: Avg loss so far = 0.960538\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3422: Avg loss so far = 0.960257\n",
      "     Misclassifications: 136\n",
      "\n",
      "k=3423: Avg loss so far = 0.959977\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3424: Avg loss so far = 0.964369\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3425: Avg loss so far = 0.964088\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3426: Avg loss so far = 0.963806\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3427: Avg loss so far = 0.963525\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3428: Avg loss so far = 0.963244\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3429: Avg loss so far = 0.962963\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3430: Avg loss so far = 0.962682\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3431: Avg loss so far = 0.962402\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3432: Avg loss so far = 0.962121\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3433: Avg loss so far = 0.961841\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3434: Avg loss so far = 0.961561\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3435: Avg loss so far = 0.961281\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3436: Avg loss so far = 0.961001\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3437: Avg loss so far = 0.960722\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3438: Avg loss so far = 0.960442\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3439: Avg loss so far = 0.960163\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3440: Avg loss so far = 0.959884\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3441: Avg loss so far = 0.959605\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3442: Avg loss so far = 0.959326\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3443: Avg loss so far = 0.959047\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3444: Avg loss so far = 0.958769\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3445: Avg loss so far = 0.958491\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3446: Avg loss so far = 0.958212\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3447: Avg loss so far = 0.957934\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3448: Avg loss so far = 0.957657\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3449: Avg loss so far = 0.957379\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3450: Avg loss so far = 0.957101\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3451: Avg loss so far = 0.956824\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3452: Avg loss so far = 0.956547\n",
      "     Misclassifications: 137\n",
      "\n",
      "k=3453: Avg loss so far = 0.956270\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3454: Avg loss so far = 0.956283\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3455: Avg loss so far = 0.956006\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3456: Avg loss so far = 0.955729\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3457: Avg loss so far = 0.955453\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3458: Avg loss so far = 0.955176\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3459: Avg loss so far = 0.954900\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3460: Avg loss so far = 0.954624\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3461: Avg loss so far = 0.954348\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3462: Avg loss so far = 0.954073\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3463: Avg loss so far = 0.953797\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3464: Avg loss so far = 0.953522\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3465: Avg loss so far = 0.953247\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3466: Avg loss so far = 0.952972\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3467: Avg loss so far = 0.952697\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3468: Avg loss so far = 0.952422\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3469: Avg loss so far = 0.952148\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3470: Avg loss so far = 0.951873\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3471: Avg loss so far = 0.951599\n",
      "     Misclassifications: 138\n",
      "\n",
      "k=3472: Avg loss so far = 0.951325\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3473: Avg loss so far = 0.969479\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3474: Avg loss so far = 0.969200\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3475: Avg loss so far = 0.968921\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3476: Avg loss so far = 0.968642\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3477: Avg loss so far = 0.968364\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3478: Avg loss so far = 0.968085\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3479: Avg loss so far = 0.967807\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3480: Avg loss so far = 0.967529\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3481: Avg loss so far = 0.967251\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3482: Avg loss so far = 0.966973\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3483: Avg loss so far = 0.966695\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3484: Avg loss so far = 0.966418\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3485: Avg loss so far = 0.966141\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3486: Avg loss so far = 0.965863\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3487: Avg loss so far = 0.965586\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3488: Avg loss so far = 0.965310\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3489: Avg loss so far = 0.965033\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3490: Avg loss so far = 0.964756\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3491: Avg loss so far = 0.964480\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3492: Avg loss so far = 0.964204\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3493: Avg loss so far = 0.963928\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3494: Avg loss so far = 0.963652\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3495: Avg loss so far = 0.963376\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3496: Avg loss so far = 0.963101\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3497: Avg loss so far = 0.962825\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3498: Avg loss so far = 0.962550\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3499: Avg loss so far = 0.962275\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3500: Avg loss so far = 0.962000\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3501: Avg loss so far = 0.961725\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3502: Avg loss so far = 0.961451\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3503: Avg loss so far = 0.961176\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3504: Avg loss so far = 0.960902\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3505: Avg loss so far = 0.960628\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3506: Avg loss so far = 0.960354\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3507: Avg loss so far = 0.960080\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3508: Avg loss so far = 0.959806\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3509: Avg loss so far = 0.959533\n",
      "     Misclassifications: 139\n",
      "\n",
      "k=3510: Avg loss so far = 0.959259\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3511: Avg loss so far = 0.963543\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3512: Avg loss so far = 0.963269\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3513: Avg loss so far = 0.962995\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3514: Avg loss so far = 0.962721\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3515: Avg loss so far = 0.962447\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3516: Avg loss so far = 0.962173\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3517: Avg loss so far = 0.961899\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3518: Avg loss so far = 0.961626\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3519: Avg loss so far = 0.961353\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3520: Avg loss so far = 0.961080\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3521: Avg loss so far = 0.960807\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3522: Avg loss so far = 0.960534\n",
      "     Misclassifications: 140\n",
      "\n",
      "k=3523: Avg loss so far = 0.960261\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3524: Avg loss so far = 0.964529\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3525: Avg loss so far = 0.964255\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3526: Avg loss so far = 0.963982\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3527: Avg loss so far = 0.963709\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3528: Avg loss so far = 0.963435\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3529: Avg loss so far = 0.963162\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3530: Avg loss so far = 0.962890\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3531: Avg loss so far = 0.962617\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3532: Avg loss so far = 0.962344\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3533: Avg loss so far = 0.962072\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3534: Avg loss so far = 0.961800\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3535: Avg loss so far = 0.961528\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3536: Avg loss so far = 0.961256\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3537: Avg loss so far = 0.960984\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3538: Avg loss so far = 0.960712\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3539: Avg loss so far = 0.960441\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3540: Avg loss so far = 0.960169\n",
      "     Misclassifications: 141\n",
      "\n",
      "k=3541: Avg loss so far = 0.959898\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3542: Avg loss so far = 0.977696\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3543: Avg loss so far = 0.977420\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3544: Avg loss so far = 0.977144\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3545: Avg loss so far = 0.976869\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3546: Avg loss so far = 0.976593\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3547: Avg loss so far = 0.976318\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3548: Avg loss so far = 0.976043\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3549: Avg loss so far = 0.975768\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3550: Avg loss so far = 0.975493\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3551: Avg loss so far = 0.975218\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3552: Avg loss so far = 0.974944\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3553: Avg loss so far = 0.974669\n",
      "     Misclassifications: 142\n",
      "\n",
      "k=3554: Avg loss so far = 0.974395\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3555: Avg loss so far = 0.992124\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3556: Avg loss so far = 0.991845\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3557: Avg loss so far = 0.991566\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3558: Avg loss so far = 0.991287\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3559: Avg loss so far = 0.991009\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3560: Avg loss so far = 0.990730\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3561: Avg loss so far = 0.990452\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3562: Avg loss so far = 0.990174\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3563: Avg loss so far = 0.989896\n",
      "     Misclassifications: 143\n",
      "\n",
      "k=3564: Avg loss so far = 0.989618\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3565: Avg loss so far = 1.007293\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3566: Avg loss so far = 1.007011\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3567: Avg loss so far = 1.006728\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3568: Avg loss so far = 1.006446\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3569: Avg loss so far = 1.006164\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3570: Avg loss so far = 1.005882\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3571: Avg loss so far = 1.005601\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3572: Avg loss so far = 1.005319\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3573: Avg loss so far = 1.005038\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3574: Avg loss so far = 1.004757\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3575: Avg loss so far = 1.004476\n",
      "     Misclassifications: 144\n",
      "\n",
      "k=3576: Avg loss so far = 1.004195\n",
      "     Misclassifications: 145\n",
      "\n",
      "k=3577: Avg loss so far = 1.008387\n",
      "     Misclassifications: 145\n",
      "\n",
      "k=3578: Avg loss so far = 1.008105\n",
      "     Misclassifications: 145\n",
      "\n",
      "k=3579: Avg loss so far = 1.007823\n",
      "     Misclassifications: 145\n",
      "\n",
      "k=3580: Avg loss so far = 1.007542\n",
      "     Misclassifications: 145\n",
      "\n",
      "k=3581: Avg loss so far = 1.007261\n",
      "     Misclassifications: 146\n",
      "\n",
      "k=3582: Avg loss so far = 1.008096\n",
      "     Misclassifications: 147\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3583: Avg loss so far = 1.008094\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3584: Avg loss so far = 1.007812\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3585: Avg loss so far = 1.007531\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3586: Avg loss so far = 1.007250\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3587: Avg loss so far = 1.006970\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3588: Avg loss so far = 1.006689\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3589: Avg loss so far = 1.006408\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3590: Avg loss so far = 1.006128\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3591: Avg loss so far = 1.005848\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3592: Avg loss so far = 1.005568\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3593: Avg loss so far = 1.005288\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3594: Avg loss so far = 1.005008\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3595: Avg loss so far = 1.004729\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3596: Avg loss so far = 1.004449\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3597: Avg loss so far = 1.004170\n",
      "     Misclassifications: 147\n",
      "\n",
      "k=3598: Avg loss so far = 1.003891\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3599: Avg loss so far = 1.004724\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3600: Avg loss so far = 1.004444\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3601: Avg loss so far = 1.004166\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3602: Avg loss so far = 1.003887\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3603: Avg loss so far = 1.003608\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3604: Avg loss so far = 1.003330\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3605: Avg loss so far = 1.003051\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3606: Avg loss so far = 1.002773\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3607: Avg loss so far = 1.002495\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3608: Avg loss so far = 1.002217\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3609: Avg loss so far = 1.001940\n",
      "     Misclassifications: 148\n",
      "\n",
      "k=3610: Avg loss so far = 1.001662\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3611: Avg loss so far = 1.023816\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3612: Avg loss so far = 1.023533\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3613: Avg loss so far = 1.023249\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3614: Avg loss so far = 1.022966\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3615: Avg loss so far = 1.022683\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3616: Avg loss so far = 1.022400\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3617: Avg loss so far = 1.022118\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3618: Avg loss so far = 1.021835\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3619: Avg loss so far = 1.021553\n",
      "     Misclassifications: 149\n",
      "\n",
      "k=3620: Avg loss so far = 1.021271\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3621: Avg loss so far = 1.022093\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3622: Avg loss so far = 1.021811\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3623: Avg loss so far = 1.021529\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3624: Avg loss so far = 1.021247\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3625: Avg loss so far = 1.020966\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3626: Avg loss so far = 1.020684\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3627: Avg loss so far = 1.020403\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3628: Avg loss so far = 1.020121\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3629: Avg loss so far = 1.019840\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3630: Avg loss so far = 1.019559\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3631: Avg loss so far = 1.019278\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3632: Avg loss so far = 1.018998\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3633: Avg loss so far = 1.018717\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3634: Avg loss so far = 1.018437\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3635: Avg loss so far = 1.018157\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3636: Avg loss so far = 1.017877\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3637: Avg loss so far = 1.017597\n",
      "     Misclassifications: 150\n",
      "\n",
      "k=3638: Avg loss so far = 1.017317\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3639: Avg loss so far = 1.034625\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3640: Avg loss so far = 1.034341\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3641: Avg loss so far = 1.034057\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3642: Avg loss so far = 1.033773\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3643: Avg loss so far = 1.033489\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3644: Avg loss so far = 1.033205\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3645: Avg loss so far = 1.032922\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3646: Avg loss so far = 1.032639\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3647: Avg loss so far = 1.032355\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3648: Avg loss so far = 1.032072\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3649: Avg loss so far = 1.031790\n",
      "     Misclassifications: 151\n",
      "\n",
      "k=3650: Avg loss so far = 1.031507\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3651: Avg loss so far = 1.048754\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3652: Avg loss so far = 1.048467\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3653: Avg loss so far = 1.048180\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3654: Avg loss so far = 1.047893\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3655: Avg loss so far = 1.047606\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3656: Avg loss so far = 1.047319\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3657: Avg loss so far = 1.047033\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3658: Avg loss so far = 1.046747\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3659: Avg loss so far = 1.046461\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3660: Avg loss so far = 1.046175\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3661: Avg loss so far = 1.045889\n",
      "     Misclassifications: 152\n",
      "\n",
      "k=3662: Avg loss so far = 1.045603\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3663: Avg loss so far = 1.045591\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3664: Avg loss so far = 1.045306\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3665: Avg loss so far = 1.045020\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3666: Avg loss so far = 1.044735\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3667: Avg loss so far = 1.044451\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3668: Avg loss so far = 1.044166\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3669: Avg loss so far = 1.043881\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3670: Avg loss so far = 1.043597\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3671: Avg loss so far = 1.043312\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3672: Avg loss so far = 1.043028\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3673: Avg loss so far = 1.042744\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3674: Avg loss so far = 1.042461\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3675: Avg loss so far = 1.042177\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3676: Avg loss so far = 1.041893\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3677: Avg loss so far = 1.041610\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3678: Avg loss so far = 1.041327\n",
      "     Misclassifications: 153\n",
      "\n",
      "k=3679: Avg loss so far = 1.041044\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3680: Avg loss so far = 1.058152\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3681: Avg loss so far = 1.057865\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3682: Avg loss so far = 1.057577\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3683: Avg loss so far = 1.057290\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3684: Avg loss so far = 1.057003\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3685: Avg loss so far = 1.056716\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3686: Avg loss so far = 1.056430\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3687: Avg loss so far = 1.056143\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3688: Avg loss so far = 1.055857\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3689: Avg loss so far = 1.055571\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3690: Avg loss so far = 1.055285\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3691: Avg loss so far = 1.054999\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3692: Avg loss so far = 1.054713\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3693: Avg loss so far = 1.054427\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3694: Avg loss so far = 1.054142\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3695: Avg loss so far = 1.053857\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3696: Avg loss so far = 1.053571\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3697: Avg loss so far = 1.053286\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3698: Avg loss so far = 1.053002\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3699: Avg loss so far = 1.052717\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3700: Avg loss so far = 1.052432\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3701: Avg loss so far = 1.052148\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3702: Avg loss so far = 1.051864\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3703: Avg loss so far = 1.051580\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3704: Avg loss so far = 1.051296\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3705: Avg loss so far = 1.051012\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3706: Avg loss so far = 1.050729\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3707: Avg loss so far = 1.050445\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3708: Avg loss so far = 1.050162\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3709: Avg loss so far = 1.049879\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3710: Avg loss so far = 1.049596\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3711: Avg loss so far = 1.049313\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3712: Avg loss so far = 1.049030\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3713: Avg loss so far = 1.048748\n",
      "     Misclassifications: 154\n",
      "\n",
      "k=3714: Avg loss so far = 1.048465\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3715: Avg loss so far = 1.065410\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3716: Avg loss so far = 1.065124\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3717: Avg loss so far = 1.064837\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3718: Avg loss so far = 1.064551\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3719: Avg loss so far = 1.064265\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3720: Avg loss so far = 1.063978\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3721: Avg loss so far = 1.063693\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3722: Avg loss so far = 1.063407\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3723: Avg loss so far = 1.063121\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3724: Avg loss so far = 1.062836\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3725: Avg loss so far = 1.062550\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3726: Avg loss so far = 1.062265\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3727: Avg loss so far = 1.061980\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3728: Avg loss so far = 1.061695\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3729: Avg loss so far = 1.061411\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3730: Avg loss so far = 1.061126\n",
      "     Misclassifications: 155\n",
      "\n",
      "k=3731: Avg loss so far = 1.060842\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3732: Avg loss so far = 1.060825\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3733: Avg loss so far = 1.060541\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3734: Avg loss so far = 1.060257\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3735: Avg loss so far = 1.059973\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3736: Avg loss so far = 1.059690\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3737: Avg loss so far = 1.059406\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3738: Avg loss so far = 1.059123\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3739: Avg loss so far = 1.058839\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3740: Avg loss so far = 1.058556\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3741: Avg loss so far = 1.058273\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3742: Avg loss so far = 1.057990\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3743: Avg loss so far = 1.057708\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3744: Avg loss so far = 1.057425\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3745: Avg loss so far = 1.057143\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3746: Avg loss so far = 1.056861\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3747: Avg loss so far = 1.056579\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3748: Avg loss so far = 1.056297\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3749: Avg loss so far = 1.056015\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3750: Avg loss so far = 1.055733\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3751: Avg loss so far = 1.055452\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3752: Avg loss so far = 1.055171\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3753: Avg loss so far = 1.054889\n",
      "     Misclassifications: 156\n",
      "\n",
      "k=3754: Avg loss so far = 1.054608\n",
      "     Misclassifications: 157\n",
      "\n",
      "k=3755: Avg loss so far = 1.055393\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3756: Avg loss so far = 1.064696\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3757: Avg loss so far = 1.064413\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3758: Avg loss so far = 1.064130\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3759: Avg loss so far = 1.063847\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3760: Avg loss so far = 1.063564\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3761: Avg loss so far = 1.063281\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3762: Avg loss so far = 1.062998\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3763: Avg loss so far = 1.062716\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3764: Avg loss so far = 1.062434\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3765: Avg loss so far = 1.062151\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3766: Avg loss so far = 1.061869\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3767: Avg loss so far = 1.061587\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3768: Avg loss so far = 1.061306\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3769: Avg loss so far = 1.061024\n",
      "     Misclassifications: 158\n",
      "\n",
      "k=3770: Avg loss so far = 1.060743\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3771: Avg loss so far = 1.060727\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3772: Avg loss so far = 1.060445\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3773: Avg loss so far = 1.060164\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3774: Avg loss so far = 1.059883\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3775: Avg loss so far = 1.059603\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3776: Avg loss so far = 1.059322\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3777: Avg loss so far = 1.059042\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3778: Avg loss so far = 1.058761\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3779: Avg loss so far = 1.058481\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3780: Avg loss so far = 1.058201\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3781: Avg loss so far = 1.057921\n",
      "     Misclassifications: 159\n",
      "\n",
      "k=3782: Avg loss so far = 1.057641\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3783: Avg loss so far = 1.058419\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3784: Avg loss so far = 1.058140\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3785: Avg loss so far = 1.057860\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3786: Avg loss so far = 1.057581\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3787: Avg loss so far = 1.057301\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3788: Avg loss so far = 1.057022\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3789: Avg loss so far = 1.056743\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3790: Avg loss so far = 1.056464\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3791: Avg loss so far = 1.056186\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3792: Avg loss so far = 1.055907\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3793: Avg loss so far = 1.055629\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3794: Avg loss so far = 1.055351\n",
      "     Misclassifications: 160\n",
      "\n",
      "k=3795: Avg loss so far = 1.055072\n",
      "     Misclassifications: 161\n",
      "\n",
      "k=3796: Avg loss so far = 1.059009\n",
      "     Misclassifications: 161\n",
      "\n",
      "k=3797: Avg loss so far = 1.058731\n",
      "     Misclassifications: 161\n",
      "\n",
      "k=3798: Avg loss so far = 1.058452\n",
      "     Misclassifications: 161\n",
      "\n",
      "k=3799: Avg loss so far = 1.058173\n",
      "     Misclassifications: 161\n",
      "\n",
      "k=3800: Avg loss so far = 1.057895\n",
      "     Misclassifications: 162\n",
      "\n",
      "k=3801: Avg loss so far = 1.074454\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3802: Avg loss so far = 1.074435\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3803: Avg loss so far = 1.074152\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3804: Avg loss so far = 1.073870\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3805: Avg loss so far = 1.073587\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3806: Avg loss so far = 1.073305\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3807: Avg loss so far = 1.073023\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3808: Avg loss so far = 1.072742\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3809: Avg loss so far = 1.072460\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3810: Avg loss so far = 1.072178\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3811: Avg loss so far = 1.071897\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3812: Avg loss so far = 1.071616\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3813: Avg loss so far = 1.071335\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3814: Avg loss so far = 1.071054\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3815: Avg loss so far = 1.070773\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3816: Avg loss so far = 1.070493\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3817: Avg loss so far = 1.070212\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3818: Avg loss so far = 1.069932\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3819: Avg loss so far = 1.069652\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3820: Avg loss so far = 1.069372\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3821: Avg loss so far = 1.069092\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3822: Avg loss so far = 1.068812\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3823: Avg loss so far = 1.068533\n",
      "     Misclassifications: 163\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3824: Avg loss so far = 1.068253\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3825: Avg loss so far = 1.067974\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3826: Avg loss so far = 1.067695\n",
      "     Misclassifications: 163\n",
      "\n",
      "k=3827: Avg loss so far = 1.067416\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3828: Avg loss so far = 1.083856\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3829: Avg loss so far = 1.083573\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3830: Avg loss so far = 1.083290\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3831: Avg loss so far = 1.083007\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3832: Avg loss so far = 1.082724\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3833: Avg loss so far = 1.082442\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3834: Avg loss so far = 1.082160\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3835: Avg loss so far = 1.081877\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3836: Avg loss so far = 1.081595\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3837: Avg loss so far = 1.081314\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3838: Avg loss so far = 1.081032\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3839: Avg loss so far = 1.080750\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3840: Avg loss so far = 1.080469\n",
      "     Misclassifications: 164\n",
      "\n",
      "k=3841: Avg loss so far = 1.080187\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3842: Avg loss so far = 1.080947\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3843: Avg loss so far = 1.080666\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3844: Avg loss so far = 1.080385\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3845: Avg loss so far = 1.080104\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3846: Avg loss so far = 1.079823\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3847: Avg loss so far = 1.079543\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3848: Avg loss so far = 1.079262\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3849: Avg loss so far = 1.078982\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3850: Avg loss so far = 1.078701\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3851: Avg loss so far = 1.078421\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3852: Avg loss so far = 1.078141\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3853: Avg loss so far = 1.077861\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3854: Avg loss so far = 1.077582\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3855: Avg loss so far = 1.077302\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3856: Avg loss so far = 1.077023\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3857: Avg loss so far = 1.076744\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3858: Avg loss so far = 1.076464\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3859: Avg loss so far = 1.076186\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3860: Avg loss so far = 1.075907\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3861: Avg loss so far = 1.075628\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3862: Avg loss so far = 1.075350\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3863: Avg loss so far = 1.075071\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3864: Avg loss so far = 1.074793\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3865: Avg loss so far = 1.074515\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3866: Avg loss so far = 1.074237\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3867: Avg loss so far = 1.073959\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3868: Avg loss so far = 1.073681\n",
      "     Misclassifications: 165\n",
      "\n",
      "k=3869: Avg loss so far = 1.073404\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3870: Avg loss so far = 1.074160\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3871: Avg loss so far = 1.073883\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3872: Avg loss so far = 1.073605\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3873: Avg loss so far = 1.073328\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3874: Avg loss so far = 1.073051\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3875: Avg loss so far = 1.072774\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3876: Avg loss so far = 1.072497\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3877: Avg loss so far = 1.072221\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3878: Avg loss so far = 1.071944\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3879: Avg loss so far = 1.071668\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3880: Avg loss so far = 1.071392\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3881: Avg loss so far = 1.071116\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3882: Avg loss so far = 1.070840\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3883: Avg loss so far = 1.070564\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3884: Avg loss so far = 1.070288\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3885: Avg loss so far = 1.070013\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3886: Avg loss so far = 1.069738\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3887: Avg loss so far = 1.069462\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3888: Avg loss so far = 1.069187\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3889: Avg loss so far = 1.068912\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3890: Avg loss so far = 1.068638\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3891: Avg loss so far = 1.068363\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3892: Avg loss so far = 1.068088\n",
      "     Misclassifications: 166\n",
      "\n",
      "k=3893: Avg loss so far = 1.067814\n",
      "     Misclassifications: 167\n",
      "\n",
      "k=3894: Avg loss so far = 1.083975\n",
      "     Misclassifications: 167\n",
      "\n",
      "k=3895: Avg loss so far = 1.083697\n",
      "     Misclassifications: 167\n",
      "\n",
      "k=3896: Avg loss so far = 1.083419\n",
      "     Misclassifications: 167\n",
      "\n",
      "k=3897: Avg loss so far = 1.083141\n",
      "     Misclassifications: 167\n",
      "\n",
      "k=3898: Avg loss so far = 1.082863\n",
      "     Misclassifications: 167\n",
      "\n",
      "k=3899: Avg loss so far = 1.082585\n",
      "     Misclassifications: 167\n",
      "\n",
      "k=3900: Avg loss so far = 1.082308\n",
      "     Misclassifications: 167\n",
      "\n",
      "k=3901: Avg loss so far = 1.082030\n",
      "     Misclassifications: 168\n",
      "\n",
      "k=3902: Avg loss so far = 1.082009\n",
      "     Misclassifications: 168\n",
      "\n",
      "k=3903: Avg loss so far = 1.081732\n",
      "     Misclassifications: 168\n",
      "\n",
      "k=3904: Avg loss so far = 1.081455\n",
      "     Misclassifications: 168\n",
      "\n",
      "k=3905: Avg loss so far = 1.081178\n",
      "     Misclassifications: 168\n",
      "\n",
      "k=3906: Avg loss so far = 1.080901\n",
      "     Misclassifications: 168\n",
      "\n",
      "k=3907: Avg loss so far = 1.080625\n",
      "     Misclassifications: 168\n",
      "\n",
      "k=3908: Avg loss so far = 1.080348\n",
      "     Misclassifications: 168\n",
      "\n",
      "k=3909: Avg loss so far = 1.080072\n",
      "     Misclassifications: 168\n",
      "\n",
      "k=3910: Avg loss so far = 1.079795\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3911: Avg loss so far = 1.083610\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3912: Avg loss so far = 1.083333\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3913: Avg loss so far = 1.083056\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3914: Avg loss so far = 1.082780\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3915: Avg loss so far = 1.082503\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3916: Avg loss so far = 1.082227\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3917: Avg loss so far = 1.081950\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3918: Avg loss so far = 1.081674\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3919: Avg loss so far = 1.081398\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3920: Avg loss so far = 1.081122\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3921: Avg loss so far = 1.080847\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3922: Avg loss so far = 1.080571\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3923: Avg loss so far = 1.080296\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3924: Avg loss so far = 1.080020\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3925: Avg loss so far = 1.079745\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3926: Avg loss so far = 1.079470\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3927: Avg loss so far = 1.079195\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3928: Avg loss so far = 1.078921\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3929: Avg loss so far = 1.078646\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3930: Avg loss so far = 1.078372\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3931: Avg loss so far = 1.078097\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3932: Avg loss so far = 1.077823\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3933: Avg loss so far = 1.077549\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3934: Avg loss so far = 1.077275\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3935: Avg loss so far = 1.077001\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3936: Avg loss so far = 1.076728\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3937: Avg loss so far = 1.076454\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3938: Avg loss so far = 1.076181\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3939: Avg loss so far = 1.075908\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3940: Avg loss so far = 1.075635\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3941: Avg loss so far = 1.075362\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3942: Avg loss so far = 1.075089\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3943: Avg loss so far = 1.074816\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3944: Avg loss so far = 1.074544\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3945: Avg loss so far = 1.074271\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3946: Avg loss so far = 1.073999\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3947: Avg loss so far = 1.073727\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3948: Avg loss so far = 1.073455\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3949: Avg loss so far = 1.073183\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3950: Avg loss so far = 1.072911\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3951: Avg loss so far = 1.072640\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3952: Avg loss so far = 1.072368\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3953: Avg loss so far = 1.072097\n",
      "     Misclassifications: 169\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3954: Avg loss so far = 1.071826\n",
      "     Misclassifications: 169\n",
      "\n",
      "k=3955: Avg loss so far = 1.071555\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3956: Avg loss so far = 1.091759\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3957: Avg loss so far = 1.091483\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3958: Avg loss so far = 1.091208\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3959: Avg loss so far = 1.090932\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3960: Avg loss so far = 1.090657\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3961: Avg loss so far = 1.090381\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3962: Avg loss so far = 1.090106\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3963: Avg loss so far = 1.089831\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3964: Avg loss so far = 1.089556\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3965: Avg loss so far = 1.089281\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3966: Avg loss so far = 1.089007\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3967: Avg loss so far = 1.088732\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3968: Avg loss so far = 1.088458\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3969: Avg loss so far = 1.088183\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3970: Avg loss so far = 1.087909\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3971: Avg loss so far = 1.087635\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3972: Avg loss so far = 1.087362\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3973: Avg loss so far = 1.087088\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3974: Avg loss so far = 1.086814\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3975: Avg loss so far = 1.086541\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3976: Avg loss so far = 1.086268\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3977: Avg loss so far = 1.085994\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3978: Avg loss so far = 1.085721\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3979: Avg loss so far = 1.085449\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3980: Avg loss so far = 1.085176\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3981: Avg loss so far = 1.084903\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3982: Avg loss so far = 1.084631\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3983: Avg loss so far = 1.084359\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3984: Avg loss so far = 1.084086\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3985: Avg loss so far = 1.083814\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3986: Avg loss so far = 1.083542\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3987: Avg loss so far = 1.083271\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3988: Avg loss so far = 1.082999\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3989: Avg loss so far = 1.082728\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3990: Avg loss so far = 1.082456\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3991: Avg loss so far = 1.082185\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3992: Avg loss so far = 1.081914\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3993: Avg loss so far = 1.081643\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3994: Avg loss so far = 1.081372\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3995: Avg loss so far = 1.081101\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3996: Avg loss so far = 1.080831\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3997: Avg loss so far = 1.080560\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3998: Avg loss so far = 1.080290\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=3999: Avg loss so far = 1.080020\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4000: Avg loss so far = 1.079750\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4001: Avg loss so far = 1.079480\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4002: Avg loss so far = 1.079210\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4003: Avg loss so far = 1.078941\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4004: Avg loss so far = 1.078671\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4005: Avg loss so far = 1.078402\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4006: Avg loss so far = 1.078133\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4007: Avg loss so far = 1.077864\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4008: Avg loss so far = 1.077595\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4009: Avg loss so far = 1.077326\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4010: Avg loss so far = 1.077057\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4011: Avg loss so far = 1.076789\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4012: Avg loss so far = 1.076520\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4013: Avg loss so far = 1.076252\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4014: Avg loss so far = 1.075984\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4015: Avg loss so far = 1.075716\n",
      "     Misclassifications: 170\n",
      "\n",
      "k=4016: Avg loss so far = 1.075448\n",
      "     Misclassifications: 171\n",
      "\n",
      "k=4017: Avg loss so far = 1.091113\n",
      "     Misclassifications: 171\n",
      "\n",
      "k=4018: Avg loss so far = 1.090841\n",
      "     Misclassifications: 171\n",
      "\n",
      "k=4019: Avg loss so far = 1.090570\n",
      "     Misclassifications: 171\n",
      "\n",
      "k=4020: Avg loss so far = 1.090299\n",
      "     Misclassifications: 171\n",
      "\n",
      "k=4021: Avg loss so far = 1.090027\n",
      "     Misclassifications: 171\n",
      "\n",
      "k=4022: Avg loss so far = 1.089756\n",
      "     Misclassifications: 172\n",
      "\n",
      "k=4023: Avg loss so far = 1.089734\n",
      "     Misclassifications: 172\n",
      "\n",
      "k=4024: Avg loss so far = 1.089463\n",
      "     Misclassifications: 172\n",
      "\n",
      "k=4025: Avg loss so far = 1.089193\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4026: Avg loss so far = 1.092896\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4027: Avg loss so far = 1.092625\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4028: Avg loss so far = 1.092354\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4029: Avg loss so far = 1.092082\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4030: Avg loss so far = 1.091811\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4031: Avg loss so far = 1.091541\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4032: Avg loss so far = 1.091270\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4033: Avg loss so far = 1.090999\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4034: Avg loss so far = 1.090729\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4035: Avg loss so far = 1.090458\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4036: Avg loss so far = 1.090188\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4037: Avg loss so far = 1.089918\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4038: Avg loss so far = 1.089648\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4039: Avg loss so far = 1.089379\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4040: Avg loss so far = 1.089109\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4041: Avg loss so far = 1.088839\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4042: Avg loss so far = 1.088570\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4043: Avg loss so far = 1.088301\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4044: Avg loss so far = 1.088032\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4045: Avg loss so far = 1.087763\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4046: Avg loss so far = 1.087494\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4047: Avg loss so far = 1.087225\n",
      "     Misclassifications: 173\n",
      "\n",
      "k=4048: Avg loss so far = 1.086957\n",
      "     Misclassifications: 174\n",
      "\n",
      "k=4049: Avg loss so far = 1.090640\n",
      "     Misclassifications: 174\n",
      "\n",
      "k=4050: Avg loss so far = 1.090370\n",
      "     Misclassifications: 174\n",
      "\n",
      "k=4051: Avg loss so far = 1.090101\n",
      "     Misclassifications: 174\n",
      "\n",
      "k=4052: Avg loss so far = 1.089832\n",
      "     Misclassifications: 174\n",
      "\n",
      "k=4053: Avg loss so far = 1.089563\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4054: Avg loss so far = 1.093241\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4055: Avg loss so far = 1.092972\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4056: Avg loss so far = 1.092702\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4057: Avg loss so far = 1.092433\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4058: Avg loss so far = 1.092164\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4059: Avg loss so far = 1.091895\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4060: Avg loss so far = 1.091626\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4061: Avg loss so far = 1.091357\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4062: Avg loss so far = 1.091088\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4063: Avg loss so far = 1.090820\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4064: Avg loss so far = 1.090551\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4065: Avg loss so far = 1.090283\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4066: Avg loss so far = 1.090015\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4067: Avg loss so far = 1.089747\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4068: Avg loss so far = 1.089479\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4069: Avg loss so far = 1.089211\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4070: Avg loss so far = 1.088943\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4071: Avg loss so far = 1.088676\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4072: Avg loss so far = 1.088409\n",
      "     Misclassifications: 175\n",
      "\n",
      "k=4073: Avg loss so far = 1.088141\n",
      "     Misclassifications: 176\n",
      "\n",
      "k=4074: Avg loss so far = 1.103584\n",
      "     Misclassifications: 176\n",
      "\n",
      "k=4075: Avg loss so far = 1.103313\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4076: Avg loss so far = 1.106968\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4077: Avg loss so far = 1.106696\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4078: Avg loss so far = 1.106425\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4079: Avg loss so far = 1.106153\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4080: Avg loss so far = 1.105882\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4081: Avg loss so far = 1.105611\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4082: Avg loss so far = 1.105341\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4083: Avg loss so far = 1.105070\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4084: Avg loss so far = 1.104799\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4085: Avg loss so far = 1.104529\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4086: Avg loss so far = 1.104258\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4087: Avg loss so far = 1.103988\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4088: Avg loss so far = 1.103718\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4089: Avg loss so far = 1.103448\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4090: Avg loss so far = 1.103178\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4091: Avg loss so far = 1.102909\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4092: Avg loss so far = 1.102639\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4093: Avg loss so far = 1.102370\n",
      "     Misclassifications: 177\n",
      "\n",
      "k=4094: Avg loss so far = 1.102101\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4095: Avg loss so far = 1.126252\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4096: Avg loss so far = 1.125977\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4097: Avg loss so far = 1.125702\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4098: Avg loss so far = 1.125427\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4099: Avg loss so far = 1.125152\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4100: Avg loss so far = 1.124878\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4101: Avg loss so far = 1.124604\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4102: Avg loss so far = 1.124330\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4103: Avg loss so far = 1.124056\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4104: Avg loss so far = 1.123782\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4105: Avg loss so far = 1.123508\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4106: Avg loss so far = 1.123234\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4107: Avg loss so far = 1.122961\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4108: Avg loss so far = 1.122687\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4109: Avg loss so far = 1.122414\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4110: Avg loss so far = 1.122141\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4111: Avg loss so far = 1.121868\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4112: Avg loss so far = 1.121595\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4113: Avg loss so far = 1.121323\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4114: Avg loss so far = 1.121050\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4115: Avg loss so far = 1.120778\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4116: Avg loss so far = 1.120505\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4117: Avg loss so far = 1.120233\n",
      "     Misclassifications: 178\n",
      "\n",
      "k=4118: Avg loss so far = 1.119961\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4119: Avg loss so far = 1.120660\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4120: Avg loss so far = 1.120388\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4121: Avg loss so far = 1.120116\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4122: Avg loss so far = 1.119845\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4123: Avg loss so far = 1.119573\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4124: Avg loss so far = 1.119302\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4125: Avg loss so far = 1.119030\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4126: Avg loss so far = 1.118759\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4127: Avg loss so far = 1.118488\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4128: Avg loss so far = 1.118217\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4129: Avg loss so far = 1.117946\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4130: Avg loss so far = 1.117676\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4131: Avg loss so far = 1.117405\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4132: Avg loss so far = 1.117135\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4133: Avg loss so far = 1.116864\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4134: Avg loss so far = 1.116594\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4135: Avg loss so far = 1.116324\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4136: Avg loss so far = 1.116054\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4137: Avg loss so far = 1.115784\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4138: Avg loss so far = 1.115515\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4139: Avg loss so far = 1.115245\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4140: Avg loss so far = 1.114976\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4141: Avg loss so far = 1.114707\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4142: Avg loss so far = 1.114437\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4143: Avg loss so far = 1.114168\n",
      "     Misclassifications: 179\n",
      "\n",
      "k=4144: Avg loss so far = 1.113900\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4145: Avg loss so far = 1.117491\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4146: Avg loss so far = 1.117221\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4147: Avg loss so far = 1.116952\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4148: Avg loss so far = 1.116683\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4149: Avg loss so far = 1.116414\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4150: Avg loss so far = 1.116145\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4151: Avg loss so far = 1.115876\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4152: Avg loss so far = 1.115607\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4153: Avg loss so far = 1.115338\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4154: Avg loss so far = 1.115070\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4155: Avg loss so far = 1.114801\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4156: Avg loss so far = 1.114533\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4157: Avg loss so far = 1.114265\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4158: Avg loss so far = 1.113997\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4159: Avg loss so far = 1.113729\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4160: Avg loss so far = 1.113462\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4161: Avg loss so far = 1.113194\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4162: Avg loss so far = 1.112926\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4163: Avg loss so far = 1.112659\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4164: Avg loss so far = 1.112392\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4165: Avg loss so far = 1.112125\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4166: Avg loss so far = 1.111858\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4167: Avg loss so far = 1.111591\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4168: Avg loss so far = 1.111324\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4169: Avg loss so far = 1.111058\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4170: Avg loss so far = 1.110791\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4171: Avg loss so far = 1.110525\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4172: Avg loss so far = 1.110259\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4173: Avg loss so far = 1.109993\n",
      "     Misclassifications: 180\n",
      "\n",
      "k=4174: Avg loss so far = 1.109727\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4175: Avg loss so far = 1.124790\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4176: Avg loss so far = 1.124521\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4177: Avg loss so far = 1.124252\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4178: Avg loss so far = 1.123983\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4179: Avg loss so far = 1.123714\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4180: Avg loss so far = 1.123445\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4181: Avg loss so far = 1.123176\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4182: Avg loss so far = 1.122908\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4183: Avg loss so far = 1.122639\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4184: Avg loss so far = 1.122371\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4185: Avg loss so far = 1.122103\n",
      "     Misclassifications: 181\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=4186: Avg loss so far = 1.121835\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4187: Avg loss so far = 1.121567\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4188: Avg loss so far = 1.121299\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4189: Avg loss so far = 1.121031\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4190: Avg loss so far = 1.120764\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4191: Avg loss so far = 1.120496\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4192: Avg loss so far = 1.120229\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4193: Avg loss so far = 1.119962\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4194: Avg loss so far = 1.119695\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4195: Avg loss so far = 1.119428\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4196: Avg loss so far = 1.119161\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4197: Avg loss so far = 1.118894\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4198: Avg loss so far = 1.118628\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4199: Avg loss so far = 1.118362\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4200: Avg loss so far = 1.118095\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4201: Avg loss so far = 1.117829\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4202: Avg loss so far = 1.117563\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4203: Avg loss so far = 1.117297\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4204: Avg loss so far = 1.117031\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4205: Avg loss so far = 1.116766\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4206: Avg loss so far = 1.116500\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4207: Avg loss so far = 1.116235\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4208: Avg loss so far = 1.115970\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4209: Avg loss so far = 1.115704\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4210: Avg loss so far = 1.115439\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4211: Avg loss so far = 1.115175\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4212: Avg loss so far = 1.114910\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4213: Avg loss so far = 1.114645\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4214: Avg loss so far = 1.114381\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4215: Avg loss so far = 1.114116\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4216: Avg loss so far = 1.113852\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4217: Avg loss so far = 1.113588\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4218: Avg loss so far = 1.113324\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4219: Avg loss so far = 1.113060\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4220: Avg loss so far = 1.112796\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4221: Avg loss so far = 1.112533\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4222: Avg loss so far = 1.112269\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4223: Avg loss so far = 1.112006\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4224: Avg loss so far = 1.111742\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4225: Avg loss so far = 1.111479\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4226: Avg loss so far = 1.111216\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4227: Avg loss so far = 1.110953\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4228: Avg loss so far = 1.110691\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4229: Avg loss so far = 1.110428\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4230: Avg loss so far = 1.110165\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4231: Avg loss so far = 1.109903\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4232: Avg loss so far = 1.109641\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4233: Avg loss so far = 1.109379\n",
      "     Misclassifications: 181\n",
      "\n",
      "k=4234: Avg loss so far = 1.109117\n",
      "     Misclassifications: 182\n",
      "\n",
      "k=4235: Avg loss so far = 1.109091\n",
      "     Misclassifications: 182\n",
      "\n",
      "k=4236: Avg loss so far = 1.108829\n",
      "     Misclassifications: 182\n",
      "\n",
      "k=4237: Avg loss so far = 1.108567\n",
      "     Misclassifications: 182\n",
      "\n",
      "k=4238: Avg loss so far = 1.108306\n",
      "     Misclassifications: 182\n",
      "\n",
      "k=4239: Avg loss so far = 1.108044\n",
      "     Misclassifications: 182\n",
      "\n",
      "k=4240: Avg loss so far = 1.107783\n",
      "     Misclassifications: 182\n",
      "\n",
      "k=4241: Avg loss so far = 1.107522\n",
      "     Misclassifications: 182\n",
      "\n",
      "k=4242: Avg loss so far = 1.107261\n",
      "     Misclassifications: 182\n",
      "\n",
      "k=4243: Avg loss so far = 1.107000\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4244: Avg loss so far = 1.107681\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4245: Avg loss so far = 1.107420\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4246: Avg loss so far = 1.107160\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4247: Avg loss so far = 1.106899\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4248: Avg loss so far = 1.106638\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4249: Avg loss so far = 1.106378\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4250: Avg loss so far = 1.106118\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4251: Avg loss so far = 1.105857\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4252: Avg loss so far = 1.105597\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4253: Avg loss so far = 1.105337\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4254: Avg loss so far = 1.105078\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4255: Avg loss so far = 1.104818\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4256: Avg loss so far = 1.104558\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4257: Avg loss so far = 1.104299\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4258: Avg loss so far = 1.104039\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4259: Avg loss so far = 1.103780\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4260: Avg loss so far = 1.103521\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4261: Avg loss so far = 1.103262\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4262: Avg loss so far = 1.103003\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4263: Avg loss so far = 1.102745\n",
      "     Misclassifications: 183\n",
      "\n",
      "k=4264: Avg loss so far = 1.102486\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4265: Avg loss so far = 1.102462\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4266: Avg loss so far = 1.102203\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4267: Avg loss so far = 1.101945\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4268: Avg loss so far = 1.101687\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4269: Avg loss so far = 1.101429\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4270: Avg loss so far = 1.101171\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4271: Avg loss so far = 1.100913\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4272: Avg loss so far = 1.100655\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4273: Avg loss so far = 1.100398\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4274: Avg loss so far = 1.100140\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4275: Avg loss so far = 1.099883\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4276: Avg loss so far = 1.099626\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4277: Avg loss so far = 1.099369\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4278: Avg loss so far = 1.099112\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4279: Avg loss so far = 1.098855\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4280: Avg loss so far = 1.098598\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4281: Avg loss so far = 1.098342\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4282: Avg loss so far = 1.098085\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4283: Avg loss so far = 1.097829\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4284: Avg loss so far = 1.097572\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4285: Avg loss so far = 1.097316\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4286: Avg loss so far = 1.097060\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4287: Avg loss so far = 1.096804\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4288: Avg loss so far = 1.096549\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4289: Avg loss so far = 1.096293\n",
      "     Misclassifications: 184\n",
      "\n",
      "k=4290: Avg loss so far = 1.096037\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4291: Avg loss so far = 1.096015\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4292: Avg loss so far = 1.095760\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4293: Avg loss so far = 1.095504\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4294: Avg loss so far = 1.095249\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4295: Avg loss so far = 1.094994\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4296: Avg loss so far = 1.094739\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4297: Avg loss so far = 1.094485\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4298: Avg loss so far = 1.094230\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4299: Avg loss so far = 1.093975\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4300: Avg loss so far = 1.093721\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4301: Avg loss so far = 1.093467\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4302: Avg loss so far = 1.093212\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4303: Avg loss so far = 1.092958\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4304: Avg loss so far = 1.092704\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4305: Avg loss so far = 1.092451\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4306: Avg loss so far = 1.092197\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4307: Avg loss so far = 1.091943\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4308: Avg loss so far = 1.091690\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4309: Avg loss so far = 1.091437\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4310: Avg loss so far = 1.091183\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4311: Avg loss so far = 1.090930\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4312: Avg loss so far = 1.090677\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4313: Avg loss so far = 1.090424\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4314: Avg loss so far = 1.090172\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4315: Avg loss so far = 1.089919\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4316: Avg loss so far = 1.089666\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4317: Avg loss so far = 1.089414\n",
      "     Misclassifications: 185\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=4318: Avg loss so far = 1.089162\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4319: Avg loss so far = 1.088909\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4320: Avg loss so far = 1.088657\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4321: Avg loss so far = 1.088405\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4322: Avg loss so far = 1.088154\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4323: Avg loss so far = 1.087902\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4324: Avg loss so far = 1.087650\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4325: Avg loss so far = 1.087399\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4326: Avg loss so far = 1.087147\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4327: Avg loss so far = 1.086896\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4328: Avg loss so far = 1.086645\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4329: Avg loss so far = 1.086394\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4330: Avg loss so far = 1.086143\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4331: Avg loss so far = 1.085892\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4332: Avg loss so far = 1.085642\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4333: Avg loss so far = 1.085391\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4334: Avg loss so far = 1.085141\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4335: Avg loss so far = 1.084890\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4336: Avg loss so far = 1.084640\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4337: Avg loss so far = 1.084390\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4338: Avg loss so far = 1.084140\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4339: Avg loss so far = 1.083890\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4340: Avg loss so far = 1.083641\n",
      "     Misclassifications: 185\n",
      "\n",
      "k=4341: Avg loss so far = 1.083391\n",
      "     Misclassifications: 186\n",
      "\n",
      "k=4342: Avg loss so far = 1.097881\n",
      "     Misclassifications: 186\n",
      "\n",
      "k=4343: Avg loss so far = 1.097628\n",
      "     Misclassifications: 186\n",
      "\n",
      "k=4344: Avg loss so far = 1.097376\n",
      "     Misclassifications: 186\n",
      "\n",
      "k=4345: Avg loss so far = 1.097123\n",
      "     Misclassifications: 187\n",
      "\n",
      "k=4346: Avg loss so far = 1.111597\n",
      "     Misclassifications: 187\n",
      "\n",
      "k=4347: Avg loss so far = 1.111341\n",
      "     Misclassifications: 187\n",
      "\n",
      "k=4348: Avg loss so far = 1.111086\n",
      "     Misclassifications: 187\n",
      "\n",
      "k=4349: Avg loss so far = 1.110830\n",
      "     Misclassifications: 187\n",
      "\n",
      "k=4350: Avg loss so far = 1.110575\n",
      "     Misclassifications: 187\n",
      "\n",
      "k=4351: Avg loss so far = 1.110319\n",
      "     Misclassifications: 187\n",
      "\n",
      "k=4352: Avg loss so far = 1.110064\n",
      "     Misclassifications: 187\n",
      "\n",
      "k=4353: Avg loss so far = 1.109809\n",
      "     Misclassifications: 187\n",
      "\n",
      "k=4354: Avg loss so far = 1.109554\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4355: Avg loss so far = 1.123995\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4356: Avg loss so far = 1.123737\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4357: Avg loss so far = 1.123479\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4358: Avg loss so far = 1.123222\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4359: Avg loss so far = 1.122964\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4360: Avg loss so far = 1.122706\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4361: Avg loss so far = 1.122449\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4362: Avg loss so far = 1.122192\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4363: Avg loss so far = 1.121934\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4364: Avg loss so far = 1.121677\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4365: Avg loss so far = 1.121420\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4366: Avg loss so far = 1.121164\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4367: Avg loss so far = 1.120907\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4368: Avg loss so far = 1.120650\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4369: Avg loss so far = 1.120394\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4370: Avg loss so far = 1.120137\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4371: Avg loss so far = 1.119881\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4372: Avg loss so far = 1.119625\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4373: Avg loss so far = 1.119369\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4374: Avg loss so far = 1.119113\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4375: Avg loss so far = 1.118857\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4376: Avg loss so far = 1.118601\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4377: Avg loss so far = 1.118346\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4378: Avg loss so far = 1.118090\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4379: Avg loss so far = 1.117835\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4380: Avg loss so far = 1.117580\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4381: Avg loss so far = 1.117325\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4382: Avg loss so far = 1.117070\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4383: Avg loss so far = 1.116815\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4384: Avg loss so far = 1.116560\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4385: Avg loss so far = 1.116306\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4386: Avg loss so far = 1.116051\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4387: Avg loss so far = 1.115797\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4388: Avg loss so far = 1.115542\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4389: Avg loss so far = 1.115288\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4390: Avg loss so far = 1.115034\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4391: Avg loss so far = 1.114780\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4392: Avg loss so far = 1.114526\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4393: Avg loss so far = 1.114273\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4394: Avg loss so far = 1.114019\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4395: Avg loss so far = 1.113766\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4396: Avg loss so far = 1.113512\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4397: Avg loss so far = 1.113259\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4398: Avg loss so far = 1.113006\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4399: Avg loss so far = 1.112753\n",
      "     Misclassifications: 188\n",
      "\n",
      "k=4400: Avg loss so far = 1.112500\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4401: Avg loss so far = 1.126789\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4402: Avg loss so far = 1.126533\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4403: Avg loss so far = 1.126278\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4404: Avg loss so far = 1.126022\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4405: Avg loss so far = 1.125766\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4406: Avg loss so far = 1.125511\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4407: Avg loss so far = 1.125255\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4408: Avg loss so far = 1.125000\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4409: Avg loss so far = 1.124745\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4410: Avg loss so far = 1.124490\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4411: Avg loss so far = 1.124235\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4412: Avg loss so far = 1.123980\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4413: Avg loss so far = 1.123725\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4414: Avg loss so far = 1.123471\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4415: Avg loss so far = 1.123216\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4416: Avg loss so far = 1.122962\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4417: Avg loss so far = 1.122708\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4418: Avg loss so far = 1.122454\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4419: Avg loss so far = 1.122200\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4420: Avg loss so far = 1.121946\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4421: Avg loss so far = 1.121692\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4422: Avg loss so far = 1.121438\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4423: Avg loss so far = 1.121185\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4424: Avg loss so far = 1.120931\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4425: Avg loss so far = 1.120678\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4426: Avg loss so far = 1.120425\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4427: Avg loss so far = 1.120172\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4428: Avg loss so far = 1.119919\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4429: Avg loss so far = 1.119666\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4430: Avg loss so far = 1.119413\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4431: Avg loss so far = 1.119160\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4432: Avg loss so far = 1.118908\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4433: Avg loss so far = 1.118656\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4434: Avg loss so far = 1.118403\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4435: Avg loss so far = 1.118151\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4436: Avg loss so far = 1.117899\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4437: Avg loss so far = 1.117647\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4438: Avg loss so far = 1.117395\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4439: Avg loss so far = 1.117144\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4440: Avg loss so far = 1.116892\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4441: Avg loss so far = 1.116640\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4442: Avg loss so far = 1.116389\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4443: Avg loss so far = 1.116138\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4444: Avg loss so far = 1.115887\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4445: Avg loss so far = 1.115636\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4446: Avg loss so far = 1.115385\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4447: Avg loss so far = 1.115134\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4448: Avg loss so far = 1.114883\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4449: Avg loss so far = 1.114633\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4450: Avg loss so far = 1.114382\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4451: Avg loss so far = 1.114132\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4452: Avg loss so far = 1.113881\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4453: Avg loss so far = 1.113631\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4454: Avg loss so far = 1.113381\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4455: Avg loss so far = 1.113131\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4456: Avg loss so far = 1.112882\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4457: Avg loss so far = 1.112632\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4458: Avg loss so far = 1.112382\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4459: Avg loss so far = 1.112133\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4460: Avg loss so far = 1.111883\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4461: Avg loss so far = 1.111634\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4462: Avg loss so far = 1.111385\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4463: Avg loss so far = 1.111136\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4464: Avg loss so far = 1.110887\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4465: Avg loss so far = 1.110638\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4466: Avg loss so far = 1.110390\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4467: Avg loss so far = 1.110141\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4468: Avg loss so far = 1.109893\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4469: Avg loss so far = 1.109644\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4470: Avg loss so far = 1.109396\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4471: Avg loss so far = 1.109148\n",
      "     Misclassifications: 189\n",
      "\n",
      "k=4472: Avg loss so far = 1.108900\n",
      "     Misclassifications: 190\n",
      "\n",
      "k=4473: Avg loss so far = 1.122960\n",
      "     Misclassifications: 190\n",
      "\n",
      "k=4474: Avg loss so far = 1.122709\n",
      "     Misclassifications: 190\n",
      "\n",
      "k=4475: Avg loss so far = 1.122458\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4476: Avg loss so far = 1.144549\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4477: Avg loss so far = 1.144293\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4478: Avg loss so far = 1.144038\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4479: Avg loss so far = 1.143782\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4480: Avg loss so far = 1.143527\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4481: Avg loss so far = 1.143272\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4482: Avg loss so far = 1.143017\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4483: Avg loss so far = 1.142762\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4484: Avg loss so far = 1.142507\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4485: Avg loss so far = 1.142252\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4486: Avg loss so far = 1.141997\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4487: Avg loss so far = 1.141743\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4488: Avg loss so far = 1.141488\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4489: Avg loss so far = 1.141234\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4490: Avg loss so far = 1.140980\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4491: Avg loss so far = 1.140726\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4492: Avg loss so far = 1.140472\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4493: Avg loss so far = 1.140218\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4494: Avg loss so far = 1.139964\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4495: Avg loss so far = 1.139711\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4496: Avg loss so far = 1.139457\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4497: Avg loss so far = 1.139204\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4498: Avg loss so far = 1.138951\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4499: Avg loss so far = 1.138697\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4500: Avg loss so far = 1.138444\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4501: Avg loss so far = 1.138192\n",
      "     Misclassifications: 191\n",
      "\n",
      "k=4502: Avg loss so far = 1.137939\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4503: Avg loss so far = 1.137908\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4504: Avg loss so far = 1.137655\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4505: Avg loss so far = 1.137403\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4506: Avg loss so far = 1.137150\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4507: Avg loss so far = 1.136898\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4508: Avg loss so far = 1.136646\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4509: Avg loss so far = 1.136394\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4510: Avg loss so far = 1.136142\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4511: Avg loss so far = 1.135890\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4512: Avg loss so far = 1.135638\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4513: Avg loss so far = 1.135387\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4514: Avg loss so far = 1.135135\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4515: Avg loss so far = 1.134884\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4516: Avg loss so far = 1.134632\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4517: Avg loss so far = 1.134381\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4518: Avg loss so far = 1.134130\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4519: Avg loss so far = 1.133879\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4520: Avg loss so far = 1.133628\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4521: Avg loss so far = 1.133378\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4522: Avg loss so far = 1.133127\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4523: Avg loss so far = 1.132876\n",
      "     Misclassifications: 192\n",
      "\n",
      "k=4524: Avg loss so far = 1.132626\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4525: Avg loss so far = 1.135912\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4526: Avg loss so far = 1.135661\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4527: Avg loss so far = 1.135410\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4528: Avg loss so far = 1.135159\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4529: Avg loss so far = 1.134908\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4530: Avg loss so far = 1.134658\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4531: Avg loss so far = 1.134407\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4532: Avg loss so far = 1.134157\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4533: Avg loss so far = 1.133907\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4534: Avg loss so far = 1.133657\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4535: Avg loss so far = 1.133407\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4536: Avg loss so far = 1.133157\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4537: Avg loss so far = 1.132907\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4538: Avg loss so far = 1.132658\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4539: Avg loss so far = 1.132408\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4540: Avg loss so far = 1.132159\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4541: Avg loss so far = 1.131909\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4542: Avg loss so far = 1.131660\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4543: Avg loss so far = 1.131411\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4544: Avg loss so far = 1.131162\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4545: Avg loss so far = 1.130913\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4546: Avg loss so far = 1.130664\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4547: Avg loss so far = 1.130416\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4548: Avg loss so far = 1.130167\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4549: Avg loss so far = 1.129919\n",
      "     Misclassifications: 193\n",
      "\n",
      "k=4550: Avg loss so far = 1.129670\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4551: Avg loss so far = 1.130301\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4552: Avg loss so far = 1.130053\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4553: Avg loss so far = 1.129805\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4554: Avg loss so far = 1.129556\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4555: Avg loss so far = 1.129308\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4556: Avg loss so far = 1.129061\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4557: Avg loss so far = 1.128813\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4558: Avg loss so far = 1.128565\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4559: Avg loss so far = 1.128318\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4560: Avg loss so far = 1.128070\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4561: Avg loss so far = 1.127823\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4562: Avg loss so far = 1.127576\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4563: Avg loss so far = 1.127329\n",
      "     Misclassifications: 194\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=4564: Avg loss so far = 1.127082\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4565: Avg loss so far = 1.126835\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4566: Avg loss so far = 1.126588\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4567: Avg loss so far = 1.126341\n",
      "     Misclassifications: 194\n",
      "\n",
      "k=4568: Avg loss so far = 1.126095\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4569: Avg loss so far = 1.126724\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4570: Avg loss so far = 1.126477\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4571: Avg loss so far = 1.126231\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4572: Avg loss so far = 1.125984\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4573: Avg loss so far = 1.125738\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4574: Avg loss so far = 1.125492\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4575: Avg loss so far = 1.125246\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4576: Avg loss so far = 1.125000\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4577: Avg loss so far = 1.124754\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4578: Avg loss so far = 1.124509\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4579: Avg loss so far = 1.124263\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4580: Avg loss so far = 1.124017\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4581: Avg loss so far = 1.123772\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4582: Avg loss so far = 1.123527\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4583: Avg loss so far = 1.123282\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4584: Avg loss so far = 1.123037\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4585: Avg loss so far = 1.122792\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4586: Avg loss so far = 1.122547\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4587: Avg loss so far = 1.122302\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4588: Avg loss so far = 1.122058\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4589: Avg loss so far = 1.121813\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4590: Avg loss so far = 1.121569\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4591: Avg loss so far = 1.121324\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4592: Avg loss so far = 1.121080\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4593: Avg loss so far = 1.120836\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4594: Avg loss so far = 1.120592\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4595: Avg loss so far = 1.120348\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4596: Avg loss so far = 1.120104\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4597: Avg loss so far = 1.119861\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4598: Avg loss so far = 1.119617\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4599: Avg loss so far = 1.119374\n",
      "     Misclassifications: 195\n",
      "\n",
      "k=4600: Avg loss so far = 1.119130\n",
      "     Misclassifications: 196\n",
      "\n",
      "k=4601: Avg loss so far = 1.132797\n",
      "     Misclassifications: 196\n",
      "\n",
      "k=4602: Avg loss so far = 1.132551\n",
      "     Misclassifications: 196\n",
      "\n",
      "k=4603: Avg loss so far = 1.132305\n",
      "     Misclassifications: 196\n",
      "\n",
      "k=4604: Avg loss so far = 1.132059\n",
      "     Misclassifications: 196\n",
      "\n",
      "k=4605: Avg loss so far = 1.131813\n",
      "     Misclassifications: 196\n",
      "\n",
      "k=4606: Avg loss so far = 1.131568\n",
      "     Misclassifications: 196\n",
      "\n",
      "k=4607: Avg loss so far = 1.131322\n",
      "     Misclassifications: 196\n",
      "\n",
      "k=4608: Avg loss so far = 1.131076\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4609: Avg loss so far = 1.131048\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4610: Avg loss so far = 1.130803\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4611: Avg loss so far = 1.130557\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4612: Avg loss so far = 1.130312\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4613: Avg loss so far = 1.130067\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4614: Avg loss so far = 1.129822\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4615: Avg loss so far = 1.129577\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4616: Avg loss so far = 1.129333\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4617: Avg loss so far = 1.129088\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4618: Avg loss so far = 1.128844\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4619: Avg loss so far = 1.128599\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4620: Avg loss so far = 1.128355\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4621: Avg loss so far = 1.128111\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4622: Avg loss so far = 1.127867\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4623: Avg loss so far = 1.127623\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4624: Avg loss so far = 1.127379\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4625: Avg loss so far = 1.127135\n",
      "     Misclassifications: 197\n",
      "\n",
      "k=4626: Avg loss so far = 1.126891\n",
      "     Misclassifications: 198\n",
      "\n",
      "k=4627: Avg loss so far = 1.140480\n",
      "     Misclassifications: 198\n",
      "\n",
      "k=4628: Avg loss so far = 1.140233\n",
      "     Misclassifications: 198\n",
      "\n",
      "k=4629: Avg loss so far = 1.139987\n",
      "     Misclassifications: 198\n",
      "\n",
      "k=4630: Avg loss so far = 1.139741\n",
      "     Misclassifications: 198\n",
      "\n",
      "k=4631: Avg loss so far = 1.139495\n",
      "     Misclassifications: 198\n",
      "\n",
      "k=4632: Avg loss so far = 1.139249\n",
      "     Misclassifications: 199\n",
      "\n",
      "k=4633: Avg loss so far = 1.152817\n",
      "     Misclassifications: 199\n",
      "\n",
      "k=4634: Avg loss so far = 1.152568\n",
      "     Misclassifications: 199\n",
      "\n",
      "k=4635: Avg loss so far = 1.152319\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4636: Avg loss so far = 1.152286\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4637: Avg loss so far = 1.152038\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4638: Avg loss so far = 1.151790\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4639: Avg loss so far = 1.151541\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4640: Avg loss so far = 1.151293\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4641: Avg loss so far = 1.151045\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4642: Avg loss so far = 1.150797\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4643: Avg loss so far = 1.150549\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4644: Avg loss so far = 1.150301\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4645: Avg loss so far = 1.150054\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4646: Avg loss so far = 1.149806\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4647: Avg loss so far = 1.149559\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4648: Avg loss so far = 1.149312\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4649: Avg loss so far = 1.149064\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4650: Avg loss so far = 1.148817\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4651: Avg loss so far = 1.148570\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4652: Avg loss so far = 1.148323\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4653: Avg loss so far = 1.148077\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4654: Avg loss so far = 1.147830\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4655: Avg loss so far = 1.147583\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4656: Avg loss so far = 1.147337\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4657: Avg loss so far = 1.147090\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4658: Avg loss so far = 1.146844\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4659: Avg loss so far = 1.146598\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4660: Avg loss so far = 1.146352\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4661: Avg loss so far = 1.146106\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4662: Avg loss so far = 1.145860\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4663: Avg loss so far = 1.145614\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4664: Avg loss so far = 1.145369\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4665: Avg loss so far = 1.145123\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4666: Avg loss so far = 1.144878\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4667: Avg loss so far = 1.144633\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4668: Avg loss so far = 1.144387\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4669: Avg loss so far = 1.144142\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4670: Avg loss so far = 1.143897\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4671: Avg loss so far = 1.143652\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4672: Avg loss so far = 1.143408\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4673: Avg loss so far = 1.143163\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4674: Avg loss so far = 1.142918\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4675: Avg loss so far = 1.142674\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4676: Avg loss so far = 1.142429\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4677: Avg loss so far = 1.142185\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4678: Avg loss so far = 1.141941\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4679: Avg loss so far = 1.141697\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4680: Avg loss so far = 1.141453\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4681: Avg loss so far = 1.141209\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4682: Avg loss so far = 1.140965\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4683: Avg loss so far = 1.140722\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4684: Avg loss so far = 1.140478\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4685: Avg loss so far = 1.140235\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4686: Avg loss so far = 1.139991\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4687: Avg loss so far = 1.139748\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4688: Avg loss so far = 1.139505\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4689: Avg loss so far = 1.139262\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4690: Avg loss so far = 1.139019\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4691: Avg loss so far = 1.138776\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4692: Avg loss so far = 1.138534\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4693: Avg loss so far = 1.138291\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4694: Avg loss so far = 1.138049\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4695: Avg loss so far = 1.137806\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4696: Avg loss so far = 1.137564\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4697: Avg loss so far = 1.137322\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4698: Avg loss so far = 1.137080\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4699: Avg loss so far = 1.136838\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4700: Avg loss so far = 1.136596\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4701: Avg loss so far = 1.136354\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4702: Avg loss so far = 1.136112\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4703: Avg loss so far = 1.135871\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4704: Avg loss so far = 1.135629\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4705: Avg loss so far = 1.135388\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4706: Avg loss so far = 1.135147\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4707: Avg loss so far = 1.134905\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4708: Avg loss so far = 1.134664\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4709: Avg loss so far = 1.134423\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4710: Avg loss so far = 1.134183\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4711: Avg loss so far = 1.133942\n",
      "     Misclassifications: 200\n",
      "\n",
      "k=4712: Avg loss so far = 1.133701\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4713: Avg loss so far = 1.133673\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4714: Avg loss so far = 1.133432\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4715: Avg loss so far = 1.133192\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4716: Avg loss so far = 1.132952\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4717: Avg loss so far = 1.132711\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4718: Avg loss so far = 1.132471\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4719: Avg loss so far = 1.132231\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4720: Avg loss so far = 1.131992\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4721: Avg loss so far = 1.131752\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4722: Avg loss so far = 1.131512\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4723: Avg loss so far = 1.131272\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4724: Avg loss so far = 1.131033\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4725: Avg loss so far = 1.130794\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4726: Avg loss so far = 1.130554\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4727: Avg loss so far = 1.130315\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4728: Avg loss so far = 1.130076\n",
      "     Misclassifications: 201\n",
      "\n",
      "k=4729: Avg loss so far = 1.129837\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4730: Avg loss so far = 1.132981\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4731: Avg loss so far = 1.132741\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4732: Avg loss so far = 1.132502\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4733: Avg loss so far = 1.132263\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4734: Avg loss so far = 1.132024\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4735: Avg loss so far = 1.131785\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4736: Avg loss so far = 1.131546\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4737: Avg loss so far = 1.131307\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4738: Avg loss so far = 1.131068\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4739: Avg loss so far = 1.130829\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4740: Avg loss so far = 1.130591\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4741: Avg loss so far = 1.130352\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4742: Avg loss so far = 1.130114\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4743: Avg loss so far = 1.129876\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4744: Avg loss so far = 1.129637\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4745: Avg loss so far = 1.129399\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4746: Avg loss so far = 1.129161\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4747: Avg loss so far = 1.128924\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4748: Avg loss so far = 1.128686\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4749: Avg loss so far = 1.128448\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4750: Avg loss so far = 1.128211\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4751: Avg loss so far = 1.127973\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4752: Avg loss so far = 1.127736\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4753: Avg loss so far = 1.127498\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4754: Avg loss so far = 1.127261\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4755: Avg loss so far = 1.127024\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4756: Avg loss so far = 1.126787\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4757: Avg loss so far = 1.126550\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4758: Avg loss so far = 1.126314\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4759: Avg loss so far = 1.126077\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4760: Avg loss so far = 1.125840\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4761: Avg loss so far = 1.125604\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4762: Avg loss so far = 1.125367\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4763: Avg loss so far = 1.125131\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4764: Avg loss so far = 1.124895\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4765: Avg loss so far = 1.124659\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4766: Avg loss so far = 1.124423\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4767: Avg loss so far = 1.124187\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4768: Avg loss so far = 1.123951\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4769: Avg loss so far = 1.123716\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4770: Avg loss so far = 1.123480\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4771: Avg loss so far = 1.123245\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4772: Avg loss so far = 1.123009\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4773: Avg loss so far = 1.122774\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4774: Avg loss so far = 1.122539\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4775: Avg loss so far = 1.122304\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4776: Avg loss so far = 1.122069\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4777: Avg loss so far = 1.121834\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4778: Avg loss so far = 1.121599\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4779: Avg loss so far = 1.121364\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4780: Avg loss so far = 1.121130\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4781: Avg loss so far = 1.120895\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4782: Avg loss so far = 1.120661\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4783: Avg loss so far = 1.120427\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4784: Avg loss so far = 1.120192\n",
      "     Misclassifications: 202\n",
      "\n",
      "k=4785: Avg loss so far = 1.119958\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4786: Avg loss so far = 1.119933\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4787: Avg loss so far = 1.119699\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4788: Avg loss so far = 1.119465\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4789: Avg loss so far = 1.119232\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4790: Avg loss so far = 1.118998\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4791: Avg loss so far = 1.118764\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4792: Avg loss so far = 1.118531\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4793: Avg loss so far = 1.118298\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4794: Avg loss so far = 1.118064\n",
      "     Misclassifications: 203\n",
      "\n",
      "k=4795: Avg loss so far = 1.117831\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4796: Avg loss so far = 1.117807\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4797: Avg loss so far = 1.117573\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4798: Avg loss so far = 1.117341\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4799: Avg loss so far = 1.117108\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4800: Avg loss so far = 1.116875\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4801: Avg loss so far = 1.116642\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4802: Avg loss so far = 1.116410\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4803: Avg loss so far = 1.116177\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4804: Avg loss so far = 1.115945\n",
      "     Misclassifications: 204\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=4805: Avg loss so far = 1.115713\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4806: Avg loss so far = 1.115481\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4807: Avg loss so far = 1.115249\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4808: Avg loss so far = 1.115017\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4809: Avg loss so far = 1.114785\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4810: Avg loss so far = 1.114553\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4811: Avg loss so far = 1.114321\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4812: Avg loss so far = 1.114090\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4813: Avg loss so far = 1.113858\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4814: Avg loss so far = 1.113627\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4815: Avg loss so far = 1.113396\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4816: Avg loss so far = 1.113164\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4817: Avg loss so far = 1.112933\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4818: Avg loss so far = 1.112702\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4819: Avg loss so far = 1.112471\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4820: Avg loss so far = 1.112241\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4821: Avg loss so far = 1.112010\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4822: Avg loss so far = 1.111779\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4823: Avg loss so far = 1.111549\n",
      "     Misclassifications: 204\n",
      "\n",
      "k=4824: Avg loss so far = 1.111318\n",
      "     Misclassifications: 205\n",
      "\n",
      "k=4825: Avg loss so far = 1.124352\n",
      "     Misclassifications: 205\n",
      "\n",
      "k=4826: Avg loss so far = 1.124119\n",
      "     Misclassifications: 205\n",
      "\n",
      "k=4827: Avg loss so far = 1.123886\n",
      "     Misclassifications: 205\n",
      "\n",
      "k=4828: Avg loss so far = 1.123654\n",
      "     Misclassifications: 205\n",
      "\n",
      "k=4829: Avg loss so far = 1.123421\n",
      "     Misclassifications: 205\n",
      "\n",
      "k=4830: Avg loss so far = 1.123188\n",
      "     Misclassifications: 205\n",
      "\n",
      "k=4831: Avg loss so far = 1.122956\n",
      "     Misclassifications: 205\n",
      "\n",
      "k=4832: Avg loss so far = 1.122724\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4833: Avg loss so far = 1.125802\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4834: Avg loss so far = 1.125569\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4835: Avg loss so far = 1.125336\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4836: Avg loss so far = 1.125103\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4837: Avg loss so far = 1.124871\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4838: Avg loss so far = 1.124638\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4839: Avg loss so far = 1.124406\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4840: Avg loss so far = 1.124174\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4841: Avg loss so far = 1.123941\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4842: Avg loss so far = 1.123709\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4843: Avg loss so far = 1.123477\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4844: Avg loss so far = 1.123245\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4845: Avg loss so far = 1.123013\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4846: Avg loss so far = 1.122782\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4847: Avg loss so far = 1.122550\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4848: Avg loss so far = 1.122318\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4849: Avg loss so far = 1.122087\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4850: Avg loss so far = 1.121856\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4851: Avg loss so far = 1.121624\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4852: Avg loss so far = 1.121393\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4853: Avg loss so far = 1.121162\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4854: Avg loss so far = 1.120931\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4855: Avg loss so far = 1.120700\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4856: Avg loss so far = 1.120470\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4857: Avg loss so far = 1.120239\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4858: Avg loss so far = 1.120008\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4859: Avg loss so far = 1.119778\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4860: Avg loss so far = 1.119547\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4861: Avg loss so far = 1.119317\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4862: Avg loss so far = 1.119087\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4863: Avg loss so far = 1.118857\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4864: Avg loss so far = 1.118627\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4865: Avg loss so far = 1.118397\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4866: Avg loss so far = 1.118167\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4867: Avg loss so far = 1.117937\n",
      "     Misclassifications: 206\n",
      "\n",
      "k=4868: Avg loss so far = 1.117707\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4869: Avg loss so far = 1.130622\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4870: Avg loss so far = 1.130390\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4871: Avg loss so far = 1.130158\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4872: Avg loss so far = 1.129926\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4873: Avg loss so far = 1.129694\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4874: Avg loss so far = 1.129462\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4875: Avg loss so far = 1.129231\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4876: Avg loss so far = 1.128999\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4877: Avg loss so far = 1.128768\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4878: Avg loss so far = 1.128536\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4879: Avg loss so far = 1.128305\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4880: Avg loss so far = 1.128074\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4881: Avg loss so far = 1.127843\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4882: Avg loss so far = 1.127612\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4883: Avg loss so far = 1.127381\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4884: Avg loss so far = 1.127150\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4885: Avg loss so far = 1.126919\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4886: Avg loss so far = 1.126688\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4887: Avg loss so far = 1.126458\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4888: Avg loss so far = 1.126227\n",
      "     Misclassifications: 207\n",
      "\n",
      "k=4889: Avg loss so far = 1.125997\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4890: Avg loss so far = 1.146217\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4891: Avg loss so far = 1.145982\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4892: Avg loss so far = 1.145748\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4893: Avg loss so far = 1.145514\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4894: Avg loss so far = 1.145280\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4895: Avg loss so far = 1.145046\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4896: Avg loss so far = 1.144812\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4897: Avg loss so far = 1.144578\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4898: Avg loss so far = 1.144345\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4899: Avg loss so far = 1.144111\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4900: Avg loss so far = 1.143878\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4901: Avg loss so far = 1.143644\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4902: Avg loss so far = 1.143411\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4903: Avg loss so far = 1.143178\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4904: Avg loss so far = 1.142945\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4905: Avg loss so far = 1.142712\n",
      "     Misclassifications: 208\n",
      "\n",
      "k=4906: Avg loss so far = 1.142479\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4907: Avg loss so far = 1.155288\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4908: Avg loss so far = 1.155053\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4909: Avg loss so far = 1.154818\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4910: Avg loss so far = 1.154582\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4911: Avg loss so far = 1.154347\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4912: Avg loss so far = 1.154112\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4913: Avg loss so far = 1.153877\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4914: Avg loss so far = 1.153643\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4915: Avg loss so far = 1.153408\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4916: Avg loss so far = 1.153173\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4917: Avg loss so far = 1.152939\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4918: Avg loss so far = 1.152704\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4919: Avg loss so far = 1.152470\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4920: Avg loss so far = 1.152236\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4921: Avg loss so far = 1.152002\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4922: Avg loss so far = 1.151768\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4923: Avg loss so far = 1.151534\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4924: Avg loss so far = 1.151300\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4925: Avg loss so far = 1.151066\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4926: Avg loss so far = 1.150832\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4927: Avg loss so far = 1.150599\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4928: Avg loss so far = 1.150365\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4929: Avg loss so far = 1.150132\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4930: Avg loss so far = 1.149899\n",
      "     Misclassifications: 209\n",
      "\n",
      "k=4931: Avg loss so far = 1.149665\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4932: Avg loss so far = 1.162409\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4933: Avg loss so far = 1.162173\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4934: Avg loss so far = 1.161938\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4935: Avg loss so far = 1.161702\n",
      "     Misclassifications: 210\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=4936: Avg loss so far = 1.161467\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4937: Avg loss so far = 1.161232\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4938: Avg loss so far = 1.160996\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4939: Avg loss so far = 1.160761\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4940: Avg loss so far = 1.160526\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4941: Avg loss so far = 1.160291\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4942: Avg loss so far = 1.160057\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4943: Avg loss so far = 1.159822\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4944: Avg loss so far = 1.159587\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4945: Avg loss so far = 1.159353\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4946: Avg loss so far = 1.159118\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4947: Avg loss so far = 1.158884\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4948: Avg loss so far = 1.158650\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4949: Avg loss so far = 1.158416\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4950: Avg loss so far = 1.158182\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4951: Avg loss so far = 1.157948\n",
      "     Misclassifications: 210\n",
      "\n",
      "k=4952: Avg loss so far = 1.157714\n",
      "     Misclassifications: 211\n",
      "\n",
      "k=4953: Avg loss so far = 1.160711\n",
      "     Misclassifications: 211\n",
      "\n",
      "k=4954: Avg loss so far = 1.160476\n",
      "     Misclassifications: 211\n",
      "\n",
      "k=4955: Avg loss so far = 1.160242\n",
      "     Misclassifications: 211\n",
      "\n",
      "k=4956: Avg loss so far = 1.160008\n",
      "     Misclassifications: 211\n",
      "\n",
      "k=4957: Avg loss so far = 1.159774\n",
      "     Misclassifications: 211\n",
      "\n",
      "k=4958: Avg loss so far = 1.159540\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4959: Avg loss so far = 1.172212\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4960: Avg loss so far = 1.171976\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4961: Avg loss so far = 1.171740\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4962: Avg loss so far = 1.171503\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4963: Avg loss so far = 1.171267\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4964: Avg loss so far = 1.171031\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4965: Avg loss so far = 1.170796\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4966: Avg loss so far = 1.170560\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4967: Avg loss so far = 1.170324\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4968: Avg loss so far = 1.170089\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4969: Avg loss so far = 1.169853\n",
      "     Misclassifications: 212\n",
      "\n",
      "k=4970: Avg loss so far = 1.169618\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4971: Avg loss so far = 1.170187\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4972: Avg loss so far = 1.169952\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4973: Avg loss so far = 1.169716\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4974: Avg loss so far = 1.169481\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4975: Avg loss so far = 1.169246\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4976: Avg loss so far = 1.169011\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4977: Avg loss so far = 1.168776\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4978: Avg loss so far = 1.168542\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4979: Avg loss so far = 1.168307\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4980: Avg loss so far = 1.168072\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4981: Avg loss so far = 1.167838\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4982: Avg loss so far = 1.167603\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4983: Avg loss so far = 1.167369\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4984: Avg loss so far = 1.167135\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4985: Avg loss so far = 1.166901\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4986: Avg loss so far = 1.166667\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4987: Avg loss so far = 1.166433\n",
      "     Misclassifications: 213\n",
      "\n",
      "k=4988: Avg loss so far = 1.166199\n",
      "     Misclassifications: 214\n",
      "\n",
      "k=4989: Avg loss so far = 1.169172\n",
      "     Misclassifications: 214\n",
      "\n",
      "k=4990: Avg loss so far = 1.168938\n",
      "     Misclassifications: 214\n",
      "\n",
      "k=4991: Avg loss so far = 1.168704\n",
      "     Misclassifications: 214\n",
      "\n",
      "k=4992: Avg loss so far = 1.168470\n",
      "     Misclassifications: 214\n",
      "\n",
      "k=4993: Avg loss so far = 1.168236\n",
      "     Misclassifications: 214\n",
      "\n",
      "k=4994: Avg loss so far = 1.168002\n",
      "     Misclassifications: 214\n",
      "\n",
      "k=4995: Avg loss so far = 1.167768\n",
      "     Misclassifications: 214\n",
      "\n",
      "k=4996: Avg loss so far = 1.167534\n",
      "     Misclassifications: 214\n",
      "\n",
      "k=4997: Avg loss so far = 1.167300\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=4998: Avg loss so far = 1.172069\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=4999: Avg loss so far = 1.171834\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5000: Avg loss so far = 1.171600\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5001: Avg loss so far = 1.171366\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5002: Avg loss so far = 1.171132\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5003: Avg loss so far = 1.170897\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5004: Avg loss so far = 1.170663\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5005: Avg loss so far = 1.170430\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5006: Avg loss so far = 1.170196\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5007: Avg loss so far = 1.169962\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5008: Avg loss so far = 1.169728\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5009: Avg loss so far = 1.169495\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5010: Avg loss so far = 1.169261\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5011: Avg loss so far = 1.169028\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5012: Avg loss so far = 1.168795\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5013: Avg loss so far = 1.168562\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5014: Avg loss so far = 1.168329\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5015: Avg loss so far = 1.168096\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5016: Avg loss so far = 1.167863\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5017: Avg loss so far = 1.167630\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5018: Avg loss so far = 1.167397\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5019: Avg loss so far = 1.167165\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5020: Avg loss so far = 1.166932\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5021: Avg loss so far = 1.166700\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5022: Avg loss so far = 1.166468\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5023: Avg loss so far = 1.166235\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5024: Avg loss so far = 1.166003\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5025: Avg loss so far = 1.165771\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5026: Avg loss so far = 1.165539\n",
      "     Misclassifications: 215\n",
      "\n",
      "k=5027: Avg loss so far = 1.165307\n",
      "     Misclassifications: 216\n",
      "\n",
      "k=5028: Avg loss so far = 1.177804\n",
      "     Misclassifications: 217\n",
      "\n",
      "k=5029: Avg loss so far = 1.190296\n",
      "     Misclassifications: 217\n",
      "\n",
      "k=5030: Avg loss so far = 1.190060\n",
      "     Misclassifications: 217\n",
      "\n",
      "k=5031: Avg loss so far = 1.189823\n",
      "     Misclassifications: 217\n",
      "\n",
      "k=5032: Avg loss so far = 1.189587\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5033: Avg loss so far = 1.189549\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5034: Avg loss so far = 1.189313\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5035: Avg loss so far = 1.189076\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5036: Avg loss so far = 1.188840\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5037: Avg loss so far = 1.188604\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5038: Avg loss so far = 1.188368\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5039: Avg loss so far = 1.188133\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5040: Avg loss so far = 1.187897\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5041: Avg loss so far = 1.187661\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5042: Avg loss so far = 1.187426\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5043: Avg loss so far = 1.187190\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5044: Avg loss so far = 1.186955\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5045: Avg loss so far = 1.186720\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5046: Avg loss so far = 1.186484\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5047: Avg loss so far = 1.186249\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5048: Avg loss so far = 1.186014\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5049: Avg loss so far = 1.185779\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5050: Avg loss so far = 1.185545\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5051: Avg loss so far = 1.185310\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5052: Avg loss so far = 1.185075\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5053: Avg loss so far = 1.184841\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5054: Avg loss so far = 1.184606\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5055: Avg loss so far = 1.184372\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5056: Avg loss so far = 1.184138\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5057: Avg loss so far = 1.183904\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5058: Avg loss so far = 1.183669\n",
      "     Misclassifications: 218\n",
      "\n",
      "k=5059: Avg loss so far = 1.183435\n",
      "     Misclassifications: 219\n",
      "\n",
      "k=5060: Avg loss so far = 1.183399\n",
      "     Misclassifications: 219\n",
      "\n",
      "k=5061: Avg loss so far = 1.183165\n",
      "     Misclassifications: 219\n",
      "\n",
      "k=5062: Avg loss so far = 1.182932\n",
      "     Misclassifications: 219\n",
      "\n",
      "k=5063: Avg loss so far = 1.182698\n",
      "     Misclassifications: 219\n",
      "\n",
      "k=5064: Avg loss so far = 1.182464\n",
      "     Misclassifications: 220\n",
      "\n",
      "k=5065: Avg loss so far = 1.183021\n",
      "     Misclassifications: 220\n",
      "\n",
      "k=5066: Avg loss so far = 1.182787\n",
      "     Misclassifications: 220\n",
      "\n",
      "k=5067: Avg loss so far = 1.182554\n",
      "     Misclassifications: 220\n",
      "\n",
      "k=5068: Avg loss so far = 1.182320\n",
      "     Misclassifications: 220\n",
      "\n",
      "k=5069: Avg loss so far = 1.182087\n",
      "     Misclassifications: 220\n",
      "\n",
      "k=5070: Avg loss so far = 1.181854\n",
      "     Misclassifications: 220\n",
      "\n",
      "k=5071: Avg loss so far = 1.181621\n",
      "     Misclassifications: 220\n",
      "\n",
      "k=5072: Avg loss so far = 1.181388\n",
      "     Misclassifications: 221\n",
      "\n",
      "k=5073: Avg loss so far = 1.184309\n",
      "     Misclassifications: 221\n",
      "\n",
      "k=5074: Avg loss so far = 1.184076\n",
      "     Misclassifications: 221\n",
      "\n",
      "k=5075: Avg loss so far = 1.183842\n",
      "     Misclassifications: 221\n",
      "\n",
      "k=5076: Avg loss so far = 1.183609\n",
      "     Misclassifications: 221\n",
      "\n",
      "k=5077: Avg loss so far = 1.183376\n",
      "     Misclassifications: 221\n",
      "\n",
      "k=5078: Avg loss so far = 1.183143\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5079: Avg loss so far = 1.195511\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5080: Avg loss so far = 1.195276\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5081: Avg loss so far = 1.195040\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5082: Avg loss so far = 1.194805\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5083: Avg loss so far = 1.194570\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5084: Avg loss so far = 1.194335\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5085: Avg loss so far = 1.194100\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5086: Avg loss so far = 1.193866\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5087: Avg loss so far = 1.193631\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5088: Avg loss so far = 1.193396\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5089: Avg loss so far = 1.193162\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5090: Avg loss so far = 1.192927\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5091: Avg loss so far = 1.192693\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5092: Avg loss so far = 1.192459\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5093: Avg loss so far = 1.192225\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5094: Avg loss so far = 1.191991\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5095: Avg loss so far = 1.191757\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5096: Avg loss so far = 1.191523\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5097: Avg loss so far = 1.191289\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5098: Avg loss so far = 1.191055\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5099: Avg loss so far = 1.190822\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5100: Avg loss so far = 1.190588\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5101: Avg loss so far = 1.190355\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5102: Avg loss so far = 1.190122\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5103: Avg loss so far = 1.189888\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5104: Avg loss so far = 1.189655\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5105: Avg loss so far = 1.189422\n",
      "     Misclassifications: 222\n",
      "\n",
      "k=5106: Avg loss so far = 1.189189\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5107: Avg loss so far = 1.201488\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5108: Avg loss so far = 1.201253\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5109: Avg loss so far = 1.201018\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5110: Avg loss so far = 1.200783\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5111: Avg loss so far = 1.200548\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5112: Avg loss so far = 1.200313\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5113: Avg loss so far = 1.200078\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5114: Avg loss so far = 1.199844\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5115: Avg loss so far = 1.199609\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5116: Avg loss so far = 1.199375\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5117: Avg loss so far = 1.199140\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5118: Avg loss so far = 1.198906\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5119: Avg loss so far = 1.198672\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5120: Avg loss so far = 1.198438\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5121: Avg loss so far = 1.198203\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5122: Avg loss so far = 1.197970\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5123: Avg loss so far = 1.197736\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5124: Avg loss so far = 1.197502\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5125: Avg loss so far = 1.197268\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5126: Avg loss so far = 1.197035\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5127: Avg loss so far = 1.196801\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5128: Avg loss so far = 1.196568\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5129: Avg loss so far = 1.196335\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5130: Avg loss so far = 1.196101\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5131: Avg loss so far = 1.195868\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5132: Avg loss so far = 1.195635\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5133: Avg loss so far = 1.195402\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5134: Avg loss so far = 1.195169\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5135: Avg loss so far = 1.194937\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5136: Avg loss so far = 1.194704\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5137: Avg loss so far = 1.194471\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5138: Avg loss so far = 1.194239\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5139: Avg loss so far = 1.194007\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5140: Avg loss so far = 1.193774\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5141: Avg loss so far = 1.193542\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5142: Avg loss so far = 1.193310\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5143: Avg loss so far = 1.193078\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5144: Avg loss so far = 1.192846\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5145: Avg loss so far = 1.192614\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5146: Avg loss so far = 1.192382\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5147: Avg loss so far = 1.192151\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5148: Avg loss so far = 1.191919\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5149: Avg loss so far = 1.191688\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5150: Avg loss so far = 1.191456\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5151: Avg loss so far = 1.191225\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5152: Avg loss so far = 1.190994\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5153: Avg loss so far = 1.190763\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5154: Avg loss so far = 1.190532\n",
      "     Misclassifications: 223\n",
      "\n",
      "k=5155: Avg loss so far = 1.190301\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5156: Avg loss so far = 1.190264\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5157: Avg loss so far = 1.190033\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5158: Avg loss so far = 1.189802\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5159: Avg loss so far = 1.189572\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5160: Avg loss so far = 1.189341\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5161: Avg loss so far = 1.189111\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5162: Avg loss so far = 1.188880\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5163: Avg loss so far = 1.188650\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5164: Avg loss so far = 1.188420\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5165: Avg loss so far = 1.188190\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5166: Avg loss so far = 1.187960\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5167: Avg loss so far = 1.187730\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5168: Avg loss so far = 1.187500\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5169: Avg loss so far = 1.187270\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5170: Avg loss so far = 1.187041\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5171: Avg loss so far = 1.186811\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5172: Avg loss so far = 1.186582\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5173: Avg loss so far = 1.186352\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5174: Avg loss so far = 1.186123\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5175: Avg loss so far = 1.185894\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5176: Avg loss so far = 1.185665\n",
      "     Misclassifications: 224\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5177: Avg loss so far = 1.185436\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5178: Avg loss so far = 1.185207\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5179: Avg loss so far = 1.184978\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5180: Avg loss so far = 1.184749\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5181: Avg loss so far = 1.184520\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5182: Avg loss so far = 1.184292\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5183: Avg loss so far = 1.184063\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5184: Avg loss so far = 1.183835\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5185: Avg loss so far = 1.183607\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5186: Avg loss so far = 1.183378\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5187: Avg loss so far = 1.183150\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5188: Avg loss so far = 1.182922\n",
      "     Misclassifications: 224\n",
      "\n",
      "k=5189: Avg loss so far = 1.182694\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5190: Avg loss so far = 1.194798\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5191: Avg loss so far = 1.194568\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5192: Avg loss so far = 1.194337\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5193: Avg loss so far = 1.194107\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5194: Avg loss so far = 1.193878\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5195: Avg loss so far = 1.193648\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5196: Avg loss so far = 1.193418\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5197: Avg loss so far = 1.193188\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5198: Avg loss so far = 1.192959\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5199: Avg loss so far = 1.192729\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5200: Avg loss so far = 1.192500\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5201: Avg loss so far = 1.192271\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5202: Avg loss so far = 1.192042\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5203: Avg loss so far = 1.191812\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5204: Avg loss so far = 1.191583\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5205: Avg loss so far = 1.191354\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5206: Avg loss so far = 1.191126\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5207: Avg loss so far = 1.190897\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5208: Avg loss so far = 1.190668\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5209: Avg loss so far = 1.190440\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5210: Avg loss so far = 1.190211\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5211: Avg loss so far = 1.189983\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5212: Avg loss so far = 1.189754\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5213: Avg loss so far = 1.189526\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5214: Avg loss so far = 1.189298\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5215: Avg loss so far = 1.189070\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5216: Avg loss so far = 1.188842\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5217: Avg loss so far = 1.188614\n",
      "     Misclassifications: 225\n",
      "\n",
      "k=5218: Avg loss so far = 1.188386\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5219: Avg loss so far = 1.200422\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5220: Avg loss so far = 1.200192\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5221: Avg loss so far = 1.199962\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5222: Avg loss so far = 1.199732\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5223: Avg loss so far = 1.199502\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5224: Avg loss so far = 1.199273\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5225: Avg loss so far = 1.199043\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5226: Avg loss so far = 1.198814\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5227: Avg loss so far = 1.198584\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5228: Avg loss so far = 1.198355\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5229: Avg loss so far = 1.198126\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5230: Avg loss so far = 1.197897\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5231: Avg loss so far = 1.197668\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5232: Avg loss so far = 1.197439\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5233: Avg loss so far = 1.197210\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5234: Avg loss so far = 1.196981\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5235: Avg loss so far = 1.196753\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5236: Avg loss so far = 1.196524\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5237: Avg loss so far = 1.196296\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5238: Avg loss so far = 1.196067\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5239: Avg loss so far = 1.195839\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5240: Avg loss so far = 1.195611\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5241: Avg loss so far = 1.195383\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5242: Avg loss so far = 1.195155\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5243: Avg loss so far = 1.194927\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5244: Avg loss so far = 1.194699\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5245: Avg loss so far = 1.194471\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5246: Avg loss so far = 1.194243\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5247: Avg loss so far = 1.194016\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5248: Avg loss so far = 1.193788\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5249: Avg loss so far = 1.193561\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5250: Avg loss so far = 1.193333\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5251: Avg loss so far = 1.193106\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5252: Avg loss so far = 1.192879\n",
      "     Misclassifications: 226\n",
      "\n",
      "k=5253: Avg loss so far = 1.192652\n",
      "     Misclassifications: 227\n",
      "\n",
      "k=5254: Avg loss so far = 1.192615\n",
      "     Misclassifications: 227\n",
      "\n",
      "k=5255: Avg loss so far = 1.192388\n",
      "     Misclassifications: 227\n",
      "\n",
      "k=5256: Avg loss so far = 1.192161\n",
      "     Misclassifications: 227\n",
      "\n",
      "k=5257: Avg loss so far = 1.191935\n",
      "     Misclassifications: 227\n",
      "\n",
      "k=5258: Avg loss so far = 1.191708\n",
      "     Misclassifications: 227\n",
      "\n",
      "k=5259: Avg loss so far = 1.191481\n",
      "     Misclassifications: 227\n",
      "\n",
      "k=5260: Avg loss so far = 1.191255\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5261: Avg loss so far = 1.194070\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5262: Avg loss so far = 1.193843\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5263: Avg loss so far = 1.193616\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5264: Avg loss so far = 1.193389\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5265: Avg loss so far = 1.193162\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5266: Avg loss so far = 1.192936\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5267: Avg loss so far = 1.192709\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5268: Avg loss so far = 1.192483\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5269: Avg loss so far = 1.192257\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5270: Avg loss so far = 1.192030\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5271: Avg loss so far = 1.191804\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5272: Avg loss so far = 1.191578\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5273: Avg loss so far = 1.191352\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5274: Avg loss so far = 1.191126\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5275: Avg loss so far = 1.190900\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5276: Avg loss so far = 1.190675\n",
      "     Misclassifications: 228\n",
      "\n",
      "k=5277: Avg loss so far = 1.190449\n",
      "     Misclassifications: 229\n",
      "\n",
      "k=5278: Avg loss so far = 1.190413\n",
      "     Misclassifications: 229\n",
      "\n",
      "k=5279: Avg loss so far = 1.190188\n",
      "     Misclassifications: 229\n",
      "\n",
      "k=5280: Avg loss so far = 1.189962\n",
      "     Misclassifications: 229\n",
      "\n",
      "k=5281: Avg loss so far = 1.189737\n",
      "     Misclassifications: 229\n",
      "\n",
      "k=5282: Avg loss so far = 1.189512\n",
      "     Misclassifications: 230\n",
      "\n",
      "k=5283: Avg loss so far = 1.201401\n",
      "     Misclassifications: 230\n",
      "\n",
      "k=5284: Avg loss so far = 1.201173\n",
      "     Misclassifications: 230\n",
      "\n",
      "k=5285: Avg loss so far = 1.200946\n",
      "     Misclassifications: 230\n",
      "\n",
      "k=5286: Avg loss so far = 1.200719\n",
      "     Misclassifications: 230\n",
      "\n",
      "k=5287: Avg loss so far = 1.200492\n",
      "     Misclassifications: 230\n",
      "\n",
      "k=5288: Avg loss so far = 1.200265\n",
      "     Misclassifications: 231\n",
      "\n",
      "k=5289: Avg loss so far = 1.203063\n",
      "     Misclassifications: 231\n",
      "\n",
      "k=5290: Avg loss so far = 1.202836\n",
      "     Misclassifications: 231\n",
      "\n",
      "k=5291: Avg loss so far = 1.202608\n",
      "     Misclassifications: 231\n",
      "\n",
      "k=5292: Avg loss so far = 1.202381\n",
      "     Misclassifications: 231\n",
      "\n",
      "k=5293: Avg loss so far = 1.202154\n",
      "     Misclassifications: 231\n",
      "\n",
      "k=5294: Avg loss so far = 1.201927\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5295: Avg loss so far = 1.213787\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5296: Avg loss so far = 1.213557\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5297: Avg loss so far = 1.213328\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5298: Avg loss so far = 1.213099\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5299: Avg loss so far = 1.212870\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5300: Avg loss so far = 1.212642\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5301: Avg loss so far = 1.212413\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5302: Avg loss so far = 1.212184\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5303: Avg loss so far = 1.211955\n",
      "     Misclassifications: 232\n",
      "\n",
      "k=5304: Avg loss so far = 1.211727\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5305: Avg loss so far = 1.211687\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5306: Avg loss so far = 1.211459\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5307: Avg loss so far = 1.211230\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5308: Avg loss so far = 1.211002\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5309: Avg loss so far = 1.210774\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5310: Avg loss so far = 1.210546\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5311: Avg loss so far = 1.210318\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5312: Avg loss so far = 1.210090\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5313: Avg loss so far = 1.209863\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5314: Avg loss so far = 1.209635\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5315: Avg loss so far = 1.209407\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5316: Avg loss so far = 1.209180\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5317: Avg loss so far = 1.208952\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5318: Avg loss so far = 1.208725\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5319: Avg loss so far = 1.208498\n",
      "     Misclassifications: 233\n",
      "\n",
      "k=5320: Avg loss so far = 1.208271\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5321: Avg loss so far = 1.211051\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5322: Avg loss so far = 1.210823\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5323: Avg loss so far = 1.210596\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5324: Avg loss so far = 1.210368\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5325: Avg loss so far = 1.210141\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5326: Avg loss so far = 1.209914\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5327: Avg loss so far = 1.209687\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5328: Avg loss so far = 1.209459\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5329: Avg loss so far = 1.209233\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5330: Avg loss so far = 1.209006\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5331: Avg loss so far = 1.208779\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5332: Avg loss so far = 1.208552\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5333: Avg loss so far = 1.208326\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5334: Avg loss so far = 1.208099\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5335: Avg loss so far = 1.207873\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5336: Avg loss so far = 1.207646\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5337: Avg loss so far = 1.207420\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5338: Avg loss so far = 1.207194\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5339: Avg loss so far = 1.206968\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5340: Avg loss so far = 1.206742\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5341: Avg loss so far = 1.206516\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5342: Avg loss so far = 1.206290\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5343: Avg loss so far = 1.206064\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5344: Avg loss so far = 1.205838\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5345: Avg loss so far = 1.205613\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5346: Avg loss so far = 1.205387\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5347: Avg loss so far = 1.205162\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5348: Avg loss so far = 1.204936\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5349: Avg loss so far = 1.204711\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5350: Avg loss so far = 1.204486\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5351: Avg loss so far = 1.204261\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5352: Avg loss so far = 1.204036\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5353: Avg loss so far = 1.203811\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5354: Avg loss so far = 1.203586\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5355: Avg loss so far = 1.203361\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5356: Avg loss so far = 1.203137\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5357: Avg loss so far = 1.202912\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5358: Avg loss so far = 1.202688\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5359: Avg loss so far = 1.202463\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5360: Avg loss so far = 1.202239\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5361: Avg loss so far = 1.202015\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5362: Avg loss so far = 1.201790\n",
      "     Misclassifications: 234\n",
      "\n",
      "k=5363: Avg loss so far = 1.201566\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5364: Avg loss so far = 1.201529\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5365: Avg loss so far = 1.201305\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5366: Avg loss so far = 1.201081\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5367: Avg loss so far = 1.200857\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5368: Avg loss so far = 1.200633\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5369: Avg loss so far = 1.200410\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5370: Avg loss so far = 1.200186\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5371: Avg loss so far = 1.199963\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5372: Avg loss so far = 1.199739\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5373: Avg loss so far = 1.199516\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5374: Avg loss so far = 1.199293\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5375: Avg loss so far = 1.199070\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5376: Avg loss so far = 1.198847\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5377: Avg loss so far = 1.198624\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5378: Avg loss so far = 1.198401\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5379: Avg loss so far = 1.198178\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5380: Avg loss so far = 1.197955\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5381: Avg loss so far = 1.197733\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5382: Avg loss so far = 1.197510\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5383: Avg loss so far = 1.197288\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5384: Avg loss so far = 1.197065\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5385: Avg loss so far = 1.196843\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5386: Avg loss so far = 1.196621\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5387: Avg loss so far = 1.196399\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5388: Avg loss so far = 1.196177\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5389: Avg loss so far = 1.195955\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5390: Avg loss so far = 1.195733\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5391: Avg loss so far = 1.195511\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5392: Avg loss so far = 1.195289\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5393: Avg loss so far = 1.195068\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5394: Avg loss so far = 1.194846\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5395: Avg loss so far = 1.194625\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5396: Avg loss so far = 1.194403\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5397: Avg loss so far = 1.194182\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5398: Avg loss so far = 1.193961\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5399: Avg loss so far = 1.193740\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5400: Avg loss so far = 1.193519\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5401: Avg loss so far = 1.193298\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5402: Avg loss so far = 1.193077\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5403: Avg loss so far = 1.192856\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5404: Avg loss so far = 1.192635\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5405: Avg loss so far = 1.192414\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5406: Avg loss so far = 1.192194\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5407: Avg loss so far = 1.191973\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5408: Avg loss so far = 1.191753\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5409: Avg loss so far = 1.191533\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5410: Avg loss so far = 1.191312\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5411: Avg loss so far = 1.191092\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5412: Avg loss so far = 1.190872\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5413: Avg loss so far = 1.190652\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5414: Avg loss so far = 1.190432\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5415: Avg loss so far = 1.190212\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5416: Avg loss so far = 1.189993\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5417: Avg loss so far = 1.189773\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5418: Avg loss so far = 1.189553\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5419: Avg loss so far = 1.189334\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5420: Avg loss so far = 1.189114\n",
      "     Misclassifications: 235\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5421: Avg loss so far = 1.188895\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5422: Avg loss so far = 1.188676\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5423: Avg loss so far = 1.188457\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5424: Avg loss so far = 1.188237\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5425: Avg loss so far = 1.188018\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5426: Avg loss so far = 1.187799\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5427: Avg loss so far = 1.187581\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5428: Avg loss so far = 1.187362\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5429: Avg loss so far = 1.187143\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5430: Avg loss so far = 1.186924\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5431: Avg loss so far = 1.186706\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5432: Avg loss so far = 1.186487\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5433: Avg loss so far = 1.186269\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5434: Avg loss so far = 1.186051\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5435: Avg loss so far = 1.185833\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5436: Avg loss so far = 1.185614\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5437: Avg loss so far = 1.185396\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5438: Avg loss so far = 1.185178\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5439: Avg loss so far = 1.184960\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5440: Avg loss so far = 1.184743\n",
      "     Misclassifications: 235\n",
      "\n",
      "k=5441: Avg loss so far = 1.184525\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5442: Avg loss so far = 1.185042\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5443: Avg loss so far = 1.184825\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5444: Avg loss so far = 1.184607\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5445: Avg loss so far = 1.184389\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5446: Avg loss so far = 1.184172\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5447: Avg loss so far = 1.183954\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5448: Avg loss so far = 1.183737\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5449: Avg loss so far = 1.183520\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5450: Avg loss so far = 1.183303\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5451: Avg loss so far = 1.183086\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5452: Avg loss so far = 1.182869\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5453: Avg loss so far = 1.182652\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5454: Avg loss so far = 1.182435\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5455: Avg loss so far = 1.182218\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5456: Avg loss so far = 1.182001\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5457: Avg loss so far = 1.181785\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5458: Avg loss so far = 1.181568\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5459: Avg loss so far = 1.181352\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5460: Avg loss so far = 1.181136\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5461: Avg loss so far = 1.180919\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5462: Avg loss so far = 1.180703\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5463: Avg loss so far = 1.180487\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5464: Avg loss so far = 1.180271\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5465: Avg loss so far = 1.180055\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5466: Avg loss so far = 1.179839\n",
      "     Misclassifications: 236\n",
      "\n",
      "k=5467: Avg loss so far = 1.179623\n",
      "     Misclassifications: 237\n",
      "\n",
      "k=5468: Avg loss so far = 1.191112\n",
      "     Misclassifications: 237\n",
      "\n",
      "k=5469: Avg loss so far = 1.190894\n",
      "     Misclassifications: 237\n",
      "\n",
      "k=5470: Avg loss so far = 1.190676\n",
      "     Misclassifications: 237\n",
      "\n",
      "k=5471: Avg loss so far = 1.190459\n",
      "     Misclassifications: 237\n",
      "\n",
      "k=5472: Avg loss so far = 1.190241\n",
      "     Misclassifications: 237\n",
      "\n",
      "k=5473: Avg loss so far = 1.190024\n",
      "     Misclassifications: 237\n",
      "\n",
      "k=5474: Avg loss so far = 1.189806\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5475: Avg loss so far = 1.201279\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5476: Avg loss so far = 1.201059\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5477: Avg loss so far = 1.200840\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5478: Avg loss so far = 1.200621\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5479: Avg loss so far = 1.200402\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5480: Avg loss so far = 1.200182\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5481: Avg loss so far = 1.199964\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5482: Avg loss so far = 1.199745\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5483: Avg loss so far = 1.199526\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5484: Avg loss so far = 1.199307\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5485: Avg loss so far = 1.199088\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5486: Avg loss so far = 1.198870\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5487: Avg loss so far = 1.198651\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5488: Avg loss so far = 1.198433\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5489: Avg loss so far = 1.198215\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5490: Avg loss so far = 1.197996\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5491: Avg loss so far = 1.197778\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5492: Avg loss so far = 1.197560\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5493: Avg loss so far = 1.197342\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5494: Avg loss so far = 1.197124\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5495: Avg loss so far = 1.196906\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5496: Avg loss so far = 1.196689\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5497: Avg loss so far = 1.196471\n",
      "     Misclassifications: 238\n",
      "\n",
      "k=5498: Avg loss so far = 1.196253\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5499: Avg loss so far = 1.214221\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5500: Avg loss so far = 1.214000\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5501: Avg loss so far = 1.213779\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5502: Avg loss so far = 1.213559\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5503: Avg loss so far = 1.213338\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5504: Avg loss so far = 1.213118\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5505: Avg loss so far = 1.212897\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5506: Avg loss so far = 1.212677\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5507: Avg loss so far = 1.212457\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5508: Avg loss so far = 1.212237\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5509: Avg loss so far = 1.212017\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5510: Avg loss so far = 1.211797\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5511: Avg loss so far = 1.211577\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5512: Avg loss so far = 1.211357\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5513: Avg loss so far = 1.211137\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5514: Avg loss so far = 1.210918\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5515: Avg loss so far = 1.210698\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5516: Avg loss so far = 1.210479\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5517: Avg loss so far = 1.210259\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5518: Avg loss so far = 1.210040\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5519: Avg loss so far = 1.209821\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5520: Avg loss so far = 1.209601\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5521: Avg loss so far = 1.209382\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5522: Avg loss so far = 1.209163\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5523: Avg loss so far = 1.208944\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5524: Avg loss so far = 1.208726\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5525: Avg loss so far = 1.208507\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5526: Avg loss so far = 1.208288\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5527: Avg loss so far = 1.208069\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5528: Avg loss so far = 1.207851\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5529: Avg loss so far = 1.207632\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5530: Avg loss so far = 1.207414\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5531: Avg loss so far = 1.207196\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5532: Avg loss so far = 1.206978\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5533: Avg loss so far = 1.206759\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5534: Avg loss so far = 1.206541\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5535: Avg loss so far = 1.206323\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5536: Avg loss so far = 1.206105\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5537: Avg loss so far = 1.205888\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5538: Avg loss so far = 1.205670\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5539: Avg loss so far = 1.205452\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5540: Avg loss so far = 1.205235\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5541: Avg loss so far = 1.205017\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5542: Avg loss so far = 1.204800\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5543: Avg loss so far = 1.204582\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5544: Avg loss so far = 1.204365\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5545: Avg loss so far = 1.204148\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5546: Avg loss so far = 1.203931\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5547: Avg loss so far = 1.203714\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5548: Avg loss so far = 1.203497\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5549: Avg loss so far = 1.203280\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5550: Avg loss so far = 1.203063\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5551: Avg loss so far = 1.202846\n",
      "     Misclassifications: 239\n",
      "\n",
      "k=5552: Avg loss so far = 1.202630\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5553: Avg loss so far = 1.213938\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5554: Avg loss so far = 1.213720\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5555: Avg loss so far = 1.213501\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5556: Avg loss so far = 1.213283\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5557: Avg loss so far = 1.213065\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5558: Avg loss so far = 1.212846\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5559: Avg loss so far = 1.212628\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5560: Avg loss so far = 1.212410\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5561: Avg loss so far = 1.212192\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5562: Avg loss so far = 1.211974\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5563: Avg loss so far = 1.211756\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5564: Avg loss so far = 1.211538\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5565: Avg loss so far = 1.211321\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5566: Avg loss so far = 1.211103\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5567: Avg loss so far = 1.210886\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5568: Avg loss so far = 1.210668\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5569: Avg loss so far = 1.210451\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5570: Avg loss so far = 1.210233\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5571: Avg loss so far = 1.210016\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5572: Avg loss so far = 1.209799\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5573: Avg loss so far = 1.209582\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5574: Avg loss so far = 1.209365\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5575: Avg loss so far = 1.209148\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5576: Avg loss so far = 1.208931\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5577: Avg loss so far = 1.208714\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5578: Avg loss so far = 1.208498\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5579: Avg loss so far = 1.208281\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5580: Avg loss so far = 1.208065\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5581: Avg loss so far = 1.207848\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5582: Avg loss so far = 1.207632\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5583: Avg loss so far = 1.207415\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5584: Avg loss so far = 1.207199\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5585: Avg loss so far = 1.206983\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5586: Avg loss so far = 1.206767\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5587: Avg loss so far = 1.206551\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5588: Avg loss so far = 1.206335\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5589: Avg loss so far = 1.206119\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5590: Avg loss so far = 1.205903\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5591: Avg loss so far = 1.205688\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5592: Avg loss so far = 1.205472\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5593: Avg loss so far = 1.205257\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5594: Avg loss so far = 1.205041\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5595: Avg loss so far = 1.204826\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5596: Avg loss so far = 1.204610\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5597: Avg loss so far = 1.204395\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5598: Avg loss so far = 1.204180\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5599: Avg loss so far = 1.203965\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5600: Avg loss so far = 1.203750\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5601: Avg loss so far = 1.203535\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5602: Avg loss so far = 1.203320\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5603: Avg loss so far = 1.203105\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5604: Avg loss so far = 1.202891\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5605: Avg loss so far = 1.202676\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5606: Avg loss so far = 1.202462\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5607: Avg loss so far = 1.202247\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5608: Avg loss so far = 1.202033\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5609: Avg loss so far = 1.201819\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5610: Avg loss so far = 1.201604\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5611: Avg loss so far = 1.201390\n",
      "     Misclassifications: 240\n",
      "\n",
      "k=5612: Avg loss so far = 1.201176\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5613: Avg loss so far = 1.201675\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5614: Avg loss so far = 1.201461\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5615: Avg loss so far = 1.201247\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5616: Avg loss so far = 1.201033\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5617: Avg loss so far = 1.200819\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5618: Avg loss so far = 1.200605\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5619: Avg loss so far = 1.200392\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5620: Avg loss so far = 1.200178\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5621: Avg loss so far = 1.199964\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5622: Avg loss so far = 1.199751\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5623: Avg loss so far = 1.199538\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5624: Avg loss so far = 1.199324\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5625: Avg loss so far = 1.199111\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5626: Avg loss so far = 1.198898\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5627: Avg loss so far = 1.198685\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5628: Avg loss so far = 1.198472\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5629: Avg loss so far = 1.198259\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5630: Avg loss so far = 1.198046\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5631: Avg loss so far = 1.197833\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5632: Avg loss so far = 1.197621\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5633: Avg loss so far = 1.197408\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5634: Avg loss so far = 1.197196\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5635: Avg loss so far = 1.196983\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5636: Avg loss so far = 1.196771\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5637: Avg loss so far = 1.196558\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5638: Avg loss so far = 1.196346\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5639: Avg loss so far = 1.196134\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5640: Avg loss so far = 1.195922\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5641: Avg loss so far = 1.195710\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5642: Avg loss so far = 1.195498\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5643: Avg loss so far = 1.195286\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5644: Avg loss so far = 1.195074\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5645: Avg loss so far = 1.194863\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5646: Avg loss so far = 1.194651\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5647: Avg loss so far = 1.194440\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5648: Avg loss so far = 1.194228\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5649: Avg loss so far = 1.194017\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5650: Avg loss so far = 1.193805\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5651: Avg loss so far = 1.193594\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5652: Avg loss so far = 1.193383\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5653: Avg loss so far = 1.193172\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5654: Avg loss so far = 1.192961\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5655: Avg loss so far = 1.192750\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5656: Avg loss so far = 1.192539\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5657: Avg loss so far = 1.192328\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5658: Avg loss so far = 1.192117\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5659: Avg loss so far = 1.191907\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5660: Avg loss so far = 1.191696\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5661: Avg loss so far = 1.191486\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5662: Avg loss so far = 1.191275\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5663: Avg loss so far = 1.191065\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5664: Avg loss so far = 1.190855\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5665: Avg loss so far = 1.190644\n",
      "     Misclassifications: 241\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5666: Avg loss so far = 1.190434\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5667: Avg loss so far = 1.190224\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5668: Avg loss so far = 1.190014\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5669: Avg loss so far = 1.189804\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5670: Avg loss so far = 1.189594\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5671: Avg loss so far = 1.189385\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5672: Avg loss so far = 1.189175\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5673: Avg loss so far = 1.188965\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5674: Avg loss so far = 1.188756\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5675: Avg loss so far = 1.188546\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5676: Avg loss so far = 1.188337\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5677: Avg loss so far = 1.188128\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5678: Avg loss so far = 1.187918\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5679: Avg loss so far = 1.187709\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5680: Avg loss so far = 1.187500\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5681: Avg loss so far = 1.187291\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5682: Avg loss so far = 1.187082\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5683: Avg loss so far = 1.186873\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5684: Avg loss so far = 1.186664\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5685: Avg loss so far = 1.186456\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5686: Avg loss so far = 1.186247\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5687: Avg loss so far = 1.186038\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5688: Avg loss so far = 1.185830\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5689: Avg loss so far = 1.185621\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5690: Avg loss so far = 1.185413\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5691: Avg loss so far = 1.185205\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5692: Avg loss so far = 1.184996\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5693: Avg loss so far = 1.184788\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5694: Avg loss so far = 1.184580\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5695: Avg loss so far = 1.184372\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5696: Avg loss so far = 1.184164\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5697: Avg loss so far = 1.183956\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5698: Avg loss so far = 1.183749\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5699: Avg loss so far = 1.183541\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5700: Avg loss so far = 1.183333\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5701: Avg loss so far = 1.183126\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5702: Avg loss so far = 1.182918\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5703: Avg loss so far = 1.182711\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5704: Avg loss so far = 1.182504\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5705: Avg loss so far = 1.182296\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5706: Avg loss so far = 1.182089\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5707: Avg loss so far = 1.181882\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5708: Avg loss so far = 1.181675\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5709: Avg loss so far = 1.181468\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5710: Avg loss so far = 1.181261\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5711: Avg loss so far = 1.181054\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5712: Avg loss so far = 1.180847\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5713: Avg loss so far = 1.180641\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5714: Avg loss so far = 1.180434\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5715: Avg loss so far = 1.180227\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5716: Avg loss so far = 1.180021\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5717: Avg loss so far = 1.179815\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5718: Avg loss so far = 1.179608\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5719: Avg loss so far = 1.179402\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5720: Avg loss so far = 1.179196\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5721: Avg loss so far = 1.178990\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5722: Avg loss so far = 1.178784\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5723: Avg loss so far = 1.178578\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5724: Avg loss so far = 1.178372\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5725: Avg loss so far = 1.178166\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5726: Avg loss so far = 1.177960\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5727: Avg loss so far = 1.177754\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5728: Avg loss so far = 1.177549\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5729: Avg loss so far = 1.177343\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5730: Avg loss so far = 1.177138\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5731: Avg loss so far = 1.176932\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5732: Avg loss so far = 1.176727\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5733: Avg loss so far = 1.176522\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5734: Avg loss so far = 1.176317\n",
      "     Misclassifications: 241\n",
      "\n",
      "k=5735: Avg loss so far = 1.176112\n",
      "     Misclassifications: 242\n",
      "\n",
      "k=5736: Avg loss so far = 1.176604\n",
      "     Misclassifications: 242\n",
      "\n",
      "k=5737: Avg loss so far = 1.176399\n",
      "     Misclassifications: 242\n",
      "\n",
      "k=5738: Avg loss so far = 1.176194\n",
      "     Misclassifications: 242\n",
      "\n",
      "k=5739: Avg loss so far = 1.175989\n",
      "     Misclassifications: 242\n",
      "\n",
      "k=5740: Avg loss so far = 1.175784\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5741: Avg loss so far = 1.186727\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5742: Avg loss so far = 1.186520\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5743: Avg loss so far = 1.186314\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5744: Avg loss so far = 1.186107\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5745: Avg loss so far = 1.185901\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5746: Avg loss so far = 1.185694\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5747: Avg loss so far = 1.185488\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5748: Avg loss so far = 1.185282\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5749: Avg loss so far = 1.185076\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5750: Avg loss so far = 1.184870\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5751: Avg loss so far = 1.184664\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5752: Avg loss so far = 1.184458\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5753: Avg loss so far = 1.184252\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5754: Avg loss so far = 1.184046\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5755: Avg loss so far = 1.183840\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5756: Avg loss so far = 1.183634\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5757: Avg loss so far = 1.183429\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5758: Avg loss so far = 1.183223\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5759: Avg loss so far = 1.183018\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5760: Avg loss so far = 1.182813\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5761: Avg loss so far = 1.182607\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5762: Avg loss so far = 1.182402\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5763: Avg loss so far = 1.182197\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5764: Avg loss so far = 1.181992\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5765: Avg loss so far = 1.181787\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5766: Avg loss so far = 1.181582\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5767: Avg loss so far = 1.181377\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5768: Avg loss so far = 1.181172\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5769: Avg loss so far = 1.180967\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5770: Avg loss so far = 1.180763\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5771: Avg loss so far = 1.180558\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5772: Avg loss so far = 1.180353\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5773: Avg loss so far = 1.180149\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5774: Avg loss so far = 1.179945\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5775: Avg loss so far = 1.179740\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5776: Avg loss so far = 1.179536\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5777: Avg loss so far = 1.179332\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5778: Avg loss so far = 1.179128\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5779: Avg loss so far = 1.178924\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5780: Avg loss so far = 1.178720\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5781: Avg loss so far = 1.178516\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5782: Avg loss so far = 1.178312\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5783: Avg loss so far = 1.178108\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5784: Avg loss so far = 1.177905\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5785: Avg loss so far = 1.177701\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5786: Avg loss so far = 1.177497\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5787: Avg loss so far = 1.177294\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5788: Avg loss so far = 1.177091\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5789: Avg loss so far = 1.176887\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5790: Avg loss so far = 1.176684\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5791: Avg loss so far = 1.176481\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5792: Avg loss so far = 1.176278\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5793: Avg loss so far = 1.176075\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5794: Avg loss so far = 1.175872\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5795: Avg loss so far = 1.175669\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5796: Avg loss so far = 1.175466\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5797: Avg loss so far = 1.175263\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5798: Avg loss so far = 1.175060\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5799: Avg loss so far = 1.174858\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5800: Avg loss so far = 1.174655\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5801: Avg loss so far = 1.174453\n",
      "     Misclassifications: 243\n",
      "\n",
      "k=5802: Avg loss so far = 1.174250\n",
      "     Misclassifications: 244\n",
      "\n",
      "k=5803: Avg loss so far = 1.176805\n",
      "     Misclassifications: 244\n",
      "\n",
      "k=5804: Avg loss so far = 1.176602\n",
      "     Misclassifications: 244\n",
      "\n",
      "k=5805: Avg loss so far = 1.176400\n",
      "     Misclassifications: 244\n",
      "\n",
      "k=5806: Avg loss so far = 1.176197\n",
      "     Misclassifications: 244\n",
      "\n",
      "k=5807: Avg loss so far = 1.175994\n",
      "     Misclassifications: 244\n",
      "\n",
      "k=5808: Avg loss so far = 1.175792\n",
      "     Misclassifications: 244\n",
      "\n",
      "k=5809: Avg loss so far = 1.175590\n",
      "     Misclassifications: 244\n",
      "\n",
      "k=5810: Avg loss so far = 1.175387\n",
      "     Misclassifications: 245\n",
      "\n",
      "k=5811: Avg loss so far = 1.177938\n",
      "     Misclassifications: 245\n",
      "\n",
      "k=5812: Avg loss so far = 1.177736\n",
      "     Misclassifications: 245\n",
      "\n",
      "k=5813: Avg loss so far = 1.177533\n",
      "     Misclassifications: 245\n",
      "\n",
      "k=5814: Avg loss so far = 1.177331\n",
      "     Misclassifications: 245\n",
      "\n",
      "k=5815: Avg loss so far = 1.177128\n",
      "     Misclassifications: 245\n",
      "\n",
      "k=5816: Avg loss so far = 1.176926\n",
      "     Misclassifications: 246\n",
      "\n",
      "k=5817: Avg loss so far = 1.176895\n",
      "     Misclassifications: 246\n",
      "\n",
      "k=5818: Avg loss so far = 1.176693\n",
      "     Misclassifications: 246\n",
      "\n",
      "k=5819: Avg loss so far = 1.176491\n",
      "     Misclassifications: 246\n",
      "\n",
      "k=5820: Avg loss so far = 1.176289\n",
      "     Misclassifications: 246\n",
      "\n",
      "k=5821: Avg loss so far = 1.176087\n",
      "     Misclassifications: 246\n",
      "\n",
      "k=5822: Avg loss so far = 1.175885\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5823: Avg loss so far = 1.176370\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5824: Avg loss so far = 1.176168\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5825: Avg loss so far = 1.175966\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5826: Avg loss so far = 1.175764\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5827: Avg loss so far = 1.175562\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5828: Avg loss so far = 1.175360\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5829: Avg loss so far = 1.175159\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5830: Avg loss so far = 1.174957\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5831: Avg loss so far = 1.174756\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5832: Avg loss so far = 1.174554\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5833: Avg loss so far = 1.174353\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5834: Avg loss so far = 1.174152\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5835: Avg loss so far = 1.173950\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5836: Avg loss so far = 1.173749\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5837: Avg loss so far = 1.173548\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5838: Avg loss so far = 1.173347\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5839: Avg loss so far = 1.173146\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5840: Avg loss so far = 1.172945\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5841: Avg loss so far = 1.172744\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5842: Avg loss so far = 1.172544\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5843: Avg loss so far = 1.172343\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5844: Avg loss so far = 1.172142\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5845: Avg loss so far = 1.171942\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5846: Avg loss so far = 1.171741\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5847: Avg loss so far = 1.171541\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5848: Avg loss so far = 1.171341\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5849: Avg loss so far = 1.171140\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5850: Avg loss so far = 1.170940\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5851: Avg loss so far = 1.170740\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5852: Avg loss so far = 1.170540\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5853: Avg loss so far = 1.170340\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5854: Avg loss so far = 1.170140\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5855: Avg loss so far = 1.169940\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5856: Avg loss so far = 1.169740\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5857: Avg loss so far = 1.169541\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5858: Avg loss so far = 1.169341\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5859: Avg loss so far = 1.169141\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5860: Avg loss so far = 1.168942\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5861: Avg loss so far = 1.168743\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5862: Avg loss so far = 1.168543\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5863: Avg loss so far = 1.168344\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5864: Avg loss so far = 1.168145\n",
      "     Misclassifications: 247\n",
      "\n",
      "k=5865: Avg loss so far = 1.167945\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5866: Avg loss so far = 1.178657\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5867: Avg loss so far = 1.178456\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5868: Avg loss so far = 1.178255\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5869: Avg loss so far = 1.178054\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5870: Avg loss so far = 1.177853\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5871: Avg loss so far = 1.177653\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5872: Avg loss so far = 1.177452\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5873: Avg loss so far = 1.177252\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5874: Avg loss so far = 1.177051\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5875: Avg loss so far = 1.176851\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5876: Avg loss so far = 1.176651\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5877: Avg loss so far = 1.176451\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5878: Avg loss so far = 1.176250\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5879: Avg loss so far = 1.176050\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5880: Avg loss so far = 1.175850\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5881: Avg loss so far = 1.175650\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5882: Avg loss so far = 1.175451\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5883: Avg loss so far = 1.175251\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5884: Avg loss so far = 1.175051\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5885: Avg loss so far = 1.174851\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5886: Avg loss so far = 1.174652\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5887: Avg loss so far = 1.174452\n",
      "     Misclassifications: 248\n",
      "\n",
      "k=5888: Avg loss so far = 1.174253\n",
      "     Misclassifications: 249\n",
      "\n",
      "k=5889: Avg loss so far = 1.176770\n",
      "     Misclassifications: 249\n",
      "\n",
      "k=5890: Avg loss so far = 1.176570\n",
      "     Misclassifications: 250\n",
      "\n",
      "k=5891: Avg loss so far = 1.177050\n",
      "     Misclassifications: 250\n",
      "\n",
      "k=5892: Avg loss so far = 1.176850\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5893: Avg loss so far = 1.179365\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5894: Avg loss so far = 1.179165\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5895: Avg loss so far = 1.178965\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5896: Avg loss so far = 1.178765\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5897: Avg loss so far = 1.178565\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5898: Avg loss so far = 1.178366\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5899: Avg loss so far = 1.178166\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5900: Avg loss so far = 1.177966\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5901: Avg loss so far = 1.177766\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5902: Avg loss so far = 1.177567\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5903: Avg loss so far = 1.177367\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5904: Avg loss so far = 1.177168\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5905: Avg loss so far = 1.176969\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5906: Avg loss so far = 1.176769\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5907: Avg loss so far = 1.176570\n",
      "     Misclassifications: 251\n",
      "\n",
      "k=5908: Avg loss so far = 1.176371\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5909: Avg loss so far = 1.187003\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5910: Avg loss so far = 1.186802\n",
      "     Misclassifications: 252\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5911: Avg loss so far = 1.186601\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5912: Avg loss so far = 1.186401\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5913: Avg loss so far = 1.186200\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5914: Avg loss so far = 1.185999\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5915: Avg loss so far = 1.185799\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5916: Avg loss so far = 1.185598\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5917: Avg loss so far = 1.185398\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5918: Avg loss so far = 1.185198\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5919: Avg loss so far = 1.184997\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5920: Avg loss so far = 1.184797\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5921: Avg loss so far = 1.184597\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5922: Avg loss so far = 1.184397\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5923: Avg loss so far = 1.184197\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5924: Avg loss so far = 1.183997\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5925: Avg loss so far = 1.183797\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5926: Avg loss so far = 1.183598\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5927: Avg loss so far = 1.183398\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5928: Avg loss so far = 1.183198\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5929: Avg loss so far = 1.182999\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5930: Avg loss so far = 1.182799\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5931: Avg loss so far = 1.182600\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5932: Avg loss so far = 1.182401\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5933: Avg loss so far = 1.182201\n",
      "     Misclassifications: 252\n",
      "\n",
      "k=5934: Avg loss so far = 1.182002\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5935: Avg loss so far = 1.181971\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5936: Avg loss so far = 1.181772\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5937: Avg loss so far = 1.181573\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5938: Avg loss so far = 1.181374\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5939: Avg loss so far = 1.181175\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5940: Avg loss so far = 1.180976\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5941: Avg loss so far = 1.180778\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5942: Avg loss so far = 1.180579\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5943: Avg loss so far = 1.180380\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5944: Avg loss so far = 1.180182\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5945: Avg loss so far = 1.179983\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5946: Avg loss so far = 1.179785\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5947: Avg loss so far = 1.179586\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5948: Avg loss so far = 1.179388\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5949: Avg loss so far = 1.179190\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5950: Avg loss so far = 1.178992\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5951: Avg loss so far = 1.178793\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5952: Avg loss so far = 1.178595\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5953: Avg loss so far = 1.178397\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5954: Avg loss so far = 1.178200\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5955: Avg loss so far = 1.178002\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5956: Avg loss so far = 1.177804\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5957: Avg loss so far = 1.177606\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5958: Avg loss so far = 1.177409\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5959: Avg loss so far = 1.177211\n",
      "     Misclassifications: 253\n",
      "\n",
      "k=5960: Avg loss so far = 1.177013\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5961: Avg loss so far = 1.187552\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5962: Avg loss so far = 1.187353\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5963: Avg loss so far = 1.187154\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5964: Avg loss so far = 1.186955\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5965: Avg loss so far = 1.186756\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5966: Avg loss so far = 1.186557\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5967: Avg loss so far = 1.186358\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5968: Avg loss so far = 1.186160\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5969: Avg loss so far = 1.185961\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5970: Avg loss so far = 1.185762\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5971: Avg loss so far = 1.185564\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5972: Avg loss so far = 1.185365\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5973: Avg loss so far = 1.185167\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5974: Avg loss so far = 1.184968\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5975: Avg loss so far = 1.184770\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5976: Avg loss so far = 1.184572\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5977: Avg loss so far = 1.184373\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5978: Avg loss so far = 1.184175\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5979: Avg loss so far = 1.183977\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5980: Avg loss so far = 1.183779\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5981: Avg loss so far = 1.183581\n",
      "     Misclassifications: 254\n",
      "\n",
      "k=5982: Avg loss so far = 1.183383\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5983: Avg loss so far = 1.193883\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5984: Avg loss so far = 1.193683\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5985: Avg loss so far = 1.193484\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5986: Avg loss so far = 1.193284\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5987: Avg loss so far = 1.193085\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5988: Avg loss so far = 1.192886\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5989: Avg loss so far = 1.192687\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5990: Avg loss so far = 1.192487\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5991: Avg loss so far = 1.192288\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5992: Avg loss so far = 1.192089\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5993: Avg loss so far = 1.191891\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5994: Avg loss so far = 1.191692\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5995: Avg loss so far = 1.191493\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5996: Avg loss so far = 1.191294\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5997: Avg loss so far = 1.191096\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5998: Avg loss so far = 1.190897\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=5999: Avg loss so far = 1.190698\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6000: Avg loss so far = 1.190500\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6001: Avg loss so far = 1.190302\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6002: Avg loss so far = 1.190103\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6003: Avg loss so far = 1.189905\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6004: Avg loss so far = 1.189707\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6005: Avg loss so far = 1.189509\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6006: Avg loss so far = 1.189311\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6007: Avg loss so far = 1.189113\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6008: Avg loss so far = 1.188915\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6009: Avg loss so far = 1.188717\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6010: Avg loss so far = 1.188519\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6011: Avg loss so far = 1.188321\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6012: Avg loss so far = 1.188124\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6013: Avg loss so far = 1.187926\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6014: Avg loss so far = 1.187729\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6015: Avg loss so far = 1.187531\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6016: Avg loss so far = 1.187334\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6017: Avg loss so far = 1.187136\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6018: Avg loss so far = 1.186939\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6019: Avg loss so far = 1.186742\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6020: Avg loss so far = 1.186545\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6021: Avg loss so far = 1.186348\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6022: Avg loss so far = 1.186151\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6023: Avg loss so far = 1.185954\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6024: Avg loss so far = 1.185757\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6025: Avg loss so far = 1.185560\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6026: Avg loss so far = 1.185363\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6027: Avg loss so far = 1.185167\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6028: Avg loss so far = 1.184970\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6029: Avg loss so far = 1.184774\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6030: Avg loss so far = 1.184577\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6031: Avg loss so far = 1.184381\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6032: Avg loss so far = 1.184184\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6033: Avg loss so far = 1.183988\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6034: Avg loss so far = 1.183792\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6035: Avg loss so far = 1.183596\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6036: Avg loss so far = 1.183400\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6037: Avg loss so far = 1.183204\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6038: Avg loss so far = 1.183008\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6039: Avg loss so far = 1.182812\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6040: Avg loss so far = 1.182616\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6041: Avg loss so far = 1.182420\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6042: Avg loss so far = 1.182224\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6043: Avg loss so far = 1.182029\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6044: Avg loss so far = 1.181833\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6045: Avg loss so far = 1.181638\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6046: Avg loss so far = 1.181442\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6047: Avg loss so far = 1.181247\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6048: Avg loss so far = 1.181052\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6049: Avg loss so far = 1.180856\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6050: Avg loss so far = 1.180661\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6051: Avg loss so far = 1.180466\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6052: Avg loss so far = 1.180271\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6053: Avg loss so far = 1.180076\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6054: Avg loss so far = 1.179881\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6055: Avg loss so far = 1.179686\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6056: Avg loss so far = 1.179491\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6057: Avg loss so far = 1.179297\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6058: Avg loss so far = 1.179102\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6059: Avg loss so far = 1.178907\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6060: Avg loss so far = 1.178713\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6061: Avg loss so far = 1.178518\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6062: Avg loss so far = 1.178324\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6063: Avg loss so far = 1.178130\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6064: Avg loss so far = 1.177935\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6065: Avg loss so far = 1.177741\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6066: Avg loss so far = 1.177547\n",
      "     Misclassifications: 255\n",
      "\n",
      "k=6067: Avg loss so far = 1.177353\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6068: Avg loss so far = 1.177818\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6069: Avg loss so far = 1.177624\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6070: Avg loss so far = 1.177430\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6071: Avg loss so far = 1.177236\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6072: Avg loss so far = 1.177042\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6073: Avg loss so far = 1.176848\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6074: Avg loss so far = 1.176655\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6075: Avg loss so far = 1.176461\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6076: Avg loss so far = 1.176267\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6077: Avg loss so far = 1.176074\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6078: Avg loss so far = 1.175880\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6079: Avg loss so far = 1.175687\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6080: Avg loss so far = 1.175493\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6081: Avg loss so far = 1.175300\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6082: Avg loss so far = 1.175107\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6083: Avg loss so far = 1.174914\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6084: Avg loss so far = 1.174721\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6085: Avg loss so far = 1.174528\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6086: Avg loss so far = 1.174335\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6087: Avg loss so far = 1.174142\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6088: Avg loss so far = 1.173949\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6089: Avg loss so far = 1.173756\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6090: Avg loss so far = 1.173563\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6091: Avg loss so far = 1.173371\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6092: Avg loss so far = 1.173178\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6093: Avg loss so far = 1.172985\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6094: Avg loss so far = 1.172793\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6095: Avg loss so far = 1.172600\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6096: Avg loss so far = 1.172408\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6097: Avg loss so far = 1.172216\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6098: Avg loss so far = 1.172024\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6099: Avg loss so far = 1.171831\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6100: Avg loss so far = 1.171639\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6101: Avg loss so far = 1.171447\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6102: Avg loss so far = 1.171255\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6103: Avg loss so far = 1.171063\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6104: Avg loss so far = 1.170872\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6105: Avg loss so far = 1.170680\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6106: Avg loss so far = 1.170488\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6107: Avg loss so far = 1.170296\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6108: Avg loss so far = 1.170105\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6109: Avg loss so far = 1.169913\n",
      "     Misclassifications: 256\n",
      "\n",
      "k=6110: Avg loss so far = 1.169722\n",
      "     Misclassifications: 257\n",
      "\n",
      "k=6111: Avg loss so far = 1.172149\n",
      "     Misclassifications: 257\n",
      "\n",
      "k=6112: Avg loss so far = 1.171957\n",
      "     Misclassifications: 257\n",
      "\n",
      "k=6113: Avg loss so far = 1.171765\n",
      "     Misclassifications: 257\n",
      "\n",
      "k=6114: Avg loss so far = 1.171573\n",
      "     Misclassifications: 257\n",
      "\n",
      "k=6115: Avg loss so far = 1.171382\n",
      "     Misclassifications: 258\n",
      "\n",
      "k=6116: Avg loss so far = 1.171844\n",
      "     Misclassifications: 258\n",
      "\n",
      "k=6117: Avg loss so far = 1.171653\n",
      "     Misclassifications: 258\n",
      "\n",
      "k=6118: Avg loss so far = 1.171461\n",
      "     Misclassifications: 258\n",
      "\n",
      "k=6119: Avg loss so far = 1.171270\n",
      "     Misclassifications: 258\n",
      "\n",
      "k=6120: Avg loss so far = 1.171078\n",
      "     Misclassifications: 258\n",
      "\n",
      "k=6121: Avg loss so far = 1.170887\n",
      "     Misclassifications: 258\n",
      "\n",
      "k=6122: Avg loss so far = 1.170696\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6123: Avg loss so far = 1.180957\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6124: Avg loss so far = 1.180764\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6125: Avg loss so far = 1.180571\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6126: Avg loss so far = 1.180379\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6127: Avg loss so far = 1.180186\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6128: Avg loss so far = 1.179993\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6129: Avg loss so far = 1.179801\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6130: Avg loss so far = 1.179608\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6131: Avg loss so far = 1.179416\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6132: Avg loss so far = 1.179224\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6133: Avg loss so far = 1.179031\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6134: Avg loss so far = 1.178839\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6135: Avg loss so far = 1.178647\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6136: Avg loss so far = 1.178455\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6137: Avg loss so far = 1.178263\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6138: Avg loss so far = 1.178071\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6139: Avg loss so far = 1.177879\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6140: Avg loss so far = 1.177687\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6141: Avg loss so far = 1.177496\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6142: Avg loss so far = 1.177304\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6143: Avg loss so far = 1.177112\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6144: Avg loss so far = 1.176921\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6145: Avg loss so far = 1.176729\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6146: Avg loss so far = 1.176538\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6147: Avg loss so far = 1.176346\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6148: Avg loss so far = 1.176155\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6149: Avg loss so far = 1.175964\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6150: Avg loss so far = 1.175772\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6151: Avg loss so far = 1.175581\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6152: Avg loss so far = 1.175390\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6153: Avg loss so far = 1.175199\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6154: Avg loss so far = 1.175008\n",
      "     Misclassifications: 259\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=6155: Avg loss so far = 1.174817\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6156: Avg loss so far = 1.174626\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6157: Avg loss so far = 1.174436\n",
      "     Misclassifications: 259\n",
      "\n",
      "k=6158: Avg loss so far = 1.174245\n",
      "     Misclassifications: 260\n",
      "\n",
      "k=6159: Avg loss so far = 1.174217\n",
      "     Misclassifications: 260\n",
      "\n",
      "k=6160: Avg loss so far = 1.174026\n",
      "     Misclassifications: 260\n",
      "\n",
      "k=6161: Avg loss so far = 1.173835\n",
      "     Misclassifications: 260\n",
      "\n",
      "k=6162: Avg loss so far = 1.173645\n",
      "     Misclassifications: 260\n",
      "\n",
      "k=6163: Avg loss so far = 1.173454\n",
      "     Misclassifications: 260\n",
      "\n",
      "k=6164: Avg loss so far = 1.173264\n",
      "     Misclassifications: 260\n",
      "\n",
      "k=6165: Avg loss so far = 1.173074\n",
      "     Misclassifications: 260\n",
      "\n",
      "k=6166: Avg loss so far = 1.172884\n",
      "     Misclassifications: 260\n",
      "\n",
      "k=6167: Avg loss so far = 1.172693\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6168: Avg loss so far = 1.173152\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6169: Avg loss so far = 1.172962\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6170: Avg loss so far = 1.172771\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6171: Avg loss so far = 1.172581\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6172: Avg loss so far = 1.172391\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6173: Avg loss so far = 1.172202\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6174: Avg loss so far = 1.172012\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6175: Avg loss so far = 1.171822\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6176: Avg loss so far = 1.171632\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6177: Avg loss so far = 1.171442\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6178: Avg loss so far = 1.171253\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6179: Avg loss so far = 1.171063\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6180: Avg loss so far = 1.170874\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6181: Avg loss so far = 1.170684\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6182: Avg loss so far = 1.170495\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6183: Avg loss so far = 1.170306\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6184: Avg loss so far = 1.170116\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6185: Avg loss so far = 1.169927\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6186: Avg loss so far = 1.169738\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6187: Avg loss so far = 1.169549\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6188: Avg loss so far = 1.169360\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6189: Avg loss so far = 1.169171\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6190: Avg loss so far = 1.168982\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6191: Avg loss so far = 1.168793\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6192: Avg loss so far = 1.168605\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6193: Avg loss so far = 1.168416\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6194: Avg loss so far = 1.168227\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6195: Avg loss so far = 1.168039\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6196: Avg loss so far = 1.167850\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6197: Avg loss so far = 1.167662\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6198: Avg loss so far = 1.167473\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6199: Avg loss so far = 1.167285\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6200: Avg loss so far = 1.167097\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6201: Avg loss so far = 1.166909\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6202: Avg loss so far = 1.166720\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6203: Avg loss so far = 1.166532\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6204: Avg loss so far = 1.166344\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6205: Avg loss so far = 1.166156\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6206: Avg loss so far = 1.165968\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6207: Avg loss so far = 1.165781\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6208: Avg loss so far = 1.165593\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6209: Avg loss so far = 1.165405\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6210: Avg loss so far = 1.165217\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6211: Avg loss so far = 1.165030\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6212: Avg loss so far = 1.164842\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6213: Avg loss so far = 1.164655\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6214: Avg loss so far = 1.164467\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6215: Avg loss so far = 1.164280\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6216: Avg loss so far = 1.164093\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6217: Avg loss so far = 1.163905\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6218: Avg loss so far = 1.163718\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6219: Avg loss so far = 1.163531\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6220: Avg loss so far = 1.163344\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6221: Avg loss so far = 1.163157\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6222: Avg loss so far = 1.162970\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6223: Avg loss so far = 1.162783\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6224: Avg loss so far = 1.162596\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6225: Avg loss so far = 1.162410\n",
      "     Misclassifications: 261\n",
      "\n",
      "k=6226: Avg loss so far = 1.162223\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6227: Avg loss so far = 1.162679\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6228: Avg loss so far = 1.162492\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6229: Avg loss so far = 1.162305\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6230: Avg loss so far = 1.162119\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6231: Avg loss so far = 1.161932\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6232: Avg loss so far = 1.161746\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6233: Avg loss so far = 1.161559\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6234: Avg loss so far = 1.161373\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6235: Avg loss so far = 1.161187\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6236: Avg loss so far = 1.161001\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6237: Avg loss so far = 1.160814\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6238: Avg loss so far = 1.160628\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6239: Avg loss so far = 1.160442\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6240: Avg loss so far = 1.160256\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6241: Avg loss so far = 1.160071\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6242: Avg loss so far = 1.159885\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6243: Avg loss so far = 1.159699\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6244: Avg loss so far = 1.159513\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6245: Avg loss so far = 1.159327\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6246: Avg loss so far = 1.159142\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6247: Avg loss so far = 1.158956\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6248: Avg loss so far = 1.158771\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6249: Avg loss so far = 1.158585\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6250: Avg loss so far = 1.158400\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6251: Avg loss so far = 1.158215\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6252: Avg loss so far = 1.158029\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6253: Avg loss so far = 1.157844\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6254: Avg loss so far = 1.157659\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6255: Avg loss so far = 1.157474\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6256: Avg loss so far = 1.157289\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6257: Avg loss so far = 1.157104\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6258: Avg loss so far = 1.156919\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6259: Avg loss so far = 1.156734\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6260: Avg loss so far = 1.156550\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6261: Avg loss so far = 1.156365\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6262: Avg loss so far = 1.156180\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6263: Avg loss so far = 1.155996\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6264: Avg loss so far = 1.155811\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6265: Avg loss so far = 1.155626\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6266: Avg loss so far = 1.155442\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6267: Avg loss so far = 1.155258\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6268: Avg loss so far = 1.155073\n",
      "     Misclassifications: 262\n",
      "\n",
      "k=6269: Avg loss so far = 1.154889\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6270: Avg loss so far = 1.154864\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6271: Avg loss so far = 1.154680\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6272: Avg loss so far = 1.154496\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6273: Avg loss so far = 1.154312\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6274: Avg loss so far = 1.154128\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6275: Avg loss so far = 1.153944\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6276: Avg loss so far = 1.153760\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6277: Avg loss so far = 1.153577\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6278: Avg loss so far = 1.153393\n",
      "     Misclassifications: 263\n",
      "\n",
      "k=6279: Avg loss so far = 1.153209\n",
      "     Misclassifications: 264\n",
      "\n",
      "k=6280: Avg loss so far = 1.163217\n",
      "     Misclassifications: 264\n",
      "\n",
      "k=6281: Avg loss so far = 1.163031\n",
      "     Misclassifications: 264\n",
      "\n",
      "k=6282: Avg loss so far = 1.162846\n",
      "     Misclassifications: 264\n",
      "\n",
      "k=6283: Avg loss so far = 1.162661\n",
      "     Misclassifications: 264\n",
      "\n",
      "k=6284: Avg loss so far = 1.162476\n",
      "     Misclassifications: 264\n",
      "\n",
      "k=6285: Avg loss so far = 1.162291\n",
      "     Misclassifications: 264\n",
      "\n",
      "k=6286: Avg loss so far = 1.162106\n",
      "     Misclassifications: 264\n",
      "\n",
      "k=6287: Avg loss so far = 1.161921\n",
      "     Misclassifications: 264\n",
      "\n",
      "k=6288: Avg loss so far = 1.161737\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6289: Avg loss so far = 1.161711\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6290: Avg loss so far = 1.161526\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6291: Avg loss so far = 1.161342\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6292: Avg loss so far = 1.161157\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6293: Avg loss so far = 1.160973\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6294: Avg loss so far = 1.160788\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6295: Avg loss so far = 1.160604\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6296: Avg loss so far = 1.160419\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6297: Avg loss so far = 1.160235\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6298: Avg loss so far = 1.160051\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6299: Avg loss so far = 1.159867\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6300: Avg loss so far = 1.159683\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6301: Avg loss so far = 1.159498\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6302: Avg loss so far = 1.159315\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6303: Avg loss so far = 1.159131\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6304: Avg loss so far = 1.158947\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6305: Avg loss so far = 1.158763\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6306: Avg loss so far = 1.158579\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6307: Avg loss so far = 1.158395\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6308: Avg loss so far = 1.158212\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6309: Avg loss so far = 1.158028\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6310: Avg loss so far = 1.157845\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6311: Avg loss so far = 1.157661\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6312: Avg loss so far = 1.157478\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6313: Avg loss so far = 1.157294\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6314: Avg loss so far = 1.157111\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6315: Avg loss so far = 1.156928\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6316: Avg loss so far = 1.156745\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6317: Avg loss so far = 1.156562\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6318: Avg loss so far = 1.156379\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6319: Avg loss so far = 1.156196\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6320: Avg loss so far = 1.156013\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6321: Avg loss so far = 1.155830\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6322: Avg loss so far = 1.155647\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6323: Avg loss so far = 1.155464\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6324: Avg loss so far = 1.155281\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6325: Avg loss so far = 1.155099\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6326: Avg loss so far = 1.154916\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6327: Avg loss so far = 1.154734\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6328: Avg loss so far = 1.154551\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6329: Avg loss so far = 1.154369\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6330: Avg loss so far = 1.154186\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6331: Avg loss so far = 1.154004\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6332: Avg loss so far = 1.153822\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6333: Avg loss so far = 1.153640\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6334: Avg loss so far = 1.153458\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6335: Avg loss so far = 1.153275\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6336: Avg loss so far = 1.153093\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6337: Avg loss so far = 1.152911\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6338: Avg loss so far = 1.152730\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6339: Avg loss so far = 1.152548\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6340: Avg loss so far = 1.152366\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6341: Avg loss so far = 1.152184\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6342: Avg loss so far = 1.152003\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6343: Avg loss so far = 1.151821\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6344: Avg loss so far = 1.151639\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6345: Avg loss so far = 1.151458\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6346: Avg loss so far = 1.151276\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6347: Avg loss so far = 1.151095\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6348: Avg loss so far = 1.150914\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6349: Avg loss so far = 1.150732\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6350: Avg loss so far = 1.150551\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6351: Avg loss so far = 1.150370\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6352: Avg loss so far = 1.150189\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6353: Avg loss so far = 1.150008\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6354: Avg loss so far = 1.149827\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6355: Avg loss so far = 1.149646\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6356: Avg loss so far = 1.149465\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6357: Avg loss so far = 1.149284\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6358: Avg loss so far = 1.149103\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6359: Avg loss so far = 1.148923\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6360: Avg loss so far = 1.148742\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6361: Avg loss so far = 1.148562\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6362: Avg loss so far = 1.148381\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6363: Avg loss so far = 1.148201\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6364: Avg loss so far = 1.148020\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6365: Avg loss so far = 1.147840\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6366: Avg loss so far = 1.147659\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6367: Avg loss so far = 1.147479\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6368: Avg loss so far = 1.147299\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6369: Avg loss so far = 1.147119\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6370: Avg loss so far = 1.146939\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6371: Avg loss so far = 1.146759\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6372: Avg loss so far = 1.146579\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6373: Avg loss so far = 1.146399\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6374: Avg loss so far = 1.146219\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6375: Avg loss so far = 1.146039\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6376: Avg loss so far = 1.145859\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6377: Avg loss so far = 1.145680\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6378: Avg loss so far = 1.145500\n",
      "     Misclassifications: 265\n",
      "\n",
      "k=6379: Avg loss so far = 1.145321\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6380: Avg loss so far = 1.155172\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6381: Avg loss so far = 1.154991\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6382: Avg loss so far = 1.154810\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6383: Avg loss so far = 1.154629\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6384: Avg loss so far = 1.154449\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6385: Avg loss so far = 1.154268\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6386: Avg loss so far = 1.154087\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6387: Avg loss so far = 1.153906\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6388: Avg loss so far = 1.153726\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6389: Avg loss so far = 1.153545\n",
      "     Misclassifications: 266\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=6390: Avg loss so far = 1.153365\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6391: Avg loss so far = 1.153184\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6392: Avg loss so far = 1.153004\n",
      "     Misclassifications: 266\n",
      "\n",
      "k=6393: Avg loss so far = 1.152823\n",
      "     Misclassifications: 267\n",
      "\n",
      "k=6394: Avg loss so far = 1.152799\n",
      "     Misclassifications: 267\n",
      "\n",
      "k=6395: Avg loss so far = 1.152619\n",
      "     Misclassifications: 267\n",
      "\n",
      "k=6396: Avg loss so far = 1.152439\n",
      "     Misclassifications: 267\n",
      "\n",
      "k=6397: Avg loss so far = 1.152259\n",
      "     Misclassifications: 267\n",
      "\n",
      "k=6398: Avg loss so far = 1.152079\n",
      "     Misclassifications: 267\n",
      "\n",
      "k=6399: Avg loss so far = 1.151899\n",
      "     Misclassifications: 267\n",
      "\n",
      "k=6400: Avg loss so far = 1.151719\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6401: Avg loss so far = 1.151695\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6402: Avg loss so far = 1.151515\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6403: Avg loss so far = 1.151335\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6404: Avg loss so far = 1.151156\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6405: Avg loss so far = 1.150976\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6406: Avg loss so far = 1.150796\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6407: Avg loss so far = 1.150617\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6408: Avg loss so far = 1.150437\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6409: Avg loss so far = 1.150257\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6410: Avg loss so far = 1.150078\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6411: Avg loss so far = 1.149899\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6412: Avg loss so far = 1.149719\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6413: Avg loss so far = 1.149540\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6414: Avg loss so far = 1.149361\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6415: Avg loss so far = 1.149182\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6416: Avg loss so far = 1.149002\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6417: Avg loss so far = 1.148823\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6418: Avg loss so far = 1.148644\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6419: Avg loss so far = 1.148465\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6420: Avg loss so far = 1.148287\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6421: Avg loss so far = 1.148108\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6422: Avg loss so far = 1.147929\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6423: Avg loss so far = 1.147750\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6424: Avg loss so far = 1.147572\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6425: Avg loss so far = 1.147393\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6426: Avg loss so far = 1.147214\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6427: Avg loss so far = 1.147036\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6428: Avg loss so far = 1.146857\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6429: Avg loss so far = 1.146679\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6430: Avg loss so far = 1.146501\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6431: Avg loss so far = 1.146323\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6432: Avg loss so far = 1.146144\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6433: Avg loss so far = 1.145966\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6434: Avg loss so far = 1.145788\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6435: Avg loss so far = 1.145610\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6436: Avg loss so far = 1.145432\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6437: Avg loss so far = 1.145254\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6438: Avg loss so far = 1.145076\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6439: Avg loss so far = 1.144898\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6440: Avg loss so far = 1.144720\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6441: Avg loss so far = 1.144543\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6442: Avg loss so far = 1.144365\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6443: Avg loss so far = 1.144187\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6444: Avg loss so far = 1.144010\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6445: Avg loss so far = 1.143832\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6446: Avg loss so far = 1.143655\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6447: Avg loss so far = 1.143478\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6448: Avg loss so far = 1.143300\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6449: Avg loss so far = 1.143123\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6450: Avg loss so far = 1.142946\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6451: Avg loss so far = 1.142769\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6452: Avg loss so far = 1.142591\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6453: Avg loss so far = 1.142414\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6454: Avg loss so far = 1.142237\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6455: Avg loss so far = 1.142060\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6456: Avg loss so far = 1.141884\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6457: Avg loss so far = 1.141707\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6458: Avg loss so far = 1.141530\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6459: Avg loss so far = 1.141353\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6460: Avg loss so far = 1.141176\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6461: Avg loss so far = 1.141000\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6462: Avg loss so far = 1.140823\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6463: Avg loss so far = 1.140647\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6464: Avg loss so far = 1.140470\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6465: Avg loss so far = 1.140294\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6466: Avg loss so far = 1.140118\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6467: Avg loss so far = 1.139941\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6468: Avg loss so far = 1.139765\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6469: Avg loss so far = 1.139589\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6470: Avg loss so far = 1.139413\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6471: Avg loss so far = 1.139237\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6472: Avg loss so far = 1.139061\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6473: Avg loss so far = 1.138885\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6474: Avg loss so far = 1.138709\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6475: Avg loss so far = 1.138533\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6476: Avg loss so far = 1.138357\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6477: Avg loss so far = 1.138181\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6478: Avg loss so far = 1.138006\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6479: Avg loss so far = 1.137830\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6480: Avg loss so far = 1.137654\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6481: Avg loss so far = 1.137479\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6482: Avg loss so far = 1.137303\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6483: Avg loss so far = 1.137128\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6484: Avg loss so far = 1.136952\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6485: Avg loss so far = 1.136777\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6486: Avg loss so far = 1.136602\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6487: Avg loss so far = 1.136427\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6488: Avg loss so far = 1.136252\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6489: Avg loss so far = 1.136076\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6490: Avg loss so far = 1.135901\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6491: Avg loss so far = 1.135726\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6492: Avg loss so far = 1.135551\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6493: Avg loss so far = 1.135377\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6494: Avg loss so far = 1.135202\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6495: Avg loss so far = 1.135027\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6496: Avg loss so far = 1.134852\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6497: Avg loss so far = 1.134678\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6498: Avg loss so far = 1.134503\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6499: Avg loss so far = 1.134328\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6500: Avg loss so far = 1.134154\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6501: Avg loss so far = 1.133979\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6502: Avg loss so far = 1.133805\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6503: Avg loss so far = 1.133631\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6504: Avg loss so far = 1.133456\n",
      "     Misclassifications: 268\n",
      "\n",
      "k=6505: Avg loss so far = 1.133282\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6506: Avg loss so far = 1.135567\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6507: Avg loss so far = 1.135393\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6508: Avg loss so far = 1.135218\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6509: Avg loss so far = 1.135044\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6510: Avg loss so far = 1.134869\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6511: Avg loss so far = 1.134695\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6512: Avg loss so far = 1.134521\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6513: Avg loss so far = 1.134347\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6514: Avg loss so far = 1.134173\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6515: Avg loss so far = 1.133998\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6516: Avg loss so far = 1.133824\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6517: Avg loss so far = 1.133650\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6518: Avg loss so far = 1.133477\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6519: Avg loss so far = 1.133303\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6520: Avg loss so far = 1.133129\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6521: Avg loss so far = 1.132955\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6522: Avg loss so far = 1.132781\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6523: Avg loss so far = 1.132608\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6524: Avg loss so far = 1.132434\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6525: Avg loss so far = 1.132261\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6526: Avg loss so far = 1.132087\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6527: Avg loss so far = 1.131914\n",
      "     Misclassifications: 269\n",
      "\n",
      "k=6528: Avg loss so far = 1.131740\n",
      "     Misclassifications: 270\n",
      "\n",
      "k=6529: Avg loss so far = 1.132180\n",
      "     Misclassifications: 270\n",
      "\n",
      "k=6530: Avg loss so far = 1.132006\n",
      "     Misclassifications: 270\n",
      "\n",
      "k=6531: Avg loss so far = 1.131833\n",
      "     Misclassifications: 270\n",
      "\n",
      "k=6532: Avg loss so far = 1.131660\n",
      "     Misclassifications: 270\n",
      "\n",
      "k=6533: Avg loss so far = 1.131486\n",
      "     Misclassifications: 270\n",
      "\n",
      "k=6534: Avg loss so far = 1.131313\n",
      "     Misclassifications: 270\n",
      "\n",
      "k=6535: Avg loss so far = 1.131140\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6536: Avg loss so far = 1.133415\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6537: Avg loss so far = 1.133242\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6538: Avg loss so far = 1.133068\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6539: Avg loss so far = 1.132895\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6540: Avg loss so far = 1.132722\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6541: Avg loss so far = 1.132549\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6542: Avg loss so far = 1.132375\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6543: Avg loss so far = 1.132202\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6544: Avg loss so far = 1.132029\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6545: Avg loss so far = 1.131856\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6546: Avg loss so far = 1.131683\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6547: Avg loss so far = 1.131511\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6548: Avg loss so far = 1.131338\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6549: Avg loss so far = 1.131165\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6550: Avg loss so far = 1.130992\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6551: Avg loss so far = 1.130820\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6552: Avg loss so far = 1.130647\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6553: Avg loss so far = 1.130475\n",
      "     Misclassifications: 271\n",
      "\n",
      "k=6554: Avg loss so far = 1.130302\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6555: Avg loss so far = 1.132571\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6556: Avg loss so far = 1.132398\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6557: Avg loss so far = 1.132225\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6558: Avg loss so far = 1.132052\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6559: Avg loss so far = 1.131880\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6560: Avg loss so far = 1.131707\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6561: Avg loss so far = 1.131535\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6562: Avg loss so far = 1.131362\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6563: Avg loss so far = 1.131190\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6564: Avg loss so far = 1.131018\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6565: Avg loss so far = 1.130845\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6566: Avg loss so far = 1.130673\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6567: Avg loss so far = 1.130501\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6568: Avg loss so far = 1.130329\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6569: Avg loss so far = 1.130157\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6570: Avg loss so far = 1.129985\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6571: Avg loss so far = 1.129813\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6572: Avg loss so far = 1.129641\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6573: Avg loss so far = 1.129469\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6574: Avg loss so far = 1.129297\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6575: Avg loss so far = 1.129125\n",
      "     Misclassifications: 272\n",
      "\n",
      "k=6576: Avg loss so far = 1.128954\n",
      "     Misclassifications: 273\n",
      "\n",
      "k=6577: Avg loss so far = 1.138513\n",
      "     Misclassifications: 273\n",
      "\n",
      "k=6578: Avg loss so far = 1.138340\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6579: Avg loss so far = 1.138775\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6580: Avg loss so far = 1.138602\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6581: Avg loss so far = 1.138429\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6582: Avg loss so far = 1.138256\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6583: Avg loss so far = 1.138083\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6584: Avg loss so far = 1.137910\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6585: Avg loss so far = 1.137737\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6586: Avg loss so far = 1.137565\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6587: Avg loss so far = 1.137392\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6588: Avg loss so far = 1.137219\n",
      "     Misclassifications: 274\n",
      "\n",
      "k=6589: Avg loss so far = 1.137047\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6590: Avg loss so far = 1.137481\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6591: Avg loss so far = 1.137308\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6592: Avg loss so far = 1.137136\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6593: Avg loss so far = 1.136963\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6594: Avg loss so far = 1.136791\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6595: Avg loss so far = 1.136619\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6596: Avg loss so far = 1.136446\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6597: Avg loss so far = 1.136274\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6598: Avg loss so far = 1.136102\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6599: Avg loss so far = 1.135930\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6600: Avg loss so far = 1.135758\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6601: Avg loss so far = 1.135586\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6602: Avg loss so far = 1.135414\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6603: Avg loss so far = 1.135242\n",
      "     Misclassifications: 275\n",
      "\n",
      "k=6604: Avg loss so far = 1.135070\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6605: Avg loss so far = 1.144587\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6606: Avg loss so far = 1.144414\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6607: Avg loss so far = 1.144241\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6608: Avg loss so far = 1.144068\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6609: Avg loss so far = 1.143895\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6610: Avg loss so far = 1.143722\n",
      "     Misclassifications: 276\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=6611: Avg loss so far = 1.143549\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6612: Avg loss so far = 1.143376\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6613: Avg loss so far = 1.143203\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6614: Avg loss so far = 1.143030\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6615: Avg loss so far = 1.142857\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6616: Avg loss so far = 1.142684\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6617: Avg loss so far = 1.142512\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6618: Avg loss so far = 1.142339\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6619: Avg loss so far = 1.142166\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6620: Avg loss so far = 1.141994\n",
      "     Misclassifications: 276\n",
      "\n",
      "k=6621: Avg loss so far = 1.141821\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6622: Avg loss so far = 1.144065\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6623: Avg loss so far = 1.143892\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6624: Avg loss so far = 1.143720\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6625: Avg loss so far = 1.143547\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6626: Avg loss so far = 1.143375\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6627: Avg loss so far = 1.143202\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6628: Avg loss so far = 1.143030\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6629: Avg loss so far = 1.142857\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6630: Avg loss so far = 1.142685\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6631: Avg loss so far = 1.142512\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6632: Avg loss so far = 1.142340\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6633: Avg loss so far = 1.142168\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6634: Avg loss so far = 1.141996\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6635: Avg loss so far = 1.141824\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6636: Avg loss so far = 1.141652\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6637: Avg loss so far = 1.141480\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6638: Avg loss so far = 1.141308\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6639: Avg loss so far = 1.141136\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6640: Avg loss so far = 1.140964\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6641: Avg loss so far = 1.140792\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6642: Avg loss so far = 1.140620\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6643: Avg loss so far = 1.140449\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6644: Avg loss so far = 1.140277\n",
      "     Misclassifications: 277\n",
      "\n",
      "k=6645: Avg loss so far = 1.140105\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6646: Avg loss so far = 1.142341\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6647: Avg loss so far = 1.142169\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6648: Avg loss so far = 1.141998\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6649: Avg loss so far = 1.141826\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6650: Avg loss so far = 1.141654\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6651: Avg loss so far = 1.141482\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6652: Avg loss so far = 1.141311\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6653: Avg loss so far = 1.141139\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6654: Avg loss so far = 1.140968\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6655: Avg loss so far = 1.140796\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6656: Avg loss so far = 1.140625\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6657: Avg loss so far = 1.140454\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6658: Avg loss so far = 1.140282\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6659: Avg loss so far = 1.140111\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6660: Avg loss so far = 1.139940\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6661: Avg loss so far = 1.139769\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6662: Avg loss so far = 1.139598\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6663: Avg loss so far = 1.139427\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6664: Avg loss so far = 1.139256\n",
      "     Misclassifications: 278\n",
      "\n",
      "k=6665: Avg loss so far = 1.139085\n",
      "     Misclassifications: 279\n",
      "\n",
      "k=6666: Avg loss so far = 1.139514\n",
      "     Misclassifications: 279\n",
      "\n",
      "k=6667: Avg loss so far = 1.139343\n",
      "     Misclassifications: 279\n",
      "\n",
      "k=6668: Avg loss so far = 1.139172\n",
      "     Misclassifications: 279\n",
      "\n",
      "k=6669: Avg loss so far = 1.139001\n",
      "     Misclassifications: 279\n",
      "\n",
      "k=6670: Avg loss so far = 1.138831\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6671: Avg loss so far = 1.141058\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6672: Avg loss so far = 1.140887\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6673: Avg loss so far = 1.140716\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6674: Avg loss so far = 1.140545\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6675: Avg loss so far = 1.140375\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6676: Avg loss so far = 1.140204\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6677: Avg loss so far = 1.140033\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6678: Avg loss so far = 1.139862\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6679: Avg loss so far = 1.139692\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6680: Avg loss so far = 1.139521\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6681: Avg loss so far = 1.139350\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6682: Avg loss so far = 1.139180\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6683: Avg loss so far = 1.139009\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6684: Avg loss so far = 1.138839\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6685: Avg loss so far = 1.138669\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6686: Avg loss so far = 1.138498\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6687: Avg loss so far = 1.138328\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6688: Avg loss so far = 1.138158\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6689: Avg loss so far = 1.137988\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6690: Avg loss so far = 1.137818\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6691: Avg loss so far = 1.137648\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6692: Avg loss so far = 1.137478\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6693: Avg loss so far = 1.137308\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6694: Avg loss so far = 1.137138\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6695: Avg loss so far = 1.136968\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6696: Avg loss so far = 1.136798\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6697: Avg loss so far = 1.136628\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6698: Avg loss so far = 1.136459\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6699: Avg loss so far = 1.136289\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6700: Avg loss so far = 1.136119\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6701: Avg loss so far = 1.135950\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6702: Avg loss so far = 1.135780\n",
      "     Misclassifications: 280\n",
      "\n",
      "k=6703: Avg loss so far = 1.135611\n",
      "     Misclassifications: 281\n",
      "\n",
      "k=6704: Avg loss so far = 1.144988\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6705: Avg loss so far = 1.144966\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6706: Avg loss so far = 1.144796\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6707: Avg loss so far = 1.144625\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6708: Avg loss so far = 1.144454\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6709: Avg loss so far = 1.144284\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6710: Avg loss so far = 1.144113\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6711: Avg loss so far = 1.143943\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6712: Avg loss so far = 1.143772\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6713: Avg loss so far = 1.143602\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6714: Avg loss so far = 1.143432\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6715: Avg loss so far = 1.143261\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6716: Avg loss so far = 1.143091\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6717: Avg loss so far = 1.142921\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6718: Avg loss so far = 1.142751\n",
      "     Misclassifications: 282\n",
      "\n",
      "k=6719: Avg loss so far = 1.142581\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6720: Avg loss so far = 1.151935\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6721: Avg loss so far = 1.151763\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6722: Avg loss so far = 1.151592\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6723: Avg loss so far = 1.151420\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6724: Avg loss so far = 1.151249\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6725: Avg loss so far = 1.151078\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6726: Avg loss so far = 1.150907\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6727: Avg loss so far = 1.150736\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6728: Avg loss so far = 1.150565\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6729: Avg loss so far = 1.150394\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6730: Avg loss so far = 1.150223\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6731: Avg loss so far = 1.150052\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6732: Avg loss so far = 1.149881\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6733: Avg loss so far = 1.149710\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6734: Avg loss so far = 1.149540\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6735: Avg loss so far = 1.149369\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6736: Avg loss so far = 1.149198\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6737: Avg loss so far = 1.149028\n",
      "     Misclassifications: 283\n",
      "\n",
      "k=6738: Avg loss so far = 1.148857\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6739: Avg loss so far = 1.158184\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6740: Avg loss so far = 1.158012\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6741: Avg loss so far = 1.157840\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6742: Avg loss so far = 1.157668\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6743: Avg loss so far = 1.157497\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6744: Avg loss so far = 1.157325\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6745: Avg loss so far = 1.157153\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6746: Avg loss so far = 1.156982\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6747: Avg loss so far = 1.156810\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6748: Avg loss so far = 1.156639\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6749: Avg loss so far = 1.156468\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6750: Avg loss so far = 1.156296\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6751: Avg loss so far = 1.156125\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6752: Avg loss so far = 1.155954\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6753: Avg loss so far = 1.155783\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6754: Avg loss so far = 1.155611\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6755: Avg loss so far = 1.155440\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6756: Avg loss so far = 1.155269\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6757: Avg loss so far = 1.155098\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6758: Avg loss so far = 1.154927\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6759: Avg loss so far = 1.154757\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6760: Avg loss so far = 1.154586\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6761: Avg loss so far = 1.154415\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6762: Avg loss so far = 1.154244\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6763: Avg loss so far = 1.154074\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6764: Avg loss so far = 1.153903\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6765: Avg loss so far = 1.153732\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6766: Avg loss so far = 1.153562\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6767: Avg loss so far = 1.153391\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6768: Avg loss so far = 1.153221\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6769: Avg loss so far = 1.153051\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6770: Avg loss so far = 1.152880\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6771: Avg loss so far = 1.152710\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6772: Avg loss so far = 1.152540\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6773: Avg loss so far = 1.152370\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6774: Avg loss so far = 1.152200\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6775: Avg loss so far = 1.152030\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6776: Avg loss so far = 1.151860\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6777: Avg loss so far = 1.151690\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6778: Avg loss so far = 1.151520\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6779: Avg loss so far = 1.151350\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6780: Avg loss so far = 1.151180\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6781: Avg loss so far = 1.151010\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6782: Avg loss so far = 1.150840\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6783: Avg loss so far = 1.150671\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6784: Avg loss so far = 1.150501\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6785: Avg loss so far = 1.150332\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6786: Avg loss so far = 1.150162\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6787: Avg loss so far = 1.149993\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6788: Avg loss so far = 1.149823\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6789: Avg loss so far = 1.149654\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6790: Avg loss so far = 1.149485\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6791: Avg loss so far = 1.149315\n",
      "     Misclassifications: 284\n",
      "\n",
      "k=6792: Avg loss so far = 1.149146\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6793: Avg loss so far = 1.149124\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6794: Avg loss so far = 1.148955\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6795: Avg loss so far = 1.148786\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6796: Avg loss so far = 1.148617\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6797: Avg loss so far = 1.148448\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6798: Avg loss so far = 1.148279\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6799: Avg loss so far = 1.148110\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6800: Avg loss so far = 1.147941\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6801: Avg loss so far = 1.147772\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6802: Avg loss so far = 1.147604\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6803: Avg loss so far = 1.147435\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6804: Avg loss so far = 1.147266\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6805: Avg loss so far = 1.147098\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6806: Avg loss so far = 1.146929\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6807: Avg loss so far = 1.146761\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6808: Avg loss so far = 1.146592\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6809: Avg loss so far = 1.146424\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6810: Avg loss so far = 1.146256\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6811: Avg loss so far = 1.146087\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6812: Avg loss so far = 1.145919\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6813: Avg loss so far = 1.145751\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6814: Avg loss so far = 1.145583\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6815: Avg loss so far = 1.145415\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6816: Avg loss so far = 1.145246\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6817: Avg loss so far = 1.145078\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6818: Avg loss so far = 1.144911\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6819: Avg loss so far = 1.144743\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6820: Avg loss so far = 1.144575\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6821: Avg loss so far = 1.144407\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6822: Avg loss so far = 1.144239\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6823: Avg loss so far = 1.144072\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6824: Avg loss so far = 1.143904\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6825: Avg loss so far = 1.143736\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6826: Avg loss so far = 1.143569\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6827: Avg loss so far = 1.143401\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6828: Avg loss so far = 1.143234\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6829: Avg loss so far = 1.143066\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6830: Avg loss so far = 1.142899\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6831: Avg loss so far = 1.142732\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6832: Avg loss so far = 1.142564\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6833: Avg loss so far = 1.142397\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6834: Avg loss so far = 1.142230\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6835: Avg loss so far = 1.142063\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6836: Avg loss so far = 1.141896\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6837: Avg loss so far = 1.141729\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6838: Avg loss so far = 1.141562\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6839: Avg loss so far = 1.141395\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6840: Avg loss so far = 1.141228\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6841: Avg loss so far = 1.141061\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6842: Avg loss so far = 1.140894\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6843: Avg loss so far = 1.140728\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6844: Avg loss so far = 1.140561\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6845: Avg loss so far = 1.140394\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6846: Avg loss so far = 1.140228\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6847: Avg loss so far = 1.140061\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6848: Avg loss so far = 1.139895\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6849: Avg loss so far = 1.139728\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6850: Avg loss so far = 1.139562\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6851: Avg loss so far = 1.139396\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6852: Avg loss so far = 1.139229\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6853: Avg loss so far = 1.139063\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6854: Avg loss so far = 1.138897\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6855: Avg loss so far = 1.138731\n",
      "     Misclassifications: 285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k=6856: Avg loss so far = 1.138565\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6857: Avg loss so far = 1.138399\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6858: Avg loss so far = 1.138233\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6859: Avg loss so far = 1.138067\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6860: Avg loss so far = 1.137901\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6861: Avg loss so far = 1.137735\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6862: Avg loss so far = 1.137569\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6863: Avg loss so far = 1.137403\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6864: Avg loss so far = 1.137238\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6865: Avg loss so far = 1.137072\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6866: Avg loss so far = 1.136906\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6867: Avg loss so far = 1.136741\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6868: Avg loss so far = 1.136575\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6869: Avg loss so far = 1.136410\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6870: Avg loss so far = 1.136245\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6871: Avg loss so far = 1.136079\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6872: Avg loss so far = 1.135914\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6873: Avg loss so far = 1.135749\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6874: Avg loss so far = 1.135583\n",
      "     Misclassifications: 285\n",
      "\n",
      "k=6875: Avg loss so far = 1.135418\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6876: Avg loss so far = 1.135835\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6877: Avg loss so far = 1.135670\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6878: Avg loss so far = 1.135505\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6879: Avg loss so far = 1.135339\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6880: Avg loss so far = 1.135174\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6881: Avg loss so far = 1.135009\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6882: Avg loss so far = 1.134845\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6883: Avg loss so far = 1.134680\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6884: Avg loss so far = 1.134515\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6885: Avg loss so far = 1.134350\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6886: Avg loss so far = 1.134185\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6887: Avg loss so far = 1.134021\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6888: Avg loss so far = 1.133856\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6889: Avg loss so far = 1.133691\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6890: Avg loss so far = 1.133527\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6891: Avg loss so far = 1.133362\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6892: Avg loss so far = 1.133198\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6893: Avg loss so far = 1.133034\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6894: Avg loss so far = 1.132869\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6895: Avg loss so far = 1.132705\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6896: Avg loss so far = 1.132541\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6897: Avg loss so far = 1.132376\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6898: Avg loss so far = 1.132212\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6899: Avg loss so far = 1.132048\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6900: Avg loss so far = 1.131884\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6901: Avg loss so far = 1.131720\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6902: Avg loss so far = 1.131556\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6903: Avg loss so far = 1.131392\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6904: Avg loss so far = 1.131228\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6905: Avg loss so far = 1.131064\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6906: Avg loss so far = 1.130901\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6907: Avg loss so far = 1.130737\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6908: Avg loss so far = 1.130573\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6909: Avg loss so far = 1.130410\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6910: Avg loss so far = 1.130246\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6911: Avg loss so far = 1.130082\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6912: Avg loss so far = 1.129919\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6913: Avg loss so far = 1.129756\n",
      "     Misclassifications: 286\n",
      "\n",
      "k=6914: Avg loss so far = 1.129592\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6915: Avg loss so far = 1.143890\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6916: Avg loss so far = 1.143725\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6917: Avg loss so far = 1.143559\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6918: Avg loss so far = 1.143394\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6919: Avg loss so far = 1.143229\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6920: Avg loss so far = 1.143064\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6921: Avg loss so far = 1.142898\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6922: Avg loss so far = 1.142733\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6923: Avg loss so far = 1.142568\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6924: Avg loss so far = 1.142403\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6925: Avg loss so far = 1.142238\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6926: Avg loss so far = 1.142073\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6927: Avg loss so far = 1.141908\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6928: Avg loss so far = 1.141744\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6929: Avg loss so far = 1.141579\n",
      "     Misclassifications: 287\n",
      "\n",
      "k=6930: Avg loss so far = 1.141414\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6931: Avg loss so far = 1.150483\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6932: Avg loss so far = 1.150317\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6933: Avg loss so far = 1.150151\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6934: Avg loss so far = 1.149986\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6935: Avg loss so far = 1.149820\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6936: Avg loss so far = 1.149654\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6937: Avg loss so far = 1.149488\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6938: Avg loss so far = 1.149323\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6939: Avg loss so far = 1.149157\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6940: Avg loss so far = 1.148991\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6941: Avg loss so far = 1.148826\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6942: Avg loss so far = 1.148660\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6943: Avg loss so far = 1.148495\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6944: Avg loss so far = 1.148329\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6945: Avg loss so far = 1.148164\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6946: Avg loss so far = 1.147999\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6947: Avg loss so far = 1.147834\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6948: Avg loss so far = 1.147668\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6949: Avg loss so far = 1.147503\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6950: Avg loss so far = 1.147338\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6951: Avg loss so far = 1.147173\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6952: Avg loss so far = 1.147008\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6953: Avg loss so far = 1.146843\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6954: Avg loss so far = 1.146678\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6955: Avg loss so far = 1.146513\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6956: Avg loss so far = 1.146348\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6957: Avg loss so far = 1.146184\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6958: Avg loss so far = 1.146019\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6959: Avg loss so far = 1.145854\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6960: Avg loss so far = 1.145690\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6961: Avg loss so far = 1.145525\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6962: Avg loss so far = 1.145361\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6963: Avg loss so far = 1.145196\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6964: Avg loss so far = 1.145032\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6965: Avg loss so far = 1.144867\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6966: Avg loss so far = 1.144703\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6967: Avg loss so far = 1.144539\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6968: Avg loss so far = 1.144374\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6969: Avg loss so far = 1.144210\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6970: Avg loss so far = 1.144046\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6971: Avg loss so far = 1.143882\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6972: Avg loss so far = 1.143718\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6973: Avg loss so far = 1.143554\n",
      "     Misclassifications: 288\n",
      "\n",
      "k=6974: Avg loss so far = 1.143390\n",
      "     Misclassifications: 289\n",
      "\n",
      "k=6975: Avg loss so far = 1.152401\n",
      "     Misclassifications: 289\n",
      "\n",
      "k=6976: Avg loss so far = 1.152236\n",
      "     Misclassifications: 289\n",
      "\n",
      "k=6977: Avg loss so far = 1.152071\n",
      "     Misclassifications: 289\n",
      "\n",
      "k=6978: Avg loss so far = 1.151906\n",
      "     Misclassifications: 289\n",
      "\n",
      "k=6979: Avg loss so far = 1.151741\n",
      "     Misclassifications: 289\n",
      "\n",
      "k=6980: Avg loss so far = 1.151576\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6981: Avg loss so far = 1.160579\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6982: Avg loss so far = 1.160412\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6983: Avg loss so far = 1.160246\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6984: Avg loss so far = 1.160080\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6985: Avg loss so far = 1.159914\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6986: Avg loss so far = 1.159748\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6987: Avg loss so far = 1.159582\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6988: Avg loss so far = 1.159416\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6989: Avg loss so far = 1.159250\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6990: Avg loss so far = 1.159084\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6991: Avg loss so far = 1.158919\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6992: Avg loss so far = 1.158753\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6993: Avg loss so far = 1.158587\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6994: Avg loss so far = 1.158422\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6995: Avg loss so far = 1.158256\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6996: Avg loss so far = 1.158090\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6997: Avg loss so far = 1.157925\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6998: Avg loss so far = 1.157759\n",
      "     Misclassifications: 290\n",
      "\n",
      "k=6999: Avg loss so far = 1.157594\n",
      "     Misclassifications: 290\n",
      "\n",
      "1.15742857143\n",
      "Misclassified 290 out of 7000 -> Loss of 4.14 percent\n",
      "\n",
      "28.749242544174194  seconds have elapsed during testing\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    t = time.time()\n",
    "    avg_loss, misclfd, total_num = D.test(test_data_path, test_label_path,noise=mynoise,use_data_subset=7000,fuzzify=0)\n",
    "    print(avg_loss)\n",
    "    print('Misclassified %d out of %d -> Loss of %.2f percent\\n'%(misclfd,total_num,100*misclfd/total_num))\n",
    "    elapsed = time.time() - t\n",
    "    print(elapsed,' seconds have elapsed during testing')\n",
    "except:\n",
    "    print('Some error occurred, probably test data file size exceeds maximum permitted size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bit error rate: 0.09850\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tbit = 0.003\n",
    "bits_per_slot = 4\n",
    "\n",
    "decoded = D.decode_binary('test_message.csv',Tbit,bits_per_slot)\n",
    "original = D.raw_datatable_load('test_message_bin.csv')\n",
    "srec = D.raw_datatable_load('test_message.csv')\n",
    "\n",
    "diff = decoded - original \n",
    "BER = float(len(diff[diff!=0])/original.shape[1])\n",
    "\n",
    "print(\"Bit error rate: %.5f\\n\"%(BER))\n",
    "plt.plot(srec[1,:])\n",
    "plt.title('Transmitted random message')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(diff[0,:]!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_model\\DECODER_090.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(D.save())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Progress\n",
    "-  _MATLAB_ framework to generate and store training and test data according to one parameter set, and later test cases with the same parameters\n",
    "-  _DECODER_ in Python plus functionality to automatically disasseble any received message from _MATLAB_ framework into slots and decode\n",
    "-  Set parameters in _MATLAB_, train and test _DECODER_, then enter arbitrary string in _MATLAB_, generate the corresponding received sequence, and fully decode within python _DECODER_, to output original string\n",
    "-  __Currently__: The framework is there, but  $BER\\approx 4\\%$  is insufficient to reliably transmit text, so I'm working on improving that by tweaking the _DECODER_ neural network a bit\n",
    "\n",
    "***\n",
    "\n",
    "### Issues\n",
    "-  Having some trouble with arbitrary received data  $\\Rightarrow$ **SOLVED**\n",
    "    -  Subsequent slots aren't always of _DECODER_ required input length\n",
    "    -  <del>Hence my solution: Resample data</del>\n",
    "    -  <del>But this changes some of the features which _DECODER_ uses for classification (apparently)</del>\n",
    "    -  Was an issue with the _MATLAB_ script used to generate data, fixed it\n",
    "-  In-between slots, channel needs a certain cooldown period or else detection is less reliable  $\\Rightarrow$ **SOLVED**\n",
    "    -  I.e. _DECODER_ deals well with interference within one slot, but not in-between slots\n",
    "    -  This is mainly because slot interference is not factored into the training process at this point\n",
    "\n",
    "***\n",
    "\n",
    "### My planned solution\n",
    "-  [x] Incorporate resampling into the training process\n",
    "-  [x] Incorporate slot-to-slot interference into the training process\n",
    "-  <del>[ ] Increase number of bits per slot which can be decoded at once (Four and five bits per slot work, after that training process takes a lot more data)</del>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### TODO\n",
    "-  [x]  Plot BER over different NN architectures\n",
    "-  [x]  Plot BER over different training data corpus sizes\n",
    "-  [ ]  Build a gradually more complex scenario and show effect on BER\n",
    "    -  Network size can vary\n",
    "    -  Training data corpus size can vary\n",
    "    -  Randomness may vary\n",
    "    -  $T_{\\text{bit}}$ may vary\n",
    "-  [ ]  For each scenario, construct a pseudo-optimal neural network for the _DECODER_\n",
    "-  [ ]  Try with Harald data\n",
    "-  [x]  Increase number of bits per slot which can be decoded at once -> Works, but requires more layers and accordingly, longer training times. Had to add one layer for 4-bit slots\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 100)\n",
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "DATA, LABELS = D.load_data_and_labels(manualtrial_data_path,manualtrial_label_path,noise=mynoise)\n",
    "DATA,_ = D.norm_data(DATA,[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGWCAYAAABW5tXRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXl8o3d9598/XdZhS77PuSfJTDK5Z0II4ZhAyn2Xo1DYhS1lt91t6bbb0mVbaHehLVCOtrRQWraFLnSXI5xpgITOhOYgJJlccyZzz/g+JUvWrd/+8TyPLMmybMuSLEvf9+vll+3neST9Hll+Ps/3VlprBEEQBGGt2DZ6AYIgCMLmRAREEARBKAsREEEQBKEsREAEQRCEshABEQRBEMpCBEQQBEEoCxEQYdUopQ4rpd63zL4/Ukr9n1U+zz8qpT5a5hpW/VhzTUmlVFgp5Svn9cpYW1Qpdbnar7UalFI7lFJaKeWo8LEHyz3HtTw2Z01hpdT7y3m9Is95RimVWO1nVSiNCEiDoZQ6b17EwkqpMfOi1rrR69pA/p/WulVrHSm2Uyn1NqXUQ0qpBaXU4SL7v6iUOqWUyiil3lPqhbTW7wFeVYlFC3m0a62/CKCUcimlvml+zrVS6mDugUqpO5RSh5RSQaXU+cIn0lrvBv6kJqtuAkRAGpPXaa1bgRuBm4D/vsHrqWdmgM8Cf7bM/qeAXweO1GxFRVAG8v9q8ADwLmCsyL4I8L+B363pipoU+UA2MFrrMeBHGEICgFKqRSn150qpi0qpcaXUF5RSHnNfh1LqB0qpSaXUrPnzlnJeWyn1DdMCCiqlfqqU2ldwSLdS6l6l1LxS6n6l1Pacx+41982Yd/9vK2cNq0FrfZ/W+uvAyDL7/1pr/RMgVunXVkq9Ryn1oFLqr8z36aRS6mU5+w8rpT6mlHoQWAB2KaUCSqkvKaVGlVLDSqmPKqXs5vF28287pZQ6C7xmHWt7r1LqhPn3OauU+o9FjvmQ+VrnlVK/nLN92c/YetFaJ7TWn9VaPwCki+z/udb6n4CzlXg9oTQiIA2MefF/FXA6Z/PHgaswROUKYAj4sLnPBvwDsB3YBkSBz5X58vcAVwK9GHfvXy3Y/8vA/wK6gSet/Was4l7ga+Zj3wH8TREBss5xTin1wjLXWA/cinGx6wY+AtyllOrM2f9u4P1AG3AB+DKQwvjb3QS8HLDiUr8KvNbcfgB4yzrWNWE+lx94L/AZpdTNOfv7zTUPAf8e+KJSao+5r9RnLA+l1N8opf5mHesUNhARkMbkO0qpeeASxoXgI2C4QTAuMv9Vaz2jtZ7H8Af/EoDWelpr/S2t9YK572PAS8pZgNb6f2ut57XWceCPgBuUUoGcQ+7WWv/U3P8/gNuUUlsxLlrntdb/oLVOaa2PAN9imYuh1rrdvBvdrEwAn9VaJ7XW/w84Rb7l8I9a62Na6xTQiXFD8Fta64jWegL4DObfD3ib+VyXtNYzwJ+Wuyit9d1a6zPa4H7gx8CLCg77Q6113Nx/N/C2lT5jRV7n17XWv17uOoWNZcWMC2FT8kat9X1KqZdg3Ml3A3NAD+AFHjf+zwFQgOUC8WJckF4JdJj725RSdq31EnfBcpgulY8BbzVfM2Pu6gaC5s+XrOO11mGl1AwwiGH93KqUmst5SgfwT6t9/U3GsM7vaHoB432wuJTz83bACYzm/P1sOccMFhx/odxFKaVehXHjcZX5Gl7gmZxDZgsSE6x1l/yMCY2FCEgDo7W+Xyn1j8CfA28EpjDcUvu01sNFHvI7wB7gVq31mFLqRuAJjAvAWngn8AbgTuA8EABmC55nq/WDmSXWiRGHuATcr7X+hTW+5mZlSCmlckRkG/C9nP254nIJiAPdpkVSyCg576v5XGtGKdWCYfX9O+C7WuukUuo75P/9OpRSvhwR2QYcZeXPmNBAiAur8fks8AtKqRu11hng7zD82b0ASqkhpdQrzGPbMP7550w//EfKfM02jAvdNMbdaLG0yVcrpV6olHJhxEIe0VpfAn4AXKWUerdSyml+3aKUurrMtZTEDDy7MW6mbEopt1LKmbPfZe5XgNPcv+r/GzMQ/kclDukFftM8z7cCVwP/UuxArfUohivpU0opv1LKppTabVqaAF83n2uLUqoD+P3VrrMAF9ACTAIp0xp5eZHj/th8f16E4Xr8xio+Y+vGDNK7rbWafxNl7rOZ+5zGr8ptfsaEKiAC0uBorSeBrwB/aG76IEZQ/WdKqRBwH4bVAYbYeDDuIn8G/LDMl/0KhktjGDhuPlchX8MQqBlgP0ZQHdNn/nIMn/kIRqrmxzEuaEtQRr1LoW9+LbwbQzQ/j+Hjj2JcAC1+bG57AfBF8+cXm6/9y0qpYys8/1bgwRL7H8FINpjCcPu9RWs9XeL4f4dxgT+OYdV9Exgw9/0dRtbdUxiJC3flPtDMhvrCCuu1/ga/iSFIsxgW5fcKDhsz941gJED8J631SXNfqc9YHqtdUwGnMP4OQxjnG8Vw74Hxt4liiLCVCPLjNT6/sEqUDJQSGhWl1B9g1MAkgaHligkr+Hpfwoj7TGitrzCz4L6htb5tmePfA7xPa72Zs8iqhjJSu09hpFD/rtb671Z4yGqe8xSG8Hxda/0f1vt8zY4IiCBsECIgwmanai4spdRWZbQUOKGUOqaU+kCRYwJKqe8rpZ4yj3lvtdYjCIIgVJaqWSBKqQFgQGt9RCnVBjyOkV56POeYDwEBrfUHlVI9GOZqv9Y6UZVFCYIgCBWjahaI1nrULAKzgnInMHyPeYdh1BkooBUjoFosPVEQBEGoM2pSB6KU2oHRXuGRgl2fw8juGMFI/Xy7mQZY+Pj3Y7RzwOPx7N+6dWvhIasmk8lgszVn8lkznzs09/k387lDc59/Oef+7LPPTmmte1Y8UGtd1S8My+Jx4M1F9r0Fo/JZYfTMOQf4Sz3f/v379Xo4dOjQuh6/mWnmc9e6uc+/mc9d6+Y+/3LOHXhMr+L6XlVJNguyvgV8VWt9V5FD3gvcZa75tCkge6u5JkEQBKEyVDMLSwFfAk5orT+9zGEXgZeZx/dhFBtJG2ZBEIRNQDVjILdjVPk+o5R60tz2Icz+PFrrL2C0sPhHpdQzGG6sD2qtp6q4JkEQBKFCVE1AtNFiu2QTPq31CMV77AiCIAh1TnOmJQiCIAjrRgREEARBKAsREEEQBKEsREAEQRCEshABEQRBEMpCBEQQBEEoCxEQQRAEoSxEQARBEISyEAERBEEQykIEpAH46A+O8/2nRjZ6GYIgNBkiIA3A1x+7xH0nxjd6GYIgNBkiIJucTEYzH08xH5NBjoIg1BYRkE1OOJFCa5iPJTd6KYIgNBkiIJucUNQQDrFABEGoNSIgm5xQ1BAOERBBEGqNCMgmx3JdiQtLEIRaIwKyyQmZlkc4nkJrvcGrEQShmRAB2eRYMZCMhoVEeoNXIwhCMyECsskJ5biuJA4iCEItEQHZ5FhBdJA4iCAItUUEZJOTa4GExAIRBKGGiIBscqwYCBiBdEEQhFohAlLHHLk4y7u/9AgLieWFIRRLYrcpQFxYgiDUFhGQOuaeZ0b5t+em+MmJiWWPCUVT9PvdgATRBUGoLSIgdczR4RBAyVbtoViSoQ4PIBaIIAi1RQSkTtFac3QkiE3B4VOTecHyXEKxJAMBN0pBWCwQQRBqiAhInXJpJsp8LMVb9m8hkc7w42PF532EoinaPU5aXQ7JwhIEoaaIgNQpR0eCAPzyrdvZ0uEp6sbKZDTzsSR+j5M2t0NiIIIg1BQRkDrl2EgQh02xp7+N190wyAOnp5iJJPKOiSRSZDT43U7a3E6JgQiCUFNEQOqUo8Mhruxrw+2087rrB0lnNPccHc07xnJZ+T0OWt0OqQMRBKGmiIDUIVprjg4HuXbQD8DVA23s7vEtcWNZRYSGBSIuLEEQaosISB0yHoozHUmwzxQQpRSvu2GQR87NMB6KZY/LCohHXFiCINQeEZA65OiwEUC/diiQ3XZwTy9aw1OX5rLbsi4ssUAEQdgAREDqkGMjIZSCqwf82W1D7Uax4FhRC8RBW4uDeYmBCIJQQ0RA6pCjI0F2dfvwtTiy27p8Lpx2xWgwR0Bi+TGQRCpDPCVDpQRBqA0iIHXIseFgnvsKwGZT9PndjM5Fs9usWSBtbgdtbicg/bAEQagdIiB1xnQ4zkgwlg2g5zIY8CyxQHwuOw67jTa3Ya2IgAiCUCtEQOqMYyNGA8VrBwNL9vUH3EtiIH6PYXm0mu4u6YclCEKtEAGpMywB2VdEQAYCbkaDMbTWgGGB+E3X1aILS1J5BUGoDSIgdcbRkSBbOjwEvM4l+wYCbhKpTLalSSiawu8xLA/LhSUNFQVBqBUiIHXGiZFQ0fgHQH/ASOW14iDz8UULxPou7UwEQagVIiB1RCSe4tx0hGsGlrqvwLBAYFFADAvEjIFkg+jiwhIEoTaIgNQRJ0ZDaM2yFshAuyEgY0EjldeIgeS7sJbLwkqmM5yZkxoRQRAqhwhIHXF81AygDxUXkG5fCw6bygbSc7OwnHYbbqdtWQvkB0+P8L9+FmMkp45EEARhPYiA1BHHhkN0eJ30+91F92eLCYMxIol0dhaIRZvbuWwM5NzUAgAT8/HKL1wQhKZEBKSOOD4aYt9gAKXUsscMtrsZDUbz+mBZtLUsP9bWsjxmFxJF9wuCIKwVEZA6IZnOcGpsnmuWiX9Y9Ac8jAVjeX2wLEp15LUEZE4ERBCECiECUiecmQyTSGeWDaBbWMWEwYXFWSAWpWaCLAqIZGkJglAZREDqhGPDRgD9moGVBSSeynBhxohpWNlX1s/FWplkMpoRM/V3VgREEIQKIQJSJxwbCeF22tjV01ryOKsW5NmxeSDfhdXaUtyFNR1JkEhlAHFhCYJQOURA6oTjo0H29vux25YPoMNiNfqpcVNAVuHCyk3dFReWIAiVQgSkDtBac3wktGIAHWDQtEBOmRZIoQsrkkiTzui8x1gC4rJJFpYgCJVDBKQOuDwbJRRLrRhAB+hqNYoJJ+bjeF12nPbFP6ElJoW1IFb8Y0ubTSwQQRAqhghIHWC1cF8pgA5gN4sJIT/+AbntTPJFYmQuitdlp8+rxAIRBKFiVE1AlFJblVKHlFInlFLHlFIfWOa4g0qpJ81j7q/WeuqZ46MhbAr29q8sILAYSM8tIgSWHWs7MhdlsN1Dq0tl038FQRDWi2PlQ8omBfyO1vqIUqoNeFwpda/W+rh1gFKqHfgb4JVa64tKqd4qrqdueerSHLt6WvG47Ks6vj+wkgWyjIBk4szHkyTTmTzXlyAIQjlU7SqitR7VWh8xf54HTgBDBYe9E7hLa33RPG6iWuupV565HOT+Zyd5xb6+VT9m0QIpFBBrJki+lTE8F2Oo3Y3PaWR4SRxEEIRKUE0LJItSagdwE/BIwa6rAKdS6jDQBvyF1vorRR7/fuD9AH19fRw+fLjstYTD4XU9vpJorfnEozHanLDPNsrhw2Orelxk0hCAaHA671xGwkatxyNHnsE2dgKARFozFY4Tnx3Db0sAinvvf5DB1uazQOrpb19rmvncobnPv5rnXnUBUUq1At8CfktrHSry+vuBlwEe4GGl1M+01s/mHqS1/iLwRYADBw7ogwcPlr2ew4cPs57HV5J/PTnOiZnH+OPX7+PVL9ix6sdFnxnlayePcOWOLRw8eG12+0Qoxoce+Albdl3JwedvB+D8VATuPcztN17D6LmTQJwrr72RW3Z0Vvhs6p96+tvXmmY+d2ju86/muVdVQJRSTgzx+KrW+q4ih1wGprTWESCilPopcAPwbJFjG4pUOsOf/MtJdnb7eOet29b02OVjIFYQfdFFZdWADLZ7mDddWLMRycQSBGH9VDMLSwFfAk5orT+9zGHfBV6klHIopbzArRixkobn649d5vREmA++cs+aA9pD7UY1eqAgBuJ22nDYVF4/rOGsgOTEQKISAxEEYf1U0wK5HXg38IxS6klz24eAbQBa6y9orU8opX4IPA1kgL/XWh+t4prqgsfOz/DxH57kwPYOXrGvf82P7/W7+eRbrufgnvykNaUUrQUt3UfmjCLC/oCbVpcVRBcLRBCE9VM1AdFaPwCUbuxkHPdJ4JPVWke98d0nh/ndbzzNUIeHT73thpLDo0rx1gNbi243ZoLku7B62lpocdhx28FhU9KRVxCEilCTLCzB4K8PneaTPzrF83Z28rfv2k+Hz1Xx12hrceZbIEGjBgQMC6Xd65I0XkEQKkLz5XJuEMNzUT75o1O85roB/ulXnlcV8QDDAgnmxDiG56IMtS/OWG/3Oku6sP7vzy/yb89NVmVtgiA0FiIgNeLCdASAd966jRbH6irOy+GGre0cuTjL8ZEQWmujCt1sAQ/Q4XWW7If15z8+xVcevlC19QmC0DiIgNSI4VkjG8rKoKoWv35wN36Pk//5g2PMLiSJJTNZFxZQ0oUVS6aZCickyC4IwqoQAakRl2ejKAUDOe6katDudfHbv3AVPzs7wz88eA4gX0A8zmUFxEr5lSC7IAirQQSkRgzPRek1s6GqzTuft42r+lr560OngXyrp8PnWtaFZVlJYoEIgrAaREBqxPBstOruKwuH3cYfvvYarMGEAwVB9HgqQyyZXrrGHAtEa71kvyAIQi4iIDXi8twCWzq8NXu9F13Zw51X99HmdtCVk/HV7jF+LmaFWBZIOqMJFbSEFwRBKETqQGpAOqMZnYvx2utrY4FY/OU7bmQ0GMsrVuzwGu1PZiNJBgL567EsEDDcWIWtUgRBEHIRC6QGjIdipDKaLR21FRCvy8Hunta8be1ewwIpFuewLBCAGWm4KAjCCoiA1ADrzr5WMZBStJsWSLGGisNzUXZ0GW42qVYXBGElREBqwOXZBYCaxkCWo8NbPAaSSmcYC8W4dihQdL8gCEIhIiA1oFZFhKsha4EUWBjj83HSGZ0VEHFhCYKwEiIgNWB4Lkp3qwuPq/o1ICvhdtrxOO1LYiCWyO3tb8NuU+LCEgRhRURAasDlGtaArIZ2r3NJtfnw3KKbrd1Tul+WIAgCiIDUhOHZaF3EPyyMfljFLZChdo8pMCIggiCURgSkymQymstzUYZqnMJbig7v0n5Yw3NRunyGm63T52I2Ii4sQRBKIwJSZaYicRKpTM1rQEpRzMK4PLsocu3e5ftlCYIgWIiAVJl6ysCyKNbS3Rg8ZaxxpZkhgiAIIAJSdS5bAlJHFkiH18lcdLFhojV4KisgPpc0VBQEYUVEQKpMPVWhW7R7XKQzmvm40TBxOpIglsxkRa7D6yKRyhAt0rFXEATBQgSkylyeXSDgcdLmrp/GhNliQjNQXuhmyzZclFoQQRBKIAJSZYwU3vqxPmCxnclc1IhzZK2kHAsEYFaq0QVBKIEISJXJDU7XCx0+w8K4NGMIh2WBbGn3mvuXnxkiCIJgIQJSRbTWXK6zIkKAfYMBtnV6+dN7ThCKJRmei+Jz2fF7jPEw4sISBGE1iIBUkbmFJAuJdF1lYIHRD+szbzeGTf3Rd49la0CswVPiwhIEYTWIgFQRK4W33mIgAPu3d/Bf7riCu54Y5oHTk3luNmsSobiwBEEohQhIFXn0/AwAV/a2rnDkxvAbL72Cm7a156XwAjjsNvxuh3TkFQShJCIgVeTbTwxz3VCAXT31KSAOu43Pvv1G2r1OrjPngFh0+lwyE0QQhJI4NnoBjcqz4/M8Mxzkw6+9ZqOXUpLtXT4e/R934rTn30tIPyxBEFZCLJAqcdeRYew2xetvHNzopaxIoXhA8Y69giAIuYiAVIF0RvOdJ4Y5eFUP3a0tG72csujw5ruwvvfUCL/4+YfIZKQ/liAIBiIgVeDhM9OMhWK8+eYtG72Usunw5Q+duuvIZR6/MMv4fGwDVyUIQj0hAlIBhuei/PTZyezd+V1HLtPmdvCyq3s3eGXl0+F1EkmkiafSJNMZfn7OyCg7NxnZ4JUJglAvSBC9Anzqx6e468gwV/W18v4X7+aeo2O88aYh3E77Ri+tbNqtflkLSS7PLrCQMDrznpmK8IIrujdyaYIg1AkiIBVgIhRnIOAG4L994ykAfvHmoY1c0rrpzOmH9dDpaZQygu1igQiCYCECUgGmwnH2Dfr54rsP8KNjY5ydirB/e8dGL2tdWC3fZyNJHjozzTUDfrSGc1PhDV6ZIAj1gghIBZiJJLhhSzs2m+JV1w1s9HIqgtUPaywU5fGLs/z727YzEoxxdDi4wSsTBKFekCD6OtFaMxNJ0Nnq2uilVBTLhXXfiQkSqQwv2N3Nrm4fl2YWSKQy2eMyGc3XH71ExJxuKAhC8yACsk5C0RSpjKbL11gCYrmw/vXEBHab4padnezq8ZHRcHFmIXvcYxdm+b1vPc29x8c3aqmCIGwQIiDrZDoSB6CrwSyQFocdr8tONJnm+i0BWlsc7Ow2enqdnVyMg1gNI6XtiSA0HyIg62TarNbu9G3OivNSWHGQF+zuAmBntw+Ac1OLmViPX5gFDEtMEITmQgRknUyHDQFpNBcWLI6+fcFuo+4j4HHS3erKCkgmo7MCEoxK3yxBaDZEQNZJo7qwwLBAXHZbXkryzm4fZ81akDOT4axwiIAIQvMhabzrZCZsubAaT0Besa+fawb9eRX1O7t9/OvJSWDRfdXa4hABEYQmRARknUxHErS1OGhxbN62JcvxrudvX7JtV08rX3/sMqFYkscuzNLpc3FFbyuhmAiIIDQb4sJaJ9MNWANSCiuQfn4qwuMXZrl5WwftHichsUAEoekQAVknM5F4QwbQl2OXKSCPnp/l3FSEAzs68Huc4sIShCZEBGSdTIcTDZnCuxzburzYFHzjsUsAHNjeQUAsEEFoSkRA1sl0JEF3E7mwWhx2tnR4OTk2j8tu49qhAAGPMTskmc6s/ASCIDQMIiDrIJMx+2A1kQsLFuMg120J4Hba8buNXAyxQgShuRABWQehWJJ0RtO1Seeel8uuHkNADpj1IQGzb1YoJtXozca5qQha641ehrBBiICsA6uNSTMF0WExkG4VGAY8hoBIIL25eOLiLHf8+WEeMccdC81H1QREKbVVKXVIKXVCKXVMKfWBEsfeopRKK6XeUq31VINsG5MmioEAvOzqPt580xC3X7HY4gREQJqNw6eMgtKzMqWyaalmIWEK+B2t9RGlVBvwuFLqXq318dyDlFJ24OPAj6q4lqowY7YxabYYyGC7h0+//cbs7363CEgz8tCZKQDGgtENXomwUVTNAtFaj2qtj5g/zwMngGKDwn8D+BYwUa21VIupbCPF5oqBFGJZIIVB9HRGk86If7wRicRTPHFxDoDRYGyDVyNsFDVpZaKU2gHcBDxSsH0IeBPwUuCWEo9/P/B+gL6+Pg4fPlz2WsLh8Loen8vjpw0BOfr4w5y0qYo8ZzWp5LnnkkgbIvHksVNsiZ3Lbv/0YzE63Yr3XFsfAlut898MVPrcn540BqnZFZw4P8rhw7MVe+5qIH/7w1V57qoLiFKqFcPC+C2tdahg92eBD2qt00otfwHWWn8R+CLAgQMH9MGDB8tez+HDh1nP43M5FDxK2+Vh7nzpHRV5vmpTyXMvxHXoHroGtnLw4NXZbb/74H0kHC4OHnxxVV5zrVTz/OudSp/7Q/9yApf9PLft7mJkLsrBgy+p2HNXA/nbH6zKc1dVQJRSTgzx+KrW+q4ihxwA/q8pHt3Aq5VSKa31d6q5rkphFBHWx931RhPwOPMaKqbSGabCccKxFFprSt0gCJuPB09PcdO2dnZ2+zhyob6tD6F6VDMLSwFfAk5orT9d7Bit9U6t9Q6t9Q7gm8CvbxbxAJqyiHA5AgX9sKbCCbSGaDLNxHx8A1cmVJrZSILjoyFuv6KbgYCb+XiKeenG3JRU0wK5HXg38IxS6klz24eAbQBa6y9U8bVrwnQ4wfYu70Yvoy7wu/NngoyHFgOr56ci9PndG7EsoQr87Ow0WhujjofnjAys8VCMNjMbT2geqiYgWusHgFX7LbTW76nWWqrFdCTBzdvbN3oZdUHA48xmpUG+gFyYXuDWXV0bsSyhCjx0Zhqvy84NW9uxkuxGgzGu6G3b2IUJNUcq0cskk9HMLiSaPoXXotCFNZ7jtjo/LYVmm4G3fP4hPn/4zIrHPXhmiuft7MRpt9FvWpaSytuciICUSTBq9MGSGIhBoYBMhGLYFGzr9HJhemEDVyaslqeHgzwzPFfymLFgjLOTEW7fbXQh6PUbN1DjIiBNiQhImUybVejN1sZkOfxmFlbG9GmMh2L0tLWwq8cnFsgmIJZMk0hlmFwh4eHhs0b1+W27DZek22mny+diNCQC0oyIgJTJtFSh5xHwONEawgmjI+94KE6f382OLh8XphekY2udY1mPuXGsYhy5MIfPZefqAX92W3/AzZhYIE2JCEiZzJideMWFZeC3GiouGBei8VCM3jY3O7q8hOOpbOdioT6xBGQlC+TJS3Ncv6Ude07nhYGAW2IgTYoISJlMmRfEZppGWIrChooT83H6/C1sN1u/XxA3Vl0zZwp/OJ4imkgXPSaWTHNiNMRN2/IzDw0LRBoqNiMiIGUyY5r6HWKBADkNFWNJ4qk0M5FE1oUFcG5KAun1TH4RaHEr5OhwkFRGc+PWAgHxu5ldSBJLFhceoXFZtg5EKfWXq3h8SGv9BxVcz6ZhOhIn4HHitIsGQ35HXssN0udvYajdg92mxAKpc3IFZDIcZ2vn0gLZJy8ZGVo3LrFAPICRobXDtDiF5qBUIeEbgA+v8PjfBzaNgPzmPz+BCieoRF+x6Uii6SYRlsIaaxuMJrNFhL1+Ny6HjaF2D+cllbeuybNAlomDPHFpjqF2D71t+V0FBgKLtSAiIM1FKQH5jNb6y6UerJTqqPB6qsqZyTCOZKYizzUTlj5YufjdxkcpFE0xHjItEPNCs73LKxZInRNcWExymFzGhfXkxbkl1gcYMRDI7z4gNAfL+l+01p8FUEp1Fu5TSu3MPWaz0OlzEUlWJp10eC5KX0D6O1m0tjiw21SeBdJnFpnt6PJxbioiqbx1TDCaxOuyAzA1vzRjbmI+xvBclJu2FhEQqUavGrORBF9V4JhxAAAgAElEQVS4/wypdGVufCvNahz431dKZZO+lVLXAN+v3pKqR4fXxXxi/RexcDzFxZkFru6X3j8WSqlsQ8XxUBynXdHhNSy07V1e5mOpbKaPUH8Eo0m6Wl10eJ1MhpcKwZPm9MHCADqAr8WB3+2QTKwq8MNjY/zZPSd58Mz0Ri+lKKsRkD/BEJFWpdR+4BvAu6q7rOrQ4XUSroAF8uz4PAB7+v0rHNlc+M12JhNmDYjNrBWwMrGkIr1+CUaTtHtcdLe2FLVAnrw0h8OmuHYoUPTx/VILUhVGzG7Hh07W58TvFQVEa3038Bngx8A/Am/UWj9Z8kF1SofPRSTJus3Bk6OGgOwVCyQPa6jU+Hws2yMJyAZWpSdW/TIXTRLwOOlpaykaA3ni4hxXD/hxO+1FH98f8DAmMZCKMzJnvKeHTk3UpQt4WQFRSv2VUuovzXTelwJ+4BzwG6tM8a07rKB3bsZJOZwcC9Ha4mBLh6cSy2oYrIaK46F4NoAOsLXTg1JigdQzQVNAultbltSBpDOapy/PFXVfWQz4V2eB3Hd8nN/45yfq8mJYj4yabsEL0wucnaq//59SFshjwOM5X5/EGE9r/b7psHzyswvra6txcmyePf1tMqa1AH9WQGLZADpAi8POYMAjFkgdE4om8ZsCUtjO5PREmEgivaQCPZf+gJupcJzkCtb93/3bWb7/1Eg2U08ozWgwlhXuenRjLZvGu1IK72bEEpCZSPkWiNaak6MhXnfDYKWW1TD43U4mQnHC8RS9BRMId3R7OVeHd1CC8ZkORpO0e5343U4WEmkWEim8LuPy8MRFY+Z5SQsk4EZro4XNUHtxy3wqHOfR8zMAHB8NZtN/heJorRmZi3Ln1b1E4ikOnZrgfS/atdHLyqOUC+uLKz14NcfUEx0+o9htZh2N/UaDMUKxFHsHJIBeSMDjJBw3uvEWjrDd2uHl8qxk6dQjC4k0ybQ2XVjGTVZuIP3p4SB+t4OdJYoErZT2sWCUkbkoH7v7OPcdH8875r7j49kJhsdHQhU+i/rhzGSY3/vmUytaYysxu5AknsowEPDw0r29/PzcTPb/q14oVUj4RqVUKaemAu6o8HqqihUDmVuHC+vUmATQl8NqZwLkubDAqEqfjsRJpTM4pP1LXWHFBK0gOsBkOMa2LqOdycnREHsH/CVdtlY1+sfvOcWTl+ZIpDN876kRXnRVNy0OI/D+w2NjbDNbpBwfbVwB+eHRMb7+2GXee/vOvLb3pXj0/AyReIqDe3qz26wMrIGAm2sG/fztT8/ywHNTvPLa/qqsuxxK/Sf/LvkxkMKvx4D/Ue0FVpKsC2sdAnJizPjg7xEBWYLfs3g/UmiB9La1oDXS1r0OsQSk3YyBAEyaFojWmmfHwyveMA0EPNgUPH5xljffPMQnfvF6xkNxvn1kGDCabD542rj47Rv0N7QFct501a4l5vexu0/wR987lrfNSkoYaPewf3sHbW5H3cVBmioG4nbacdmN6s5yOTk6z1C7J9u+XFgkzwIp6JdkCYoRYBff90YRiiX5+D0n+f1X7aWtoAV/wOOkN2uBGEHuy7NRwvHUijdMAY+Tf/qVW9nS4WF7lw+tNV/52Xn+9qdneeuBrRw6OUEyrXnFvn4eOj3FPUfHCMdTtLaUcoJsTqxsw4szq4v5pdIZToyGSKYzxJLpbKq0lYE1GHDjtNt48ZU92XTeekngWdGXoJS6XSl1r1LqWaXUWaXUOaXU2Vosrhq0ORWz66iIPjU2L+6rZbAEpMVhy7NGYNGlJdk3G8tDp6f46iMX+dnZmew2q0OA3+Ok0+dCqcWGimtx2d5+RTfbzaJRpRS/fvAKzk1F+OHRMX54dIzethZu2trONYOGW+dkg7qxrMahq7VATk+GiacyZHT+Y0aDMZx2lbUK79jby8R8nGMrWG/fevwyf3P4dJmrXxurcUZ/Cfg08ELgFuCA+X1T0upSZVsgiVSGM5Nh9g6IgBTDssr6A+4ld0hWB9eJeSk220isRIbh2cULVSjHAnHYbXR4XVkL5JTZdeGqvrV/5l+xr59d3T7+6l+f4/CpSV6xrx+bTWUFpBHjIJF4KpsGfXFmdQLyzOVg9ufTE+Hsz6NzUfr8ix0d7tjTg03Bj46NlXy+u58Z5QdPja516WWxGgEJaq3v0VpPaK2nra+qr6xKtDrLj4GcmQyTymj2SguTolgWSKH7CozJjUqJBbLRWAIyklP0l42BmC35e1pbshbIybF5tnR4su6utWC3Kf7jS3ZxcmyeaDKdDf72+910eJ0NGQex3Fcep33VAnJ0OIjbaUMp4xpjMRKMMRhYTInuam3h+bu6uPuZ0ZKFmJdnF2pW5FwqjfdmpdTNwCGl1CeVUrdZ28ztm5K2dVggJ80AuriwimMJSG9BBhaAw26ju7WFCWl3saFcNi2P4ZyU6mA0id2msvGI7rZFC+TkaGhdn/c33jREn7+Fdq+T5+00GnsrZVghjWiBWC6o5+/qZHg2uqq2SUdHQlw3FGCo3ZMnIKPBKAPt+Tdjr75ugLOTkaxlWIjWmsuzUbZ0LB0IVg1KRbA+VfD7gZyfNUZ7k01Hq1MxO1deDOTk6Dwuu61kPnwz4/c4UWppBpZFb1sLE8sMKxJqQ9aFNbcoIHPRBH63I+t27Glt4fGLs8RTac5ORXj5vr6yX6/FYeev3nEz4Xgyb3rnNQN+vvzwhYZL67aKZV98VQ+HTk0yMreYDl2MdEZzfCTE22/ZitflyLqwMhnNWDDGQCDfknjltf18+LtHufvp0aKekNmFJAuJdM0skFJZWJuqxmO1tLmMmRXlfHBPjs1zZV9rQ33gK4ndpvj4L17Pge3F54z1+d0ydGgDse5OYbHGACAYTeVl0Fkdec9MREhn9Lq7TluWRy7XDPpJpDKcnYqUFV+pVy5MR+hpa8nWf1yYiZQUkLOTYaLJNNcNBbDbFD8/N0Mmo5mKxEmmdba+xqK7tYVbdxpurN/+hauWxBotC7PYSOJq0HRXQp/TeMPnymioeHIsJPUfK/C2A1vZ1dNadF+fv0ViIBtIMJokHDfEYmI+TjyVzm4PeBena3a3tRBNpjlitjCpxtybawaMtvCNFgc5P73Aji5vtmBypUysZ4aNAPq1QwF297QSTaYZCUYZNbvwFgoIwKuvX96NZd0gbHgMpFFpcxkCstY4SCyZZjwUZ5e4r8qmp22xGl2oPdbF5ZYdhkUwZgbSrU68Fj1m2ugDz03hstuqMud8V48Pl8PWcHGQ81MRtnf56Pe7cTlsKwbSnzED6Lt7fFzRa9x4nZmMLNaAFOkr9sp9/dgU/MvTSzOtLpmvNyQCUh2yArLGWhDL9dIfkBbu5dLnN6rRp8JSjb4RWO6NW02XkhVIDy4k8l1YZjHhQ2em2N3bmhe7qBROu409fW0NZYEsJFJMzMfZ2e3DZlNs7fBwcQUL5NhwiGsG/DjshogAnJkIZ+eAFLNAetoMN9YPimRjXZ6NEvA4a1bovJpCQq9S6g+VUn9n/n6lUuq11V9adTD7Ka65oaLVVqBfqqjLxkrvlTjIxmBZILfuMgXEjIMYFshiONSyQEKxVFUzDveZmViNMhvEcldtN2Me27t8XChhgWQymmMjweyUx06fi3avk9OTYUaDUVoctmz/vkKWc2PVMoUXVmeB/AMQB24zf78MfLRqK6oyixbI2gRk0QJZmqIqrA4rvVcysTaGy7NR2loc2Tje8FwUrTWhWIp2T24MZPHnagrINYN+ZiKJhplkaPXAskY4b+v0cnE6sqxAnpuOEEmkswKilOKKnlbDAgnGGChSkGvxyn39KAX3HsvveGyk8NaXgOzWWn8CSAJoraMYnXg3Ja3OpQKSyWiiiXTJx1n+YnFhlU9uPyyh9lyeXWCow0OLw05PWwsjc0afq3RG57mwunwtmMXPVU0auc68cD55ca5qr1FLzhdYINs6vUQS6WUbiB61AuiDi3Pmd/e0cmYyzOhcdEkKby49bS3s7PbxVE4Ve61rQGB1ApJQSnkwaj9QSu3GsEg2JS67wuuy5wXRv/LweV748X8lkVo+uDsWitHa4mjI5m+1osvssyTFhBtD7sVlqN3DyFws2wcrV0DsNpV1nVSz68K+wQAuh43HL8xW7TVqyYXpCN2trmzVviUky2ViPXM5iMth48q+xazF3b0+psIJnpsILykiLOS6oUBWhMBwy0eTtasBgdUJyEeAHwJblVJfBX4C/F5VV1VlOryuvKmED52ZZjqSKDmzeywYWzLjQlgb2Wp0cWHVnMW7U+PiMtTuYXguutiJ15sfdO1ubSHgcVb1M+9y2Lh+KJBNF97snDMzsCwsASnWlffSzAIPn53m6gF/XpKClYk1H0sVDaDnct1QgLFQLNt7azGFt44sEK31vcCbgfcA/wwc0Fofru6yqkuHz5nnwrK6W1qdR4sxFlpaFSqsHaMWRCyQWhNJQjieWhSQjgIB8eQLyNUDfp6/q7PqbcP3b+/g6HAoW5OymbkwvZCNf4BxIVdq0QLRWvOF+8/wys/+lBd94hDHRkK8umA41O6cGqqVrjdW7MSyQmpdAwIlKtGL9Luyko63KaW2aa2PVG9Z1aXD68oKyNxCIpuN8twy/WUAxoMxbtvdXZP1NTK9be5sPEmoHVNRwz1r3Z0OBtxGJbjZe6lQQD711huoRW7UTds6+NufnuXocIj9y3Qw2AxEE2nGQjF25FSdu512+v3ubC3It58Y5s/uOcmB7R38wWuu5s6r+5bU2Gzp8OJy2EikMgyu4MLaZ3Y1fmY4yB17e7Np2rWqAYHV9cJyY/TBegojeH498AhGe/dNSafPlS24yc1DX65BWTqjmZiPSwZWBejzt/B0TuBPqA1TUUMOFi2Q/NGyhQJitRCvNjdvbwfgyIXZTS0gF0w31fYCQdja6eXi9AJzCwk+dvcJbtrWztf/423Lvr92m2JXt4+TY/MrWiBtbie7un3ZavZa14BACReW1voOsx/WBeBmrfUBrfV+4CagNtNKqoQRAzEsEMt99bydnTw7Hi56/HQ4TiqjpQakAvSa1ehJsxo9ndH823OTDVMLUK9YArLVskDMu9vjo8ZNU7t3YyZs9ra52dbp3fRxkPNTxg3pzq58Adne6eXCzAJ/ds9J5qJJ/uRN160ozpYba3AVLvNrcwLpl2cX2NpZWzf7alKK9mqtn7F+0VofVUrdWMU1VZ0Or4tQLEUqneHYSJCBgJvn7+ric//6XN5ISYsxqUKvGL3ZavQ4AwEP335imP/2jaf41q+9YFPfgdY7U9EMbS2O7KTILe2GkJwaC+G0KzwFn/lacvO2dh46M11Xo1qX4zP3PsuxkSC+Fgc+MyvT67JzdNi4ES1snLi9y8vkfJz/++gl3v/iXdkmi6V44ZXdnJuKLJnqWYzrhgJ876kRpsJxLs9G82IotWA1AnJCKfX3wP/BSOV9F3CiqquqMp1mOfpcNMmxkRD7Bv1c1ddKRhsTwazglMWYVKFXDKsafSJkCMgPnh4BjK6kIiDVYyqqGerwZi/Qfo8Dn8tOJJE2h31t3IV7//YOvvPkCMNzta1hKIe//7eztDjttLkdROIpIvE00aSRALCrx7fEFbjNtEgGA24+8LIrV/Ua73jeNt7xvG2rOta6Vj0zHOTybJSXXNWz2lOpCKsRkPcCvwZ8wPz9p8Dnq7aiGtBudh4dmYtyZjLMq64bYI/ZUvrZ8fmlAmJaIH0SA1k3ucWEcwsJHnhuClhsAidUh6lohr1bFy/OSikG2z08NxHG79kY95XFTduMG4fHL8zWtYCkM5pIIs2vvngXv3XnVXnbFxIpWhxLrbjrhgK4nTY++qZr8VWhhmzfkGHR3H9qsuY1ILAKAdFax4DPmF8NgVUk9dCZaTLayGbY0e3DaVdF4yBjwRgOm6LbJwKyXqx2JuPzcX58bJxURuOy20r2DBLWh9aaqahecnEZ6jAEpH2DBWRvfxtel50nLs7xhhuHNnQtpQjHUgBLxvvabWrZkb87u30c/aNXVG2GkN/tZGe3LzsnvdYCvKKAKKXOwdKMPq31rqqsqAZ0mBbIg6eNu999g0Yxz67uVp4tkok1ForlDbcXyqfL58KmYDIU48nLQbZ1etnS4VlxboJQPsFoklh6aX2A1Sq80O1Saxx2GzdsaV9VRXoknkLDhnSECMWMmpk299peu9oD6K4dCvD9pwxX8JYaB9FXc2YHgFvMrxcBf4kRD9m0WBbIz8/NEPA4GTL/ka7qbysqIOMhqUKvFFY1+smxeR48PcVrrh9ge5d3xbkJQvksV6E8VCcCAkYc5PhoiIVEasm+RCrDvcfH+c9fO8LN/+te3vX3j2zAChcFpJZpsqvhuqHFwPxQkfkh1WQ1lejTOV/DWuvPsknnoVtYKYvxVIZ9g/5sAHFPXyuXZ40Gc7mMBmP0r9BWQFg9vf4WfnJygnRG85rrBtjW6WMmkmA+Vt6seqE0VoHZEheWebFp9xZvGV5Lbt7eTjqjefD0dN72UCzJ6z/3AL/6lcd4+Mw0/QE3F0q0HKom86YLy79GC6TaWDHbdq9zWVdatVjNPJCbc74OKKX+E7Cp57q6nXa8LiPgZVVzAlxpBtILK9LHgzH6/ZLCWyn62tykM5odXV72DfpzegaJFVINfnRsHLtammJqVSxvdBAd4Pm7utjZ7eN3v/kUpyeM/79UOsN/+doTnJ4I8xe/dCOPfOhlvOGGQeaiSdKZ2tcNhaKWC2vj369cLAGpdQAdVufC+lTO158CNwNvq+aiaoEVB9mX00p5T1ZAFgPp87EkkURaqtArSK+ZifWa6wdQSmXnR680vU1YO4dOTvDtJ4Z5za6lFcrWBadzg4oIc/G6HHz5vc/DYbPx7//3o4wFY3z07hP89NlJPvrGa3nDjUM47TY6fC60XryY15L5bBC9viwQv9vJnr42rqhxDQisLo33V7TWZ3M3KKV2Vmk9NaPT52J4LppngWzt9OJ22vJamliN//qkBqRiWPGkV183ACzeGUsmVmWZjyX50Lef4creVl63e+mogoGAh79+58288Ir66PG2rcvLP773Fn7piz/jdZ97gMn5OO974U5+Kacmwrrxm1lI0LHMtL5qYblY68FiK+TL/+F5uJ21n1C+mlf85iq3bSravU7cThu7clTbblNc0ZufiWWNspVOvJXjrQe28rE3Xcs1ZlWu3+2kw+sUF1aF+dN7TjIeivGJt1yPc5kMwtdcP7CklftGcu1QgC+8az9zCwleureX//7qq/P2W6Ixu8aR1JWgXi0QgP6Ae0NiWaW68e4F9gEBpdSbc3b5MRosbmru2NPLzm4f9oJ/rKv62rLpvSBV6NVgqN3DL9+6PW/bti6fuLAqyMNnpvnaIxf51Rft5KZtHRw+u/Jj6oUXXtnNAx98KV0+15L/zw5T7GYXau/CCsWSuJ22vPkdzU4pKd0DvBZoB16Xs30e+NVqLqoW/IcXFvfC7elr464jw8wtJGj3urIurF5J460q2zq9PHlpczfUqye+/cRlAh4nv/0LezZ6KWWxnMvYcmFtlAVSbym8G82yAqK1/i7wXaXUbVrrh2u4pg3lZrMf0zcfv8z7XrSL0WCMDq9zSYNFobJs7/TyL8+Mkkxn5A6vAoSiKfr8LXhcjfW5tWq4ZhY2RkDq0X21kZRyYf2e1voTwDuVUu8o3K+1/s2qrmyDuGVHJy+5qoe/+MlzvOmmIcZDMenCWwO2dXlJZzQjc9G8saBCeczHkxtSrV1tvC47Lrstb6JorQjFknWXwrvRlLrVszruPgY8XuSrJEqprUqpQ0qpE0qpY0qpDxQ55peVUk+bXw8ppW4o4xwqzh+85moWEmk+c9+zjIVi9Iv7qupsN1N5paVJZQjHUg15sVNKGSOpN8CFFRILZAmlXFjfN79/ucznTgG/o7U+opRqAx5XSt2rtT6ec8w54CVa61ml1KuALwK3lvl6FePKvjbedes2/ulnF3A5bFxX0J1XqDySyltZ5mMptnTWb2fb9WAMhCsdRL8wHWFrh7ei/evmY8kNKdarZ0q5sL5PkSaKFlrr15d6Yq31KOYcda31vFLqBDAEHM855qGch/wM2LK6ZVef37rzKr79xDChWEqq0GtAX5sbl8Mmbd0rRCiWqruWG5Wiw+tiroQLazwU46Wfup/PveMmXmXWGlWC+QZ+T8ul1Lvx55V6EaXUDoxRuKW6oP0KcM8yj38/8H6Avr4+Dh8+XPZawuHwqh//2h02vnYS5sbOc/jwcNmvWS+s5dw3gu4WzeOnLnDYO16V56/3868koYU4sxOjHD48AzTWuacWYlyezyx7Pqfn0qQzmkOPPYNn+hRQmfOfi8SZnRjLvqebhar+7bXWK34BLuB64DrAtZrH5Dy2FSNm8uYSx9yBEXPpWun59u/fr9fDoUOHVn1sIpXW//DAWT0XSazrNeuFtZz7RvDef/i5fsVn7q/a89f7+VeKRCqtt3/wB/ov7ns2u62Rzv1Ddz2tb/qfP152/33Hx/T2D/5A/8ndx7Pb1nv+8aTxnv7VT55d+eA6o5xzBx7Tq7i+r6aZ4muAMxht3D8HnDbjFSuilHIC3wK+qrW+a5ljrgf+HniD1nq62DEbhdNu4z2376yrSt1GZlun0dbd+PwK5RKu44rpStDpM1xYyzVUnDED7FPhygXa52P12Uhxo1nNJ+xTwB1a69MASqndwN0s426yUEaP9C8BJ7TWn17mmG3AXcC7tdbPrmXhQuOxvcvLQiLNdCRBd6tkvpWL1XKjEdN4wYiBZMyGisX6YVkCMh2JV+w1Qw0uyuWymndjwhIPk7PAxCoedzvwbuAZpdST5rYPAdsAtNZfAD4MdAF/Y87kSGmtD6xy7UKDYbV1vzC9IAKyDubjjX233OGz2pkUb6hoFRnOVDDVVyyQ4qxGQI4ppf4F+DpGVtZbgUet/ljLuaa01g8AJXPotNbvA963phULDUu2rftMhP1mRwBh7dRz079KkG1nskwmllUjMl2mC+vcVIS3/e3D3PVrL2Cr+Zms12FSG81qeka4gXHgJcBBYBLoxOiP9dqqrUxoOqz+R5PzlXM9NCPNEAMBlq0FyXVhlRNPOzUWYnI+ztHhYHZbvQ6T2mhW/IRprd9bi4UIQmuLA5fDVtHgZzPS8C6sFSwQS0BiyQwLiTS+NcaCgqZYWI1UofGtunJZ8d0wh0f9BrAj93i9QiGhIKwVpRQ9rS1MhcUCWQ8NH0RfYSbITCSBUqC18XO5AjIWWvwchup4mNRGspp39jsY2VTfB5aONROECtLV6irbdy0YNPrdss9sqLhcR96ZSIKtHUZK+FQ4no1jrJZSFkijinK5rObdiGmt/7LqKxEEoLu1Je8fV1g787EUTruixdGYbfGVUrR7ncwViYEk0xlCsRS37Ojk4sxCWZlYxQQkFDO6GxcOuGp2VvMJ+wul1EeUUrcppW62vqq+MqEp6fKJBbJewnGj7biZGt+QdPpcRS0QKy5yRa8xqrqcz1IwalgbYwUWSKNadOthNe/IdRj1HC9l0YWlzd8FoaJ0tbZks2dyL4DffXIYpRSvv2FwA1e3OZiPpRre1dLudRZtqDhrWiWWgEyVUUyYtUCCuQKSlGmERVjNp+xNwC6ttdwWClWnu9VFMq0JRVN5LWQ+f/gMo8EYL7+mT6ZDrkC4Ce6WO30uTo3NL9luVZ8PdXjwuuzMFFggD52ewuWwcWBH57LPbQlIJJEmHDfEOBRt/Pe0HFbjwnoKYy66IFQdqwK98M5xNBgjGE3y4+Pldep9+Mw0EwvNkQPSDO6WDq+L2YWlMRDLAun0uej0uZguiIF85HvH+IPvHC353KFoMhvrGDOtkPl4suHf03JYjYD0ASeVUj9SSn3P+qr2woTmJCsgOcWEC4lU9q7w649eKut5f+2rj/P9M6WHEDUK8/EUrS2N7W6xZoJkChoqWnGRTq/LdIcuCkgmo7kws8DJsfmSwfVgNMkOs62OFUifj6UkhbcIq5HUj1R9FYJg0tVq5Pjn/uNbd4G7enw8cHqKSzMLa0rNDC4kmVtIMutpDteX4a9v2+hlVJUOn9lQMZak3bvYD8tyWXX4XHT5XHmZVGOhGImUYYX+/Nw0r7x26bAprTXBaJLn7+rkzGQkT0DEAlnKihaI1vr+3C+MUbVvq/7ShGbEEpDcYkJLQP7zwStQCr7x+OU1PedFc8phMNEcbeLnYylaG/xi12k2VCy0JGYXErS5HTjtNrp8rrz9F6YXp10+fKb45IhIwhhGdWWvIcBjoRhaa0LRZMNW9q+HVSWKK6VuVEp9Qil1HvgoxvAnQag4nV4XSuXPchg1BWT/9g5edGUP33zs0rKzIIphCchcvPFjIFprwvHGv1tuz7YzyXdLzkQSdJmV6p1mUarVD+vCdASAXd0+Hj5bXECszK7BdjdtbgfjwRixZIZURjf8e1oOywqIUuoqpdSHzVnmnwMuAUprfYfW+nM1W6HQVDjsNjq8LqZzLRDTjdAfcPP2A1sZCcZ44PTUqp/z0qwhIOGEUWjWyESTxh10o8dAOr3F25nMRBZbvHf7WkikM8zHjbqOCzMLOGyKN900xLPj4aItc6xYW8DjpM/vZjwUz7ZylzTepZSyQE4CLwNep7V+odb6r4B0bZYlNDPdra68f+7RYJQOrxO3086d1/TS4XXy/x69uOrnsywQTfktvjcLjd6J1yLbkXdhqYBY4mK5Q624yIXpCFs7vdx+ZTcAj5xdOtvcEhC/x0m/381YKJbtg9Xo72k5lBKQXwTGgENKqb9TSr2MFeZ7CEIl6PK15F3ox4Ix+gMeAFocdl593QCHTk4uycBZjkszi77vifnGbpPSLJPz2s0aocJiwplIIisu1nerNuTC9ALbOr1cNxTA57Lz8NmlVmyowAKZCMWy76lYIEtZVkC01t/WWr8d2AscBu/ctDAAACAASURBVP4r0KeU+rxS6uU1Wp/QhHQtsUBiDATc2d+v3xIgmkxnLYuVMLK2DAFq9Fkj4XhzCEhriwOnXeXNBNFaM7OwKCBWSrgVB7k4vcCOLi9Ou41bdnbysxIWSMDjpD/QwsR8PMcqaez3tBxWk4UV0Vp/VWv9WmAL8CTw+1VfmdC0dLcWs0AWBWRvvx+Ak2OhFZ8rndEMz0XZv82YcDjR4ALSLKNXjYaKrrwYyEIiTSKVycZAFi2QBPNJoz5mW5cPgOfv6uL0RHiJRVoYA0llNOenjOB7o7+n5bCmdp1a6xmt9d9qraUPllA1ultdzMdTxJJpYsk005EEA/5FAbmqrw2l4MTo0lYWhYyFYiTTmpvNEbkNb4E0UdvxTq8rb6iUlbJb6MKaiSSyXQi2m/VDt+3qApbGQYJmFXpriyM7IfO5iTDQ+FZdOTRmv2dhU5N1PUQSTJhDfXItEI/Lzs4uX9FeSIVcNHP/d/e00ups/BhIo88CyaXD5ywuIGYQ3e2009biYCocZ2LBiJft6DYEZN+gn7YWx5J03mA0id/tQClFvykgp7MCIhZIIY3/KRM2HV1Z33WchYSR+DdgBtEt9g60cXxkZReWFUDf1ukl0KKygtSoWCmrbQ2exgtGOxPLOoCcNiati5Xpna1GMaFayKAUbOkwBMRhxkEeWSIgKQJmy5KsBTI+j00Zg6yEfMQCEeqO3Gp0qwo91wIBIw5yYWaBiHnBXI5LswvYbYqBgJv2FsVkg4/LtWIgjV6JDka7ktwYiJWu25nT2sSaLzOxoBnwu/M6Oe/pb+PizEJeUWowmswKSHerC5syihUbfb5KuYiACHVHj9VQMZzIVqEPLBGQNrSGZ8dLu7Euziww2O7GYbfhbwYLJJbC57I3xeQ8KwZiCYDlzrKC6ACdvhbThZVhW1d+/7TBdg/JtM7L+AtGk9mmiQ67jZ4247PYDC7BchABEeqObEPFcIKxYBS/24GvICi8mIm1soBsMwOn7S02JsPxbGuLRiTcBH2wLK7qbyOj4clLs4ARM3PYFP6c8+82XVgTCxl2mBlYFlvaDbfo5dlodlsoxwKBRTeW1IAURwREqDu8Lgdel52pcNysAfEsOWZLhwefy87J0dJxkEszUbaafu+AS5FIZQhFS7u9NjPz8eZp+veSq3pw2BT3Hp8AjLYmHT5Xnqup02fUFIUSFLVAAEbmFgUkuIyAiAVSHBEQoS7pajX6YY2FYkviHwA2m2JPfxsnSlggC4kUU+F4tvV7e4txYWnkTKxmGGdrEfA4ef6uLu49PgbktzGx6GptwQpxbO/Mt0AG243P1bApIFYr91wB6c8KSHOI8loRARHqki5fSzYGUhj/sNg74OfkaGhZl9SlGePCYLmwAqaANHItSLPNrbjz6l7OTEY4OxnOa2Ni0Z2TkbW9wAJpczvxux1ZC8Rq5Z5vgRgxEH8TvadrQQREqEu6W1sYDUaZCseLWiAAV/e3EYqlsoH2QqwU3q0FAtLI1ejheKqp/PUvu7oPgJ+cmMhrY2KR+3uhgAAMdXgZNmMguVXoFtkYiEwjLIoIiFCXdLe6ODcVQeulGVgWewdKtzS5mFMDAosurMa2QJJN48IC4+Zgb38b954YL2qBdPnMLCpXcTfUULs768IKLiwVEOvmpZmsurUgAiLUJd05vuv+IkF0MPL4YfmWJhdnFmhtcdBhdm71OKDFYWvoGEi4yVxYAC+/po/Hzs8wt5DMS+GFxYy+Xk/xS91Qu2dRQEpYIM32nq4WERChLunK8V0vZ4H43U6G2j3LtjS5PLvAlg5PNitHKUWvv6VhXVjpjCaSSDdNGq/Fndf0ZW82Or35VkaHGVTv9RWvixls9zAfSxGKJfNmgVhs6/TyvB2d7N/eWYWVb36a65MmbBqsdiawtAo9l6sH2kq6sApz/3vb3A3rwlocJtVc/vprBwP0+VsYD8XpzPncALgcNl5z/QA7bEtbtwMMdSym8oaKWCBup52v/6fbqrTyzY9YIEJdYmXP+FxGQ7zl2NPfxpnJCPFU/rBMrTWXZqLZ+IdFT2vjWiDzcbOVexPFQMBI6baC6YVpvAB//c6buaW/+HuSWwsyFzUq2QPe5hLg9SACItQlVkfe/oC7ZA+i7V0+0hm9pEXJTCRBNJlmS0d+/KTX39KwFkgzdeIt5E03DeF22tjZ41v54BysavTh2Wi2lXuzCfB6EAER6hJLQIpVoedi9c0qbJJo/d7T5l5yfDCaJJbMt1gagcVphM13B33Ljk6O//ErGWov/XkppLu1BZfdxvBcLK+Vu7A6RECEuqTd48SmSsc/IKdzb4FVMTVvuCNyC8nAsECgMVN5m6kTbzFsZTSQtNkUA2Yqb24rd2F1iIAIdYnNpvjVF+/iDTcOljwud/hULtMRQyC62/KDqr2mRdKIbd2b2YW1HgYDHkbmokvamAgrI580oW7576+6esVjrMKxQgvEsjC6C7JyrPbcjdjWPSsg4sNfE0MdHh54boq+gFsqzteIWCDCpsbttNPmdiyxQKbCCVx225IeRr1txWMmm5X7jo9nx/Y2cwxkPQy2exifjzEdjosFskZEQIRNT09ryxJBmArH6Wp1LQmIdvpcKAWToaXV6JdmFvjwd4+SSmequt5K8hv//AS/8uVHiSXTzMeMLCK3U/6t18KWdg9aG3NBREDWhnzShE2P1fo9l6lwfIn7Cowpc12+4rUg33z8Ml95+ALnzTv6eieWTBNNpnluIsxf/uS5bCdeySJaG4M5mVsiIGtDBETY9HS3Gq3fczEEZGlRGRhurGJZWEcuGpPtrJYW9Y4V8+jwOvnC/Wf4+bkZCaCXwVCHCEi5iIAIm56uVlfeXGsw0niLWSBgXDDOTIbztmUymicvzQEQjCaKPazuCJlpu7/98j30trk5OTZPa4tcANdKbq81EZC1IQIibHq6W1uYW0iSNGMXWmumI/ElKbwWz9/VxfnphWwXVoDTk+HsHf1msUCs3k1bOjz86ZuvAySFtxzcTnv2ZkMEZG2IgAibHuuff8bMxApGkyTTelkL5PYrugB48PRUdtsTpvsKFudC1DshU/D8bid37O3lv955Fa+/oXTdjFAcy40lArI2RECETY8V67DcWNb35WIge/ra6G518VCOgBy5MJdN+Z3bZBZIwGOs+wN3Xsm7nr99I5e0aRlql8mD5SACImx6LEvDCqRPmm1MepaxQJRSvGB3Nw+emc7OUz9ycZb92ztobXFsHheWGQNpphG21cLqoSUWyNoQARE2PdbsEKsa3Wpj0rWMgIDhxpqcj/PcRJhgNMlzE2Fu3tZBwOPcPC6sqOnCkoveurl2KIDf7VjW7SkURyJuwqbHclVZwjE1X9qFBfCC3d2AEQfZ3dMKwE3bOrjn6NimskBcdhstDrkPXC+vv2GQV+zrx+20b/RSNhUiIMKmp7XFQYvDlnVhTYUT2G0qO860GFs7vWzv8vLg6SmC0SRKwQ1bA7R7nZtHQKJJ/B4pHKwESikRjzIQARE2PUops5hwMYje6XOt2N77Bbu7+cFTI8SSGfb0tdHmdhLwOHluIlzycfVCKJaS+IewoYjtKzQE3a2uHAukeBuTQm6/oov5eIoHz0xx07Z2wAiibiYLpE3iH8IGIgIiNATdrS3ZfliT4UTJ+IeFFQfR2oh/gDEPO7iQzGZn1TOhWHJJt2FBqCUiIEJDkNvOZGo+vmwKby6dPhfXDPgBuNkSEI+TRDpDLFn/HXmNGIhYIMLGUTUBUUptVUodUkqdUEodU/+/vfsPkruu7zj+fN/P3N5dsveDhCR3SQiJQRoJIRGCII1IGUQROtVRa9GhVnTUgoy2WPuHdjodtf6so2IpUrBV1AGmjSgKIwkaKphAgCQEIQSSy+UH+XGX3CX3a2/f/eP73cvdZu9H9vZ7u7f7eszcXPa7n73v55Pvd/e9n99mt2ZIY2b2bTPbaWbPm9lFUeVHiltQA+knmfSgCWuUZUzSXbP8bFoaaljcXAucmgcwHZqx1Aci+RZl/TcBfMbdnzGzeuBpM3vU3V8YluYdwNLw5xLgjvC3yBlpqqsmkXTaO3voSyRpqh2/CQvgU29bwsf+dPFQh3u8JnhdZ0//uPux51tqFJZIvkRWA3H3/e7+TPjvLmAHMD8t2fXADz3wJBA3s7lR5UmKV6rP448HusLHE6uBlJUZ1RWnhm8O1UAKfDJhX2KQvkRSNRDJqyn5+mJmi4CVwFNpT80H2oY93hse25/2+puBmwHmzJnDhg0bss5Ld3f3pF4/nRVz2duPDALwy98/B8C+XS+yoWvniDQTKf9rx4K/s3HTFnr2FO63++N9QSf/gbZX2bBh77jpi/naT0Qplz/Kskf+DjGzOuAB4NPufjz96QwvOW34i7vfCdwJsHr1al+7dm3W+dmwYQOTef10Vsxln3ugi3/d9Fv6a5qB/Vx52Zv5k3mzRqSZSPnbjp7ki79fT+u5y1i7ujW6DE/SrkPdsP5xVl9wPmsvTK/Yn66Yr/1ElHL5oyx7pKOwzKySIHj8yN0fzJBkLzD8XdoC7IsyT1Kc0puwJjIKK5PUqKbjBd6JPnwpd5F8iXIUlgE/AHa4+zdGSbYO+FA4GmsNcMzd94+SVmRU8VgVZQa7Dp/ALBiim4366grKDDrH6AN57MWDbGs/lm1WcyIV4NSJLvkU5d13GXAjsNXMng2PfR5YAODu3wd+CVwL7AROAjdFmB8pYuVlRmNt9dAyJhXl2X03KiszZo4xG31gMMkt9z3LBS2z+PFH10wmy5OipdylEEQWQNx9I5n7OIanceCTUeVBSktzOJlwIrPQxxKvqRx1U6ln2zrp7kvwzJ4O+hKDI0ZwTSUt5S6FQDPRpWikhu5Odk+HsdbD+t3LwS6GvQNJnt+bv2Ys1UCkECiASNFI1TzG2khqIsZqwtr48iEWnxXMWn/ylSOTOs9kHO8ZoLLcmFGpt7Dkj+4+KRpNQzWQSTZhxao4drL/tOPHewd4bu8xrl0+l/POruepV49O6jyTESykWKm9QCSvNIRDikbumrAy74v+5CtHGEw6ly9tprsvwU827aE/kaQqDzsCHu9JqP9D8k41ECkaqZpHtnNAUuI1VRzrGSCZHDmndePOw8SqyrloQQNrFjfSO5Bka3vnpM6VLS3lLoVAAUSKxlANpH5yTVizaipJOnT3J0Yc3/jyYS45p5GqijIuPqcJgCd35acZS0u5SyFQAJGiccniRj761nO4JPxwz1amBRXbO3vYdfgEly89CwgmKi6bU8+Tu/LTka6l3KUQKIBI0YhVVfCP7zyf2urJNe3Mip2+J8gT4fDdy5c0Dx1bs7iRza91MDA49ZtPaSl3KQQKICJpMm0q9budh5ldX80b5tQNHVuzuImegcG8zAdJjcISyScFEJE08bAGkloPK5l0/m/nYS5f0jxi2OzF5zQC8NSrU9uM1ZcYpHcgqT4QyTsFEJE06TWQVw51c+REP2vOHdm30lQX1EimuiO9a2glXjVhSX4pgIikSQ8gm3d3APDmRY2npX3zoka27O44bchvlE6txKsaiOSXAohImprKcqrKy+jsCWajb3rtKE21VSxqip2WduWCBrr6Euw81D1l+dNeIFIoFEBE0pgFS7qnvuk/vbuDVQsbMi4bsnJBHIAtezqmLH/aC0QKhQKISAbxWCWdJwc41NXH7iMnMzZfASxurmVWTSVb9kx+RnpP/yCdGdbgSqeVeKVQKICIZJBa0v3p3UEH+apFDRnTmRkrF8RzEkC+9PAOPnjXU+Om014gUigUQEQySAWQza91UF1RxvJ5s0ZNu7K1gZde76Krd3L7qLd39PDy693jdsirBiKFQgFEJIN4TdCEtWl3Byta4mOuuLtyQRx3eK5tchMKu3oT9CeSHDkxdjOW9gKRQqE7UCSDmTWVHDnRx/b2Y6M2X6WsaM1NR3pXX9A0ta+zZ8x02gtECoUCiEgG8VglvQNJEkln9cKxA8ismkqWzK5jS9vk+kFSTWDjBhDtBSIFQgFEJINZwz6gV40TQAAuWhBny54O3LOfUNgd1kDaJ1QD0RBeyT8FEJEMUgFk6ew64rHx9xdZuaCBjpMD7D5yMqvzufvQEiX7OnvHTKu9QKRQKICIZJBaUHH1OP0fKakJhc9k2Q/SO5BkMBx9NX4fiPYCkcKgACKSQUNY61i1MPMEwnRLZ9dTW1We9XyQ4UOA9x0brw9Ee4FIYdBdKJLBipY4X3/vCq5bMW9C6cvLjBWtcba0ZVcDSa1vVVddMeFRWCL5phqISAZlZcZfrGoZc/5HuhWtcXbs76I/ceY7FKY60N8wp47D3f30DgxmTNefSGovECkYCiAiObK4uZbBpI87iiqTVBPWsrNnAqP3g5yaha7GA8k/BRCRHFnYVAvA7iMnzvi13WET1rJwy9zRRmI9+sJBAM49qy7j8yJTSQFEJEdS+4VkM5Q3NYR3rBpIfyLJdx7byYWtcS5N2x1RJB8UQERy5Kz6amoqy7MLIGEfyNI5dZhlnkz4s81ttHf2cNufvUHLmEhBUAARyREzY2FTLKsmrFQfSEOsitn11afVQPoSg3x3/U5WLWzgiqXNOcmvyGQpgIjk0ILGGLuPnnkNpLs3QayqnPIyY1685rS5ID/d1Mb+Y73cdpVqH1I4FEBEcmhRcy17jp4cd0+PdF29CerDkVXz4jUjOtF7B4Lax8WLGrlsifo+pHAogIjk0ILGGP2JJAeOj72eVbruvgR11UEAmR+vob2zZ2hhxl88v5+Dx/u49aqlqn1IQVEAEcmhRUNDec+sGet47wD14ezyebNmjNhYat1z+2hpqOEtGnklBUYBRCSHFg4N5T2zjvTuvpFNWBAM5T3S3cfGnYe5bsU81T6k4Gg6q0gOzZ01g8pyO+OO9K7eBHNnzQBGBpDn9x5jMOlcd8HE1uQSmUoKICI5VFFeRkvDmQ/l7e4d2QcC0N7ZyyPbD7Bkdh1vnFuf87yKTJaasERybEFj7Iz7QLqG9YHEY5XUVJbzzJ4O/vDaUa67QM1XUpgUQERybFFTEEAmur3tYNI50T84VAMxM+bFZ/Dw1v24w3Ur5kaZXZGsKYCI5NiCplq6+xIcDUdRjSe1lHv9sBV258VrSDosnz+TxVo4UQqUAohIjg0tqjjBjvRMASTVD/LuCW5oJZIPCiAiOXamQ3lT62DVD9tlcGFTLWUG79ToKylgGoUlkmMtDTHMJj6ZsHvYdrYpN166kMuXNA/VREQKkWogIjk2o7KcuTNnTDiApPYCGd6EVVddwZtaZkWSP5FcUQARicDCptqJN2Fl6AMRmQ4UQEQisLBp4nNBMvWBiEwHCiAiEVjQFOPIif6h4DCWTH0gItOBAohIBBY2Bqvy7pnAUN6u3gRlBrGq8qizJZJTCiAiEWhtDEZPtR09fW/zdKm9QLRciUw3CiAiEWhtCOaC7O0YvwYyfC8QkelEAUQkAvFYJXXVFbRNoAmre9h2tiLTiQKISATMjJaGGvZ2jN+E1aUAItOUAohIRFobY7RNoAlr+H7oItNJZAHEzO42s9fNbNsoz88ys5+b2XNmtt3MbooqLyL50NoQo+1oz7jLunepD0SmqShrIPcA14zx/CeBF9x9BbAW+LqZVUWYH5Ep1dpYQ8/AIEfGWda9uy9BnZqwZBqKLIC4+2+Bo2MlAeotGLtYF6ZNRJUfkamWGok1Xkf6cfWByDSVz7v2O8A6YB9QD7zP3ZOZEprZzcDNAHPmzGHDhg1Zn7S7u3tSr5/OSrnsMPXl398V3M6/fuJpju3K/FYbSDr9iSSH9rWxYcPByPKia1+65Y+07O4e2Q+wCNg2ynPvAb4JGLAEeBWYOd7fXLVqlU/G+vXrJ/X66ayUy+4+9eXv7h3whbc/5N9d//KoaQ539frC2x/ye554NdK86Nqvz3cW8iabsgObfQKf8fkchXUT8GCY351hADkvj/kRyana6goaa6vGnI2e2o1Qo7BkOspnANkDvB3AzOYAy4BdecyPSM61NtSMORs9014gItNFZHetmd1HMLqq2cz2Al8AKgHc/fvAPwP3mNlWgmas2939cFT5EcmHlsYY29uPjfp8KoBoFJZMR5Hdte7+gXGe3wdcHdX5RQpBa0OMR7YfYDDplJedvlhiarn3mZoHItOQZqKLRKi1sYaBQefg8d6Mz6sPRKYzBRCRCI03F0R9IDKdKYCIRKilIdgXZLRFFYdqIAogMg0pgIhEaH5DDWaMWFSx40Q/yWSwPtbx3gGqKsqortBuhDL9KICIRKi6opw59TOG5oK0d/Zw+Vce4xM/eoZk0oO9QNT/IdOUAohIxFoba4ZqIF9++EVODgzyq+0H+N6GndoLRKY13bkiEWttiPHkriM8vfsoP39uH7dcuYTdR0/y9UdfYnZ9NWfVV+c7iyJZUQARiVhLY4z9z7bzhXXbmTOzmo+vPRfDeOlgNzv2H2dxc12+syiSFTVhiUSstaEGd9jWfpzbrzmPWFUFNVXl3HnjKuKxStVAZNpSDUQkYi3hXJAVrXFuuHD+0PHWxhi/uvUKZlTqe5xMTwogIhFbPn8mb13azO3XnEdZ2nImZ8+akadciUyeAohIxOpnVPJfH7kk39kQyTnVnUVEJCsKICIikhUFEBERyYoCiIiIZEUBREREsqIAIiIiWVEAERGRrCiAiIhIVhRAREQkKwogIiKSFQUQERHJigKIiIhkRQFERESyogAiIiJZMXfPdx7OiJkdAnZP4k80A4dzlJ3pppTLDqVd/lIuO5R2+bMp+0J3P2u8RNMugEyWmW1299X5zkc+lHLZobTLX8plh9Iuf5RlVxOWiIhkRQFERESyUooB5M58ZyCPSrnsUNrlL+WyQ2mXP7Kyl1wfiIiI5EYp1kBERCQHFEBERCQrJRNAzOwaM/ujme00s8/lOz9RM7NWM1tvZjvMbLuZ3RoebzSzR83s5fB3Q77zGhUzKzezLWb2UPj4HDN7Kiz7T82sKt95jIqZxc3sfjN7MbwHLi2Va29mt4X3/DYzu8/MZhTztTezu83sdTPbNuxYxmttgW+Hn4PPm9lFkzl3SQQQMysHvgu8Azgf+ICZnZ/fXEUuAXzG3d8IrAE+GZb5c8Bv3H0p8JvwcbG6Fdgx7PFXgG+GZe8APpKXXE2NfwN+5e7nASsI/h+K/tqb2XzgFmC1uy8HyoH3U9zX/h7gmrRjo13rdwBLw5+bgTsmc+KSCCDAxcBOd9/l7v3AT4Dr85ynSLn7fnd/Jvx3F8EHyHyCct8bJrsXuCE/OYyWmbUA7wTuCh8bcCVwf5ikmMs+E7gC+AGAu/e7eyclcu2BCqDGzCqAGLCfIr727v5b4Gja4dGu9fXADz3wJBA3s7nZnrtUAsh8oG3Y473hsZJgZouAlcBTwBx33w9BkAFm5y9nkfoW8PdAMnzcBHS6eyJ8XMz3wGLgEPCfYRPeXWZWSwlce3dvB74G7CEIHMeApymda58y2rXO6WdhqQQQy3CsJMYvm1kd8ADwaXc/nu/8TAUzexfwurs/PfxwhqTFeg9UABcBd7j7SuAERdhclUnY1n89cA4wD6glaLZJV6zXfjw5fR+USgDZC7QOe9wC7MtTXqaMmVUSBI8fufuD4eGDqSpr+Pv1fOUvQpcB7zaz1wiaK68kqJHEw2YNKO57YC+w192fCh/fTxBQSuHaXwW86u6H3H0AeBB4C6Vz7VNGu9Y5/SwslQCyCVgajsSoIuhUW5fnPEUqbPP/AbDD3b8x7Kl1wIfDf38Y+N+pzlvU3P0f3L3F3RcRXOvH3P2DwHrgPWGyoiw7gLsfANrMbFl46O3AC5TAtSdoulpjZrHwPZAqe0lc+2FGu9brgA+Fo7HWAMdSTV3ZKJmZ6GZ2LcG30HLgbnf/lzxnKVJmdjnwO2Arp/oBPk/QD/IzYAHBm+297p7eAVc0zGwt8Fl3f5eZLSaokTQCW4C/cve+fOYvKmZ2IcEAgipgF3ATwRfGor/2ZvZPwPsIRiJuAf6GoJ2/KK+9md0HrCVYtv0g8AXgf8hwrcOg+h2CUVsngZvcfXPW5y6VACIiIrlVKk1YIiKSYwogIiKSFQUQERHJigKIiIhkRQFERESyUjF+EpHpzcyaCBaUAzgbGCRY6gPgpLu/JcfniwH/AVxAMPO3k2DYZAXwl+7+vVyeL+3cXwS63f1rUZ1DJEUBRIqeux8BLoQp+4C9FTjo7m8Kz7kMGCAYp/8JILIAIjKV1IQlJc3MusPfa83scTP7mZm9ZGZfNrMPmtkfzGyrmZ0bpjvLzB4ws03hz2UZ/uxcoD31wN3/GE5a+zJwrpk9a2ZfDf/e34V/5/lwAhxmtijcx+Pe8Pj9Ya2GMF8vhMfHDIJm9lEze9jManLxfyWSTjUQkVNWAG8kWBp7F3CXu19swWZcfwt8mmCfjW+6+0YzWwD8OnzNcHcDj5jZewiazu5195cJFjRc7u6p2tDVBPsyXEzQ1LXOzK4gmDm8DPiIuz9hZncDnwh//zlwnru7mcVHK4iZfQq4GrihWGZcS+FRABE5ZVNqXSAzewV4JDy+FXhb+O+rgPODFSEAmGlm9eGeKwC4+7PhsilXh+k3mdmlQE/a+a4Of7aEj+sIAsoeoM3dnwiP/zfBJknfAnqBu8zsF8BDo5TjRoJF824IFxQUiYQCiMgpw7+pJ4c9TnLqvVIGXOru6cFgBHfvJlgJ9kEzSwLXEqyMPJwBX3L3fx9xMNi/JX2NIXf3hJldTLBA4PuBTxGsNJxuG0GfTwvw6lj5FJkM9YGInJlHCD64gaFFC0cws8uG7UFdRbCN8m6gC6gflvTXwF+He7ZgZvPNLLXxz4Kw1gLwAWBjmG6Wu/+SoDnttHOHtgAfI2gSm5ddMUXGpwAicmZuAVaHndgvAB/PkOZc4HEz20rwYb4ZeCAcDfaEmW0zs6+6iRwU/AAAAHFJREFU+yPAj4Hfh2nv51SA2QF82MyeJ1hB9o7wuYfCY48Dt42WSXffCHwW+IWZNU++2CKn02q8IgUmbMJ6yN2X5zkrImNSDURERLKiGoiIiGRFNRAREcmKAoiIiGRFAURERLKiACIiIllRABERkaz8P2E/DB5E3ljwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGWCAYAAABW5tXRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd82/Wd+PHXx5Yl2ZI85ZHYTpwNBLJZYYVSxlFaKHfdpXQdnddxvd61/fVKe23vet3XcaWbDq70WujgSmkpEAI0QAYjZCeOE8cz3pJs7c/vj6+kyLZsy0PWV9b7+Xj4EVvfr6T311b01vszldYaIYQQYroKsh2AEEKI3CQJRAghxIxIAhFCCDEjkkCEEELMiCQQIYQQMyIJRAghxIxIAhFzQim1XSn1zgmOfVop9fM0H+dupdTnZhhD2veNxRRSSnmVUo6ZPN+Yx3t57LGiSqmXz/bx5sJkf5NZntsy02uczn1jMfmVUjvSPH917G8QSfdaxOxIAskjsf+8I7H/ZJ2xN1xntuPKol9qrZ1aa1+qg0qp/bHfVfwrrJR6INW5Wuu/aK2dwKmMRpx/3q+1vjL+w5i/RzxZfBNAa30k9jd4ImvR5hlJIPnnlbH/ZBuAjcDHsxyPaWmt18YSjBNwYSSHX2UjFqWUJRvPazbxv0fsb1ILjJClv4mQBJK3tNadwJ8wEgkASimbUurLSqlTSqkupdRdSqni2LEKpdT/KaXOKKX6Y983zOS5lVK/ilVAg0qpHUqptWNOcSulHlZKeZRSjyullibd95zYsT6l1GGl1GtnEsMMXAnUAPfN1QMqpbRS6gNKqWalVI9S6ktKqYLYsbcqpZ5SSn1NKdUHfDp2+9uVUgdjf4M/jfndXKuUOhT7vX4LUDOMa4VS6lGlVG8srnuUUuVjTrtQKXUgFsePlVL2pPvfpJR6Xik1oJT6q1Jq3UziSMPfAd1IxZE1kkDyVOzN/2+AY0k3/yewGiOprATqgU/FjhUAPwaWAkswPvl9a4ZP/0dgFcYb8l7gnjHH3wR8FnADz8ePx/oqHgb+J3bfNwD/nSIBxa9xQCl1+QxjHOt24NcTNXfNwquBLcAm4Gbg7UnHLgaaMa7180qpW4BPALcC1RhvnL8AUEq5MZLbJzF+b8eBy2YYkwL+A1gMnAs0EktgSd4EXA+swHjNfDIWxybgR8C7gCrgu8DvlVK2cU+i1OVKqYEZxgjG3+SnWtZjyh6ttXzlyRfQAngBD6CBR4Dy2DEF+IAVSedfCpyY4LE2AP1JP28H3jnBuZ8Gfj7BsfJYLGWxn+8G7k067gQiGG9irwOeGHP/7wJ3Jt33c2n+LiaMKcW5JcAQsC3N3/HL03xcDdyQ9PN7gUdi378VODXm/D8C70j6uQAYxkjqbwGeTjqmgNMT/U1SxDLZ3+8W4Lkx1/jupJ9vBI7Hvv8O8Nkx9z8MXDWD389kMS2JvS6WTed+8jW3X9Kumn9u0Vr/RSl1FcYneTcwgPGJtgTYo1Si5UMBhQBKqRLga8ANQEXsuEspVai1jqT75EqpQuDzwGtizxmNHXIDg7HvW+Pna629sSacxRhvlBeP+dRqAX6W7vPP0K1AH/B4Bh67Nen7kxjXmeoYGNf/X0qpryTdpjAqxcWM/r1ppdTY+6dFKVUDfAO4AqPvpwDoTzPupcDtSql/SDpuZfR1zYW3AE9qrU/M8eOKaZAmrDyltX4c4xP7l2M39WA0S63VWpfHvsq00VkJ8BFgDXCx1roUo08Apt/O/kaMppqXA2VAU4rHaYx/ExslVgm0Y7xpPZ4UX7k2OlTfM80YpiuTTSWNSd8vwbjOuLHP1wq8a8z1F2ut/wp0MPr3psY89nT8R+y518X+1m9m/N95orhbgc+PibFEa/2LGcYykbcAP5njxxTTJAkkv30duFYptUFrHQW+D3wt9gkUpVS9Uur62LkujAQzoJSqBO6c4XO6gADQi1Hx/HuKc26MtY9bMfpCntFatwL/B6xWSt2mlCqKfV2olDp3hrFMKdZXdDUzeLOKdYS3THHaR2MDFBqBDwK/nOTcu4CPx/t8lFJlSqnXxI79AVirlLo1NmLrA0DddGOOcWE0dQ4opeqBj6Y4531KqYbYa+ETSXF/H3i3UupiZXAopV6hlHLNMJZxlFJbMaouGX2VZZJA8pjW+gzwU+BfYzf9C0an+tNKqSHgLxhVBxjJphijUnkaeGiGT/tTjCaPNuBA7LHG+h+MBNUHbMbosEVr7QGuA16P8Ym3E6Pjf1wHLSTmDFwxwzjjbgN2aq2Pz+DxG4Gnpnj83wF7MAYL/AH44UQnaq1/g3G998b+Pi9hDIRAa92D0Sz4BYzkvCr5uZVSVyilvFPEEvcZjE79wVhM96c453+AP2N08jcDn4vFsRv4e4wBFv0Yr6e3pnqSacaU7Hbg/tjrQWSRykxVLoS5KaU+iTEHJgTU61mOrlJKXYMxCsoG3Ki1fkwp9Wfgg1rrgxPcRwOrtNbHUh3Pd7Hf36XAbq311WmcvwrYhdHn8l6t9d2ZjVBIAhEiSySBiFwnTVhCCCFmRCoQIYQQMyIViBBCiBnJuYmEbrdbNzU1zfj+Pp8Ph2PWq3fnpHy+dsjv68/na4f8vv6ZXPuePXt6tNbVU52XcwmkqamJ3bt3z/j+27dvZ9u2bXMXUA7J52uH/L7+fL52yO/rn8m1K6VOpnOeNGEJIYSYEUkgQgghZkQSiBBCiBmRBCKEEGJGJIEIIYSYEUkgQgghZkQSiBBCiBmRBCKEEGJGJIEIIYSYEUkgQgghZkQSiBBCiBmRBCKEEGJGJIEIIYSYkZxbjVcIMTdCkSjv+tkeKh1Wrj2vlitXVVNsLcx2WCKHSAIRIk+19g3z6KFuCgsUv95zGpulgC/+3Tpu3lCf7dBEjpAmLCHyVMegH4C733Yh97zzYuorivnRUy3ZDUrkFEkgQuSpeAJZUlnCZSvdvHLdYl48PcDAcDDLkYlcIQlEiDzVOTgCQG2pHYArV1ejNTx5rCebYYkcIglEiDzVMein0mHFXmR0nK9vKMNlt/DEEUkgIj2SQITIU52Dfupi1QeApbCAy1e6eeLoGbTWWYxM5ApJIELkqY5BP4vK7KNuu2JVNe2Dfo6f8Y47PxCO8ExzL3/c1zFfIQqTk2G8QuSpziE/G5eUj7rtilVuAHYc6WFljQuA3S19fP0vR9l9sg9/KArAwx++klW1rvkNWJiOVCBC5CF/KEKfLziuAmmsLGG528ETR88ARjPXHT/bw7FuL2+4aAn/dvNaAJ5vHZj3mIX5SAIRIg91DRlDeOvKiscdu2KVm6eb+xgJRvjQL59jJBjh5++8mDtfuZY3X7wUp83Ci6cH5ztkYUKSQITIQ+0DRgIZW4GA0Q8yEorw7p/v4enmPv7t5rWsrHECUFCguKC+jBdOSwUiJIEIkZc6h4w5IHUpEsilK6ooKlQ8fuQMN29YzN9tbhh1fF1jGQc7hgiEI/MSqzAvSSBC5KH4LPTkYbxxDpuFS5ZX0VRVwuduOR+l1Kjj6xvKCUU0hzo88xKrMC8ZhSVEHuoc9FNqt+CwpX4L+M6bN6O1xmUvGndsfaMxcuuF0wOJ70V+kgpEiDxkzAEZ34Ee57RZUiYPgMVldtxOKy+0Skd6vpMEIkQe6hz0s6h8fPNVOpRSrGso58WkjvRoVPONR46mnIAoFi5JIELkoVSz0KdjXUMZx8548QbCAPz5QBdfffgIv9p9eq5CFDlAEogQeSYYjtLjDVBXOnET1lTWN5ajNew7PYjWRvUB0CwVSF6RTnQh8kx8EuFsKpD1DUbn+YunB/AFwhzoGMJps9Dc45uTGEVukApEiDyTGMI7iwRS6bDSUFHMi6cH+eajR1lSWcIbLmrkZK+PcCQ6V6EKk5MKRIg80xHbSGo2FQgYVcjDB7oIRqJ84dYLKCxQhCKa1v4RlrkdcxGqMDmpQITIM51zUIEArG8sIxiJUl9ezK2bGlhebSx3Iv0g+UMSiBB5pmPQP+k8j3RtXloBwHu2rcBqKWBFtVF1yFDe/CFNWELkmc5B/6yrD4BNSyq4/71b2RDrUC8vsVLlsNJ8RjrS84VUIELkmY6h2c0BiVNKsWlJBQUFZ9fKWl7tkASSpvf8fA/ffuxYtsOYFUkgQuSZzsGRlIsozoUV1U5pwkrDwHCQP77UyXcfP85IMHdXNZYEIkQeCUWidHsCc1KBpLK82kGvL8jgcCgjj5+LTqSYG7PnZD8AQ/4wD7zQPt8hzRlJIELkkTOeAFrDovKZz0KfzHK3MRLreI9UIWAkiqu/vJ3HDnWPun1XSz9FhYrlbgf3PHMyS9HNniQQIfJIS+zTcMaasGI7Fx7vlgQC8PgRY2/5P+3vHHX7rpY+zq8v4/atTbxwepB9ObpFsCQQIfLIXTuaKSsuYnNTRUYev7GimKJCJUuaxDx9vBeAxw53o7UGwB+K8OLpAS5qquTVm+opLirk50/nZhUiCUSIPPHUsR52HDnD+69eSeks54BMxFJYwNIqh0wmBEaCEZ5r7ae+vJiuoQD724cAePH0IKGIZktTJaX2Im7esJjfv9DO4Eju9RtJAhEiD0S15gt/PER9eTG3Xbo0o8+13O3guAzlZffJPkIRzYevXY1S8GisH2RXSx9wdiLmmy5eykgowm/2jl8Kv9cb4BuPHDXt+mKSQITIA7s6I+xrG+Qfr12Nvagwo8+1vNopiyoCO4/3UliguOH8OtY1lCcSyO6WPlbWOKl0WAG4oKGMdQ1l3P9c27jHuH9vG199+AjPxpKO2UgCEWKBC4aj3Hc0yDl1Lm7ZWJ/x51tR7SAU0ZzuH8n4c5nZzuZe1jeU4bRZeNmaGl44PUC3x8/uk/1cOKYP6opVbva3D+EPjZ4T8mKb0bm+60T/vMU9HZJAhFjgHtzXQfew5l9uOIfCpFnjmRJfVDGfJxR6A2FePD3IpSuqALjm3Bq0hu/vaMbjD3NhU+Wo89c3lBOJava3jx6NFd82eJdUIEKIbDjZOwzA5avc8/J88UUV83lJk10n+ohENZcuN37naxeXUuOy8ZOdxmirsQlkQ6OxntjzrWcTyMBwkJO9w9gsBew91W/KJkFJIEIscP3DQYotUFQ4P//dy0usuJ1Wnms1Z7PLfNjZ3Iu1sCDRUa6U4uo1NQTDUWpLbTRUjJ7IWVNqZ1GZnRdaBxK37Ys1X926qZ7hYCQxistMJIEIscANDAdxFmW+6SrZ321u5MF9nTx7wpxNL5m283gvG5aUU2w9O2DhZefWALClqRKlxv891jeU88LpswnkxdjkwrdftgwwZzOWJBAhFrj+4dC8J5APXLOS+vJiPvGbfQTD5mt6yaTB4RD72we5dHnVqNsvX+lmcZmd69fWpbzf+sZyTvYO0+cLAkb/xzK3g1W1LpZUlpgyGUsCEWKBGxgO4rDObwIpsVr47C1rOdbt5ftPNM/rc2fb9iPdRDVsXTE6gThsFv768Wt41frFKe+3vrEMIFGFvHh6kHUNxm0XNlWy+2R/Yja7WWQsgSilGpVSjymlDiql9iulPpjinDcppV6Mff1VKbU+U/EIka+MCmT+n/dl59TyN+fX8Y1HjnKyd+F1qLcNjIy7rvaBET7zwAFW1TjZuGR6y8VcUF+GUvBCqzHct2PQzwX1RgK5aFkFfb6g6Ua2ZbICCQMf0VqfC1wCvE8pdd6Yc04AV2mt1wGfBb6XwXiEyEv9WegDibvzlWspKizgs/93MCvPn0kf/uXzXPu1Hfw2NgEwEI7wnnv2EgxHueu2zVgt03t7ddmLWFXj5IXWgcTiiutjo7Pio7aeNdl8kIxtaau17gA6Yt97lFIHgXrgQNI5f026y9NAQ6biESIfhSNRPP4wTmsWShCgrszO2y5r4tuPHZuzrXTNQGvN/tgoqQ/98nkOdXoYHAnxQusAd715Mytic2Gma31DOY8c6uaC04MUKGP4L8AytwO308qulj7eePGSObuO2ZqXPdGVUk3ARuCZSU57B/DHCe5/B3AHQG1tLdu3b59xLF6vd1b3z2X5fO2Qn9c/FDDazIuiwaxde30oSlTDV+/fwY3LrFmJYa7/9meGo/iCEd58rpU2b5S7Hj8OwCuWFWHvOcT27Ydm9LjFIyH6fEF+/fQxFjsUz/71ycSxJkeEHQfb2b59YJJHGC+Tr/uMJxCllBO4D/iQ1jrlQGal1NUYCeTyVMe11t8j1ry1ZcsWvW3bthnHs337dmZz/1yWz9cO+Xn9x7o98NgOqpz2rF77L08+xYuDEb647cqsPP9c/+0fOdgFO3bz6m2b2by0knufPcWhTg+ffMW5WGYx38bdNshPDzxJu0/zms0NbNt2tlv4RNEJPvPAAVZvuJjF09gQLJOv+4yOwlJKFWEkj3u01vdPcM464AfAzVrr3kzGI0S+6Y9tLevMzgf/hFs31nOo08MBE06Gm4lDnR4AVtW6AHj9RUv49KvWzip5AKypcyX6TuIjsOK2rjBmtX/xoUNEo+YYjZXJUVgK+CFwUGv91QnOWQLcD9ymtT6SqViEyFf9sTkF2epEj7tp3WKKChX3p1iyPBcd7vRQX1485/uqFBUWcH6s32NdQ/moY2vqXHz0+jX89vl2PvPAflMM6c1kBXIZcBvwMqXU87GvG5VS71ZKvTt2zqeAKuC/Y8d3ZzAeIfLOQKwCcWQ5gVQ4rLzsnBp+90K7Kdd0mq4jXR5W186so3wqFzZVUmIt5JxFrnHH3rttBX9/xTJ+svMkX3s4+5+5MzkK60lg0let1vqdwDszFYMQ+a5/OFaBzPNEwlRevbGBP+3v4sljPWxbU5PtcGYsFIly/Iw3Y9fwD9es4jVbGrFZxu/bopTiEzeey9BImG88eoxzFpVy4wWLMhJHOmQmuhALWP9wiKJChT2ze0il5epzqikvKeI3KTZOyiUnenyEIppz6sZXCHPBabOwsmbi6kYpxb/fegHFRYXsOZndeSGSQIRYwAaGg5SXWFMu3jffbJZCXrV+MX94sYN7nz2V7XBmLN6Bvro2MwkkHYUFCrfLSq83kLUYQBKIEAta/3CQipLsTCJM5SPXreHSFVV87P59fOp3LxGKRAlFouxq6ePup04wHAxnO8QpHen0UFigWFHjyGocbqeNHm8wqzHMy0RCIUR29A+HKC+xAtn9pBpXVlzE3W+7iC8+dIjv7mjmyaM9nPEE8ASMxFFaXMStm8y9IMWhTg/L3Y6UfRTzqcph43T/cFZjkApEiAVswGQVCBjNLx+/8Vy+/roNuIqLuGn9Yr79xk0UKGjpMf+ii4e7hlidof6P6ah2WaUCEUJkTv9wiE0lWZ5FOIFbNtZzy8b6xM9feKiYlt7sfqKeii8QprVvhNdubsx2KFQ5bPT5AkSjmoJ52Os+FalAhFigtNaJTvRc0FTlMP2y70e6Yh3oJqhA3E4rUX12qHY2SAIRYoHyBSOEItp0TVgTWVpVYvoKJJ5AMjWEdzqqnDYAen2SQIQQsxSJ6lFrJMWXManIoQpkcCTEQBY/UU/lUKeH4qJCGitKsh0K7lgC6fFkb4CEJBAhFoh3/WwP//SrFxI/x5cxKc+ZCsQYFmvmKuRwp7GESbb6HJK5Yytk9kgFIoSYjUA4wo6jZ3jmRF/itnjbeIUjVyoQ41O9mftBjnR5szqBMFm8AsnmZEJJIEIsAC+1DREMR2kbGMHjNyqPRALJkQqksbIEpaClx5wVyOBIiB5vYNJlRuZTWXERhQWKHkkgQojZ2N1ytvI42u0FkpuwcqMCsRcVsqjUbtoK5ERsjsoyd3ZnoMcVFCiqHFZ6szgXRBKIEAvA7pP9OG3GtK6jsZFC8QqkvDg3KhAw+kFaTJpAms8YiXn5DPc7z4Qqp00qECHEzGmt2XOyn+vW1mIvKuBI19kKxGW3zHqXvPnU5C7hVJ85m7BO9PgoLFAsqcz+CKw4tzO7s9Fz55UlhEipucdHny/IRU2VrKxxJuYqGAsp5kbzVdySSgc93mCiH8dMms/4aKwoTmw5awZuqUCEELOxp8XYE2JLUyWra1xJCSSUMx3ocWdHYpmvCjl+xmuq5iswKhDpAxFCzNjuk31UlBSxotrB6joXXUMBBkdC9PtyZxmTuPhcELMlkGhU09LrY7lJOtDjqpw2RkIRfIHsLIMvCUSIHLe7pZ/NSytQSiX26T7a5THdXiDpWBqrQMzWkd4x5McfirKs2lwJ5OxckOxUIZJAhMhhvd4AzT0+Ni+tBGBVjTHJ7XCXh4HEXiC5w2GzUO2ymW4o74kzRjzL3eZqwqqKzUY/k6V+EEkgQuSw+J7YFzZVAFBfXozDWsiB9iG8gXDOdaKD0Q8y38uZdHv83PvsqVFriSVr7okP4TVXBVKd5dnokkCEyGG7T/ZjLSzg/PoywJhctrLWxbOxJU0qHLnVhAVGP8h8VyD37WnjY/fv4z8fOpTyePMZHw5rITUu27zGNZV4BZKtobySQITIYbtb+rigoQx70dntVVfXOBOz0XOtCQuMCqRrKDCv+6N3Do4A8N0dzdzzzMlxx5t7fCyvdqJU9hdRTFblkApECDEDWmsOdAyxvqF81O1rkvaqyLVOdDg7Ems+JxR2DQVY7nZw9ZpqPvW7/Tx2uHvU8eYzXtMsYZLMaimg1G7J2lwQSSBC5KjhYAR/KEpt6ehmlVW1yQkkFyuQ2LLu87ioYpfHz+LyYr71xk2sqXXx/nv2cirWD+MPRWgbGDFd/0ec22XL2pLukkCEyFF9sTeNyjHLtceH8kLu7AWSbKnbGMp7PLb2VDKt9YQd3bPRPRSgptSGw2bhB7dvIRTVfOfx44AxJ0Vr8yyiOJbbYcvaplKSQITIUfFmi3hHalxdqR1XbGHFXKxASu1FrGso4zfPtaH16GTxsfv28cpvPUk4Ep2z54tGNd0eP7WldgAWlxfzd5sbuG/PabqG/IlFFFeYbBZ6nNtlzdq2tpJAhMhRZyuQ0U1YSilW17mwFhZQYi1MdVfTu/3SJo51e3nqWG/itpYeH7/a08r+9iF+93z7nD1X/3CQUERTmzTC6l1XLiccjfKjJ0/QbLJl3MeqctikE10IMT3xT51VKXYc3LK0gmVuh+lGDaXrpvWLqHJYufuvLYnb7nr8OJbCAlbWOPn6I0cIhuemCukaMt584xUIGB35r1i3mJ8/fZLnWweojTVvmZHbaaN/OERoDquydEkCESJHTdQHAvCR69Zw/3u3zndIc8ZmKeQNFy3hkUNdtPYN0z4wwn17T/P6Cxv5fzeeS2vfCP+7u3VOnqvL4wegJimBALznqhX4ghEePtBluhnoyeJNmP1ZaMaSBCJEjurzBbFZUjdTWS0Fpv3EnK43XbKEAqX42dMn+d6OZrSGO65czrY11WxeWsE3Hz2KPxSZ9fN0DxkJZOxotvMWl7JtTTVgvhnoyeLrYWVjORNJIELkqF5vkCqHNWebqaayqKyYG9bWce+zp7h31ylu2VhPQ0UJSik+ev0auoYC/Pzp8ZP+pivehFWdYpb5e7etBDDNPuipuGMVSHxBxWdP9PHAC3PXRzQZSSBC5Kg+X4BKZ+6NspqO27c2MeQPEwhHec+2FYnbL1lexRWr3Hxn+/FZ94V0DfmpdFixWcZXchctq+Sed17Ma7c0zuo5MilegfR4Axw/4+WOn+3mvx45Omd9RJORBCJEjurzBceNwFpoLmyqYMvSCm7d2DBuGO1tlyyl1xdk98m+WT1H11Bg0jWuLlvpNnVzYLwP5EiXl7f9eBeFSvGj2y+cl50TzftbEUJMqtcXNO3chLmilOLX79k6bj4IwNaVbooKFY8fPsPWFe4ZP0fyHJBc5LRZsFkK+O6O41gLC/jFHZewpGp+9m2XCkSIHGVUIAu7CSsuVT+P02bhomWVbD98ZlaP3TnoH9eBnkuUUolmrK+/bgObllTM23NLBSJEDhoJRhgORhZ8H8hUtq2u4fMPHqR9YITF5cXTvn84EqXHG8jpCgTg7Zcvw2W38DcXLJrX55UKRIgc1OuLLWOSJxXIROLDbGdahfT6gkT1+DkgueYdly/LSke/JBAhctBEy5jkm5U1TurLi9k+Zvn1dHXF54CYbKOoXCEJRIgc1DvJLPR8opRi25pqnjrWM6Nhq6mWMRHpkwQiRA7q8068Dla+2bamBl8wwu6W6Q/njVcgdWWSQGZCEogQOSjRhJXnnegAW1dUYS0sYPuR6feDdA/5KVCSiGdKEogQOajXF6SoUCX2/chnDpuFC5dVjOoHiaS56VTXUAC304alUN4KZ0JefULkoD5fgMoFvA7WdMWH82767MN4/WEiWvOzt1/E1pWTTzDsyvFJhNkmCUSIHJQPy5hMx62b6mnu8VJYoLBbCvnBkyd4qX1w6gQyFKC+XBLITEkCESIH9fqCiVVYBVQ5bfzHresAY9/0e545lRhhNZnuIT8bl5RnOrwFSxr+hMhBvd78WcZkupRS1Jba6PZMnkCC4Si9viC1LqlAZkoSiBA5KJ/WwZqJmlJ7YojuROIbMOXyOljZJglEiBwTCEfwBsIy9HQStaX2xE6DE0nMQpdO9BmTBCJEjpFlTKZW47LRNRRIuQx8XNdgfC90+T3OlCQQIXJMfOtSacKaWG2pjZFQBE8gPOE5UoHMniQQIXJMvAKpklFYE4onhcmasbo8ASwFisoS+T3OVF4mEK0133zkKF986FC2QxFi2vpkIcUp1bjiCWTikVh7WvpprCyhoEAmY85UXiaQr//lKF95+Aj/u7s126EIMW3xlXilE31i8ZFVXZ7UFcgzzb0829LHbZcsnc+wFpyMJRClVKNS6jGl1EGl1H6l1AdTnKOUUt9QSh1TSr2olNqUqXjiHjwR5L8eOYrbaaXHG2Q4OHEbqRBm1OcLUFigKLUXZTsU04pvEDXRZMJvPnoMt9PKGy5aMp9hLTiZrEDCwEe01ucClwDvU0qdN+acvwFWxb7uAL6TwXj46c4W/vdwiJvWLeL/veJcAE73j2TyKYWYc/E5INL0MjGnzYLDWphyLsjeU/08eayHO65cTrG1MAvRLRwZSyBa6w6t9d7Y9x7gIFA/5rSbgZ9qw9NAuVIqI5v6BsNR/ueZU2ysKeR0qCAiAAAgAElEQVRrr9vA0ioHAK19w5l4OiEypscblOarNBhzQcZXIN985CgVJUW86WJpvpqteVkLSynVBGwEnhlzqB5I7og4HbutY8z978CoUKitrWX79u0ziuP952lC/jBPPbGDgYCxe9ljz75IYVd+NAV4vd4Z/+4WgoVy/SfaRygqYFrXslCufTqs0RGOtI6wffv2xPW3DEZ47LCfv11VxK6dT2Y7xHmR0b+91jqjX4AT2APcmuLYH4DLk35+BNg82eNt3rxZz8Zjjz2mtdY6Go3qNZ98UH/2gf2jju9vG9RXffFR3ePxz+p5zCh+7flqoVz/ti89pt93z55p3WehXPt0fOAXe/UV//mo1vrs9b/3nj36gjsf0kMjwSxGNr9m8rcHdus03t8zOgpLKVUE3Afco7W+P8Upp4HGpJ8bgPZMxpQUGw0VJbT2j27CevLYGVp6hzl+xjcfYQgxbb3egDRhpaE2th6Wjs1G11qz83gvN5xfh0sGIMyJTI7CUsAPgYNa669OcNrvgbfERmNdAgxqrTsmOHfONVYU09o3uhP9SJcXODvWXggzCUWiDPnDsoxJGmpcNgLhKEMjxkjLjkE/fb4gF9SXZTmyhSOTfSCXAbcB+5RSz8du+wSwBEBrfRfwIHAjcAwYBt6WwXjGaagoYc/J/lG3He3yANA/LAlEmE+/7IWetsRQ3thckJfaBgFYKwlkzmQsgWitnwQmHWcYa2t7X6ZimEpjZTFD/jCDIyHKiouIRjVHu6UCEeY15A8BUFYsTTBTqXXFJhPGhvK+1D5EgYJz60qzGdaCkpcz0eMaK0qAs0N52wZGGA5GAEkgwpy8AeP16bTJ/IWp1I6ZTLi/bZCVNU6Z+zGH8juBVBoJJD6Z8Gi3J3GsXxKIMCGv32jPd9qkAplKfJn27ngTVvsgaxdL89VcyusE0lBRDMDp2Eiso7EO9KVVJfRJH4gwIW9seXKHVCBTKrFacNktdA8FGAxouoYCrF0szVdzaV4mEppVWXERLpsl0YR1pMtLjctGU5VDKhBhSr5AvALJ6/+6aYsP5T1pM5r+zpcO9DmV1xWIUoqGyhJak5qwVte6qHJYEyueCmEmXkkg02LsTOjn5JCx8sR5UoHMqbxOIGA0Y53uHzZGYHV5WVXrpMJhlQpEmNLZJixJIOkwKpAAJ4eiNFWVyArGcyzvE0hjRQmtfSO0DYwwEoqwutZFpcOKLxjBH4pkOzwhRvEFwlgKFDZL3v/XTUtNqY0zngAtQ1GZ/5EBef8qbKwsZiQUYWdzLwCrapxUxLa4HBgOZTM0IcbxBsI47RaMhR7EVGpddoKRKD0jmvNlBNackwQSmwvy6MFuAFbFKhCAXt/E22EKkQ3eQBiHVZqv0hWfCwLICKwMyPsE0lBpDOV98lgPtaU2yoqLEgmk3ycViDAXXyCMyy4JJF3xrW1BEkgmTPhKVEp9I437D2mtPzmH8cy7eAXiDYTZuKQcgEqH0dEmc0GE2XgDYelAn4Yal1GBVNoVVU5ZgHKuTfZKvBn41BT3/xiQ0wnEYbNQ6bDS5wuyqsYFkOgDkZFYwmy8gYisgzUN8dnoS0vzvrElIyZLIF/TWv9ksjsrpSrmOJ6saKwops8XZHWtE4DyEitKIXNBhOl4/SEayouzHUbOsBcVct15tSy3DGQ7lAVpwrSstf46gFKqcuwxpdSy5HNyXUOsGWtVLIEUFijKi4ukAhGm4wtEZBmTafreW7ZwyWJp9suEdOq6B5RSid4npdR5wAOZC2n+LakyEsjKWBMWQIXDKn0gwnR80gciTCSdV+K/YySRVwBrgJ8Cb8poVPPsbVub2NhYPqptubJEZqMLc9Fa4w2GcUkCESYx5StRa/2H2N7mfwZcwC1a66MZj2we1ZTauW5t3ajbKhzWxCKLQpjBcDCC1rKMiTCPyYbxfhPQSTeVAs3APyil0Fp/INPBZVOVw8oLrdLxJswjsRKvzAMRJjHZK3H3mJ/3ZDIQs6lwWOkfDqK1lmUjhCl4ZCVeYTITvhKnGsK70FWWWAlFNN5AGJes4ClMIF6ByFImwiwmHIWllPreVHdO55xcVRFbzkT2RhdmkdjOVpqwhElM9kq8RSnln+S4Aq6e43hMI7GciS/I0ipHlqMRQjaTEuYz2Svxo2nc/4m5CsRsKh3GEgj9MhdEmIQvKJtJCXORPpAJVJbEm7BkRV5hDokmLEkgwiSmfCUqpS4DPg0sjZ2vAK21Xp7Z0LKrItGEJXuCCHPwBowdMiWBCLNI55X4Q+DDGMN482aPV6fNQlGhkgpEmIYvEKZAgb1IVpYV5pBOAhnUWv8x45GYjFKKSocsZyLMwxsI47TJdrbCPCabib4p9u1jSqkvAfcDifYcrfXeDMeWdRUlsqCiMI94AhHCLCZ7NX5lzM9bkr7XwMvmPhxziW80JYQZ+AJhmQMiTGWyUVgLdo5HuiocVg62D2U7DCEA2c5WmI/0xk2iUpqwhIlIE5YwG0kgk6h0WBkYDhGORLMdihB4/ZJAhLlIAplEZWw9rIERGcorsk92IxRmM2UCUUqVKKX+VSn1/djPq5RSN2U+tOyLL6goQ3mFGUgTljCbdCqQH2MM37009vNp4HMZi8hEzi5nIglEZJfWWhKIMJ10EsgKrfUXgRCA1noEYzmTBS/ehPWrPadle1uRVf5QlKhsZytMJp1XY1ApVUxse1ul1AqSJhQuZCtqHNywto77957mvr2n2ba6mldtWMyVq6qpctqyHZ6YA32+IO0DI5xfX5btUCblle1shQml82q8E3gIaFRK3QNcBrw1k0GZhc1SyF23baZ9YIR7d7Xyy12neOzwGZSCdQ3l/OO1q7lqdXW2wxSz8I1HjnLvrlM8/6nrsBcVZjucCZ3dC8S8MYr8M2UTltb6YeBWjKTxC2CL1np7ZsMyl8XlxfzjtavZ+bFr+P37L+ND16ymxxPgk7/dh9Y62+GJWTjQMYQ/FOW5UwPZDmVSsp2tMKN01sKK64j9u0QptSQf1sIaq6BAsa6hnHUN5dSV2fiX+/axv33I9M0fIjWtNUe6PAA83dzLpSuqshzRxKQJS5hROmth2THWwXoBo/N8HfAMcHlmQzO3686r4xO/eYk/7OuQBJKjzngCDAwbc3yebu7NcjSTk82khBlN2ISltb46th7WSWCT1nqL1nozsBE4Nl8BmlWFw8rWFVU8uK9DmrFy1OFY9XF+fSnPtQ7gD5l3uxvZzlaYUTrDeM/RWu+L/6C1fgnYkLmQcseNFyziZO8w+2XBxZx0pMsLwFsubSIYjvJ8q3n7QTyxCsQlCUSYSDoJ5KBS6gdKqW1KqatiM9IPZjqwXHD92joKCxQP7uuY+mRhOkc6PbidVq5fW4dS5m7GSnSiSwIRJpJOAnkbsB/4IPAh4EDstrxX6bBy6XJpxspVh7s8rKpxUVZcxNrFpaMSyEttg1z0+b9wsMMc1aUvEEYpKLHKMF5hHukM4/Vrrb+mtX517OtrWmv/fASXC268YBEtvcMc7PBkOxQxDVprjnZ5WFPnAuCSZVU8d8roB4lGNZ/63Ut0ewLsaxvMcqQGTyCM0yrb2QpzSWcxxRNKqeaxX/MRXC64fm2tNGPloLaBEXzBCKtrYwlkeRWBcJQXWge4/7k29sbmhXQPmeOzkqzEK8wonVdk8la2duA1QGVmwsk9VU4blyyv5KH9nfzT9WuyHY5IU3z+x5o6JwAXLqtEKXj4QBe/fb6dDY3lnOjx0WmaBBKROSDCdNJpwupN+mrTWn+dPNgPfTquWl3NsW6vaT6tiqkd7jRGYK2sMSqQsuIizltUyg+fOkGvL8C/3byWulI7XUPmWPbNIxWIMKF0mrA2JX1tUUq9G3DNQ2w54+JlxgzmZ070jTsWCJt3bkE+O9rlYVGZnbLiosRtlyyvQmt4/YWNrGsop6bURpdJPhT4AmFZB0uYTjqjsL6S9PUfwCbgtZkMKtesXVyK02bhmROjh4Huaunj/Dv/xIkeX5YiExM53OVJ9H/E3bKhnkuXV/FP1xlNkUYFYqYEIhWIMJd0XpHv0FqP6jRXSi3LUDw5yVJYwJamCp5uHl2B/Oa5NkIRY7TPMrcjS9GJsSJRzdFuL1vHrH11QUMZv7jjksTPtaV2zngCRKKawoLMj3461TtM33CQDY3l4455/NKEJcwnnQrk12neltcuXlbFsW4vPV6jzTwS1fx5fxcA3R5ztKMLw8leH8FwdFwFMlZtmZ2oJvE3zbQvPHSQ2374TMolVXxBqUCE+UyYQJRS5yil/hYoU0rdmvT1VozRWJNSSv1IKdWtlHppguNlSqkHlFIvKKX2K6VyenLixcuNgWnPxvpB9p7qT7zxSAIxl/gSJvE5IBOpdRmbhs1XM9aJnmE8/jCPHuoedbvWGq9fEogwn8kqkDXATUA58Mqkr03A36fx2HcDN0xy/H3AAa31emAb8BWllDWNxzWlC+rLKLEW8kxsNvNDL3VitRTgslk44zFHO7owHOnyoBSsrHFOel5dmfE5qXMw838/rTWneo2+svv3to06FghHCUe1NGEJ05nwFam1/h3wO6XUpVrrndN9YK31DqVU02SnAC5lTK11An1AeLrPYxZFhQVsXmr0g2iteeilTq5Y6aZtYIRukwwFFYbDXR4aK0oomWJzptpSI4F0zUMF2esL4gtGKC8pYvvhbvp8QSodxuep+DpYLpkHIkxmsg2l/llr/UXgjUqpN4w9rrX+wCyf+1vA74F2jGHBr9NaRyeI5Q7gDoDa2lq2b98+4yf1er2zuv9kagjyRFeIb9/3CG0DAW5oiNAVjnC83Zex55yOTF67GfhCmp8dCPDmc204reM7vePXv79lhFKrmvJ3EYlqFPDsi4dp9J/ITNAxxwaMfo+X1cP9RzVfu+9xrlliDDHuHjb+W7Q2H2V7oGVGj7/Q//ZTyefrz+S1T/aRJr7i7u6MPDNcDzyPMSlxBfCwUuoJrfW41eu01t8DvgewZcsWvW3bthk/6fbt25nN/SfjbOrjvqM7+b/TVgoLgrzv1Vcx+OBBnjzak7HnnI5MXrsZ/Hl/J08/sod33bCWbWtqxh2PX7/niYe5dHkd27ZdMOVj1jz9F+wV1Wzbtj4TIScMPNcGTz/Pe266lAO/eI793kI+u+0yAPa3D8KOJ9m8/gK2nV83o8df6H/7qeTz9Wfy2idrwnog9u9PMvLMxoq+X9DGMrbHlFIngHOAZzP0fBm3rqEce1EBhzo9bF1RRaXDSo3LRo83QDSqKZiHoaD5LN7ZHd87IxV/KEKvL0h9+ZTjQACjGWs+ljM52TsMQGNlCbdsrOcLfzzEyV4fS6sc+AJGdSJNWMJsJmvCegCjnyIlrfWrZvncp4BrgCeUUrUYnfY5vUij1WL0gzx1rJcbYp8Ua1w2wlFN33AQt9OW5QgXts5EAglNeE77wAgAi8uL03rM2lI7p2Jv7pl0qm+YulI79qJCXrV+Mf/50CHu39vG+sYyvvGIsQFolTNnx5iIBWqyjzRfns0DK6V+gTG6yq2UOg3cCRQBaK3vAj4L3K2U2oex1/q/aK17ZvOcZnDZSjfPNPdx3XmxBBLriO0eCkgCybDOQaOze7IKpH3ASDLpJxAbu1rGL1Ez1071+VhSWQIYsV2yrIpvPHoUrWFxmZ3P3XI+59SVZjwOIaZjsiasx+Pfx4bXnoNRkRzWWgenemCt9biO9zHH24Hr0g81N7z9smVce25tYghodWwuQbfHz3nIG0AmxZuwvJMmEKMCqU8zgdSV2hkYDuEPRbAXZW4tqpO9w1y5ujrx87u3rSAcjfL6C5fwqg2LKSpMZ86vEPNrykZVpdQrgLuA4xiVwjKl1Lu01n/MdHC5yF5UyKqkGc41iQQiQ3kzLZ0mrLaBEZQ6O8djKskV5JKqktkHmcJIMEK3J8DSyrOPf9Xqaq5KSihCmFE6vXJfAa7WWh8DUEqtAP4ASAJJQ43LeAM6Iwkk4+IT/iZvwhqh1mVP+xN9XSyBdA75M5ZAWvuNPpZMPb4QmZLO/6LuePKIaQa6JzpZjFZsLYzNRpcEkkneQBhvbMLd0GQJZHCExWmOwIKkyYQZHIkVH4G1pFISiMgt6SSQ/UqpB5VSb1VK3Q48AOyKr42V4fgWhOpSG92ynElGJS834g1MNgrLn3YHOpytQGaTQIaDYd79sz209qUezXUqdvvSKlmxWeSWdBKIHegCrsIYVXUGY0vbV2KslSWmUOOyyXImGRZ/g3faLBM2YWmtaRsYSbsDHaC02ILNUjCrBHKwY4iH9neOWyQx7lSvD5fNQkVJUcrjQpjVlH0gWuucXiXXDGpcdp5vHch2GAtavAJZUeOk35d6kKAnCMFwdFoViFIqNpkw9QeAaFSjlHHeROIfHlp6U28sdrJvmMbKkkkfQwgzSmcU1jLgH4Cm5PPnYCJh3qhxGU1YWmt5k8iQ+AisldVOHu3tSnlOr99YU2o6CQQm35nw/b/Yiy8Q4Sdvv2jC+8dH4LVMsDPlqb5h1kyxN4kQZpTOKKzfAj/E6PtIudihmFy1y4Y/FMUTCFNql2aKTOga8lNqt1BTasPjD6dM1j0jxsIK0+lEB6gptfFS2+C42x852MWD+zpx2iyTfjiI93+1pJjRHolqTveNcO15tdOKSQgzSCeB+LXW38h4JAtYTakxF+SMJyAJJEM6B/3Uldlx2S2Eo5pAODpu4l+f30gg0+kDAaMC+cvBrlFJwh+K8JkHDgDGCLAz3kBiyPZY8Sas1r5hwpEolqQhxJ1DfoKRqIzAEjkpnU70/1JK3amUulQptSn+lfHIFpD4G4t0pGdO15Cf2lI7rliCHkoxmbB3JEqJtZCy4ukl8dpSO/5QdNTw4O/taOZU3zDvunI5ACfOpG6egrNNWOGo0YmfLL7O1tJKGYElck86CeQCjB0Iv4AxqfArzHKdrHxTk7SciciMziE/daV2XLFd+1KNxOr1axaXF0+7H6q2bPRQ3ta+Yb792DFeccEi3nzJUgBOTNC/AUYCiSetsc1Yp/qM+y2VSYQiB6XThPVqYHk661+J1GQ2emaFI1HOeAKJJixInUD6RjSNddNrvoLRe6NHopo7f7efAqX4xCvOpa7UjtVSQPNkCWTIz4VNlfzlYBctPb5RS5Sc7B3GUqBYlObSKkKYSToJ5AWMfdFl9vkMlRZbsFoKZD2sDOnxBolqRjVhpVpQsdcf5ZJpdqDD2XWz/t9vXuJU3zAl1kI+86q1ib6UpqoSmidowgpFovT6gpy3uJSdx3vGVSqn+oapryge1S8iRK5IJ4HUAoeUUruAxDugDONNn1IqNplQmrAyoWPQ6FeoK02uQEb3gfhDEYaCsLhsBhVIqR2nzcJwMMJHr1/Dmy9eSlnSpL9lbgfHur0p79vjDcQew8bSKgcnx8wFaen1SQe6yFnpJJA7Mx5FHjDmgkxdgTx8oIvdLX18/MZz5yGqhSHeNzFZE1bH4PT2AUlmLyrk0X+6ilJ7Ucol3Ze5nTx6qHvcCCs4O3CixmVnmdvBgY6zOzZ7/CEOdnh4z1Urph2TEGYwZd2stX48+QsIA6/NfGgLS7XLllYfyC93neJHT50gGp1wM0gxRnwWel2ZHZct9Sis6e5EOFaNyz7hfiDL3Q5CkfEjrODsCKwal42lVSWJobwAu1r6iEQ1l66omlFMQmRbWg2vSqkNSqkvKqVagM8BBzMa1QJU47KnVYEc7PAQiuhE04eYWudQgKJCRWWJFecEFUjbNDeSmo5l1cYQ3FQd6fGRdzWlNprcjlFDeXce78VaaGyDLEQumjCBKKVWK6U+pZQ6CHwLaAWU1vpqrfW35i3CBaLGZWNwxNjZDowZyGOrDI8/lHhzSfVpVqTWNeSnxmWnoEBRWKBwWAsTS7vHtQ+MoIDasrnfVniZ20ggqeaCdA8FUArcTtvZ82KJZmdzLxuXlGd0p0MhMmmyCuQQcA3wSq315VrrbwKR+Qlr4Umejf7X4z1s+dzD/Pf2Y6POOdLlSXwf37tbTC0+Cz3OZS8a14nePjBCmU1hs8z9m3WVw0qp3ZJyLki3J0BliZWiwoLEXI+TvcMMDAfZ3z7E1hXuOY9HiPkyWQL5W6ATeEwp9X2l1DUYW9qKGYjPBbnr8eO85YfP0j8c4pExy3sf7EhOIFKBpKsrNokwzmUfv6R7+4CfSntmXr5KKZZVO2nuGT8Sq3vIT3VsHkm104bDWsiJHh/PnOhDa6T/Q+S0CROI1vo3WuvXAecA24EPA7VKqe8opa6bp/gWjPibyD3PnGLrSjdvvHgJ+9uGCITPFnWHOz24bBYc1kLaByWBpENrTWdsGZM4Z8oEMkJVceY+/yx3O1I3YXkCidiUUomhvDuP92IvKmBDY3nGYhIi09IZheXTWt+jtb4JaACeBz6W8cgWmCVVJbhsFm6/dCk/un0LV66qJhiJ8lLb2WGdhzs9rK5zsbi8WCqQNHkCYYaDEeqS+jbGNmFprWkfHMlYBQJGP0j7oJ+R4OhW3m6PP7GUTfy8lt5hdh7v5cKmSqwWmUAocte0Xr1a6z6t9Xe11i/LVEALVam9iOc+dS2fufl8LIUFbFpqfPJ87lQ/YLzJHewc4pxEApE+kHR0xYbw1o5twkrqRDcGL0SptGfuzTreQZ68aVQkqunxBhP9XwBN7hJO9vo43OWR5iuR8+TjzzxKnmRW47LTUFHM3lgC6Rj04/GHkxKIVCDpiG8kldwHUjqmCSs+iTDTFQiMXlSxzxckEtWjlnlfWuUgPvju0uWSQERukwSSRZuWVLD3pLHV7eFOowN9TV0pi8vs9PqCiSG/YmLJkwjjjH3RQ+POqZjnBJKYAzKmCSse4wX1ZRmLR4j5IAkkizYtKadzyE/7wAgHO42+kDWxCgTOfnIWE4svYzK6CasIfyhKKDbjez4qEIfNQl2pfdSiiolZ6ElNWPGhvBctq5QFFEXOk1dwFm2KzUDee6qfw50eFpfZKSsuSiQQacaaWtdQgPKS0WtUxdfDiq/I2zE4QoGCMmtmR6EvcztGDeWNL56Z3IRV7bRx9ZpqXrulIaOxCDEf0llMUWTIuYtKsRcVsPfkAIc7PaypcwFnl9uQ2ehT6xryUztmK9n4ku4ef5gKh5WOQWOmemFBhhNItYM/vNiR2Po2vpBidVITllKKH7/toozGIcR8kQoki4oKC1hXX86zLb0c6/ZyzqJS4OxyGx0yEmtKXZ7AqCYiOFuBxBdUHDtTPVO2LK1gcCTEsyf6gLM7EcpSJWKhkgSSZRuXlvNS2xDhqOacWAVisxRS7bKNasLq9wX50L3P0eeTjSGTdY+ZRAiM29a2Y3BkXnb8u+H8Opw2C7/ac9qIbcwcECEWGkkgWbZpydmVWONNWGAsO548G/2h/Z389vl2njh6Zl7jM7NoVMdmeo+tQOJNWCG01nTMUwVSYrXwyvWL+MOLHXgDYbpTVEdCLCSSQLIsnkAsBYrlbmfi9vpy+6g+kL8e7wWYcOvUfNTjCxCJ6vEVSLwTPRBOzFSfrz3HX7OlkZFQhD+82E73UGBUB7oQC40kkCyrdtlorCxmZY1z1LIWi8qK6Rjwo7VGa83O4z1A6j0n8lW8k3qiBOLxhxNzQBbNYCvbmdjYWM6Kage/3NXKGU9AmrDEgiajsEzgk684j0I1eoTQ4vJiRkIRBoZDdHsC9HiDFBYoms+k3ns7H6WaAwIkbSoVSswBWVRmx9uf+ZiUUrx2SyP/8cdDwOgRWEIsNFKBmMD1a+t4+Xm1o26rLzfeFNsGRvhrrPq45pwams/4ZLvbmK5EBTL6TdpmKcRqKYhVIEYz4Hz0gcS9elN9YshwTak0YYmFSxKISSVPJvzr8V6WVJZw5epqRkKRxPpP+a5ryJ/Y7W+sUruFIX+YjkHjnPnsi6hx2bl6TQ0AtVKBiAVMEohJxdvsW/tHeLq5l60rqlge33tbOtIBY5hslcNGUYolQVz2IrwBow/E7bTN+7Lpb7+siSqHlRU1zqlPFiJHSQIxqSqHFaulgL8c6MLjD3PpiipWVBtvRql2vstHxgTB1J/wjV0JjT6Q+RqBlWzrSjd7/vXalNWREAuFdKKbVEGBYnGZnZ3NxvDdrSvcuJ1WHNZCqUBiuoYCEyYHY0XeMF5/OLGAoRBibkkFYmLxfpDVtU6qXTaUUiyvdnJcRmIBsZneE3RSn61A5mcWuhD5SBKIicX7QbaucCduW17tkAoECEWi9HiD40ZgxbnsRXQNBRjyh6mbpzkgQuQbSSAmFh/Km7z16XK3k/bBkXF7b+ebM57UkwjjXHYLgyPGYopSgQiRGZJATGxzUyVLKktGJ5BqB1qP3vkuH6XayjZZfD0smN85IELkE0kgJnbV6mp2/PPVlCa9GSaG8ub5SKzEZk0TNWHZzo4PWSxNWEJkhCSQHBPfU3uifpDBkRADwwt/yfeuCdbBiouvhwUTJxkhxOxIAskxJVYL9eXFKdfE0lrzlh89y8u/+jitfcNZiG7+dA35sRQoKkusKY/Hm7CqHFbZ0EmIDJEEkoOWVztSrsq783gvL7QO0OcL8tYfP8vgcCgL0c2PriFjpduCCbapjVcg0v8hROZIAslBy93GUF6tRy+q+N0dzbidNu5+20W09o1wx892EwgvzNFak80BgbMJREZgCZE5kkBy0PJqJ95AODGUFeBgxxCPHznDW7cu5crV1XzpNet45kQfH79/XxYjzZzOQf+EI7BAKhAh5oMkkBwUH4l1LKkf5Ps7mimxFvLmS5YCcPOGet5+2TLu39uWmA+xkHQN+SecRAhn+0DmayMpIfKRJJAcFF9U8a7Hmzl+xkv7wAi/f6Gd113YSHlSp/I15xpLir/QOpCVODNlJBhhyB+etAmrxmXjH162kpvWLZrHyITIL7KYYg5aXF7MP9+whm89eoxrv/o4y9wONPCOy5eNOm9dQw3GGVUAABWASURBVBlKwXOnBrhydXV2gs2Abk/qnQiTKaX4yHVr5iskIfKSVCA56r3bVrLjn6/mbZcto7V/hFs21NNQMXrVWZe9iNU1Lvaemoe9XOfRRDsRCiHml1QgOczttPGvN53HB1++Crsl9VyHTUvLeXBf54LaBrdrimVMhBDzI2MViFLqR0qpbqXUS5Ocs00p9bxSar9S6vFMxbLQldqLJtxxb2NjBYMjoZTzRnJVV2IZE0kgQmRTJiuQu4FvAT9NdVApVQ78N3CD1vqUUqomg7HkrY1LygF47lQ/udwL8rOdLTy0vxOAk73D2IsKKLVLAS1ENmWsAtFa7wD6JjnljcD9WutTsfO7MxVLPltR7cRlt/Bcjo/EuuvxZo50eQmEoiwqs3P71iaUSj0LXQgxP9TY2cxz+uBKNQH/p7U+P8WxrwNFwFrABfyX1nqiauUO4A6A2trazffee++MY/J6vTidzhnfPxd9eZefwaDmX9ZHcvLavUHN+x8d5rWri7hxeeq1r9J6nDz828fl87VDfl//TK796quv3qO13jLVedlsA7AAm4FrgGJgp1Lqaa31kbEnaq2/B3wPYMuWLXrbtm0zftLt27czm/vnor2hI3zr0aMU2h05ee1PHeuBR5/hlVds5IpVM2+Iy8e/fVw+Xzvk9/Vn8tqzmUBOAz1aax/gU0rtANYD4xKImJ1NS8qJajgxGM12KDOyv30QgLWLy7IciRAiWTbngfwOuEIpZVFKlQAXAwezGM+CtbGxAoDjA7m5sOL+9iEWl9mpdMy8+UoIMfcyVoEopX4BbAPcSqnTwJ0YfR5ore/SWh9USj0EvAhEgR9orScc8itmrqykiBXVDo4P+LMdyoy81DbIeVJ9CGE6GUsgWus3pHHOl4AvZSoGcdbGJRX86cXTaK1zavTScDBMc4+Pm9YtznYoQogxZCmTPLG+sRxPCNoGRrIdyrQc7PCgNZxfLxWIEGYjCSRPNJQby5rH15Eyo3Akyqd/v5+WpFnzBxId6KXZCksIMQFJIHnC7TQWHuzxmjeBHO32cvdfW/j6X84OxHupbYiKkiLZWVAIE5IEkifcLmMEk5kTSFu/0bz2h30diSXb93cMsnZxWU712wiRLySB5IkqR6wC8QSzHMnE4v0zoYjmf545RSgS5Uinl7X10nwlhBlJAskTVksBjiJzVyCn+4exWQq4cnU19zxzigPtQwQjUZlAKIRJSQLJI2VWZeoE0jYwQn1FMW/b2sQZT4Av//kwIB3oQpiVJJA8UmpTnPGYN4Gc7h+hvryYq1ZX01RVwhNHeyixFrKsypHt0IQQKUgCySOlZq9A+kdoqCihoEBx26VNAJy3qJSCAulAF8KMJIHkkTKbosdrzk704WCYXl+QhgpjvsprtjTgslvYtLQiy5EJISYiW7rlkVKrwhsI4Q9FsBel3kM9W9pjI7DiCaTUXsSfP3wlZcVF2QxLCDEJqUDySJnNaApKtx9kyB+id56avFpjc0DqYzPmARaVFVNilc84QpiVJJA8Umo1Eki6/SD/+tuXeMdPdmcypIT4JML6iuIpzhRCmIV8vMsj061A9rcP0TU0P0vAtw2MUFSoqHHJkiVC5AqpQPLI2Qpk6o70SFRzqncYjz+MLxDOdGic7h9hUVkxhTLiSoicIQkkj5Ta0m/Cah8YIRgxtsDtnIcqpK1/ONGBLoTIDZJA8khRgaKsuCitBNKctKR612DmE0h8EqEQIndIAskzbqc1rQSSvCdHR4YTSCAcodsToKGiJKPPI4SYW5JA8ozbaUtrRd4TPT7sRcbLI9NNWO2xvdplBJYQuUUSSJ5xu2ycSbMJa2WNk7LiIjozXIG0pZgDIoQwPxnGm2eqnTZ60hjG29LjY31jOaGwzngFcrp/GEA60YXIMVKB5Jlqlw1PIIw/FJnwnEA4wun+YZa5HdSV2TNfgQyMUKCgTratFSKnSALJM27n1FvbtvYNE9WwzF1CXak94xVIW2wOSFGhvByFyCXyPzbPuJ2xrW0nmUx4osdoUlrmdlJXZqfHGyAUmxOSCTKEV4jcJAkkzyQSyCT9ICd6vAAsqzKasLSG7gxuRBXfiVAIkVskgeQZtytegUyWQHxUOqyUlRQl+iU6B0cyEk8oEqVjcEQ60IXIQTIKK8/E+0CSF1R8qW2QFdVOiq3GHiHNZ3wscxvbyNaVxhPI3FUgHYMj/O75dtbUuXA7bES1DOEVIhdJAskzNkshpXZLogI53T/Mzd9+itdf2MjnX30BAC29Pi5fWQ3AolgF0jGHFcjdT7Xw3R3No26TJiwhco8kkDzkdtkSnei/2n2aSFTzq92n+cA1q3DaLHQNBVhebVQgZcVF2IsK5nRZ9z0n+1nfUMbHbzyX51sH6Bz0c2FT5Zw9vhBifkgCyUNupzEbPRLV/HrPac5dVMqRLg8/eKKZmzfUAySasJRS1JXa52w9rGA4yottg7zlkqVcsryKS5ZXzcnjCiHmn3Si56Fqp40eb4Anj/XQNjDC+65ewavWL+aeZ07xXOsAAE1VjsT5dWX2OatADnQMEQxH2bS0Yk4eTwiRPZJA8lC1y1jO5H93tVJRUsT/b+/ug+Oq7jOOfx9JrCxLfkFyLDu2BcQBgwsFjE15SYNDEvOSTICElNCkJSkNJa8kU9qm7XSa/tFJMkkL7bSlJYRApy1pBmhCnbSQ0hiKIWBiBzA4GAN+w+A3Gduy0Puvf9y7tixblr3a1dr3Pp8Zj7RXV3vP8dndR/ece859/9xWPrNwNp09/dzyk9UAnDhl38q45TwDWb5uBwDz2hwgZsc6B0gOTWkqsKurj4deeIOrzp5JfV0tp7ROYNHcVtr39DBt4jjGF/b1bk6b1MDmXV0MDMSoj718/Q5mTG7wsiVmGeAAyaHiZMLe/uCaBbP2bv/ce94J7Bv/KJo2sZ7e/qC9Mxl4X7NlN5/87lNs2X3kZyXL1+3g7LbJpRbdzI4iDpAcKgbIWbMmM2fahL3bz5w1mU//+kl85JyZ++0/bVJyiW1xUcVvP/oqS17cytd+/MsjOu4bO7vYtLPL3VdmGeEAyaHinItrz511wM/+9ANzufqAAClOJuyio7uP/3x2ExPH1fEfK17jyVe2H/Zxl69Pxz88gG6WCQ6QHDpt+kTu+8z5fPScAwPkYPZOJtzVxeJnNtHZ088/fuIcZkxu4M9+uPKwF1pcvm4H9XU1zJ0+seSym9nRwwGSU+ec0ExNjQ5r3ylN9dTWiM07u7hn2QZOaW3i/NktfPVDv8LqzR3ctXTtYT3P8vU7OGPGJAp1ftmZZYHfyTai2hoxdUI9S1Zv4ZkNb3LNgjYk8f65rbz31Knc+j+rR5wn0t3Xz8rXdrn7yixDHCB2WKZNGsfK13ZRqK3hw2fP2Lv95kvmsKenn0dXbz3k7z+/aRc9/QPM8xVYZpnhALHDUlyV95LTp3F8Y2Hv9lnNyYTD9j3D36AKPIHQLIscIHZYildiXbtg/4H3xkIt9XU1bB8hQJ5eu4OZxzcwdaInEJplhRdTtMNy+RnT6e4bOGDxQ0m0NBbYfohb5PYPBE+8sp1Fc1srXUwzG0MOEDssC05sHnbJ9eamAu17hr/h1AubdrHzrV4ufOeUShXPzKrAXVg2ai2N9Yfswlr68jYALpjtpdvNssQBYqM2UhfW0jXbOHlqk8c/zDLGAWKj1tJUYPswXVjdff0sW9vu7iuzDHKA2Kg1N9bT1TtAZ0/fAT9bsf5NunoH3H1llkEOEBu1lnReyMG6sR5fs40awa/51rVmmeMAsVFraUoD5CAD6Y+t2cYZMyczqeG4sS6WmVWYA8RGrTk9Axl6Ke/url6e2biTC919ZZZJDhAbteINqrYN6cJ66tV2+geCd3kA3SyTHCA2avvOQPYPkKVrtlNfV+MVeM0yygFioza+UMu442oOCJBla9uZ13Y8446rrVLJzKySKhYgku6UtEXSyhH2WyCpX9LVlSqLVVayHlY92zr2jYFEBGu37eGU1qYqlszMKqmSZyB3AZceagdJtcA3gAcrWA4bA82Nhf3OQHZ09rK7u4+2lsYqlsrMKqliARIRjwLtI+z2BeA+YEulymFjo6Vp/+VM1m3fA0Bber8QM8ueqq3GK2kGcBVwMbBghH1vAG4AaG1tZcmSJSUft6OjY1S/fyyrZN17d3ezqb1/7/P/bFMyK33Ly8+zZMuqihzzSLntl1S7GFWT5/pXsu7VXM79VuCPIqJf0iF3jIjbgdsB5s+fHwsXLiz5oEuWLGE0v38sq2TdH+9cxdOPr+Wiiy5CEs89/BKwmg9fchENhaNjEN1tv7DaxaiaPNe/knWvZoDMB76XhscU4HJJfRHxgyqWyUrU3Figu2+Azp5+GuvrWN/eydQJ9UdNeJhZ+VUtQCLipOL3ku4CFjs8jl0tg+aCNNbXsa69kxNaPP5hlmWVvIz3HuAJYI6kjZKul3SjpBsrdUyrnuJ6WMVLeTe0dzLLA+hmmVaxM5CIuPYI9v1kpcphY6O5MVnOpH1PD129/byxq4sTmn0Jr1mWeSa6lcXgJd037ugkAtpaGqpcKjOrJAeIlcXgJd3Xt3cC0OYzELNMq+ZVWJYh4wt1NBxXS/uebtZtT/4u8SRCs2xzgFjZNDcms9H7BoLxhVqmpGclZpZNDhArm5amAtv39LDzrV7amscz0gRRMzu2OUCsbFoaC2zt6Ka7d4CTpnj8wyzrPIhuZdPcWM/2jmQQ3ZMIzbLPZyBWNlOaCry+swvwALpZHvgMxMqmeGtbwPcBMcsBB4iVTUtT/d7vfQZiln0OECub4mz0GsGMyZ6FbpZ1DhArm2IX1vRJDRTq/NIyyzq/y61sisuZ+Aoss3xwgFjZtKQr8nr8wywfHCBWNg2FWj4ybyaXnTG92kUxszHgeSBWVn/1G2dWuwhmNkZ8BmJmZiVxgJiZWUkcIGZmVhIHiJmZlcQBYmZmJXGAmJlZSRwgZmZWEgeImZmVxAFiZmYlcYCYmVlJHCBmZlYSB4iZmZXEAWJmZiVxgJiZWUkUEdUuwxGRtBVYN4qnmAJsK1NxjjV5rjvku/55rjvku/6l1P2EiHjbSDsdcwEyWpKejoj51S5HNeS57pDv+ue57pDv+ley7u7CMjOzkjhAzMysJHkMkNurXYAqynPdId/1z3PdId/1r1jdczcGYmZm5ZHHMxAzMysDB4iZmZUkNwEi6VJJL0paI+kr1S5PpUmaJemnklZJel7STen2Zkk/kfRS+vX4ape1UiTVSlohaXH6+CRJT6Z1/3dJhWqXsVIkTZZ0r6Rfpq+B8/PS9pK+nL7mV0q6R9K4LLe9pDslbZG0ctC2g7a1En+bfg4+K2neaI6diwCRVAv8PXAZMBe4VtLc6paq4vqA34+I04DzgM+ldf4K8HBEnAw8nD7OqpuAVYMefwO4Ja37DuD6qpRqbPwN8N8RcSpwJsn/Q+bbXtIM4IvA/Ig4HagFPka22/4u4NIh24Zr68uAk9N/NwC3jebAuQgQ4FxgTUS8EhE9wPeAK6pcpoqKiNcjYnn6/W6SD5AZJPW+O93tbuDK6pSwsiTNBD4A3JE+FnAxcG+6S5brPhF4N/AdgIjoiYg3yUnbA3VAg6Q6YDzwOhlu+4h4FGgfsnm4tr4C+OdI/AyYLGl6qcfOS4DMADYMerwx3ZYLkk4EzgaeBFoj4nVIQgaYWr2SVdStwB8CA+njFuDNiOhLH2f5NfAOYCvw3bQL7w5JjeSg7SPiNeBbwHqS4NgJ/Jz8tH3RcG1d1s/CvASIDrItF9cvS2oC7gO+FBG7ql2esSDpg8CWiPj54M0H2TWrr4E6YB5wW0ScDewhg91VB5P29V8BnAS8HWgk6bYZKqttP5Kyvg/yEiAbgVmDHs8ENlWpLGNG0nEk4fGvEXF/unlz8ZQ1/bqlWuWroAuBD0laS9JdeTHJGcnktFsDsv0a2AhsjIgn08f3kgRKHtr+fcCrEbE1InqB+4ELyE/bFw3X1mX9LMxLgCwDTk6vxCiQDKo9UOUyVVTa5/8dYFVE/PWgHz0AXJd+fx3ww7EuW6VFxB9HxMyIOJGkrf83Ij4O/BS4Ot0tk3UHiIg3gA2S5qSb3gu8QA7anqTr6jxJ49P3QLHuuWj7QYZr6weA306vxjoP2Fns6ipFbmaiS7qc5K/QWuDOiPjLKhepoiS9C/g/4Dn2jQP8Cck4yPeBNpI320cjYugAXGZIWgjcHBEflPQOkjOSZmAF8ImI6K5m+SpF0lkkFxAUgFeAT5H8wZj5tpf0F8A1JFcirgB+l6SfP5NtL+keYCHJsu2bgT8HfsBB2joN1b8juWqrE/hURDxd8rHzEiBmZlZeeenCMjOzMnOAmJlZSRwgZmZWEgeImZmVxAFiZmYlqRt5F7Njm6QWkgXlAKYB/SRLfQB0RsQFZT7eeODbwK+SzPx9k+SyyTrgNyPiH8p5vCHH/irQERHfqtQxzIocIJZ5EbEdOAvG7AP2JmBzRJyRHnMO0Etynf5ngYoFiNlYcheW5ZqkjvTrQkmPSPq+pNWSvi7p45KekvScpNnpfm+TdJ+kZem/Cw/ytNOB14oPIuLFdNLa14HZkn4h6Zvp8/1B+jzPphPgkHRieh+Pu9Pt96ZnNaTleiHdfsgQlPRpSf8lqaEc/1dmQ/kMxGyfM4HTSJbGfgW4IyLOVXIzri8AXyK5z8YtEfGYpDbgwfR3BrsTeEjS1SRdZ3dHxEskCxqeHhHFs6FFJPdlOJekq+sBSe8mmTk8B7g+IpZKuhP4bPr1KuDUiAhJk4eriKTPA4uAK7My49qOPg4Qs32WFdcFkvQy8FC6/TngPen37wPmJitCADBR0oT0nisARMQv0mVTFqX7L5N0PvDWkOMtSv+tSB83kQTKemBDRCxNt/8LyU2SbgW6gDsk/QhYPEw9fotk0bwr0wUFzSrCAWK2z+C/1AcGPR5g33ulBjg/IoaGwX4iooNkJdj7JQ0Al5OsjDyYgK9FxD/ttzG5f8vQNYYiIvoknUuyQODHgM+TrDQ81EqSMZ+ZwKuHKqfZaHgMxOzIPETywQ3sXbRwP5IuHHQP6gLJbZTXAbuBCYN2fRD4nfSeLUiaIal445+29KwF4FrgsXS/SRHxY5LutAOOnVoB/B5Jl9jbS6um2cgcIGZH5ovA/HQQ+wXgxoPsMxt4RNJzJB/mTwP3pVeDLZW0UtI3I+Ih4N+AJ9J972VfwKwCrpP0LMkKsrelP1ucbnsE+PJwhYyIx4CbgR9JmjL6apsdyKvxmh1l0i6sxRFxepWLYnZIPgMxM7OS+AzEzMxK4jMQMzMriQPEzMxK4gAxM7OSOEDMzKwkDhAzMyvJ/wNCSC48Gj/bRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGWCAYAAABW5tXRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xl4W+d14P/vAYmFC7ivErXYEiXZlizHkpN6i+Usru2sTSbtpE06SZOmmTZtppNJ3PbXTmam6ZJpM2mbTJs4k63N1jZNmtiOndixaXm3JduSZe27uIkbuADEjvf3x8UFN5AESSwEeD7P48ci7gXwXoDEwXmX84oxBqWUUmqpHIVugFJKqeKkAUQppdSyaABRSim1LBpAlFJKLYsGEKWUUsuiAUQppdSyaABRWSEiXSLy4XmO/Q8R+VaGj/MNEfnMMtuQ8X2TbYqKiF9EqpbzfLMe703Jx0qIyJtW+njZsNB7ssJzzy/3Gpdy32SbQiKyP8PztyXfg3im16JWRgPIGpL84w0m/8j6kx+41YVuVwH9szGm2hgTSHdQRNaLyI9EZEREukXko/M9kDHmEWNMNXAxZ61dmz5mjHm9/YOIXCUij4rImIicFpFfso8ZY04m34MnCtLSNUgDyNrztuQf2XXAa4A/LHB7VrNvAeeAVuAtwJ+LyO2FaIiIlBfieVeT5GvwI+B+oAH4CPAtEdlW0IatYRpA1ihjTD/wU6xAAoCIuEXkr0XkoohcFpEviUhF8li9iNwvIoMi4kv+u2M5zy0i/5rMgMZEZL+IXDPrlCYReVhEJkTkcRHZNO2+O5LHRkTkhIj88nLakEEbq4F9wJ8ZY6LGmEPA94HfyOJzGBH5PRE5KyJDIvJXIuJIHvuAiDwlIp8XkRHgfyRv/w0ROZZ8D34667V5s4gcT76uXwRkme3akvyWP5xs17dFpG7WaTeIyNFkO74uIp5p93+riLwsIqMi8rSIXLucdqSxA1gHfN4YEzfGPAo8Bbw/S4+vlkgDyBqV/PC/Czg97ebPAtuwgspWYD3w35PHHMDXgU3ARiAIfHGZT/8g0Am0AC8C3551/NeAPwWagJft48mxioeB7yTv+17g79MEIPsaR0XklmW2UWb93/73zmU+3nx+CdgLXA+8g5kB6nXAWaxr/TMReSfwR8C7gGasrprvAohIE/BvwB9jvW5ngJuX2SYB/gLrw/oqYAPJADbNrwG/CGzB+p3542Q7rge+BvwW0Ah8GfixiLjnPInILSIyusR2pbst2++JypAGkLXn30VkArgEDACfBhARAX4T+H1jzIgxZgL4c+A/Ahhjho0x/2aMmUwe+zPgtuU0wBjzNWPMhDEmjPXBtFtEaqed8oAxZn/y+P8H3CgiG4C3AueNMV83xsSMMS9ifWj+h3mep84Y8+Qy2ziB9e32T0TEk/xgfDdQuZzHW8Bnk6/3ReBvsIKirdcY84XktQaxPpT/whhzzBgTw3p/rktmIXcDR40x3zfGRJOP1b+cBhljThtjHjbGhI0xg8D/Ye57/UVjzCVjzAjW74Ld7t8EvmyMeS6ZJXwTCAO/kOZ5njTGzM5sFnIc63f2kyLiFJE7ku3K9nuiMqQBZO15pzHGi9U9swPr2ypY32grgYPJb+6jwEPJ2xGRShH5sohcEJFxYD9QJyJlS3lyESkTkb8UkTPJxzmfPNQ07bRL9j+MMX5gBOvb8CbgdXb7km38NaBtKW1Ygl8Drki25x+wMqHuLD/HpWn/voB1nemOgXX9fzvt2kewvoGvT95v+utm0tw/IyLSIiLfE5Ge5Hv0LWa+Pwu1exPwiVnv0YZZ17UsycD4TqzxqH7gE8C/kP33RGVIA8gaZYx5HPgG8NfJm4awuqWuSX5zrzPG1CYH3MH6Y90OvM4YUwPYM2OW2s/+q1hdNW8CaoHNaR5ng/2P5FhEA9CL9aH1+LT21SVnUf3nJbYhI8aYC8aYtxpjmo0xr8Pqknk+y0+zYdq/N2JdZ6oJs869BPzWrOuvMMY8DfQx83WTWY+9FH+RfO5rk+/1+5j7Ps/X7ktY40bT21hpjPnuMtsygzHmsDHmNmNMozHmF4Eryf57ojKkAWRt+xvgzSJynTEmAXwF+LyItEBqGusvJs/1YgWYURFpINn1tQxerC6NYayM58/TnHN3sn/chTUW8pwx5hLW7JttIvL+ZBeGU0RuEJGrltmWBYk1ZdQrIi4ReR9wB1Z3Tqb3/4CInF/ktE8mJyhsAD4O/PMC534J+EN7zEdEakXkPcljDwDXiMi7xJqt9HssPzPzAn6s93o98Mk05/yOiHQkfxf+aFq7vwJ8VEReJ5YqEXmLiHiX2ZYZROTaZJdipYj8N6Ad64uQKgANIGtYsn/7H4E/Sd50D9ag+rPJrotHsLIOsIJNBVam8ixW99Zy/CNWl0cPcDT5WLN9BytAjQB7sLqS7HGJO7DGZXqxujE+C8wZoAUQa73LrctsJ1iDxGcBH/BR4M7ka5bp42/AGkdZyI+Ag1iTBR4AvjrficaYH2Jd7/eS788RrIkQGGOGgPcAf4kVnDunP7eI3Coi/kXaYvufWIP6Y8k2/SDNOd8Bfob1+pwFPpNsxwGscZAvYr1up4EPpHuSJbbJ9n6sbGsAeCPw5uRYmSoA0Q2l1FokIn+MtQYmCqyfbzHhEh7vjVgD+m7gbmPMYyLyM+Djxphj89zHAJ3GmNPpjq91ydfvRuCAMWbR9Tci0gm8ALiA3zbGfCO3LVQaQJQqEA0gqthpF5ZSSqll0QxEKaXUsmgGopRSalmKrkBbU1OT2bx587LvHwgEqKpacfXuorSWrx3W9vWv5WuHtX39y7n2gwcPDhljmhc7r+gCyObNmzlw4MCy79/V1cW+ffuy16AispavHdb29a/la4e1ff3LuXYRuZDJedqFpZRSalk0gCillFoWDSBKKaWWJWcBREQ2iMhjYm1+86qIfDzNOSIifyfW1pSHkyWzlVJKFYFcDqLHgE8YY15MFlI7KCIPG2OOTjvnLqyaPZ1Ym+f8Q/L/SimlVrmcZSDGmL7khj92EbxjWPsWTPcO4B+N5Vms/SXac9UmpZRS2ZOXlegishlrA6KdxpjxabffD/ylvWuciPwcuCdZ0XP6/T8CfASgtbV1z/e+971lt8Xv91NdXb34iSVoLV87rO3rX8vXDmv7+pdz7bfffvtBY8zexc7L+TqQ5IZA/wb8l+nBwz6c5i5zIpox5l7gXoC9e/ealczn1vng+wrdjIJZy9e/lq8d1vb15/LaczoLS0ScWMHj28aYdHsKdDNzZ7MOZu7IppRSapXK5Swswdoc55gxZr5d3H4M/HpyNtYvAGPGmL5ctUkppVT25LIL62as3cNeEZGXk7f9Edb+yRhjvgT8BLgba9eySeCDOWyPUkqpLMpZAEkOjKcb45h+jgF+J1dtUEoplTu6El0ppdSyaABRSqksOto7zoe/+QLhWLzQTck5DSBKKZVFj50Y4JFjA3T7goVuSs5pAFFKqSy6NDIJgC8QKXBLck8DiFJKZdElnxVARjSAKKWUWopLI1bXlW9SA4hSSqkMxROG3lErgIwEogVuTe5pAFFKqSzpHw8RS1jl/EYC4QK3Jvc0gCilVJbYA+igGYhSSqklsAOI11OuYyBKKaUy1+0LIgLXrKvRWVhKKaUyd8k3SVuNh7Yaj2YgSimlMtc9EmRDfSX1VS7NQNTqMeQP8/6vPkfPaOmXR1CqWF3yTdLRUEFDpYuJUIxILFHoJuWUBpAicfCCjydODfGvBy4VuilKqTQisQT94yE6khkIwGiJd2NpACkS/WMhAH7yim7YqNRq1DsaxBjYUF9BQzKAjGgAUatB75jVdXXysp/TAxMFbo1Saja7BtaGhkrqK5MBpMTHQTSAFIn+sRC1FU5E4IHD/Yue7wtE+K///DIf+PrzeWidUsqugbWhoTKVgfhKfDFhLvdEV1nUNxZie5sXjNWN9fE3dc577kNH+vjjfz/CkN/69hOKxvE4y/LVVKXWpG7fJOUOoa3Gw0iZ9benXVhqVegbC9Je6+HuXW2cuDzB6QF/2vP+8sHjfPRbL9Ja4+FDt1wBwOBE6dfkUarQLvmCrKuroMwh1FU6ARjxawBRBZZIGC6PhWmr9XDXrnZE0g+mnxn0c+/+M7zrNev599+5mVs6mwAY0ACiVNaFonGCkaltay+NTLKhoQIAZ5mDmjVQzkQDSBEYDkSIxBOsq62gtcbD3k31aQPI/3n4JB5nGX/0lqtwljlornYDmoEolQv/5Xsv8+5/eJpo3Frr0e2bZEN9Zep4wxpYTKgBpAjYU3jbaj0A3L2rneP9M7uxjvSM8cDhPj50yxU0JQNHS40dQEJ5brFSpe/skJ+jfeN8/alzBCNxhvwROuorUsfrq1yagajC60tO4V1Xa/1y3r2rHWeZ8LHvvMj5oQAAf/2zE9RWOPnwrVem7tdY5cYh2oWlVC4MJ8c3Pv/wKZ47NwxYM7BsDZWagahVoG9WBtJa4+Erv76XvrEQb/vik3z+4ZN0nRjkP+/bQm2FM3W/MofQWO3WLiylsiwWTzAyGeHd13cA8KnvHwagY1YXlk8DiCq0vrEQzjKhMTm3HGDf9hbu/91b2NRYyd/+/BQtXjf/6cbNc+7b4nVrBqJUlvkmoxgDuzfU8vE3dab+xuxBdLACyHAggjGmUM3MOQ0gRaBvLEhbrQeHQ2bcvqGhku9/9CZ+9w1b+av37KbCNXethxVAdAxEqWwa8lsBo6nazYduuYJtrdVUOMtSE1fAGgMJxxIEo/G0j/HjQ7282juWl/bmii4kLAJ9YyHaayrSHvM4y/jEHdvnvW+z182rveO5appSa5I9/tFY5cJZ5uArv76Xs4MBRKa+5DVMK2dS6Zr5Ufu1J8/xv+4/ytt2r+ML731N/hqeZZqBFIG+sSDtdZ5l3bfF62E4ECGeKN00Wql8S2UgXivj2NRYxe07WmacUz9POZN/eeES/+v+o9bjFHn3smYgq9z0RYTL0VLjJp4wJT8bRKl8SgWQKve85zRUJVejT5vK+8DhPv7gB4e5tbMJZ5kjtYd6sdIMZJUbmbQWEbbXLDcDsX7BdRxEqewZ8kdwlgk1FfN/B7cr8tozscYmo/z+v7zMnk313Pv+vbTXelKBqFhpAFnl+katD/72uvRjIItp9upqdKWWKxSN88tfeoYD50dm3D7sD9NY5Z4x5jFbYzI7GU4GkKfODBGJJfiDu66iwlVGU7Ub32SUWLx4dy3UALLK2YsI25fbheW17qdTeZVaunNDAZ4/P8KTp4dm3D7kD9NY7ZrnXhavp5wyh6QykCdODeL1lLO7oxaYGj8p5u5lDSCrnL2IsL1WMxCl8q3HZ32B607+3zYciKRKBs3H4RDqK52MTFprQfafHOKmLY2Ul1kfu03JQfbBIu7G0gCyyqVbRLgUHmcZXk85A+M6BqLUUnUndxnsmRVAhiYWz0DAGgfxBSKcGwrQMxrk1s7m1DE7Axku4pLvGkBWub6xIK01cxcRLkWL113U33KUKhQ78+genZotZYxhKBCZsWhwPvXJirxPnLK6wF4/LYDYXwqLeSBdA8gq1zcWShVRXK4Wr4eB8eL9JVWqUOwA0jcaSq2lmgjHiMQSGWUgDZVWRd4nTg2yqbGSjY1TtbI0A1E51z8WWvYaEFtzDuthjU5GeMPnunilu7hLMiiVjp15xBImNRXe/sBfbAwEoKHaxcBEmGfODHNrcoM3m9ddjqvcoRmIyo1EwtA/Flr2DCxbi9eqyJuLom5nBgOcHQzw0iVf1h9bqULr9gVTBRLtbMT+wG/MJIBUuhidjBKIxGeMfwCICE1VrqLuXtYAsoqlFhGuNIDUuAlG44TS13RbkeHkL3+xl2RQajZ/OMboZJTXXdEITA2kD6cKKWYwiJ4c5yhzCDduaZxzvMnr1i4slRv2IsK2FY6B2FN5R0NWBhKMxPmLB49lZf65vUiqmL9FKZWOHTBee0WD9fOonYEsoQsrWc7kug111Hicc443Vrm0C0vlRmonwmUWUrTZiwlHw1YAeeCVPr78+Fm+89yFlTWQqcxD15moUmNP4e1sqaaxypX62f7Ab8hgar1dzmT2+IetqVozELUMP3ixm6OLlFm/mCy0tm6ZZUxsdj2ssYgVQH7ySh8A9x/uW9HjwvQMpHj/CJRKxx7z6KivpKO+IvXzsD9CXaUTZ9niH59XtdfQ2VLNW69tT3u8yetmOJCb8cl80ABSAIMTYT7xr4f4//79lQXPO3jBR0d9RUap8kLsDGQsbBgLRnni1CAtXjfH+yc4eXliRY89pGMgqkR1+yZxlztoqnaxvr5iWhdWOOO/ydYaDw//19vY2uJNe7yxykU0bv1dFiMNIAXws6P9GAMvXRzlxYvpZy8ZY3jhvI8bNjes+PlqKqzpgqNhwyNHLxONGz7zzp04BO4/1Luix7bT71zN8lKqULp9QdbXVyAirK+roMcXxBjDsD+y7MoQs9njk0NFmsFrACmAB1/pZ0NDBV5POV998lzacy4MTzLkD7N3c/2Kn09EaK52MxY2/OSVPtbVenjz1a3cuKWR+w73reiDfzhgZR6ReILxYGzFbVVqtegZDdJRby3866ivJBxLMOSPWBmId2W9Aja7Yu9yBtIffKWPywUuUaQBJM9GAhGeOTvM23ev472v3chDR/pTqfF0zyfLR782CxkIWFN5+wIJnjg1xF272hER3nbtOs4NBVa05e2wP4LXbe2JoDOxVCnp9gXpqLfGH9cnxyF7RoNWAMlSBtLkXV45k0A4xn/+9ot8+9mVT4RZCQ0gefbw0X7iCcNdO9v5TzdtBuCbT5+fc96B8yPUVTrZ0lydledtrnZzbixBJJ7g7l3WgN6dO9sodwj3HV5eN1Y8YRiZjLCj3erf1ZlYqlQEwjFGApGpAJL8/7khP+Oh2IrHJW324yx1Jpb9pbPQk1c0gOTZg0es7qtr1tWwvq6CO3e28d3nLxIIz+z+OXDex95N9SsqojhdS431i9pe6+E1G+oAqKt0cWtnE/cfWl431kgggjGwo60G0AxElQ77A9ruwrIDyKFLVsmeTFahZ6K+0oVDlp6B2GtUfAXeS0QDSB6NTUZ56vQQd+9sT+1k9qFbrmAiFONfD1xKnTfkD3N2KJCVAXSbPRPrrp3tM4LS23avo2c0yIsXR5f8mPb4x/Y2zUBUabHXfNgZSI3HSY2nnEPd1t9JJqvQM1HmEBqqXDMG0X/wYjd3/+0TXBgOzN++ZIAr9GZUGkDy6JFj1gyoO3e2pW67fmM912+s48v7zxKMWLVG7O0z92YxgNjlUN4yaz76m69uBeCpWTuuZcJOu69srsJZJkW9olap6exv+B3T1mCtr69MjRdmKwMBayB9+t/OD1/q4WjfOP/x3mc5P5Q+iNjtG5nUALJmPHjEmgF1XbILyXbPnTvoGwtx7/6zALxw3oe73MGu9bVZe+637V7HJ/a42bNp5qwur8dJQ5VrWbM57F/6Fq+bpmq3ZiCqZHT7grjKHTPGOjrqK4jErP3LM9kLJFNN3qlyJrF4ghcv+Li1s4lwLMGv3PsMZwf9c+7ToxnI2jI2GWX/qSHunNZ9ZXvdlY3ctbONLz1+hv6xEAfOj3Ddhjpc5dl7ezzOMnY1l6c91uJ1c3kZ+4VML2vd7NUAokpHty9IR13FjO7e9dOykUz2AsnU9HImx/omCETivGfvBr7zm68jFje89yvP4p81RtqT7GIbnYyk9ikphJwFEBH5mogMiMiReY7Xish9InJIRF4VkQ/mqi2rwVefOkckluA9ezvSHv/Du64injD8z/te5UjveFbHPxZjffgvPQMZDoQpdwg1HidN1W7twlIlo9s3mRo4t9njIRXOMqrc6b+MLcf0Lix7+v4Nm+vZ0VbDZ999LZfHw3P227EzkIShoKvYc5mBfAO4c4HjvwMcNcbsBvYBnxOR7IX1VWQsGOXrT53jzmvauKq9Ju05Gxsr+eAtm3nwiDXN94Yr8hdAWryeZW04NeyP0FDlwuGwFipqBqJKhbUGpHLGbXYAyWb2AVYX1mQkzmQkxgvnRuior6A9WYH7mvXW58XpgamSQ5FYgoGJMFc2VQGF7cbKWQAxxuwHRhY6BfCK1Z9TnTy3JJcyf+3Jc0yEYvzeGzsXPO9jt2+lqdqa1nf9xroFz82m1hrrwz+xxFR4yB9ODSY2e90MBwqbTiuVDZORGMPT1oDY1tdZASVba0BsTfZq9IkIL5wfmbF4uK3GQ7W7nNMDU+MgfWNBjIGdyTHSQgaQ7OVhS/dF4MdAL+AFfsUYk0h3ooh8BPgIQGtrK11dXct+Ur/fv6L7L1Ugarj38Un2tJYxcPJFBk4ufP77twvnx5wcfPaprLdlvmsfuxwlljDc/0gXNa7M152c7Q1SUQ5dXV2M9keJJwwPPNxFjTs7a1eyLd/v/Wqylq8dlnb9vX7rY2i87zxdXd1Tj5GsZk1oIquvZe+A9b35nx56iuFAhJrI4IzHb/EkeP7EJbq6rJmSR4et2ZoVIevn/c+9yOSF+T/Kc/reG2Ny9h+wGTgyz7H/AHweEGArcA6oWewx9+zZY1biscceW9H9l+rzD58wm+653xzpGc3r86Yz37U/cLjXbLrnfvNqz9iSHu+Wz/7cfPy7LxpjjLn/kPUYx/qW9hj5lO/3fjVZy9duzNKu/9Fjl82me+43B84Pz7g9kUiYa/77Q+YP/u1wVtt26JLPbLrnfvOhb7xgNt1zvzl1eWLG8U/8y8vmhs88nPr5n1+4aDbdc7955syQ2XTP/ebbz15Y8PGX894DB0wGn/GFnIX1QeAHyfaeTgaQHQVsT9aNh6J87clz3HF1K9esy96U3Gyz9wsZWOJA+rA/kkrn7aqiOg6iip29D8+GhpljICLCl9+/h9/etyWrz2d3A+8/NUhjlYstzVUzjm9tqWZgIpwaLLfXgFyzzhofGQkU7m+ukAHkIvBGABFpBbYDZwvYnqx75sww46EYH771ykI3ZUGtNdYiw4UG0oOR+Ix+2MlIjMlIfMYYCGgAUcXv4sgkFc6ytGs9bt7aNCewrJRdGj4SS7B3c/2caf6dLVY9PPvvr2c0SIvXjdfjpMpVxkigBGdhich3gWeA7SLSLSIfEpGPishHk6f8KXCTiLwC/By4xxiz9OXQq5i9g5n9C7BaZfLh/zePnOQtf/dEqmaXPW/dnpFil3bQAKKK3cWRSTY2VM75IM8Vj7MsVdE63fT9rakAYs3E6knuUwLQUO0qaAaSs0F0Y8x7FzneC9yRq+dfDXp8QSqcZdRVOgvdlAV5nGXUeMoXXI3+s6OXCccSHOoe5aYtTamtbO3AUe0ux+N06FoQVfQujUxmPctYTJPXzUQ4ljaAdNRX4i53zMhAru2wusQbKl2MTJZgBqKgd3RqR7PVrqXGw8A8q9HPDvo5l6zJ8+IFawdFewtbe0McEdHV6KroGWNSGUg+NVa5qHSVpcY1pitzCFc2V3NqwE8iYegbm5aBVJVoBqKsbwrTyx+sZi1e97yD6I8eHwCsX/KDyQBiV+KdvqiqudqtJd1VURvyR5iMxNnYkN+/2zt3trF3cwPlZem/029tqealiz4G/WGicZMq8lhf5eLk5bm1svJFA0gO9YwG2dWxemdfTdda4+GF8+nXfT56fIBtrdVcv7GeB4/0k0iYVPnp6YuqmqrdnF+gBLVSq509A2tjY34zkMUm2nS2VHPfod5UN5adgTRWuVJf5gpBu7ByJBiJMxKIFFkGEp6zsdR4KMrz50Z4w45Wrt9Uz1gwytkhP8P+SHLcoyx1brPXPWNfA6WKzSU7gOS5C2sx9kD6/lODwNSq+PoqF6FoIrUVRL5pAMkRu9hZsQSQZq+bSCwxpzDbEyeHiCUMb9jRkioFf/CCj+FAeE5NoGavm5FAhGg8bUEBpVY9OwOZXQer0OyZnI+fSAaQaRkIULAsRANIjqQCSH1xBJCWedaC/Pz4ZWornFy/sY4rm6qoq3RaAcQfSf3y2uzpwEvd31mp1eLiyCRtNZ4ZmfVqsKmxijKHcLx/gtoKJ9XJab/1ldbfoK9Aa0E0gOSIvVp0XZFkIKnV6NNmYsUThq4Tg+zb3kx5mQMRYc/Geg5e8M0opGizx0N0Kq8qVheH8z8DKxOucgebk+My6fYl0QykxPSOBilzCK3e7FbuzJWp1ehTM7EOdY8yEojwhh0tqduu31TPmcEAl0Ym5+wLravRVbG7WIA1IJmyx0Gm92qkMpACbW2rASRHekaDtNV45p2Wt9pM1cOa+vB/9NgAZQ7htm3NqdvscZBAJJ5aA2KzSz9oAFHFKBSN0z8eWpUZCEBnixeYlYFUFbbbuDg+3YrQ9HIDxaDKXU6Vq2zGavTHTgxw/cY66iqnMo3dHXWUJbf5nDcD0S4sVYTs0kMbG1fn362dgUzfp8TrKafMIZqBlJpiWkRoa6mZ2plwcCLMq73jvL6zecY5FdNWy84eA/E4y6h0leEr4AY3Si3X1BTeqkXOLIyd62sRgc5Wb+o2h0Oor3QVbFMpDSA5EIsn6B8PFV8A8boZTA6iP3nami74+m3Nc867fqPVjZVua88aj7OgezQrtVwXV+kaENvWlmr2f/J2Xt/ZNOP2hiqnBpBScnkiTDxhiqoLC+wMxOrCeuLkEPWVztS2mdPd2tmEQ9L/odVWOBkPaQBRxccu4z67a3Y12ZCmSrBVD0sDSMkotim8thavm8vj1t7o+08NcUtnc2q8Y7o3XtXKs3/4xrSLrWoqyjUDUUXpwnB+y7hniwaQEtNbZKvQbS1eN8FonAPJdR6zU+UZ5yan/c5WW+FkPBjLVROVyplClHHPBg0gJabYypjYWmqsQfHvH7wEpB//WEyNR7uwVPEpVBn3bGiodDEajBJPmMVPzjINIDnQ7QvSWOWiwrW6yiEsptVrZRUPHO5jR5s3tbhwKWoqdBBdFZ8hf4RgNM6mPFfhzYaGKhfGwGgBpvJqAMmBntFg0Y1/wFQGEojEl5V9gBVA/OEYiQJ8G1JquVb7DKyF1FcVbjW6BpAc6C3CNSAAzd6pjGP2+o9M1XjKMQYmQjoOooqHvQaNAbReAAAgAElEQVSkGMdACrkaXQNIlhljim4Vuq3GU4673IHH6WDv5vplPUZthbX/u46DqGLSN2ZNX19Xt/Ru20Krr7L+5gqRgeiOhFnmm4wSjMaLMgMRETY0VLKpoXLZ5axrkgFkLBhlQzYbp1QOjU5GcJc7qHQV30diKgMpwEys4nu1Vjl7Cm8xjoEAfPn9e/B6lv9rkcpAdCBdFRHfZIS6Smehm7EsqQxEA0jxswuydRRhFxbAlubqFd2/xqNdWKr4jE5GU6XRi427vIxqd3lBMhAdA8mybp81GFeMXVjZUFs51YU1n1A0zon+iXw1SalFjU5GizYDASsLKcRiQg0gWXZ2KEBthbOofxlXoibZ/bXQavRvP3eRt33hSSYjOlNLrQ6+yQh1FcWZgQBsqK/k/PBk3p9XA0iWnR7ws7Wluujq6WRLlaschyycgVwamSQST8zYPlepQhoNRlNjCcWos6Wa05cnMCa/6680gGTZmQE/W1c4jlDMHA6hZpGKvHbFX907Xa0GxhhGJyMzNk4rNp2tXgKROL1jocVPziINIFnkC0QYDkRSO4etVYvtCTI4bdMqpQotEIkTjRvqKoo7AwE4eTm/Y4saQLLo9KAfYM0HEKsi70IZiBU4NANRq4FdQ6pYZ2EBbEvuUnj6sj+vz6sBJItOD2gAAWtPkPF5SpkYY1JjH5qBqNVgdNL6slPME1/qq1w0Vbs1Aylmpwf8eJyONTuF11a7QEXeQCROMBoHYLAAtXuUms0uAVLMYyBgdWOdGtAMpGidHvBzZVM1jjS7+K0lNZ75u7AGxqcG+TQDUauBnYHUF3EGArCttZrTA/68zsTSAJJF9hTetW6hPUHs8Q9XmUPHQNSqMFoiGcjWVi/+cCyvM7E0gGTJZCRGz2hQAwhWF1Y4liCU7Kqazs46trVVawaiVgVfMgOpLeJZWADbkp89p/I4DqIBJEvODgYAHUCHaavR06wFsTOQq9trGPKH877wSanZRiejVLvLcZUX98ehPRPrVB5nYhX3K7aK6AysKTWpirxzZ2INTIRwlTnY0lxNOJZgIqzlTFRhjRZxJd7prJlYLk4NaAZSdE4P+ClzCJsbqwrdlIKrWWBTqcGJMM1ed2r73CHtxlIFNhos7kKK03W2eDmpGUjxOT3gZ1NDZdGnwdlQWzF/RV47gDRVJwOITuVVBeabjBT1IsLpOvM8E0s/7bLk9KCfLdp9BUzbEyRNABkYtwJIs9cKIDqQrgrNKuVeKgHEmonVl6eZWBpAsiAaT3B+KKDjH0k1FXZJ9zQZiD9My4wMRAOIKqzRyUhR18Gabluea2JpAMmCC8OTxBJmTVfhnW5qV8KZA+SRWIKRQIQWr4f6ShdlDtEMRBVUImEYC0aLfhGhrdOuiZWnFekaQLJAZ2DN5HGW4S53zBkDsbONZq+bMofQUOXSDEQV1HgoSsIU/yJCW0NyJpZmIEXkTLIKr46BTElXkdfONlqS4x/N1W7NQFRBlUIhxdm25rEmVnlenqXEnR0M0FbjodqtL6ct3aZS9iJCewpvk9etGYgqKF8JlHKf7U1XtdLtC+blufQTLwsGJkK01XoK3YxVJV1FXnsnwuZpGcjpPJefVmq6UsxAPnzrlXl7Lu3CygJ7bYOaUuMpn7MS3e6usmdgNXldDPkjWs5EFcxosDQKKRaKBpAs0AAyV/oMJExDlQtnmfVr11ztJhJPpC15olQ++AKlUcq9UDSArFA0nmBkMkJztQaQ6dKOgYyHUwPoMNWVNajjIKpARicjiExNPVdLowFkhYb9EYyZGhhWFntTqURiqntq0D8zU7ODrs7EUoUyGoxSW+Fc85vALZcGkBWyP/w0A5mptsJJwkAgMtU9NTgemhFAmry6Gl0Vlm8yWlIzsPJNA8gKDfpnzixSllQ5k+RqdGNMsozJ1Gw1zUBUoZVKKfdC0QCyQqnFcTU6jXe6VEXe5DTJ0cko0biZEWhrK5yUO0QzEFUwo5PRkqmDVQgaQFZoYNyemqpp8HRT9bCsADIwaxU6gMMhNOlqdFVApVTKvRA0gKzQoD9MbYUTd3lZoZuyqtTM2hPEXkTYMqurz1oLogFEFUYplXIvhJwFEBH5mogMiMiRBc7ZJyIvi8irIvJ4rtqSS7oGJL3aipl7gqQmG8x6rZqr3TqNVxVENJ7AH47pGMgK5DID+QZw53wHRaQO+Hvg7caYa4D35LAtOTMwEZ7zrVpNdWFNZSDpx4qaqt0MTeiuhCr/7DImuohw+XIWQIwx+4GRBU75VeAHxpiLyfMHctWWXNIMJD2vpxyRqVlYA+NhKl1lcwpONicLKk5fL6JUPoxpGZMVK2QxxW2AU0S6AC/wt8aYf0x3ooh8BPgIQGtrK11dXct+Ur/fv6L7T2eMoX9sktBoJGuPmUvZvPZMeMrgyKlzfKr7PD88FWWD1zHn+Uf7o8QShp880kW1a+ZirkcuRNlS5+CK2uyML+X7+leTtXztkP76T/riAFw4dYwu38kCtCo/cvneFzKAlAN7gDcCFcAzIvKsMWbOO2mMuRe4F2Dv3r1m3759y37Srq4uVnL/6fzhGJGf/pQ9V29l3+u3ZOUxcymb156JxucepetSkISBO65u5TPv3DmnC2viUC/fOf4SW6/dw462mtTtJ/on+NZD+7m1s4l/esfrstKefF//arKWrx3SX3/k1X547iD7btzLzvW1hWlYHuTyvS/kLKxu4CFjTMAYMwTsB3YXsD1LNjCuiwgXsqmxkvpKF//3V6/ny+/fk3atzO6OOhwCP3yxZ8bt33j6HABPnxnGF9AxEpV9o8HSK+Web4UMID8CbhWRchGpBF4HHCtge5ZsqoyJLiJM50vv28MT99zOW65tRyR9raGNjZW8bfc6/unZC4wkA4UvEOGHL/Wwe0Md8YTh4WOX89lstUaMTuoYyErlchrvd4FngO0i0i0iHxKRj4rIRwGMMceAh4DDwPPA/zPGzDvldzUa9KefmqosXo+TStfivaQfu30rwWicrz55FoDvvXCJUDTBZ9+9i476Ch58pS/XTVVrkG8yirNMqHLpGq7lmvevW0T+LoP7jxtj/jjdAWPMexe7szHmr4C/yuB5ViV7FbpO412ZzlYvd+9s55tPX+A3br6Cf3rmPDdtaWRHWw1372rn60+dYyxZNVWpbBmdjFJb4Zo3O1aLWygDeQdwcJH/3p3rBq5mg/4wzjLRD7Ys+NgbtuIPx/jQNw/QOxbiAzdtBuCunW1E44ZHjmo3lsouXyBCY5V2X63EQv0LnzfGfHOhO4tIfZbbU1QGJ8I0Vbt1L4EsuKq9hjuubuVnRy+zoaGCN17VCsB1G+pYV+vhwSN9vHtPR4FbqUrJSCBCfZV++VuJeTMQY8zfAIhIw+xjInLF9HPWqkFdhZ5Vv/fGThwCH7zpCsqSQVlEuGtXO/tPDjExa4dDpVZiZDJCg2YgK5LJIPp9IpKaoC8iVwP35a5JxWNAV6Fn1c71tTz+ydtT3Ve2u3e1EYknePR4URYrUKuUL6ABZKUyCSB/jhVEqkVkD/CvwPty26zioGVMsm9DQ+WcLsHXbKinrcbDg6/0F6hVqtQkEgbfZIQGncK7IovOsTTGPCAiTuBnWCVH3mmMOZXzlq1y8YRhJBDWrWzzwOEQbtrSyJOnhwrdFFUixoJREgbqNQNZkYWm8X4BmF7hrgY4C/yuiGCM+b1cN241G/aHSRho1p0I82JXRy0/eKmH/rEQbbX6mquVGUkuItQurJVZKAM5MOvng7lsSLEZSK1C1wwkH67tqAPgUPcobbVtBW6NKnZ21QMNICszbwBZbArvWqer0PPr6vYayhzCK91j/OI1GkDUytgBRLezXZl5B9FF5N7F7pzJOaVqMM0e3yp3KlxlbGv1cqh7tNBNUSXADiCN1RpAVmKhLqx3ikhogeMC3J7l9hSN+bZoVbmzu6OWh17txxij5SfUimgGkh0LBZBPZnD/J7LVkGIzOBHG6ynH49RCbPmyq6OW771wiUsjQTY2Vha6OaqI+QIRKl1l+ve7QjoGsky6BiT/dk8bSNcAolZiRBcRZsWiCwlF5GYReVhETorIWRE5JyJn89G41WxgIqTjH3m2rdWLq9zBYR0HUSukZUyyI5Mtbb8K/D7WNN54bptTHBIJw4n+Cd5ybXuhm7KmuModXNVew+HusSXfNxSNkzBm8RPVmuALRHT8IwsyKWUyZox50BgzYIwZtv/LectWsVMDfsZDMfZsmlNnUuXY7o5ajvSMEU9kHgxi8QR3/e0T/OCUFmNUlmEt5Z4VC03jvV5ErgceE5G/EpEb7duSt69ZBy6MAHDD5jVdzb4gru2oIxCJc3bQn/F9njg1xLmhABcnEjlsmSomvkBEy5hkwUJdWJ+b9fPeaf82wBuy35zicPC8j6ZqNxsbdCA3367tqAXgcPcYna3ejO7zzy9cAmAkqAFEWd2ZgUhcx0CyYKFZWGt2jcdiXrgwwt5N9boWoQC2NFdT6SrjcPdoRhtMDfvDPHLsMmUOYTikYyAKfFoHK2syGQMpeYMTYR49ntmWqQPjIS6NBNmr3VcFUeYQdq6v5eUMB9J/+FIPsYThndetJxhDN6VSuogwizSAAH/fdZoPf/MAoejik8wOXPABsGeTBpBCeX1nE4cujfLQkYX3BzHG8M8vXOK6DXXctr0ZgL6xhYorqLXAF7C+RGgGsnIaQICDF3wkDIxOLv7t9MB5H+5yB9esq81Dy1Q6H3n9Fq7tqOVT3z9Et29y3vNevjTKqQE/v3LDBtbXWSXge0aD+WqmWqWGA1YZIg0gK5fJQsJKEfkTEflK8udOEXlr7puWH5ORGK/2jgNTv1gLOXhhhN0b6nCVa+wtFFe5gy+89zUkDHz8ey8Ti6cfHP+XA914nA7eem077bUVAPRqAFnzfFrKPWsy+RT8OhAGbkz+3A18JmctyrNDl6bWFNip7XyCkTiv9o7r9N1VYFNjFX/+rl0cvODj84+cnHM8FI1z36Fe7t7VjtfjpMXrxiHQN6pdWGvdyGQUEaitcBa6KUUvkwCyxRjzv4EogDEmiFWJtyS8eNGX+vdiGcjLl0aJJQx7dQHhqvD23ev4lb0b+PuuM3O6pp45O4w/HOPtu9cBUF7moN4tmoEoRgJh6itdlDlK5mOsYDIJIBERqSC5va2IbMHKSErCwQs+mpJ7Atip7fznWgsIr9+oGchq8Vu3XYkx8MjRmbPouo4P4HE6+IUrG1O3NXiE3jENIGudLxClvlKzj2zIJIB8GngI2CAi3wZ+Dnwqp63Kk0TC8OJFH/u2tyAyNb1vPi+c97GttZpa/eVbNa5srubK5ioenhZAjDE8emKAm7c0zSjX3Vgh9GoX1pqnlXizZ9EAYox5GHgX8AHgu8BeY0xXbpuVH2eHAoxORnnt5gbqK12MTM4fQOLJYKP1r1afN1/dyrNnhxkLWmNYZwYDXBoJcvuOlhnnNXgc9I+FSCyhjpYqPRpAsmfRWljJulebgD6gF9hYKrWwUl1Sm+qpr3QumIG80jPGRCjGjVsa5z1HFcYdV7cSSxgePzkIQNeJAQD2Jdd+2Bo8QiSeYCiD2XaqdGkp9+zJpBaWB6sO1iGswfNrgeeAW3LbtNw7eMFHXaWTK5uqaKxyLxhAnjxlfTjdrAFk1bluQz1N1S4ePnqZt+9ex2MnBtjWWk1H/cxaZY0V1qBp72iIFq+nEE1VBWaM0VLuWTRvBmKMuT1ZD+sCcL0xZq8xZg/wGuB0vhqYSwcv+NizsR6HQ6ivWjgDefL0EFe319BYrZtIrTZlDuGNO1rpOj6ALxDh+XMjc7qvwMpAAPp0JtaaNR6KEUsYzUCyJJNB9B3GmFfsH4wxR4Drctek/PAFIpwZDHB9siRJQ5WbkXnWgUxGYhy84OPWzqZ8NlEtwZuubmUiHONzD58gGjfcvn1uAGn0WL/uuhp97dJFhNmVSQA5JiL/T0T2ichtyRXpx3LdsFx76dLMmlaNVS58k5G0A6zPnRshGjfcogFk1bplaxMep4NvP3cRr6c8ba2yKidUOMvmrYc1Nhnln545j9GdC0vWsF1IUQNIVmQSQD4IvAp8HPgvwNHkbUXt4AUf5Q5hd0cdYP1CxROGiVBszrlPnRrCVe7ghs06A2u1qnCVcWtnM8bA6zubcZbN/dUWEdbVeeZdTPijQz38yY9e5cxgINfNVQViZyC6G2F2ZDKNN2SM+bwx5peS/33eGFPUk+njCcMDh/t4zcY6KlzWOgH7FyrdavQnTw9xw+b6GWsK1Orz5qtbgbmzr6ZbV1dB7zwZSLfPCiy6Wr102VP1dRA9OxaahQWAiJwjuQp9OmPMlTlpUR789NV+zg9Pcs+dO1K32Smtb9ZakIGJEMf7J/jUndvz2ka1dG/fvQ5fIMLbkuVL0llXW8Hx/oG0x+zKvv1a8r1kjegYSFYtGkCYuZWtB3gPULR9OcYYvvz4GTY3VnLHNW2p21MZiH9mAHn69DAAt26d/1utWh08zjJ+67YtC57TXudhcCJMOBbHXT4zo+yxMxAtd1KyfIEI7nIHlS7tTciGTLqwhqf912OM+RuKeD/04yMJDnWP8Zuvv3JGMbX5MpAnTg1RV+nkmnU1eW2nyo11dVZZ98tjc7sq7dlZWrG3dNmr0HU76uzIpAtr+qpzB1ZG4s1Zi3LsJ+eiNFW7ePf1M/fTbqi0x0CmAogxhidPD3LzliYcWrmzJKxL7gvSMxpkY+PUQsNgJM5QMvvUDKR0jegiwqzKpAvrc9P+HQPOAb+cm+bk1rG+cV4ZivPJX9w6Z0C8wlVGhbNsRkXeC8OTXB4Pc9NWXX1eKtYldybsmxUk7OzDIToGUsq0jEl2ZRJAPmSMOTv9BhG5Ikftyal795/FUwbve92mtMcbqlwzMpBTA34Arm7X7qtSYXdhzZ5pZQeQq9fVcH5o/m1yVXHzh2K01WgZm2zJZB3I9zO8bVWLJwyDE2Fu21A+bzn2hirXjAzkzKAVQK5srs5LG1XueZxlNFS55kzltQfQ925qwB+OMR5aeHdKVZz84RjV7ky+N6tMzPtKisgO4BqgVkTeNe1QDdZsrKJS5hC+9eHX8fNHH5v3nIYq14x6WGcG/DR73br1ZYlZV+dJBQxbt2+Scodw3QZrYWn/WIgaj77vpcYfjlGlASRrFnoltwNvBeqAt027fQL4zVw2KpcW2sayocrF2SF/6uczg362NFflo1kqjzY1VnHo0uiM23pGg7TXeeion+ri2tZatHNFVBrGGALhGF6PBpBsmfeVNMb8CPiRiNxojHkmj20qmIYqFyPJmTjGGM4MBnjrte0FbpXKtp3ranngcB+jkxHqkjNyenxB1tdV0J4cI5mvXpYqXsFonIRBu7CyaKEurE8ZY/438Ksi8t7Zx40xv5fTlhVAQ5WLQCROKBrHH44xFoyyRcc/Ss7O9dakiFd7x7l5q1Ugs2c0yE1bmmjxuhFZuOT7xeFJqtxlWtq/yPiTde60Cyt7Fnol7Yq7B/LRkNWgYdpiwovD1kycLS0aQErNznW1gLXL5M1bm4jEEvSPh1hfX4GzzEGL171gBvLBbzzP9Rvr+av37M5Xk1UW+MNWANEurOxZqAvrvuT/v5m/5hSWvcBoJLlXCKBjICWovsrF+roKjvSMAdaAuTGkxj/aayvmDSDxhOHC8CStOhW06NgBpMqlASRbFurCuo80RRRtxpi356RFBdRYPRVATg/48TgdqZXLqrTsWl+bCiDdo1a22VFnBxAPJy5PpL3f4ESYWMIw5Nd91YuNHUCqNQPJmoVeyb/OWytWiZkZiJ8rm6q1hEmJ2rm+hode7Wc8FE1N6V0/LQN5/OQgxpg5NZPsBYezi26q1c8eA9FB9OxZqAvrcfvfIuICdmBlJCeMMSX512NX5LUDyGs2zt3VTpWGa9Zb4yBHe8fp9gURsQIHWOtEJiNxxoOxOYtO7RXsI5MRYvEE5Wk2rlKrUyoD0QCSNYv+9ovIW4AzwN8BXwROi8hduW5YIdRWOHGI9SHRMxrU8Y8SZg+kH+kZo2c0SKvXg6vc+nOwA0m6oop2ADEGfJO6Wr2YBMI6CyvbMvn69DngdmPMPmPMbcDtwOdz26zCcDiE+koXBy/4MAadwlvCmr1u2mo8VgDxBVPdVwBttdYAebqiitNraOk4SHGZ0FlYWZdJABkwxpye9vNZIP2WbiWgocrFK8nB1a06hbek7Vxfy5HecbpHJ1lfNxVA7Iq9aTOQaUFFx0GKSyAco8whuMu12zFbMnklXxWRn4jIB0TkPwH3AS+IyLtm1ciaQUS+JiIDInJkoQcXkRtEJC4i/2GJbc+J+ioX0bhBBK5o0i6sUrZzfQ1nBv30jYZmZCAtXg9lDkm7sVTvaJDNyX1ENAMpLv6QVUhRN5PKnkwCiAe4DNwG7AMGsba0fRtWraz5fAO4c6EHFpEy4LPATzNoR17YA+kd9RVz9gxRpWXnulqMgVjCpNaAgFUvrcXrnncMZFeHVXBxdgAJReNcGtFS8KuVPxzXAfQsW/TVNMZ8cDkPbIzZLyKbFzntd4F/A25YznPkgr21rY5/lL5dHbWpf0/vwgJrLcjsMZDJSAzfZJQdbV4eOiKpHQxtX9l/lv/bdZrn/vBN824ZoArHH45qAMmyTLa0vQLrg37z9PNXupBQRNYDv4S1v/qCAUREPgJ8BKC1tZWurq5lP6/f71/w/hND1oeCO+Rb0fOsRotde6mbff3GGGpcwnjE0HvqCF19Uwl5eSTEmaHEjPN7/QkAxvvOU10Or56+QFdXf+r4U0dChKIJvvDDLm5Zv7oCiL73frr7g8TjrLnXIZfvfSbh+N+Br2KNfSSy+Nx/A9xjjIkv1idpjLkXuBdg7969Zt++fct+0q6uLha6/9nyc9x35ii3XX8V+163cdnPsxotdu2lLt317zn/PI+dGOSdd7yeymklLp4KHOXQMxe47bbbUn3m+08OwpPP86abrufJoVcpr3azb99rU/f54rGnAR9no3X88b5Vk1QD+t53dXVRXumkscI54z1bC3L53mcSQELGmL/LwXPvBb6X/ONsAu4WkZgx5t9z8FwZs8uZXKlrQNaEu3e1kzDMCB4AbbUVhGMJRiejqW5NewrvuroKmqrdM7Y/hqlV6k+cGmQsGNWNyFaZQDjG+jqtYZZNmQyi/62IfFpEbhSR6+3/VvrExpgrjDGbjTGbsbbI/e1CBw+A23e08N/u2MbeTboKfS14z94NfPM35n4jXVc7dypv72gQh0Cr101jtWvGNN5oPMHl8RC3djYRjRseOXo5941XS2LPwlLZk8mruQt4P9ZYhd2FZZI/z0tEvos1a6tJRLqBTwNOAGPMl5bZ3pyr8Tj52Bs6C90MVWAd9dZU3fNDk1yTXLXeOxaitcZDeZmDpmo3g/5wql5W/1iIhIG37GrnzICfB4/08e49HYW8BDVLIByj2q1ZYTZlEkB+CbhyqfWvjDFzNqFa4NwPLOWxlcq17W1eKl1lPHt2mLckd6XsHQ2yLjlbq6naRSSWwB+O4fU46U4WZOyor+SuXe380zMXGA9FdV/1VcIYgz8So9qtU/OzKZMurENY+6IrtWa4yh289ooGnjozlLptegBprLJ2I7Sn8trjH+vrK7h7VzuReIKfH9NurNUiHLfql2kp9+zKJIC0AsdF5Kci8mP7v1w3TKlCu3lLE2cHA/SNBUkkDL1joVSZkyavFUCGk4sJ7ZLw6+o8vGZDHW01Hh443J/+gVXeBWPW1kZaSDG7Mnk1P53zVii1Ct20tRGAp04Pc9u2ZiKxRGrBoV2xwF6N3u2bpMXrxl1udZHctauNbz93kYlQFK92YxVc0KqjqIPoWbZoBmKMeXz6f0AM+OXcN02pwrqqrYaGKhdPnx5KTeG1S703e+d2YU2vp3XnNW1EYgmeODWEKrxQ3MpANIBkV0ZlKUXkOhH53yJyHvgMcCynrVJqFXA4hBuvbOSpM0PT1oBYXVgNszKQntHgjHIoezbVU+Mp57HjJVu4uqiENAPJiXkDiIhsE5H/LiLHsDaSugSIMeZ2Y8wX89ZCpQropq2NXB4P88RpK5Owg4SzzEFdpZNhf4REwsyp6Fte5uD125p57MQgiYQpSNvVFB0DyY2FMpDjwBuBtxljbjHGfAGI56dZSq0ON29pAuC+Q71UuspmrC5vrHIx5A8z6A8TiSfomFWQ8Q07Whjyh3m1dzyvbVZzhZIBRDeTyq6FAsi7gX7gMRH5ioi8EdBC+mpN2dRYyfq6CiZCMdbVVczYS6Kp2s2wP5JaAzI9AwG4bVszIvCodmMVnD2IrhlIds0bQIwxPzTG/AqwA+gCfh9oFZF/EJE78tQ+pQpKRLhpizUba92sDKOp2s2QPzy1BqSucsbxxmo3uzvqePSEBpBCszMQHQPJrkxmYQWMMd82xrwV6ABeBv4g5y1TapW4eavVjWXXx7I1VVtdWD3zZCBgdWMd7h5d0e6F4Vic7z1/UcdSViAUh3LdzjbrlvRqGmNGjDFfNsYsWAdLqVJy09ZGHAIbG+dmGOOhGOeHAtRVOtN+u719ewvGwOMnBpf9/A8c7uMPfvAKL10aXfZjrHXBmKHao9vZZpuGY6UW0eL18IPfvplfv3HzjNubqq21IIe6R+fsaGi7Zl0NzV43j62gG+tw9xgAgxNz92hXmQnFoMql3VfZpgFEqQxct6FuToZh7x1z8vLEvAHE4RD2bWtm/8lBYvHl7cd2pCcZQPxLqmeqpgnGjM7AygENIEotk52BJEz68Q/bG3a0MB6KcfCCb8nPEU+Y1DTgoYnlj6OsdaG40RlYOaABRKllakpmIMC8GQjALZ1NlDuErpNLHwc5O+gnGLWWX61kIH6tC8Z0BlYuaABRapnsDASgY4EMxOtxsmdT/bIG0l9Jdl+5yx0aQFYgGDMaQHJAAyEhxkkAAB7mSURBVIhSy1TpKsPjtP6EZq8Bme227c0c7RtnYHxpA+Gv9IzhcTrYvaFuxha6amlCmoHkhAYQpZZJRFJZyEJjIAD7trUA8PgSu7GO9IxxdXsNrTUezUBWIJScxquySwOIUivQWO2mwllGfeXCe35c1e6lxeteUgCxB9B3ra9NLlrUDGQ5EglDKK5lTHJBX1GlVqCjroJYPLHoAjUR4bZtzfzs6GVi8QTlZYt/dzs35GcyEmfn+loGJsL4wzFC0Tgep+7rvRSBiFUIy6sBJOs0A1FqBT799qv50vv2ZHTubdubGQtGOZRcGLgYewB9V0dtasbXoE7lXbJA2JrFphlI9mkAUWoFWrweNjQsPIBuu3VrMw6BxzNclf5K9zgep4OtzdWpsRYdB1k6fzgKoGMgOaABRKk8qa108pqN9RmPg9gD6OVljlQA0ZlYS+dPZiDVbu36yzYNIErl0b5tzRzuGWN4kUwikTC82jvGrvW1ADR502cg+08OprbbVen5k/vZVrsXnuiglk4DiFJ5dNv2ZoyB/acWzkLODgUIJAfQwdr9EGYGkFg8wYe/eYAvPX4mdw0uAf6wFUCqNAPJOg0gSuXRznW1eN3lvHhh4dLsh7ut47s6rADicZbh9ZTPmMrb7QsSiSe4ODKZuwaXADuAeDUDyToNIErlkcMhdLZWc/LyxLznDPvDfO5nJ1lfV8HW5urU7U3VbganZSDnhgIAqS11VXoBzUByRgOIUnm2vc3LycsTGDN3h8FoPMHHvvMSg/4w//C+62esF2mqds2oyHs2FUAm0z6WstgZiM7Cyj4NIErlWWeLF99kNO3K8j//yTGeOTvMX/zSLq7tqJtxzN6D3XY+GUBC0QTDAZ2dNR9/OEaZgLtcM5Bs0wCiVJ5tb/MCzOnG+vGhXr7+1Hk+ePNm3r2nY879mqrdMwKF3YUF2o21EH8oRoUmHzmhAUSpPOtstcY1ZgeQbz1zgc6Wav7o7qvS3q+p2s3oZJRocmfDc0MBdiSDUbdPB9Ln4w/H8JTrXui5oAFEqTxrrnZTX+mcEUAisQSHuke5tbMZ5zx1spq81lTeYX+EUDRO71iQWzubAM1AFuIPx6jQAJITmtgplWciQmerl5OX/anbjvSOEY4luGFz/bz3m17OZCwYxRjYub6WukqnZiAL8IdieHT4Iyc0A1GqALa3ejnZPzUT6+B5a7/0PQsGkGRBRX+Yc0NW8LmyqZqO+grNQBYQiGgGkisaQJQqgG2t1UyEY/Qndyg8cGGEjQ2VtHg9894nlYFMhDk3ZGUcm5sq6air1ACyAH8ohs7gzQ0NIEoVwLZWeyaWH2MMB8772Ltp/uwDpgLIcCDCuSE/TdVuvB5nMgPRtSDz0UH03NEAolQBpAJI/wTnhycZDkTYu7lhwftUucupcJYlM5AAVzZVAdBRX6FrQeZhjGFCp/HmjAYQpQqgvspFU7Wbk5cnOHB+BIC9C4x/2Jq8Lob8VhfWFakAYu1Hot1Yc02EYwSjcerc+lGXC/qqKlUg29usmlgHL/io8ZTPqHs1n6ZqN+eGJxnyh7miORlAGioAXQuSTt+oNcbU4NEurFzQAKJUgXS2eDk14OeF8yPs2VSPw7H4h1xjlZtXk1vdbm60Asj6OjuAaAYyW++Y9ZpoAMkNDSBKFcj2Ni+TkThnBgOLjn/Ymr0uYglrsPzKZAbi9Th1Lcg8NAPJLQ0gShXIttapLqvFZmDZ7JlYIrBx2l7suhYkvf6xIA6BOrcGkFzQAKJUgXQmZ2I5y4TdG+oWOdtiB5D1dRV4nFPLq3UtSHq9YyFavB7KMugeVEunAUSpAqnxOGmv9XDNutoZwWAhdgCxZ2DZdC1Ien1jQdrr5l+cqVZGZ0crVUD/6x07qa3IfKtVu5xJugBirwWxg4yyxkB2tHuBaKGbUpI0A1GqgN58dSuvvSKzAXSAZu98GYiuBZnNGEPfWIj22opCN6VkaQBRqohc0VTFn77jGt71mpkbTmW6FiQUjfMPXWcIRuI5a+NqMRaMEozGaa/VLqxc0QCiVBEREd5/42ZqK2d2e2W6FuTJU0N89qHjfOf5izlr42rRm5zCqxlI7mgAUaoEZLoWxD7+rWcvkEiU9oB7/7gVTHUQPXc0gChVIjrqK7gwvHAA6Rm1PlTPDQV4+sxwPppVMHYGsk4zkJzRAKJUiehs8XJq2i6H6XT7gnTUV9BQ5eJbz17IU8sKo28sSJlDUhMPVPZpAFGqROxo89I/HsK3QFn3ntEgVzRV8Z69HTx87DJ9Y6U7a6tvNESr162LCHNIA4hSJWJHew0Ax/sn5j2nJ5mB/NprN5Ewhu8+fylfzcu7vrEQ7XXafZVLGkCUKhFXtVmlUY73j6c9HozEGQ5EWF9XwcbGSvZta+Z7z18kGk/ks5l50zcW1Cm8OZazACIiXxORARE5Ms/xXxORw8n/nhaR3blqi1JrQbPXTUOVixPzZCA9o9YA+/p661v5+35hEwMTYX7wYnfe2pgv9iLCdZqB5FQuM5BvAHcucPwccJsx5lrgT4F7c9gWpUqeiLCjzcuxeQKIvUbEXrW+b3sLr93cwKd//CpHknuMlArfZJRwLEFbjWYguZSzAGKM2Q+MLHD8aWOML/njs0DHfOcqpTKzo62Gk/0TxNOs8bCn8NqLDsscwt+/73oaKl385j8eYHAinNe25lJv8lrX6RqQnFotxRQ/BDw430ER+QjwEYDW1la6urqW/UR+v39F9y9ma/naYY1c/5hVvuNfH3yMtqqp74d+v59nTp6gTOD4S89yUqZmJv3WNfBnz4b41f/7KJ96rQdnCcxaemkgBkDvmaN0DZ1YG+/9PHJ57QUPICJyO1YAuWW+c4wx95Ls4tq7d6/Zt2/fsp+vq6uLldy/mK3la4e1cf0N3aN87chT1G68in272lO3d3V14fDW0l7n4w233z7nfo2be/nYd17iuOngd/d15rPJOXHxmfPw4qu89fabaanxrIn3fj65vPaCzsISkWuB/we8wxhT2stilcqDzhYvDiHtOEjPqDWFN523XruOzY2VnBxYeCFisegbC+EsEy1tn2MFCyAishH4AfB+Y8zJQrVDqVJS4Spjc1MVx/vmTuXt8QVZX1eZ5l6W+ioXo5PzL0IsJn2j/397dx4c513fcfz91bm6D8uyZPmKj8QOCSHBOGepOJpJwhGYoZSUBpomUAqUY0opZaZAp9MpLQxQphAakkBCaQoNaZuGhJhJ4oRkcBKHhNiJ7Vp2YixZtmzrsHd1a3/943me1a60ku1H2kdo9/Oa8di7z+rZ36NH2o9/9xDLamMU5UFz3G+znDVhmdk9QDvQZGadwBeBUgDn3HeALwBLgG+b1x477pzbnKvyiBSKTS217DqcOapqPOk4emo4NYQ3m8bKMo6cHM518SJxeGBYa2BFIGcB4py74TTHbwFuydX7ixSqjS01/HRnN4mRcarKvV/x3mGHc7BilnkR9ZVl7M5Sc1mMugeGuHhlw0IXI+9pJrpInjnPn5G+9+hkP8jxIW9Y70x9IACNVaX0DS7+rV+TScfRgREt4x4BBYhIntkUrInVPRkgJ4a85Upma8JqqCpjaGxi0e9WeCIxyuhEUk1YEVCAiOSZtvoKqstLMtbEOj7kMJt9d77GyjIA+hZ5R3owEKChqmyBS5L/FCAieaaoyDivpSajBnJ8yLGsJkZZycy/8vV5EiDxEW8SYXV58QKXJP8pQETy0EUr6nnhUH9q+ZITw8lZm68AGv3/sfclFnc/SGLEa4KrKlvwedJ5TwEikodu/p1zwOBrW70pVieGXGoNrJk0VpUC0LvIayCJUa8GEoxAk9xRgIjkobb6Cm66Yg33Pd/Jrq4BeofdaWsgQRPWYp9MmEg1YSlAck0BIpKnPtq+ntpYKZ+990Um3OxDeAHqK/wayCxb4i4GQYCoBpJ7ChCRPFVXWcrH37Sel/3JgadrwiopLqKuonTWPdUXg7jfB6IaSO4pQETy2I2Xr04Fx+lqIAANlaX0LvLJhImRcYoMYqX6eMs1fYdF8listJgvvfM1rK0rYmXjzAspBrItqPjwS0f4q3tfzFUR5118ZJyqshLMtJBirilARPLc752/jC9cXkF5yennRTRWlk3rA3loZzc/2nGInkWy0GL6GmCSWwoQEUmpryyb1gcSzCXZcbAv25ecla0vHeFDd++Y83lmMzg6QZUmEUZCASIiKdkWVOzq8wPk1bkHyKN7evj5y0c5NZy7fpb4yLg60COiABGRlKkLKo5NJFN7hDx3sHfO5+/0w6h7IHfNYWrCio4CRERSpi6oeGRgmKSD5ppyXjp8cs4r9QbNYbkMkLgCJDIKEBFJmbqgYlBjeMdFyxlPOl441B/63MmkSzWHdftBkguJUTVhRUUBIiIpUxdUDGoM77hoOTC3Zqzj8RFGJ7x9SXLbhDVBZZk60aOgABGRlKkLKgY1ho0tNWxorp7TSKxDfZO1ju6B3NVA1IkeHQWIiKRMXVCxq3+Q5ppyYqXFbF7TwK8O9pFMulDnDmoz1eUlOauBjE0kGR1Pqg8kIgoQEUmZuqBiV/9QahXf169u5OTwOPt64qHO3dk3CMDFq+pzFiCDwV4gCpBIKEBEJGXqgopdfUOptbQ2r24AYEfIfpCuviEaKktZt7SaIzkKkPiodiOMkgJERDI0VHqTCZNJx+H+4VQNZPWSSpqqy3gu5ITCzr4hVjRU0loXIz4ynpPJhFrKPVoKEBHJ0FBVRt/gKMf8UVMr/BqImfH61Q2hO9K7+r3aTKt/vlw0Y8UVIJFSgIhIhmBBxWAOSPpOhptXN/Kb3kGOnRo5q3M65+jsG2RFQwWtdTEgNwGSqoFoP/RIKEBEJEOwoGIwaqqtfnIZ+Ava6gDY7W9SdaZ6E6MMjyVpSw+QHEwmnGzCUh9IFBQgIpIhWFCxK0sNZGNLDQB7j5w6q3MGtZkVDZU018Qwy1UNRLsRRkkBIiIZggUV9x+LU1dRmvFh3FBVxrLacnYfObsayGRtpoKykiKaqsunTSYcmIedEBOj6gOJkgJERDIECyru6hrIuo/6xpZa9nSfbQ3EmwMS1GaW18UyaiCvHE9w8d9t5VuPdYQtNjDZia4aSDQUICKSIZiNvq8nnnUf9Y2tNXT0xBnz17U6E119Q9TESqjzJyq21MUy5oL8Yt8xkg6+8vBeHtrZHbrsiZFxiouM8hJ9tEVB32URyRAsqDiRdBn9H4GNLTWMTiR59XjijM8ZzAEJtNZVZNRAth84QUttjItX1fPpH7/Azs6BUGVPjExQVVas/dAjogARkQzBgorAjE1YALvPoiM9mAMSSJ9M6JzjmVd6uWLdEm67cTONlWXccvezHA2xB7sWUoyWAkREMgRNWEDWJqx1S6spKTL2nOFQXm8OyFDGudInE+4/Fud4fJRL1zaytKacO/74DRw7NcIPtx8867InRsapVIBERgEiIhmCBRUhcw5IoKykiPXN1Wc8lPfk0DjxkfHMAEmbTLj9gLe21qXnLAFgU2stLbWx1NDfdLf/4gCf+c9fz/heidEJjcCKkAJERDIECyoCWftAAM5rqWHPGQbIIX8EVtYA6R9K9X+sXpLWR1JfkXWeyKN7evjfXx9mYoYl5RMj41pIMUIKEBGZpqGylIrSYhoqS7Me39hSS1f/EANDp5+7kW1GezCZ8PDAME+/0sulaxszOr5b62JZN53q6h9iZDyZmuQ4VWJkXMuYREgBIiLTNFSV0dZQMeNopo2tZz4jfXIW+mQNJJhMuH3/CY6dGkk1XwWW+zUQ5yZrGsmko7vfq5Xs68n+vupEj5YCRESmuWHLKm66cs2Mxzf5I7H2nsGM9K6+ISrLiqmfUptZXhfjmVf9/o+1jRnHWutijIwnUxtbARxPTO6pPtOmVomRcfWBREjfaRGZ5r2bV856fFltOXUVpWc0lPdQ3yBt9dNrMy11MX7dOcDSmnLWNlVlHEvvZF9SXQ6Q0Wy17+hMAaJO9CipBiIiZ83M2NhSc0ZDefcfi7N2adW051vrvCatS89pnBYuwbHDaSv2Hvabr5qqy+nI0oQ1Op5kdCJJVZk60aOiABGRUDa11rL3yCmSM4yIAu9D/eCJQdY3V087FtQyLl27ZPqxeu/YkbTJhF393miuN57bREdPPKN/BGBQCylGTgEiIqFsbKkhMTqRGmWVzcETCSaSLmuAnNtSQ0mR8Tvrm6Yda6oqp7TYUrUO8GogNeUlXLKqgcToxLRhvlpIMXoKEBEJ5fzlXkf6c7Nscbv/mNdXsX5pzbRj7ecuZfvn38KapunNW0VFRsuUobxd/UMsr69ggx9GUzvSg71AVAOJjgJEREK5YHkdzTXl/GzXkRlf0+F/yK9rnh4SZkaT30GeTWttRWrYLnid6MvrY2xY5oXRvqOZ/SBx7UYYOQWIiIRSVGRce0ELj+3tSW0lO1VHT5y2+goqQ0zua62PcTitBnJ4YIi2hgoaq8porCpLhVMgoSasyClARCS0ay9sZWQ8yWN7e7Ie75hhBNaZaK2r4OjJYZJJR2JknP7BMZb7izCub66eMUDUhBUdBYiIhPaGNY00VZfz0M7pzVjJpGN/TyJrB/qZWF4fY2zCcTwxkhrOGywJv6G5mn1TRmKlmrC0lElkFCAiElpxkXHNBct4dE8PQ6MTGccODwwxNDYROkCCuSDd/cMZe6qDVwMZGBrjWHwk9frB0aATXX0gUVGAiMicXHdhK0NjE2yb0owVNDGtXxo2QILZ6EOp4bzLUzUQryO9I21GelxNWJFTgIjInGxZ08iSqjIenDIaKxUgoWsgXoAc7h+mq3+Q4iKjucYbtbVh2fShvImRcUq0H3qk9J0WkTkpKS7i6te08MjuowyPTTZj7T8Wp6GyNLWW1dlqrCqjvKQoVQNpqY1RUux9ZDXXlFMTK8noSA8WUtR+6NFRgIjInL3twlYGRzObsTp64qFrH+DNE/H2BRmetqe6mbG+uTpjWff4yISG8EZMASIic3bZ2kZa62Lc8eQrqZFR+4+FH4EVaK3z9gUJJhGm2zBlKK9XA1EHepQUICIyZyXFRfxZ+zqefbWPXx44QW9ilN7EKOtCdqAHWutjdPYNcuTk8LTtdTe11nI8Pkqnv2VuYnQ81IRFCS9nAWJmd5pZj5ntmuG4mdk3zazDzF40s0tyVRYRyb33bl5Jc00533xkX9oSJnOtgcQ4enKEiaRLjcAKXLHOW4TxqY7jQLAfugIkSrmsgXwfuGaW49cCG/w/HwZuzWFZRCTHYqXFfOR317H9QC/3PPMbIPwQ3kAwFwSYFiDnLqtmaU05T3acAILNpNSEFaWcBYhz7gmgd5aXXA/c7TzbgXoza81VeUQk927Ysoqm6nL+6/kuKkqLMzq+w0jv91gx5VxmxlXrm3iq4zjJpCOu7Wwjt5Df7TbgUNrjTv+57qkvNLMP49VSWLZsGdu2bQv9pvF4fE5fv5gV8rVDYV9/lNf+ljbHj/ZCc4XjiScen9O5uk4lU//u2LmDrt2ZQ3SbxsfoTYzygwcepT8xzMDxo1mvU/d+W07OvZABkm2wdtatzZxztwG3AWzevNm1t7eHftNt27Yxl69fzAr52qGwrz/Ka99yxTiP/NM2Lju3mfb2187pXAODY/zNU1upqyjl2re+adrxjQPDfHfnIwzXrWE0uZdz166mvX3jtNfp3rfn5NwLGSCdwMq0xyuAwwtUFhGZJ5VlJTz4iauomIe9yWsrSmZtCmupi7GhuZpH9/QwNuHUiR6xhRzGez/wAX801mXAgHNuWvOViCw+zbUxamKlcz6PmbGmqYpzsuxaGLhqQxPPvup1t1bNQ2jJmctZXJvZPUA70GRmncAXgVIA59x3gAeB64AOYBC4KVdlEZHF67YbX0+sdOZguGp9E9976lUAKlUDiVTOvtvOuRtOc9wBH8vV+4tIfljZWDnr8UvXLqGkyBhPqgkrapqJLiKLWnV5CZesagC0lHvUFCAisuhdud6blV6tiYSRUlyLyKL37ovb2HGwlw3Laha6KAVFASIii96qJZX84OZLF7oYBUdNWCIiEooCREREQlGAiIhIKAoQEREJRQEiIiKhKEBERCQUBYiIiISiABERkVAUICIiEooCREREQlGAiIhIKAoQEREJRQEiIiKhKEBERCQU83aWXTzM7BhwcA6naAKOz1NxFptCvnYo7Osv5GuHwr7+MNe+2jm39HQvWnQBMldmtsM5t3mhy7EQCvnaobCvv5CvHQr7+nN57WrCEhGRUBQgIiISSiEGyG0LXYAFVMjXDoV9/YV87VDY15+zay+4PhAREZkfhVgDERGReaAAERGRUAomQMzsGjPba2YdZva5hS5PrpnZSjN7zMx2m9lLZvZJ//lGM/u5me3z/25Y6LLmipkVm9nzZvaA//gcM3vav/YfmVnZQpcxV8ys3szuNbM9/s/A5YVy783s0/7P/C4zu8fMYvl8783sTjPrMbNdac9lvdfm+ab/OfiimV0yl/cuiAAxs2LgW8C1wPnADWZ2/sKWKufGgb9wzm0CLgM+5l/z54BHnHMbgEf8x/nqk8DutMf/CHzdv/Y+4OYFKVU0/hn4mXNuI3AR3vch7++9mbUBnwA2O+cuAIqB95Hf9/77wDVTnpvpXl8LbPD/fBi4dS5vXBABAmwBOpxzB5xzo8B/ANcvcJlyyjnX7Zz7lf/vU3gfIG14132X/7K7gHctTAlzy8xWAG8DbvcfG/Bm4F7/Jfl87bXAG4E7AJxzo865fgrk3gMlQIWZlQCVQDd5fO+dc08AvVOenuleXw/c7TzbgXozaw373oUSIG3AobTHnf5zBcHM1gAXA08Dy5xz3eCFDNC8cCXLqW8AnwWS/uMlQL9zbtx/nM8/A2uBY8D3/Ca8282sigK49865LuCrwG/wgmMAeI7CufeBme71vH4WFkqAWJbnCmL8splVAz8BPuWcO7nQ5YmCmb0d6HHOPZf+dJaX5uvPQAlwCXCrc+5iIEEeNldl47f1Xw+cAywHqvCababK13t/OvP6e1AoAdIJrEx7vAI4vEBliYyZleKFxw+dc/f5Tx8Nqqz+3z0LVb4cuhJ4p5m9itdc+Wa8Gkm936wB+f0z0Al0Ouee9h/fixcohXDv3wq84pw75pwbA+4DrqBw7n1gpns9r5+FhRIgzwIb/JEYZXidavcvcJlyym/zvwPY7Zz7Wtqh+4EP+v/+IPA/UZct15xzf+2cW+GcW4N3rx91zr0feAx4j/+yvLx2AOfcEeCQmZ3nP/UW4GUK4N7jNV1dZmaV/u9AcO0Fce/TzHSv7wc+4I/GugwYCJq6wiiYmehmdh3e/0KLgTudc3+/wEXKKTO7CvgFsJPJfoDP4/WD/BhYhffL9vvOuakdcHnDzNqBzzjn3m5ma/FqJI3A88AfOedGFrJ8uWJmr8MbQFAGHABuwvsPY97fezP7W+AP8EYiPg/cgtfOn5f33szuAdrxlm0/CnwR+G+y3Gs/VP8Fb9TWIHCTc25H6PculAAREZH5VShNWCIiMs8UICIiEooCREREQlGAiIhIKAoQEREJpeT0LxFZ3MxsCd6CcgAtwATeUh8Ag865K+b5/SqB7wKvxZv52483bLIE+EPn3Lfn8/2mvPeXgLhz7qu5eg+RgAJE8p5z7gTwOojsA/aTwFHn3IX+e54HjOGN0/8okLMAEYmSmrCkoJlZ3P+73cweN7Mfm9n/mdmXzez9ZvaMme00s3X+65aa2U/M7Fn/z5VZTtsKdAUPnHN7/UlrXwbWmdkLZvYV/3x/6Z/nRX8CHGa2xt/H4y7/+Xv9Wg1+uV72n581BM3sQ2b2kJlVzMf3SmQq1UBEJl0EbMJbGvsAcLtzbot5m3H9OfApvH02vu6ce9LMVgEP+1+T7k5gq5m9B6/p7C7n3D68BQ0vcM4FtaGr8fZl2ILX1HW/mb0Rb+bwecDNzrmnzOxO4KP+3+8GNjrnnJnVz3QhZvZx4GrgXfky41p++yhARCY9G6wLZGb7ga3+8zuBN/n/fitwvrciBAC1Zlbj77kCgHPuBX/ZlKv91z9rZpcDQ1Pe72r/z/P+42q8QPkNcMg595T//L/hbZL0DWAYuN3Mfgo8MMN13Ii3aN67/AUFRXJCASIyKf1/6sm0x0kmf1eKgMudc1PDIINzLo63Eux9ZpYErsNbGTmdAf/gnPvXjCe9/VumrjHknHPjZrYFb4HA9wEfx1tpeKpdeH0+K4BXZiunyFyoD0Tk7GzF++AGUosWZjCzK9P2oC7D20b5IHAKqEl76cPAn/h7tmBmbWYWbPyzyq+1ANwAPOm/rs459yBec9q09/Y9D/wpXpPY8nCXKXJ6ChCRs/MJYLPfif0y8JEsr1kHPG5mO/E+zHcAP/FHgz1lZrvM7CvOua3AvwO/9F97L5MBsxv4oJm9iLeC7K3+sQf85x4HPj1TIZ1zTwKfAX5qZk1zv2yR6bQar8hvGb8J6wHn3AULXBSRWakGIiIioagGIiIioagGIiIioShAREQkFAWIiIiEogAREZFQFCAiIhLK/wOColbT80QnzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I = rnd.randint(0,DATA.shape[0],10)\n",
    "\n",
    "for ind in I:\n",
    "    td = DATA[ind,:]+0*rnd.randn(DATA.shape[1])\n",
    "    tl = LABELS[ind,:]\n",
    "    class_sugg, pred_struct = D.decode(td)\n",
    "    \n",
    "    plt.figure(ind, figsize=(6, 6))\n",
    "    ax = plt.axes([0.1, 0.1, 0.8, 0.8])\n",
    "    \n",
    "    plt.plot(td)\n",
    "    plt.title('Real label: '+str(tl)+', pred. label: '+str(class_sugg))\n",
    "    plt.grid()\n",
    "    plt.xlabel('Time Steps k')\n",
    "    plt.ylabel('Amplitude h[k]')\n",
    "    #plt.show()\n",
    "    \n",
    "    savestr = 'plot_dec_data_'+str(ind)+'.png'\n",
    "    plt.savefig(savestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
