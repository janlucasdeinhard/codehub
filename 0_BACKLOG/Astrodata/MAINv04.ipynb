{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime,os,warnings,csv,calendar\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Input,Dense,LSTM,advanced_activations,Dropout,BatchNormalization,concatenate,Reshape,Embedding,Conv2D,MaxPool2D,Flatten\n",
    "from keras.wrappers.scikit_learn import KerasClassifier,KerasRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import roc_curve,auc,confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
    "from sklearn.cluster import KMeans,MeanShift\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor,NearestNeighbors\n",
    "\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pickle,h5py\n",
    "\n",
    "sns.set()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pickle.load(open('..\\\\..\\\\TF_data\\\\KEPLER\\\\DATA_train.p','rb'))\n",
    "data_test = pickle.load(open('..\\\\..\\\\TF_data\\\\KEPLER\\\\DATA_test.p','rb'))\n",
    "\n",
    "labels_train = pickle.load(open('..\\\\..\\\\TF_data\\\\KEPLER\\\\LABELS_train.p','rb'))-1\n",
    "labels_test = pickle.load(open('..\\\\..\\\\TF_data\\\\KEPLER\\\\LABELS_test.p','rb'))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.abs(data_train)\n",
    "data_test = np.abs(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = train_test_split(data_train,labels_train,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = pp.StandardScaler()\n",
    "\n",
    "Xtrain = standard_scaler.fit_transform(Xtrain)\n",
    "Xtest = standard_scaler.fit_transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE()\n",
    "Xtrain,ytrain = smt.fit_resample(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "in0 = Input(shape=(Xtrain.shape[1],))\n",
    "\n",
    "x = Dense(units=1000,activation='tanh')(in0)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(units=10,activation='tanh')(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "out0 = Dense(units=1,activation='sigmoid')(x)\n",
    "\n",
    "model0 = Model(in0,out0)\n",
    "model0.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n",
    "#model0.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7268 samples, validate on 808 samples\n",
      "Epoch 1/5\n",
      "7268/7268 [==============================] - 354s 49ms/step - loss: 0.2484 - acc: 0.5453 - val_loss: 0.2865 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "7268/7268 [==============================] - 319s 44ms/step - loss: 0.2478 - acc: 0.5517 - val_loss: 0.4354 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "7268/7268 [==============================] - 323s 44ms/step - loss: 0.2476 - acc: 0.5545 - val_loss: 0.3273 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "7268/7268 [==============================] - 312s 43ms/step - loss: 0.2474 - acc: 0.5537 - val_loss: 0.2946 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "7268/7268 [==============================] - 322s 44ms/step - loss: 0.2475 - acc: 0.5543 - val_loss: 0.3038 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21db335dc88>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.fit(Xtrain,ytrain,batch_size=3,epochs=5,validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
